[
  {
    "start": 250,
    "end": 1854,
    "text": "やあ、みんな。"
  },
  {
    "start": 1892,
    "end": 5642,
    "text": "今日はPytorchを使ったモデルの分散学習についてお話します。"
  },
  {
    "start": 5706,
    "end": 6574,
    "text": "どういう意味かって？"
  },
  {
    "start": 6692,
    "end": 24462,
    "text": "例えば、非常に大きなモデルがあって、そのモデルをトレーニングするためのデータがたくさんある。"
  },
  {
    "start": 24596,
    "end": 33090,
    "text": "ひとつの方法は、複数のGPU、あるいは1つのGPUを持つ複数のコンピューターを使ってトレーニングを並列化することだ。"
  },
  {
    "start": 33250,
    "end": 57582,
    "text": "このビデオでは、分散トレーニングがどのように機能するのか、どのように既存のプロジェクトに統合するのか、理論と実践を組み合わせてお見せします。つまり、分散トレーニングの背後にあるすべての理論をお伝えし、モデルのクラウドトレーニングを行うためのクラウドインフラストラクチャをまず構築する方法と、すでに構築済みの既存のモデルに分散トレーニングを統合する方法をお見せします。"
  },
  {
    "start": 57636,
    "end": 60074,
    "text": "すでにシングルGPUでトレーニングしているのかもしれない。"
  },
  {
    "start": 60202,
    "end": 62142,
    "text": "今日のトピックをおさらいしよう。"
  },
  {
    "start": 62276,
    "end": 67026,
    "text": "まず、分散型トレーニングについて紹介し、2つの方法を紹介する。"
  },
  {
    "start": 67048,
    "end": 69870,
    "text": "ひとつはデータ並列性、もうひとつはモデル並列性である。"
  },
  {
    "start": 69950,
    "end": 72510,
    "text": "このビデオでは、データ並列処理について説明する。"
  },
  {
    "start": 72670,
    "end": 81302,
    "text": "ニューラル・ネットワークの理論を少し見てみよう。勾配累積と呼ばれる概念を紹介したいのだが、これは分散学習にとって非常に重要だ。"
  },
  {
    "start": 81436,
    "end": 85186,
    "text": "後ほど、Pytorchで構築されている分散トレーニングを見てみよう。"
  },
  {
    "start": 85218,
    "end": 87650,
    "text": "分散データ・パラレルだ。"
  },
  {
    "start": 87810,
    "end": 89142,
    "text": "どうなるか見てみよう。"
  },
  {
    "start": 89196,
    "end": 100074,
    "text": "コミュニケーション・プリミティブの意味も説明しよう。all reduce、reduce、broadcast、all gatherなどの言葉は聞いたことがあるかもしれないが、それが何なのか、どのように機能するのかは知らないだろう。"
  },
  {
    "start": 100112,
    "end": 105450,
    "text": "このビデオでは、これらの操作の基礎となるアルゴリズムと、それらがどのように機能するかを紹介する。"
  },
  {
    "start": 105520,
    "end": 109898,
    "text": "分散トレーニングについて話すときには、ノードのフェイルオーバーを管理する方法も紹介する。"
  },
  {
    "start": 109914,
    "end": 113386,
    "text": "複数のノードでトレーニングをしていて、あるノードが突然死んだとする。"
  },
  {
    "start": 113498,
    "end": 117306,
    "text": "この状況をどのように管理するか、ちょっとしたコーディング・セッションをやってみよう。"
  },
  {
    "start": 117338,
    "end": 123538,
    "text": "私はコードを書かない。既存のコードを使い、分散学習を既存のモデルに追加する方法を紹介するだけだ。"
  },
  {
    "start": 123704,
    "end": 126562,
    "text": "以前のビデオで作ったモデルを使います。"
  },
  {
    "start": 126616,
    "end": 130930,
    "text": "トランスフォーマーのモデルをゼロからコーディングする方法についてのビデオだ。"
  },
  {
    "start": 131010,
    "end": 133606,
    "text": "もし、すでに私の前回のビデオを見ているなら、その方法を教えてあげよう。"
  },
  {
    "start": 133628,
    "end": 134370,
    "text": "素晴らしいよ。"
  },
  {
    "start": 134450,
    "end": 143098,
    "text": "というのも、今日私が教える知識は、私が書いたものだけでなく、あなたが作ったどんなモデルにも適用できるからだ。"
  },
  {
    "start": 143264,
    "end": 149770,
    "text": "また、Pytorchが分散トレーニングを行う基本的なメカニズムも紹介する。"
  },
  {
    "start": 149840,
    "end": 158942,
    "text": "今回は、分散トレーニングのPytorch実装で最適化された、計算通信のオーバーラップとバケッティングについて紹介する。"
  },
  {
    "start": 158996,
    "end": 161098,
    "text": "だから、我々はこれらすべてのトピックを探求していく。"
  },
  {
    "start": 161274,
    "end": 163050,
    "text": "さあ、旅を始めよう。"
  },
  {
    "start": 163210,
    "end": 166480,
    "text": "まず、分散型トレーニングとは何かを紹介しよう。"
  },
  {
    "start": 167030,
    "end": 172990,
    "text": "例えばウィキペディアの全コンテンツのような、非常に大きなデータセットで言語モデルを学習させたいとする。"
  },
  {
    "start": 173070,
    "end": 179906,
    "text": "データセットは何百万もの記事で構成され、各記事には何千ものトークンがある。"
  },
  {
    "start": 180098,
    "end": 184690,
    "text": "このモデルをシングルGPUでトレーニングすることは可能かもしれないが、いくつかの課題がある。"
  },
  {
    "start": 184770,
    "end": 188066,
    "text": "まず第一に、このモデルはシングルGPUに収まらないかもしれない。"
  },
  {
    "start": 188178,
    "end": 190646,
    "text": "これはモデルに多くのパラメータがある場合に起こる。"
  },
  {
    "start": 190758,
    "end": 193238,
    "text": "例えば、最新のラマでもこのようなことが起きている。"
  },
  {
    "start": 193334,
    "end": 194710,
    "text": "彼らは何十億ものパラメーターを持っている。"
  },
  {
    "start": 194790,
    "end": 199980,
    "text": "これだけ多くのパラメーターを使うと、GPUのラムでは足りないかもしれない。"
  },
  {
    "start": 200750,
    "end": 208826,
    "text": "あるいは、バッチサイズを大きくするとcudaのメモリ不足エラーにつながるため、小さなバッチサイズを使わざるを得ない。"
  },
  {
    "start": 208938,
    "end": 213070,
    "text": "あるいは、データセットが非常に大きいため、モデルの訓練に何年もかかるかもしれない。"
  },
  {
    "start": 213220,
    "end": 217090,
    "text": "上記のポイントのいずれかが当てはまるなら、トレーニングの規模を拡大する必要がある。"
  },
  {
    "start": 217160,
    "end": 220430,
    "text": "セットアップとスケーリングは縦でも横でも可能。"
  },
  {
    "start": 220510,
    "end": 222020,
    "text": "この2つの選択肢を比較してみよう。"
  },
  {
    "start": 222950,
    "end": 231250,
    "text": "垂直スケーリングとは、1台のマシン、例えば、ラムを搭載したGPUを1台用意し、GPUに4ギガバイトなどのメモリを搭載することです。"
  },
  {
    "start": 231330,
    "end": 237410,
    "text": "垂直スケーリングとは、より大きなコンピューターか、より大きなGPUを買うということだ。"
  },
  {
    "start": 237570,
    "end": 241750,
    "text": "既存のマシンを使い、ハードウェアをアップグレードする。"
  },
  {
    "start": 242410,
    "end": 247814,
    "text": "なぜなら、小さなマシンで動いていたコードは大きなマシンでも動くからだ。"
  },
  {
    "start": 247862,
    "end": 250054,
    "text": "ただ、パラメーターを少し調整する必要があるかもしれない。"
  },
  {
    "start": 250102,
    "end": 251502,
    "text": "多分、バッチサイズを大きくできるだろう。"
  },
  {
    "start": 251556,
    "end": 263578,
    "text": "水平スケーリングでは、1台のマシンから複数のマシンになり、それぞれが相互に接続され、並列化トレーニングのために通信する。"
  },
  {
    "start": 263764,
    "end": 269522,
    "text": "各マシンは1つまたは複数のGPUを持つ可能性があり、その場合はコードの変更が必要になる。"
  },
  {
    "start": 269576,
    "end": 275978,
    "text": "Pytorchとその分散データパラレルの実装のおかげで、このコード変更は最小限に抑えられている。"
  },
  {
    "start": 276174,
    "end": 279666,
    "text": "このビデオでは、水平方向のスケーリングについて説明する。"
  },
  {
    "start": 279778,
    "end": 284120,
    "text": "バーチカル・スケーリングは、基本的に何もする必要がなく、コードの変更もない。"
  },
  {
    "start": 284490,
    "end": 289350,
    "text": "モデルのトレーニングを分配する方法は2つある。"
  },
  {
    "start": 289420,
    "end": 292182,
    "text": "一つはデータ並列と呼ばれるもので、もう一つはモデル並列と呼ばれるものだ。"
  },
  {
    "start": 292246,
    "end": 309114,
    "text": "つまり、モデルが1つのGPUに収まるのであれば、複数のサーバーに学習を分散させ、それぞれが1つ以上のGPUを持ち、各GPUがデータ全体のサブセットを並列処理し、バックプロパゲーション中の勾配を同期させることができる。"
  },
  {
    "start": 309242,
    "end": 312218,
    "text": "このテクニックはデータ並列性として知られている。"
  },
  {
    "start": 312394,
    "end": 317298,
    "text": "我々は1つのGPUに収まる1つのモデルを持っており、多くのデータを持っている。"
  },
  {
    "start": 317384,
    "end": 328920,
    "text": "私たちが行っているのは、基本的にこのデータを部分集合に分割し、複数のコンピューターで並列にトレーニングすることです。"
  },
  {
    "start": 329290,
    "end": 342886,
    "text": "しかし、モデルが1つのgpuに収まらない場合は、モデルをより小さな断片、より小さなレイヤーに分割し、各gpuが放射降下中の前方ステップと後方ステップの一部を処理する必要がある。"
  },
  {
    "start": 342998,
    "end": 345590,
    "text": "このオプションはモデル並列性として知られている。"
  },
  {
    "start": 345670,
    "end": 355920,
    "text": "つまり、このモデルの初期モデルは1つのGPUに収まらないので、レイヤーに分割し、各コンピューターがモデル全体ではなく、レイヤーを管理するとします。"
  },
  {
    "start": 356610,
    "end": 362046,
    "text": "もちろん、データ並列とモデル並列を組み合わせて、ハイブリッドなオプションを作ることもできる。"
  },
  {
    "start": 362228,
    "end": 365354,
    "text": "このビデオでは、データ並列性に焦点を当てる。"
  },
  {
    "start": 365402,
    "end": 370782,
    "text": "私たちは、複雑なモデルを持っているふりをするが、それは単一のGPUに収まる。"
  },
  {
    "start": 370846,
    "end": 375650,
    "text": "たくさんのトレーニングデータがあるんだけど、1台のコンピューターでそれをトレーニングするのは本当に時間がかかるんだ。"
  },
  {
    "start": 375720,
    "end": 384280,
    "text": "各GPUがデータのサブセットでトレーニングするように、このトレーニングを複数のコンピューターまたは複数のGPUに分散させたい。"
  },
  {
    "start": 385450,
    "end": 392010,
    "text": "さて、勾配累積と呼ばれる概念を紹介する必要があるので、ニューラルネットワークを少し復習する必要がある。"
  },
  {
    "start": 392670,
    "end": 401098,
    "text": "さて、ある家の寝室数という2つの変数から、家の価格を予測するニューラルネットワークを学習させたいとする。"
  },
  {
    "start": 401184,
    "end": 407440,
    "text": "この変数をx1と呼び、家の中のバスルームの数をx2と呼ぶことにする。"
  },
  {
    "start": 407890,
    "end": 414886,
    "text": "私たちは直感的に、入力変数と出力変数の関係は線形であると考える。"
  },
  {
    "start": 415018,
    "end": 424718,
    "text": "予測価格は、x1に1番目のウェイトを掛け、x2に2番目のウェイトを掛け、バイアス項を加えたものに等しいと書くことができる。"
  },
  {
    "start": 424894,
    "end": 445382,
    "text": "我々の目標は、確率的勾配降下法を用いて、実際の住宅価格と予測住宅価格との間の平均二乗誤差損失が最小になるようなパラメータw1、w2、バイアスの値を見つけることである。"
  },
  {
    "start": 445446,
    "end": 452646,
    "text": "ここで、Pytorchで勾配を累積せずにトレーニングループを行うにはどうすればいいのだろうか？"
  },
  {
    "start": 452758,
    "end": 456634,
    "text": "そこでまず、数エポック分のトレーニングを実行する。"
  },
  {
    "start": 456762,
    "end": 461918,
    "text": "x1、x2、そして目標価格からなる学習データを取る。"
  },
  {
    "start": 462084,
    "end": 472030,
    "text": "このモデルの出力は、基本的に、x1にw1を掛けたものに、x2にw2を掛けたものにバイアスを加えたものである。"
  },
  {
    "start": 472190,
    "end": 473614,
    "text": "そして損失を計算する。"
  },
  {
    "start": 473662,
    "end": 475294,
    "text": "私たちは敗戦に後ろ向きだ。"
  },
  {
    "start": 475342,
    "end": 484242,
    "text": "これにより、各パラメータに対する損失関数の勾配が計算され、計算した勾配を使ってパラメータが更新される。"
  },
  {
    "start": 484386,
    "end": 489782,
    "text": "私はオプティマイザーを使っておらず、更新ルールを手で書いているだけだ。"
  },
  {
    "start": 489836,
    "end": 493930,
    "text": "シンプルにするために、運動量は使わない。"
  },
  {
    "start": 494270,
    "end": 497274,
    "text": "これがトレーニングのループなんだろ？"
  },
  {
    "start": 497312,
    "end": 503822,
    "text": "この部分はオプティマイザー・スナップを呼び出すのと同じで、この部分はオプティマイザー・ゼロを呼び出すのと同じである。"
  },
  {
    "start": 503956,
    "end": 505770,
    "text": "図で見てみよう。"
  },
  {
    "start": 505850,
    "end": 508222,
    "text": "このようにトレーニングをループさせるとどうなるか。"
  },
  {
    "start": 508276,
    "end": 512846,
    "text": "を表す式ができたとしよう。"
  },
  {
    "start": 512948,
    "end": 516370,
    "text": "この場合は非常にシンプルな表現だが、非常に複雑なモデルを想像してほしい。"
  },
  {
    "start": 516440,
    "end": 521102,
    "text": "Pytorchは計算グラフを作成する。"
  },
  {
    "start": 521246,
    "end": 523150,
    "text": "私たちの意見が必要だ。"
  },
  {
    "start": 523230,
    "end": 528898,
    "text": "各入力にはそれぞれ重みがあり、w個のパラメーターが掛け合わされる。"
  },
  {
    "start": 529074,
    "end": 533074,
    "text": "そして、その2つの合計とバイアス項を組み合わせる。"
  },
  {
    "start": 533122,
    "end": 534610,
    "text": "これで出力が得られる。"
  },
  {
    "start": 534690,
    "end": 536290,
    "text": "それなら目標がある。"
  },
  {
    "start": 536450,
    "end": 540410,
    "text": "目標は出力と比較され、損失が生じる。"
  },
  {
    "start": 540750,
    "end": 547206,
    "text": "その後、逆伝播法を実行し、目標に対する損失関数の勾配を計算する。"
  },
  {
    "start": 547238,
    "end": 552490,
    "text": "計算グラフを使って、トレーニングの過程を1項目ずつ可視化してみよう。"
  },
  {
    "start": 553630,
    "end": 560542,
    "text": "入力x1は6、x2は2、ターゲットは15でトレーニングしているとしよう。"
  },
  {
    "start": 560676,
    "end": 564698,
    "text": "このモデルが最初に行うことは、2つの入力ノードからスタートすることだ。"
  },
  {
    "start": 564714,
    "end": 565726,
    "text": "x1とx2だ。"
  },
  {
    "start": 565748,
    "end": 568542,
    "text": "wのウェイトが掛けられる。"
  },
  {
    "start": 568686,
    "end": 573038,
    "text": "また、w個のウェイトは以下の値で初期化されていると考えられる。"
  },
  {
    "start": 573054,
    "end": 580678,
    "text": "このウエイトの値はゼロポイント73、このウエイトは0.3対1、このウエイトはゼロポイント67である。"
  },
  {
    "start": 580844,
    "end": 585366,
    "text": "これらの値は、通常行っているように、ランダムに生成することもできる。"
  },
  {
    "start": 585388,
    "end": 592682,
    "text": "実際、Pytorchはこのノードの出力を生成し、xの値にwの値を乗算する。"
  },
  {
    "start": 592736,
    "end": 597258,
    "text": "そして、この2つを組み合わせて、モデルの出力を生成する。"
  },
  {
    "start": 597424,
    "end": 602582,
    "text": "この数値は目標値と比較され、損失が算出される。"
  },
  {
    "start": 602656,
    "end": 604938,
    "text": "勾配を計算することができる。"
  },
  {
    "start": 605114,
    "end": 611674,
    "text": "ここで通常、各パラメータに対する損失関数の勾配を計算するために、損失バックワードと呼ぶ。"
  },
  {
    "start": 611722,
    "end": 613694,
    "text": "W1、W2、B。"
  },
  {
    "start": 613812,
    "end": 619070,
    "text": "Pytorchは中間ノードも計算するが、ここでは簡単のため省略する。"
  },
  {
    "start": 619230,
    "end": 621070,
    "text": "我々はロスを逆算する。"
  },
  {
    "start": 621150,
    "end": 623026,
    "text": "後方での損失はどうなるのか？"
  },
  {
    "start": 623048,
    "end": 628030,
    "text": "各重みに対する損失関数の勾配を計算する。"
  },
  {
    "start": 628110,
    "end": 629558,
    "text": "どうやっているのか？"
  },
  {
    "start": 629724,
    "end": 637880,
    "text": "さて、最初にすることは、出力に対する損失関数の勾配を計算することだ。"
  },
  {
    "start": 638910,
    "end": 644246,
    "text": "そして、このノードに対する出力の勾配を計算する。"
  },
  {
    "start": 644438,
    "end": 651782,
    "text": "ここでは、w個のノードに対する損失関数の勾配の計算のみを示す。"
  },
  {
    "start": 651846,
    "end": 655166,
    "text": "他のものは、例えば運動のためにやってもいい。"
  },
  {
    "start": 655348,
    "end": 661354,
    "text": "次に、Z1ノードに対する損失関数の勾配を計算する。"
  },
  {
    "start": 661402,
    "end": 667886,
    "text": "そのためには、連鎖法則のため、z1ノードに対する出力の勾配が必要である。"
  },
  {
    "start": 668078,
    "end": 674274,
    "text": "そして、出力であるw1に対するz1ノードの勾配を計算する。"
  },
  {
    "start": 674312,
    "end": 678498,
    "text": "これにより、w1に対する損失関数の勾配を計算することができる。"
  },
  {
    "start": 678584,
    "end": 683414,
    "text": "以上が、このノードのグラデーションを得るために必要なすべての計算である。"
  },
  {
    "start": 683532,
    "end": 687666,
    "text": "おわかりのように、中間ノードの勾配も計算する必要がある。"
  },
  {
    "start": 687698,
    "end": 695210,
    "text": "我々は、パラメータに対する損失関数のパラメータの勾配を求めることだけに興味がある。"
  },
  {
    "start": 695790,
    "end": 701210,
    "text": "これらは、各パラメーターについて計算した勾配の値である。"
  },
  {
    "start": 701570,
    "end": 705998,
    "text": "トレーニングの次に行うのは、オプティマイザーのステップだ。"
  },
  {
    "start": 706084,
    "end": 711930,
    "text": "これにより、計算した勾配を使って各パラメーターの値が更新される。"
  },
  {
    "start": 712010,
    "end": 712926,
    "text": "どうやるのか？"
  },
  {
    "start": 712948,
    "end": 721838,
    "text": "パラメータの新しい値は、パラメータの古い値から学習率を引いた値に勾配を掛けたものに等しいと言う。"
  },
  {
    "start": 722014,
    "end": 722862,
    "text": "なぜマイナスなのか？"
  },
  {
    "start": 722926,
    "end": 727030,
    "text": "勾配は関数が最も成長する方向を示すからだ。"
  },
  {
    "start": 727100,
    "end": 732306,
    "text": "損失を最小限に抑えたいからだ。"
  },
  {
    "start": 732418,
    "end": 743020,
    "text": "ここでマイナス記号を付けると、前のステップで計算した勾配を使って値が更新される。"
  },
  {
    "start": 743950,
    "end": 748186,
    "text": "次にすることは、オプティマイザー・ゼロを実行することだ。"
  },
  {
    "start": 748288,
    "end": 754250,
    "text": "これは、各パラメータのすべての勾配と中間ノードをゼロにする。"
  },
  {
    "start": 754410,
    "end": 757994,
    "text": "そして、次の項目で次の反復を行う。"
  },
  {
    "start": 758042,
    "end": 760526,
    "text": "一度に1つの項目をトレーニングすることを想像してほしい。"
  },
  {
    "start": 760548,
    "end": 762080,
    "text": "バッチサイズは1つ。"
  },
  {
    "start": 762610,
    "end": 767650,
    "text": "次の項目は、x1が5、x2が2、ターゲットが12かもしれない。"
  },
  {
    "start": 767720,
    "end": 770814,
    "text": "これにより、このロスと出力が生まれる。"
  },
  {
    "start": 770942,
    "end": 774254,
    "text": "次にすることは、ロスを逆算することだ。"
  },
  {
    "start": 774382,
    "end": 775294,
    "text": "後方敗退。"
  },
  {
    "start": 775342,
    "end": 781480,
    "text": "各重みに対する損失関数の勾配を計算し、ここで勾配を見ることができる。"
  },
  {
    "start": 782330,
    "end": 791098,
    "text": "次のステップでは、オプティマイザ・ステップを実行し、前のステップで計算した勾配と学習率を用いてパラメータの値を更新する。"
  },
  {
    "start": 791264,
    "end": 796966,
    "text": "最後にオプティマイザー・ゼロを実行し、すべての重みの勾配をリセットする。"
  },
  {
    "start": 797158,
    "end": 801674,
    "text": "この過程を損失関数で可視化することもできる。"
  },
  {
    "start": 801712,
    "end": 805280,
    "text": "この処理をしている間、損失関数がどうなるかを見てみよう。"
  },
  {
    "start": 805810,
    "end": 808346,
    "text": "まずは最初のウエイトから始めた。"
  },
  {
    "start": 808378,
    "end": 812218,
    "text": "ランダムに初期化されたウェイト値からスタートしたことを思い出してほしい。"
  },
  {
    "start": 812394,
    "end": 815934,
    "text": "そして、最初のデータ項目で前進ステップを実行した。"
  },
  {
    "start": 816062,
    "end": 819742,
    "text": "これで出力を計算し、ロスを逆算する。"
  },
  {
    "start": 819806,
    "end": 825038,
    "text": "その結果、各重みに対する損失関数の勾配が計算された。"
  },
  {
    "start": 825214,
    "end": 837270,
    "text": "これは、損失を最小化するために重みを移動させるべき方向を示しており、勾配の方向に逆らって移動するため、矢印はすでに勾配の負の方向を指している。"
  },
  {
    "start": 838250,
    "end": 841002,
    "text": "次にすることは、オプティマイザーのステップだ。"
  },
  {
    "start": 841056,
    "end": 850170,
    "text": "オプティマイザー・ステップは、初期の重みを受け取り、勾配の負の方向に従って重みの値を変更する。"
  },
  {
    "start": 850750,
    "end": 852554,
    "text": "そして、オプティマイザー・ゼロを実行する。"
  },
  {
    "start": 852592,
    "end": 858350,
    "text": "これでグラデーションの値がリセットされ、次のデータに進む。"
  },
  {
    "start": 859010,
    "end": 867860,
    "text": "その結果、損失関数を最小化するために重みを移動させる方向を示す勾配が計算される。"
  },
  {
    "start": 868230,
    "end": 872290,
    "text": "その後、オプティマイザー・ステップを使って実際に重みを修正する。"
  },
  {
    "start": 872360,
    "end": 878598,
    "text": "パラメータ値の実際の更新は、オプティマイザー・ステップを呼び出したときに行われる。"
  },
  {
    "start": 878764,
    "end": 884918,
    "text": "最後にオプティマイザー・ゼロを実行し、勾配をゼロにリセットする。"
  },
  {
    "start": 885004,
    "end": 893242,
    "text": "これが勾配降下が累積なしで、各ステップでの勾配累積なしで機能する方法である。"
  },
  {
    "start": 893296,
    "end": 896954,
    "text": "なぜなら、ここではバッチ・サイズが1に等しいと仮定しているからだ。"
  },
  {
    "start": 896992,
    "end": 900220,
    "text": "ステップごとにモデルのパラメータを更新する。"
  },
  {
    "start": 901470,
    "end": 905182,
    "text": "しかし、グラディエント・アキュムレーションでは、すべてのステップで行うわけではない。"
  },
  {
    "start": 905236,
    "end": 906190,
    "text": "どう動くか見てみよう。"
  },
  {
    "start": 906260,
    "end": 910782,
    "text": "勾配累積によるトレーニング・ループの最初の部分は同じである。"
  },
  {
    "start": 910836,
    "end": 912506,
    "text": "私たちは数エポック走った。"
  },
  {
    "start": 912538,
    "end": 914730,
    "text": "トレーニングデータからデータを抽出する。"
  },
  {
    "start": 914820,
    "end": 916606,
    "text": "x1、x2、そしてターゲット。"
  },
  {
    "start": 916718,
    "end": 918770,
    "text": "以前と同じように損失を計算する。"
  },
  {
    "start": 918840,
    "end": 921586,
    "text": "以前と同じようにロスを逆算する。"
  },
  {
    "start": 921768,
    "end": 935602,
    "text": "ここでの違いは、モデルを学習させるアイテムごと、あるいはモデルを学習させるバッチごとにパラメーターの値を更新するのではなく、数アイテムごと、あるいは数バッチごとに更新する点である。"
  },
  {
    "start": 935746,
    "end": 939462,
    "text": "この場合は、このトレーニングループの中で行う。"
  },
  {
    "start": 939526,
    "end": 946300,
    "text": "トレーニングデータから一度に1つの項目を抽出するため、2項目ごとに行う。"
  },
  {
    "start": 946750,
    "end": 954238,
    "text": "したがって、この場合は2項目ごとに勾配を使ってパラメーターを更新する。"
  },
  {
    "start": 954404,
    "end": 961918,
    "text": "例えば、最初の項目が後方に失われた場合、このコードは実行されない。"
  },
  {
    "start": 962004,
    "end": 963454,
    "text": "ループを再開する。"
  },
  {
    "start": 963502,
    "end": 966078,
    "text": "次の項目では、出力を計算する。"
  },
  {
    "start": 966174,
    "end": 968046,
    "text": "私たちはまた後方へ迷いながら走る。"
  },
  {
    "start": 968158,
    "end": 972270,
    "text": "このロスト・バックは勾配を計算する。"
  },
  {
    "start": 972350,
    "end": 977590,
    "text": "この勾配は、前のステップで計算した勾配を置き換えるものではない。"
  },
  {
    "start": 977660,
    "end": 978994,
    "text": "それが蓄積されていく。"
  },
  {
    "start": 979042,
    "end": 981106,
    "text": "これは前のグラデーションと合計される。"
  },
  {
    "start": 981218,
    "end": 984200,
    "text": "このプロセスを段階的にイメージしてみよう。"
  },
  {
    "start": 984650,
    "end": 991130,
    "text": "最初の項目があり、これはx1が6、x2が2で、目標は15だとする。"
  },
  {
    "start": 991200,
    "end": 994810,
    "text": "この項目を使ってフォワードループを実行する。"
  },
  {
    "start": 995230,
    "end": 999894,
    "text": "その結果、出力が計算され、その目標値を使って損失を計算することができる。"
  },
  {
    "start": 1000022,
    "end": 1002202,
    "text": "そして、損失を逆算する。"
  },
  {
    "start": 1002346,
    "end": 1006190,
    "text": "これにより、この項目に対してグラデーションが計算される。"
  },
  {
    "start": 1007010,
    "end": 1011978,
    "text": "そしてパラメータは更新せず、次の項目でフォワード・ステップを行う。"
  },
  {
    "start": 1012074,
    "end": 1018226,
    "text": "この前進ステップでは、前のステップで勾配をゼロにしていないため、勾配はゼロではないことに注意。"
  },
  {
    "start": 1018328,
    "end": 1022866,
    "text": "前のステップでは、オプティマイザー・ステップもオプティマイザー・ゼロも実行しなかったからだ。"
  },
  {
    "start": 1022968,
    "end": 1025810,
    "text": "グラデーションは前の項目から残っている。"
  },
  {
    "start": 1027670,
    "end": 1028082,
    "text": "オーケー。"
  },
  {
    "start": 1028136,
    "end": 1035350,
    "text": "つ目の項目は、×1が5、×2が2、目標が12となり、損失が計算されて出力される。"
  },
  {
    "start": 1035770,
    "end": 1044902,
    "text": "その後、ロスを逆算し、パイトーチはこの新しい勾配を前の勾配と置き換えることなく、それを合計し、累積する。"
  },
  {
    "start": 1044966,
    "end": 1047094,
    "text": "だからグラディエント・アキュムレーションと呼んでいる。"
  },
  {
    "start": 1047222,
    "end": 1050522,
    "text": "新しいグラデーションは古いグラデーションと累積される。"
  },
  {
    "start": 1050656,
    "end": 1056554,
    "text": "バッチ・サイズに達したので、いよいよオプティマイザー・ステップ・メソッドを呼び出すことができる。"
  },
  {
    "start": 1056682,
    "end": 1064450,
    "text": "この結果、パラメータの値は累積勾配を使って更新される。"
  },
  {
    "start": 1065110,
    "end": 1069602,
    "text": "その場合、オプティマイザー・ゼロを実行し、勾配をゼロにリセットする。"
  },
  {
    "start": 1069656,
    "end": 1074610,
    "text": "そうすれば、2つの項目からなる別のループに進むことができる。"
  },
  {
    "start": 1075190,
    "end": 1082562,
    "text": "勾配累積を伴う勾配降下を行ったときに、損失関数、つまりパラメータと損失関数に何が起こるかを視覚化してみよう。"
  },
  {
    "start": 1082706,
    "end": 1086950,
    "text": "初期ウェイトがここにあるのは、ランダムに初期化されているからだ。"
  },
  {
    "start": 1088010,
    "end": 1091638,
    "text": "最初の項目でフォワードループを実行する。"
  },
  {
    "start": 1091734,
    "end": 1096202,
    "text": "その結果、モデルによって出力が計算される。"
  },
  {
    "start": 1096336,
    "end": 1098582,
    "text": "そして、ロス・ドットを逆算する。"
  },
  {
    "start": 1098646,
    "end": 1106746,
    "text": "これにより、最初のデータ項目に対して勾配が計算され、この勾配が方向を示すことになる。"
  },
  {
    "start": 1106938,
    "end": 1113354,
    "text": "そして、2つ目のデータ項目で再び前方に実行し、2つ目のデータ項目で後方にロスを実行する。"
  },
  {
    "start": 1113402,
    "end": 1116526,
    "text": "この場合もグラデーションが計算される。"
  },
  {
    "start": 1116638,
    "end": 1124530,
    "text": "これらの2つの勾配は、Pytorchによって合計され、その結果、方向を示すベクトルが得られる。"
  },
  {
    "start": 1124950,
    "end": 1127966,
    "text": "次にオプティマイザを実行する。"
  },
  {
    "start": 1127998,
    "end": 1138990,
    "text": "オプティマイザーSAPは、2つ前のデータ項目の2つの勾配の和が示す方向に従って、重みの値を更新する。"
  },
  {
    "start": 1139170,
    "end": 1140954,
    "text": "であれば、オプティマイザー・ゼロを実行する。"
  },
  {
    "start": 1140992,
    "end": 1145290,
    "text": "これにより、すべてのノードの勾配がゼロになる。"
  },
  {
    "start": 1145870,
    "end": 1156958,
    "text": "そこで勾配累積では、一括して勾配を累積してからモデルのパラメータを更新する。"
  },
  {
    "start": 1157044,
    "end": 1168110,
    "text": "勾配累積は分散トレーニングだけでなく、例えばバッチサイズを大きくせずに勾配を累積したい場合にも使われる。"
  },
  {
    "start": 1168190,
    "end": 1172734,
    "text": "を使えば、複数の項目の勾配を累積し、パラメータを移動させることができる。"
  },
  {
    "start": 1172862,
    "end": 1177006,
    "text": "そうすることで、よりスムーズなトレーニングになり、ロスの振動が少なくなるからだ。"
  },
  {
    "start": 1177048,
    "end": 1177800,
    "text": "例えば、こうだ。"
  },
  {
    "start": 1178490,
    "end": 1185158,
    "text": "勾配累積の仕組みを見たところで、分散データ並列トレーニングの詳細を見てみよう。"
  },
  {
    "start": 1185244,
    "end": 1190330,
    "text": "どのように機能するのか、通信プリミティブとは何を意味するのか、フェイルオーバーをどのように管理するのか。"
  },
  {
    "start": 1191550,
    "end": 1206990,
    "text": "分散データ、並列トレーニングでは、トレーニングスクリプトが1台のコンピューターで実行されているとします。しかし、データセットが非常に大きいため非常に時間がかかり、バッチサイズを大きくするとCUDAでメモリ不足エラーになるため使用できません。"
  },
  {
    "start": 1207490,
    "end": 1209466,
    "text": "分散データ・パラレルはその解決策である。"
  },
  {
    "start": 1209498,
    "end": 1212906,
    "text": "この場合、以下の3つのシナリオで機能する。"
  },
  {
    "start": 1213018,
    "end": 1221246,
    "text": "シングルGPUに収まるモデルがあり、トレーニングループは機能するが、非常に低速だとする。"
  },
  {
    "start": 1221358,
    "end": 1228562,
    "text": "最初にできることは、複数のサーバーでモデルを学習させ、それぞれのサーバーに1つのGPUを持たせることだ。"
  },
  {
    "start": 1228626,
    "end": 1233378,
    "text": "これは分散データ・パラレルで可能だ。"
  },
  {
    "start": 1233554,
    "end": 1239238,
    "text": "2つ目のセットアップは、既存のコンピュータのGPU数を増やしたい場合です。"
  },
  {
    "start": 1239324,
    "end": 1250406,
    "text": "このセットアップもまた、分散データ・パラレル・トレーニングで管理することができる。"
  },
  {
    "start": 1250598,
    "end": 1259006,
    "text": "このビデオでは、このセットアップの実装方法を紹介する。他の2つのセットアップは、このセットアップの特殊なケースに過ぎないからだ。"
  },
  {
    "start": 1259108,
    "end": 1262254,
    "text": "これが最も一般的なセットアップだ。"
  },
  {
    "start": 1262452,
    "end": 1276200,
    "text": "このセットアップのためのクラウド・インフラストラクチャの作成方法と、既存のコードを分散トレーニング・コードに変換し、作成したクラスタ上で実行する方法を紹介する。"
  },
  {
    "start": 1276810,
    "end": 1283026,
    "text": "これからは、ノードとGPUを同じ意味で使うことにする。"
  },
  {
    "start": 1283138,
    "end": 1292714,
    "text": "クラスタが2台のコンピュータで構成され、各コンピュータが2つのGPUを搭載している場合、合計で4つのノードまたは4つのGPUがデータを分散することになる。"
  },
  {
    "start": 1292752,
    "end": 1294282,
    "text": "パラレルは次のように機能する。"
  },
  {
    "start": 1294336,
    "end": 1305070,
    "text": "トレーニングの最初に、モデルの重みは1つのノード、つまり1つのGPUで初期化され、ブロードキャストと呼ばれる操作を使って他のすべてのノードに送信される。"
  },
  {
    "start": 1305730,
    "end": 1313966,
    "text": "各ノードは、データの部分集合に対して同じ初期重みから開始したため、同じモデルを訓練する。"
  },
  {
    "start": 1314068,
    "end": 1332006,
    "text": "おそらく、1つのGPUが1番目のバッチでトレーニングし、2番目のGPUが2番目のバッチで、3番目のGPUが3番目のバッチで、といった具合に、このデータと、これらのノードがこのモデルをトレーニングする数バッチごとに、重複がないようにするのだろう。"
  },
  {
    "start": 1332108,
    "end": 1337862,
    "text": "各ノードの勾配は累積され、1つのノードに合計されて送信される。"
  },
  {
    "start": 1337916,
    "end": 1340406,
    "text": "その合計が他のすべてのノードに送り返される。"
  },
  {
    "start": 1340518,
    "end": 1343450,
    "text": "この操作はオール・リデュースと呼ばれる。"
  },
  {
    "start": 1344110,
    "end": 1351482,
    "text": "その後、各ノードは前のステップで受け取った勾配を使用してローカルモデルのパラメータを更新する。"
  },
  {
    "start": 1351536,
    "end": 1358346,
    "text": "前のステップで受け取った勾配は、自身のオプティマイザも使用するすべてのノードの勾配の合計です。"
  },
  {
    "start": 1358378,
    "end": 1363102,
    "text": "だから、オプティマイザーのステップをやって、ステップ2からやり直す。"
  },
  {
    "start": 1363156,
    "end": 1365258,
    "text": "何回かに分けて訓練する。"
  },
  {
    "start": 1365354,
    "end": 1366974,
    "text": "局所的な勾配がある。"
  },
  {
    "start": 1367022,
    "end": 1373070,
    "text": "ローカル勾配を中央ノードに送り、中央ノードがそれを合計して全ノードに送り返す。"
  },
  {
    "start": 1373150,
    "end": 1378390,
    "text": "その後、すべてのノードはこの累積勾配を使用してパラメータを更新する。"
  },
  {
    "start": 1379290,
    "end": 1381160,
    "text": "そしてまた続ける。"
  },
  {
    "start": 1382090,
    "end": 1385846,
    "text": "これらのステップをひとつひとつ詳しく見ていこう。"
  },
  {
    "start": 1385948,
    "end": 1392614,
    "text": "ステップ1では、モデルのウェイトを1つのGPUで初期化する。"
  },
  {
    "start": 1392662,
    "end": 1395238,
    "text": "Gpusが4つあるとする。"
  },
  {
    "start": 1395334,
    "end": 1399818,
    "text": "ウエイトを初期化し、それを他のすべてのGPUに送るGPUが1つある。"
  },
  {
    "start": 1399904,
    "end": 1405178,
    "text": "これがパラメータの値で、これが勾配である。"
  },
  {
    "start": 1405274,
    "end": 1407566,
    "text": "パラメータimagineの値は0.1である。"
  },
  {
    "start": 1407588,
    "end": 1408634,
    "text": "パラメータは1つしかない。"
  },
  {
    "start": 1408682,
    "end": 1413318,
    "text": "簡単のため、初期重みは他のすべてのノードに送信される。"
  },
  {
    "start": 1413354,
    "end": 1416238,
    "text": "これですべてのノードの重みが同じになった。"
  },
  {
    "start": 1416414,
    "end": 1421700,
    "text": "これですべてのノードが同じパラメーター、同じ値を持つようになった。"
  },
  {
    "start": 1422390,
    "end": 1429846,
    "text": "次に行うことは、各ノードが1つまたは複数のデータのバッチに対してフォワードステップとバックワードステップを実行することだ。"
  },
  {
    "start": 1429948,
    "end": 1442570,
    "text": "この結果、局所的な勾配が計算されることになる。前に見たように、損失を逆算すると、各パラメーターに対する損失関数の勾配が計算されるからだ。"
  },
  {
    "start": 1443230,
    "end": 1449980,
    "text": "もちろん、この局所勾配はノードごとに異なる可能性がある。なぜなら、各ノードはデータの異なるサブセットでトレーニングを行っているからだ。"
  },
  {
    "start": 1450670,
    "end": 1454554,
    "text": "この局所的な勾配は、1つまたは複数のバッチの蓄積である可能性もある。"
  },
  {
    "start": 1454602,
    "end": 1463226,
    "text": "このGPUがそれぞれ3つのバッチをトレーニングしていると仮定すると、3つのバッチの勾配を累積することができます。"
  },
  {
    "start": 1463338,
    "end": 1471170,
    "text": "もちろん、データの異なる部分集合でトレーニングしているため、この累積勾配は、局所的ではあるが、各ノードで異なる。"
  },
  {
    "start": 1471590,
    "end": 1482882,
    "text": "次にすることは、この勾配をすべてのノードに送り、その勾配を1つのノードに送り、このノードが受け取ったすべての勾配の合計を計算することだ。"
  },
  {
    "start": 1483026,
    "end": 1491542,
    "text": "すべてのノードが自分の勾配を最初のGPUに送信することを決定し、合計が最初のGPUで計算されるとします。"
  },
  {
    "start": 1491686,
    "end": 1495980,
    "text": "この操作はreduceと呼ばれる。"
  },
  {
    "start": 1497230,
    "end": 1506910,
    "text": "そして、すべての勾配の合計を計算したGPUは、ブロードキャストと呼ばれる操作で、それを他のすべてのノードに送り返す。"
  },
  {
    "start": 1507250,
    "end": 1515994,
    "text": "reduceとbroadcastのシーケンスは、ここでは別のオペレーションとして示しているが、通常はall reduceとして知られる単一のオペレーションとして実装される。"
  },
  {
    "start": 1516122,
    "end": 1518706,
    "text": "後ほど、その仕組みを詳しく見ていこう。"
  },
  {
    "start": 1518888,
    "end": 1520498,
    "text": "これが重要なアイデアだ。"
  },
  {
    "start": 1520584,
    "end": 1524210,
    "text": "そこで、モデルの重みをモデル上で初期化する。"
  },
  {
    "start": 1524360,
    "end": 1526206,
    "text": "他のすべてのモデルに送り返される。"
  },
  {
    "start": 1526238,
    "end": 1533510,
    "text": "今、他のすべてのGpusは、同じ重み、初期重みを持ち、異なるデータのサブセットでトレーニングしている。"
  },
  {
    "start": 1533580,
    "end": 1535298,
    "text": "それぞれが局所的な勾配を持っている。"
  },
  {
    "start": 1535394,
    "end": 1542678,
    "text": "それぞれのローカル勾配を1つのノードに送り、そのノードがすべての勾配の合計を計算し、他のすべてのノードに送り返す。"
  },
  {
    "start": 1542694,
    "end": 1544742,
    "text": "今、彼らはすべて同じ合計を持っている。"
  },
  {
    "start": 1544886,
    "end": 1556286,
    "text": "そして、同じ合計を使って重みを更新する最適化ステップを実行し、その結果、ここにあるように、モデルの重みはすべて同じになる。"
  },
  {
    "start": 1556388,
    "end": 1564334,
    "text": "これで、各ノードは、ここで見るのと同じ勾配の合計を使って、それぞれのパラメーターの値を更新することになる。"
  },
  {
    "start": 1564372,
    "end": 1565362,
    "text": "0.3だ。"
  },
  {
    "start": 1565416,
    "end": 1572850,
    "text": "0.3を使ってローカルパラメーターの値を更新し、最終的には同じウェイトになる。"
  },
  {
    "start": 1573350,
    "end": 1578114,
    "text": "各ノードは、受け取った勾配を使用してローカルモデルのパラメータを更新する。"
  },
  {
    "start": 1578162,
    "end": 1583590,
    "text": "更新後、勾配はゼロにリセットされ、別のループを始めることができる。"
  },
  {
    "start": 1584810,
    "end": 1587618,
    "text": "では、集団的コミュニケーション・プリミティブについて話そう。"
  },
  {
    "start": 1587634,
    "end": 1595382,
    "text": "分散コンピューティング環境では、ノードは他のノードと通信する必要がある。"
  },
  {
    "start": 1595446,
    "end": 1607658,
    "text": "通信パターンがクライアントとサーバーに似ている場合、1つのクライアントが1つのサーバーにリクエスト・レスポンスの連鎖で接続するため、ポイント・ツー・ポイント通信と呼ばれる。"
  },
  {
    "start": 1607834,
    "end": 1613150,
    "text": "しかし、1つのノードが一度に複数のレシーバーに通信する必要がある場合もある。"
  },
  {
    "start": 1613220,
    "end": 1619806,
    "text": "例えば、ブロードキャスト・シナリオでは、1つのノードがその重みを他のすべてのノードに送信する必要がある。"
  },
  {
    "start": 1619998,
    "end": 1623458,
    "text": "これは、ディープラーニングにおけるデータ並列学習の典型的なケースである。"
  },
  {
    "start": 1623544,
    "end": 1627634,
    "text": "1つのノードは、他のすべてのノードに初期重みを送信する必要があります。"
  },
  {
    "start": 1627762,
    "end": 1634518,
    "text": "さらに、他のすべてのノードは、累積勾配を受信するために、1つのノードに勾配を送信する必要があります。"
  },
  {
    "start": 1634684,
    "end": 1640806,
    "text": "集団通信は、ノードのグループ間の通信パターンをモデル化することができます。"
  },
  {
    "start": 1640918,
    "end": 1644730,
    "text": "この2つのコミュニケーション・モードの違いを視覚化してみよう。"
  },
  {
    "start": 1645470,
    "end": 1648618,
    "text": "あるファイルを7人の友人に送る必要があるとしよう。"
  },
  {
    "start": 1648784,
    "end": 1654782,
    "text": "ポイント・ツー・ポイント通信では、ファイルを一人一人の友人に繰り返し送信することになる。"
  },
  {
    "start": 1654916,
    "end": 1660846,
    "text": "あなたのインターネット速度が1ファイル5メガバイトだとする。"
  },
  {
    "start": 1661028,
    "end": 1669086,
    "text": "あなたがすることは、まず、あなたがここにいることを想像して、ファイルを持っていて、それを最初の友人に送ることです。"
  },
  {
    "start": 1669118,
    "end": 1683350,
    "text": "5メガバイトを1の速度で送信し、それを2番目の友人、3番目、4番目、5番目、6番目、7番目に送信するため、7人の友人にファイルを送信する時間は35秒となる。"
  },
  {
    "start": 1683690,
    "end": 1690698,
    "text": "もちろん、オーケーと言うかもしれないが、なぜ7人の友人全員に同時にファイルを送らないのか？"
  },
  {
    "start": 1690864,
    "end": 1691914,
    "text": "もちろんできるさ。"
  },
  {
    "start": 1691952,
    "end": 1697274,
    "text": "問題は、あなたのインターネット速度がまだ1."
  },
  {
    "start": 1697312,
    "end": 1703050,
    "text": "7人の友人に同時にファイルを送信した場合のインターネット速度は、この7人の友人で分割されます。"
  },
  {
    "start": 1703120,
    "end": 1709774,
    "text": "各フレンドは、多かれ少なかれ、毎秒143キロバイトのスピードでファイルを受信することになる。"
  },
  {
    "start": 1709892,
    "end": 1715540,
    "text": "の場合、7人の友人にファイルを配布するのにかかる時間は35秒である。"
  },
  {
    "start": 1716150,
    "end": 1718100,
    "text": "もっといい方法がないか考えてみよう。"
  },
  {
    "start": 1718550,
    "end": 1724462,
    "text": "集合的な通信では、ブロードキャストと呼ばれる最初の演算子を導入する。"
  },
  {
    "start": 1724526,
    "end": 1730818,
    "text": "他のすべてのノードにデータを送信する操作は、ブロードキャストオペレータとして知られています。"
  },
  {
    "start": 1730994,
    "end": 1744890,
    "text": "NvidiaのライブラリであるNCCL（ニッケルと発音する）のような集団通信ライブラリは、各ノードに固有のIDを割り当て、この固有のIDをランクと呼ぶ。"
  },
  {
    "start": 1745550,
    "end": 1749978,
    "text": "例えば、インターネットの速度が1で5メガバイトを送信したいとします。"
  },
  {
    "start": 1749984,
    "end": 1754906,
    "text": "この放送作戦の場合、集団通信がどのように機能するか見てみよう。"
  },
  {
    "start": 1755098,
    "end": 1757502,
    "text": "まず最初にすることは、あなたがここにいることだ。"
  },
  {
    "start": 1757556,
    "end": 1762654,
    "text": "ファイルを手に入れたら、この友人ではなく、ランク4番に送ってくれ。"
  },
  {
    "start": 1762852,
    "end": 1769874,
    "text": "次のステップでは、ランク0とランク4がファイルを持っているので、別の友人に同時に送信できることに気づく。"
  },
  {
    "start": 1769992,
    "end": 1774850,
    "text": "ランク0はランク2に、ランク4はランク6に送られる。"
  },
  {
    "start": 1775000,
    "end": 1779554,
    "text": "これで、ランクゼロ、ランク2、ランク4、ランク6がすべてファイルを持っていることがわかった。"
  },
  {
    "start": 1779602,
    "end": 1782870,
    "text": "同時に別の友人を送ることもできる。"
  },
  {
    "start": 1783020,
    "end": 1788954,
    "text": "合計で、7人の友人全員に最初のファイルを配布するのに15秒かかる。"
  },
  {
    "start": 1789072,
    "end": 1792970,
    "text": "ポイント・トゥ・ポイントのコミュニケーションが可能な35セカンドに比べれば。"
  },
  {
    "start": 1793950,
    "end": 1796950,
    "text": "このアプローチは分割統治として知られている。"
  },
  {
    "start": 1797030,
    "end": 1805326,
    "text": "集団通信では、ノード間の相互接続性を利用してアイドル時間を回避し、総通信時間を短縮する。"
  },
  {
    "start": 1805508,
    "end": 1809946,
    "text": "このようにして、あなたのGPUも他のすべてのノードに初期ウェイトを送信する。"
  },
  {
    "start": 1809978,
    "end": 1812938,
    "text": "一人一人じゃないんだ。"
  },
  {
    "start": 1813114,
    "end": 1816914,
    "text": "並列でもない。とにかく、接続速度は常に同じだからだ。"
  },
  {
    "start": 1816952,
    "end": 1819038,
    "text": "それはすべてのレシーバーに分配される。"
  },
  {
    "start": 1819134,
    "end": 1821646,
    "text": "私たちがやっているのは、この分割統治アプローチだ。"
  },
  {
    "start": 1821678,
    "end": 1827910,
    "text": "初期ウェイトは、このブロードキャスト・オペレーションを使って送信される。"
  },
  {
    "start": 1828570,
    "end": 1830306,
    "text": "reduceの操作を見てみよう。"
  },
  {
    "start": 1830418,
    "end": 1831602,
    "text": "リデュースとは何ですか？"
  },
  {
    "start": 1831666,
    "end": 1839106,
    "text": "Reduce操作とは、トレーニング中に、すべてのノードの勾配の合計を計算したいときに適用することを意味する。"
  },
  {
    "start": 1839138,
    "end": 1845740,
    "text": "つまり、各ノードはデータの部分集合を使って計算された局所的な勾配を持っているが、それらはすべて互いに異なっている。"
  },
  {
    "start": 1846110,
    "end": 1852054,
    "text": "私たちが求めているのは、これらすべての勾配の合計を1つのノードで計算することだ。"
  },
  {
    "start": 1852102,
    "end": 1853294,
    "text": "どう動くか見てみよう。"
  },
  {
    "start": 1853412,
    "end": 1858186,
    "text": "ブロードキャストオペレータは、他のすべてのノードに初期重みを送信するために使用されます。"
  },
  {
    "start": 1858218,
    "end": 1860110,
    "text": "トレーニングループを開始するとき"
  },
  {
    "start": 1860610,
    "end": 1868094,
    "text": "各ノードが処理するデータの数バッチごとに、すべてのノードの勾配を1つのノードに送信し、累積する必要がある。"
  },
  {
    "start": 1868142,
    "end": 1870590,
    "text": "この演算はreduceと呼ばれる。"
  },
  {
    "start": 1870670,
    "end": 1872050,
    "text": "どう動くか見てみよう。"
  },
  {
    "start": 1872200,
    "end": 1878342,
    "text": "つまり、最初は各ノードが独自の勾配を持っていると想像してほしい。データのサブセットでトレーニングしているからだ。"
  },
  {
    "start": 1878476,
    "end": 1881430,
    "text": "これらのグラデーションはそれぞれ異なる。"
  },
  {
    "start": 1881580,
    "end": 1887170,
    "text": "私たちができることは、各ノードが自分のアディア・セントラル・ノードに勾配を送ることだ。"
  },
  {
    "start": 1887330,
    "end": 1891222,
    "text": "アディアのセントラルノードは、自分の勾配でそれを合計する。"
  },
  {
    "start": 1891286,
    "end": 1895370,
    "text": "例えば、ノード7は道路番号6に勾配を送信する。"
  },
  {
    "start": 1895440,
    "end": 1900470,
    "text": "ノード番号6の場合、受信ノードが合計の計算を担当する。"
  },
  {
    "start": 1900630,
    "end": 1906240,
    "text": "5番と4番、3番と2番、1番と0番も同じ。"
  },
  {
    "start": 1906690,
    "end": 1913742,
    "text": "次のステップでは、ランク4位、ランク2位、ランク0位の合計がここにある。"
  },
  {
    "start": 1913796,
    "end": 1923630,
    "text": "ここでは6位から4位までの合計を送信し、その合計を計算する。"
  },
  {
    "start": 1923790,
    "end": 1927346,
    "text": "そしてランク2位からランク0位へも。"
  },
  {
    "start": 1927448,
    "end": 1930386,
    "text": "ランク番号ゼロは合計を計算する。"
  },
  {
    "start": 1930498,
    "end": 1936982,
    "text": "そして最後のステップで、ランク4にあった合計をランク0に送る。"
  },
  {
    "start": 1937036,
    "end": 1944780,
    "text": "この合計は、すべてのノードのすべてのグラデーションの合計であり、合計でわずか3つのステップしか必要なかった。"
  },
  {
    "start": 1945310,
    "end": 1950758,
    "text": "の3つのステップだけで、すべてのノードの勾配を1つのノードに累積した。"
  },
  {
    "start": 1950854,
    "end": 1962490,
    "text": "通信時間はノード数に対して対数的であることが証明され、これはすべてのリデュース演算の分割統治アプローチの典型である。"
  },
  {
    "start": 1962570,
    "end": 1974018,
    "text": "先ほど見たように、まずデータをブロードキャストし、初期ウェイトを作り、局所的な勾配を減らして、それを送り返す必要がある。"
  },
  {
    "start": 1974184,
    "end": 1984706,
    "text": "リデュースとブロードキャストのシーケンスはallreduceとして知られており、通常は単一のオペレーションとして実装される。"
  },
  {
    "start": 1984898,
    "end": 1992650,
    "text": "その背後にあるアルゴリズムはすでに示していないが、論理的にはリデュースとブロードキャストの一連の操作と考えることができる。"
  },
  {
    "start": 1993070,
    "end": 2000650,
    "text": "実際には1つのオペレーションとして実装され、2つのオペレーションを単独で行うよりもはるかに高速であることを覚えておいてほしい。"
  },
  {
    "start": 2001410,
    "end": 2007882,
    "text": "複数のGPUでモデルをトレーニングしているときに、1つのノードがクラッシュしたとしよう。"
  },
  {
    "start": 2007946,
    "end": 2018222,
    "text": "下図のような分散シナリオでトレーニングしているとき、突然1つのノードがクラッシュし、この場合4つのうち2つのGPUが使用できなくなったとする。"
  },
  {
    "start": 2018366,
    "end": 2020430,
    "text": "システムはどう反応すべきか？"
  },
  {
    "start": 2020590,
    "end": 2025186,
    "text": "まあ、クラスタ全体を再起動するのもひとつの方法だが、それは簡単だ。"
  },
  {
    "start": 2025288,
    "end": 2035570,
    "text": "しかし、クラスターを再スタートさせることで、トレーニングもゼロから再スタートすることになる。覚えているように、我々は1つのノードによってランダムに選ばれた初期重みからスタートし、それが他のすべてのノードに送られるからだ。"
  },
  {
    "start": 2035730,
    "end": 2042886,
    "text": "これは、このノードがクラッシュしたときに、これまでに行ったすべてのパラメーターと計算を失うことを意味する。"
  },
  {
    "start": 2042998,
    "end": 2045446,
    "text": "より良い方法は、チェックポイントを使うことだ。"
  },
  {
    "start": 2045558,
    "end": 2058030,
    "text": "チェックポイントとは、数回反復するごとに、例えばエポックごとにモデルの重みを共有ディスクに保存し、クラッシュした場合に備えて最後のチェックポイントから学習を再開することを意味する。"
  },
  {
    "start": 2059010,
    "end": 2065810,
    "text": "1つのノードでモデルの重みを初期化し、それを他のすべてのノードに送信するステップを思い出す。"
  },
  {
    "start": 2065880,
    "end": 2074980,
    "text": "ただランダムに初期化するのではなく、最新のチェックポイントを使ってモデルの重みを初期化し、そこからトレーニングを続けることができる。"
  },
  {
    "start": 2075450,
    "end": 2087270,
    "text": "どのノードがウェイトを初期化するかを決めるのはpytorchなので、チェックポイントを保存するための共有ストレージが必要です。"
  },
  {
    "start": 2088250,
    "end": 2091406,
    "text": "すべてのノードがこの共有ストレージにアクセスできる必要がある。"
  },
  {
    "start": 2091458,
    "end": 2099370,
    "text": "さらに、分散システムでは、どのノードがいつ故障してもおかしくないので、他のノードよりも重要なノードを1つも持たないのが良いルールだ。"
  },
  {
    "start": 2099520,
    "end": 2104026,
    "text": "どのノードが重みを初期化するかについては、仮定を設けるべきではない。"
  },
  {
    "start": 2104058,
    "end": 2105758,
    "text": "ピトーチが選ぶんだ。"
  },
  {
    "start": 2105924,
    "end": 2113502,
    "text": "しかし、どのノードがランク番号0になるかを仮定するべきではありません。"
  },
  {
    "start": 2113556,
    "end": 2116542,
    "text": "すべてのノードは平等に扱われるべきである。"
  },
  {
    "start": 2116606,
    "end": 2121330,
    "text": "彼らは同じコードを実行し、同じ共有ストレージにアクセスできるはずだ。"
  },
  {
    "start": 2122470,
    "end": 2127258,
    "text": "しかし、共有のストレージがある場合、チェックポイントを保存する責任は誰にあるのだろうか？"
  },
  {
    "start": 2127294,
    "end": 2133446,
    "text": "なぜなら、全員がチェックポイントを書くようなコードを作ると、お互いを上書きしてしまう可能性があるからだ。"
  },
  {
    "start": 2133548,
    "end": 2143446,
    "text": "Pytorchは現在のノードのランクを教えてくれるので、現在のノードのランクをチェックするようにコードを書きます。"
  },
  {
    "start": 2143478,
    "end": 2146582,
    "text": "ランクがゼロなら、チェックポイントを保存する。"
  },
  {
    "start": 2146646,
    "end": 2149370,
    "text": "位、2位、3位なら何もしない。"
  },
  {
    "start": 2149520,
    "end": 2154058,
    "text": "これは、チェックポイントの保存を担当するのは1つのランクだけであることを意味する。"
  },
  {
    "start": 2154154,
    "end": 2159440,
    "text": "その後、トレーニングを再開する際には、誰がランクゼロになるかは想定していない。"
  },
  {
    "start": 2159970,
    "end": 2173330,
    "text": "Pytorchのドキュメントに書いてあるように、ランクが安定していないということは、トレーニングを再開すると、ランク番号0が別のノードに割り当てられる可能性があるということです。"
  },
  {
    "start": 2174790,
    "end": 2192902,
    "text": "複数のノードがローカルに計算した勾配を蓄積し、それを1つのノードに送り、そのノードが合計を計算して他のノードに送り返し、そのノードがパラメーターを更新する。"
  },
  {
    "start": 2192966,
    "end": 2199546,
    "text": "この勾配の合計を使って、実際にトレーニングを見てみよう。"
  },
  {
    "start": 2199648,
    "end": 2215600,
    "text": "まず、トレーニングを実行するために必要なインフラストラクチャーを構築します。そして、これから作成するインフラストラクチャー上でトレーニングを実行するために、既存のトレーニングループにどのようなコード変更を加える必要があるのかもお見せします。"
  },
  {
    "start": 2216130,
    "end": 2224494,
    "text": "ペーパースペースをクラウドサービスとして利用するつもりだが、その主な理由は、使い勝手がよく、初心者でも設定に時間がかからないからだ。"
  },
  {
    "start": 2224622,
    "end": 2233202,
    "text": "AWSには、簡単な操作をするために必要な他の設定がたくさんあり、迷子になりやすいからだ。"
  },
  {
    "start": 2233266,
    "end": 2242326,
    "text": "どんな知識レベルの人でも同じことができるように、チュートリアルに簡単に従うことができるように。"
  },
  {
    "start": 2242438,
    "end": 2243820,
    "text": "さあ、始めよう。"
  },
  {
    "start": 2245230,
    "end": 2261066,
    "text": "まず最初に、Pytorch transformer distributedというリポジトリに行く必要がある。ここには、このクラスタ上で実行する分散モデルのコードと、paperspace上でこのクラスタを作成する方法が書いてある。"
  },
  {
    "start": 2261258,
    "end": 2264518,
    "text": "すでにpaperspaceのアカウントにアクセスしました。"
  },
  {
    "start": 2264554,
    "end": 2273060,
    "text": "まず最初に行うのは、GitHub で行うのと同じように ssh 鍵を作成することです。"
  },
  {
    "start": 2274950,
    "end": 2281880,
    "text": "ペーパースペースに作成されたマシンに接続できるように、ここでパブリックsshキーをアカウントに関連付ける必要がある。"
  },
  {
    "start": 2282490,
    "end": 2288562,
    "text": "さて、最初にやるべきことは、これら2台のマシンを接続するプライベート・ネットワークを作成することだ。"
  },
  {
    "start": 2288626,
    "end": 2295782,
    "text": "このプライベート・ネットワークに接続された2台のマシンと、両方のマシンがアクセスできる共有ディスクを作成します。"
  },
  {
    "start": 2295926,
    "end": 2298086,
    "text": "2つのGPUを搭載したマシンを使う。"
  },
  {
    "start": 2298118,
    "end": 2301646,
    "text": "合計で4台のGPUでトレーニングを実施する。"
  },
  {
    "start": 2301828,
    "end": 2308154,
    "text": "ここでプライベート・ネットワーク・ネットワークを作成し、新しいネットワークを作成しよう。"
  },
  {
    "start": 2308282,
    "end": 2318100,
    "text": "コンピュータとクラスタに同じリージョンを選択することを忘れないでください。"
  },
  {
    "start": 2321770,
    "end": 2324742,
    "text": "よし、これでサブネットができた。"
  },
  {
    "start": 2324876,
    "end": 2328342,
    "text": "次のステップは、2つのノードを作成することである。"
  },
  {
    "start": 2328476,
    "end": 2334758,
    "text": "どのノードを選んでも構わないが、私は2台のマシンをテストしたかったので、このノードを選んだ。"
  },
  {
    "start": 2334854,
    "end": 2337610,
    "text": "我々はML in a boxをオペレーティング・システムとして使っている。"
  },
  {
    "start": 2337680,
    "end": 2343040,
    "text": "これらのマシンのイメージとして、箱の中にMLという新しいマシンを作る。"
  },
  {
    "start": 2343890,
    "end": 2347982,
    "text": "我々のマシンはマルチGPUで、P4000を2倍にしたものだ。"
  },
  {
    "start": 2348036,
    "end": 2351226,
    "text": "こちらは地域がネットワークと同じ。"
  },
  {
    "start": 2351258,
    "end": 2355742,
    "text": "ニューヨークの2つは、ディスクのサイズだが、合計で50ギガバイトもあれば十分だ。"
  },
  {
    "start": 2355796,
    "end": 2361090,
    "text": "前回、このクラスターを作って何エポックも走らせたときは、5ドル使ったと思う。"
  },
  {
    "start": 2361160,
    "end": 2366440,
    "text": "配布されたトレーニングに5ドル以上かけることはないと思う。"
  },
  {
    "start": 2366890,
    "end": 2370534,
    "text": "5ドルより高くてはならない。"
  },
  {
    "start": 2370732,
    "end": 2383290,
    "text": "最初のマシンは、CUDA Zeroと呼ぶことにする。ネットワークは、以前に作成したネットワークを選択する必要があり、パブリックIPがないとマシンに接続できないので、パブリックEPダイナミックを選択する。"
  },
  {
    "start": 2383630,
    "end": 2387162,
    "text": "スナップショットは作成しない。"
  },
  {
    "start": 2387216,
    "end": 2391100,
    "text": "各マシンのランニングコストは約1ドルである。"
  },
  {
    "start": 2392430,
    "end": 2398974,
    "text": "最初のマシンを作り、2台目も作る。"
  },
  {
    "start": 2399092,
    "end": 2411220,
    "text": "箱入りのML、マシンはこのニューヨークのディスクサイズで、これをCUDA oneと呼ぶことにする。"
  },
  {
    "start": 2413350,
    "end": 2415454,
    "text": "ダイナミックな分散トレーニング。"
  },
  {
    "start": 2415582,
    "end": 2419350,
    "text": "私たちはマシンを保存したり作ったりはしない。"
  },
  {
    "start": 2420650,
    "end": 2425510,
    "text": "最後に、250GBのネットワーク・ドライブを作成する必要がある。"
  },
  {
    "start": 2425580,
    "end": 2427078,
    "text": "これが一番小さいものだ。"
  },
  {
    "start": 2427164,
    "end": 2430326,
    "text": "だから250GBを選んだんだ。"
  },
  {
    "start": 2430518,
    "end": 2435866,
    "text": "モデルトレーニング、250ニューヨーク、分散トレーニングと呼ぶことにする。"
  },
  {
    "start": 2435968,
    "end": 2450254,
    "text": "2台のマシンと同じネットワークに属していなければならない。"
  },
  {
    "start": 2450302,
    "end": 2453518,
    "text": "これからマシンを設定するので、いくつかのパッケージをインストールする必要がある。"
  },
  {
    "start": 2453614,
    "end": 2457400,
    "text": "まず、IPアドレスが必要なので、コンフィグをインストールする必要がある。"
  },
  {
    "start": 2457850,
    "end": 2464786,
    "text": "ifコンフィグをインストール中にタツノオトシゴのエラーに遭遇しました。"
  },
  {
    "start": 2464978,
    "end": 2475126,
    "text": "そしてネットワーク・ドライブをマウントし、このリポジトリをクローンして、このコードを実行するのに必要なパッケージをすべてインストールし、初期化する。"
  },
  {
    "start": 2475238,
    "end": 2484942,
    "text": "また、このモデルのトレーニング中に必要なすべてのメトリクスの損失などを追跡するために、ウィッツとバイアスを使うことをお勧めする。"
  },
  {
    "start": 2484996,
    "end": 2499250,
    "text": "widthsとbiasesに登録し、インストールして、このコードを実行する際にも使用することをお勧めします。"
  },
  {
    "start": 2499750,
    "end": 2502100,
    "text": "よし、クダ・ゼロの準備ができた。"
  },
  {
    "start": 2502470,
    "end": 2509720,
    "text": "私たちはここでいくつかの情報を見ることができる。"
  },
  {
    "start": 2510890,
    "end": 2513640,
    "text": "これでIPアドレスがわかる。"
  },
  {
    "start": 2515550,
    "end": 2517020,
    "text": "私たちはそれにつながっている。"
  },
  {
    "start": 2518190,
    "end": 2526038,
    "text": "そう、素晴らしいよ。"
  },
  {
    "start": 2526134,
    "end": 2527366,
    "text": "今、私たちはマシンの中にいる。"
  },
  {
    "start": 2527398,
    "end": 2529550,
    "text": "最初にすることは、すべてのパッケージをアップデートすることだ。"
  },
  {
    "start": 2532370,
    "end": 2545090,
    "text": "ネットツールもインストールするのですが、エラーになるのを覚えています。"
  },
  {
    "start": 2545240,
    "end": 2546850,
    "text": "コンフィグを試してみよう。"
  },
  {
    "start": 2547270,
    "end": 2547934,
    "text": "素晴らしい。"
  },
  {
    "start": 2547982,
    "end": 2550706,
    "text": "これで最初のマシンのIPアドレスがわかった。"
  },
  {
    "start": 2550728,
    "end": 2554982,
    "text": "これは、ここで作成したサブネットに属するプライベート・アドレスである。"
  },
  {
    "start": 2555036,
    "end": 2559320,
    "text": "810がここで作ったものだ。"
  },
  {
    "start": 2562330,
    "end": 2578326,
    "text": "後でホストを変更する必要があるので、このIPアドレスを記録しておく必要がある。"
  },
  {
    "start": 2578358,
    "end": 2583710,
    "text": "他のノードのホスト名をipにマッピングして、ホストを修正しなければならなかった。"
  },
  {
    "start": 2585490,
    "end": 2590346,
    "text": "では、ネットワーク・ドライブをマウントしてみよう。"
  },
  {
    "start": 2590378,
    "end": 2595300,
    "text": "このパッケージをインストールする。"
  },
  {
    "start": 2600390,
    "end": 2611720,
    "text": "さて、このネットワーク・ドライブをマウントするディレクトリを作成した。"
  },
  {
    "start": 2613370,
    "end": 2615554,
    "text": "このコマンドを実行しなければならない。"
  },
  {
    "start": 2615612,
    "end": 2623100,
    "text": "ここで見ることができるが、IPアドレスとドライブのユーザー名とパスワードを置き換える必要がある。"
  },
  {
    "start": 2623470,
    "end": 2625754,
    "text": "まずは貼り付けよう。"
  },
  {
    "start": 2625872,
    "end": 2638446,
    "text": "次に、IPアドレスとネットワーク共有名に置き換える必要がある。"
  },
  {
    "start": 2638548,
    "end": 2642994,
    "text": "ここにドライブして、ここに住所がある。"
  },
  {
    "start": 2643112,
    "end": 2667462,
    "text": "エスケープ文字をスラッシュに置き換える必要がある。"
  },
  {
    "start": 2667526,
    "end": 2672742,
    "text": "パスワードもここにある。"
  },
  {
    "start": 2672806,
    "end": 2674310,
    "text": "これで取り付けられるはずだ。"
  },
  {
    "start": 2674470,
    "end": 2682106,
    "text": "最初にすることは、リポジトリをクローンして、デフォルト・ユーザーのホーム・ディレクトリにいることだ。"
  },
  {
    "start": 2682138,
    "end": 2685600,
    "text": "紙のスペースなら、ここに直接クローンを作ることができる。"
  },
  {
    "start": 2687090,
    "end": 2694050,
    "text": "それからCDを作り、必要なものをインストールする。"
  },
  {
    "start": 2697910,
    "end": 2705094,
    "text": "さて、これで要件をインストールできたので、このコマンドを使ってWeights and Biasesにログインしよう。"
  },
  {
    "start": 2705212,
    "end": 2712120,
    "text": "ウエイトとバイアスのウェブサイトからキーをコピーしてください。"
  },
  {
    "start": 2714010,
    "end": 2721530,
    "text": "走りましょう。"
  },
  {
    "start": 2723200,
    "end": 2728716,
    "text": "さて、これで1台目のコンピューターでトレーニング・コマンドを実行する準備ができたが、2台目も準備する必要がある。"
  },
  {
    "start": 2728738,
    "end": 2730590,
    "text": "つ目を用意しよう。"
  },
  {
    "start": 2734880,
    "end": 2740172,
    "text": "もちろん実際のシナリオでは、dockerファイルを作成し、kubernetesを使ってすべてを実行することになる。"
  },
  {
    "start": 2740236,
    "end": 2742412,
    "text": "自動的に行われるはずだ。"
  },
  {
    "start": 2742476,
    "end": 2751232,
    "text": "というのも、ほとんどの人はkubernetesやdockerに馴染みがなかったり、トレーニングを非常に高速に実行して動作を確認したいだけだったりするからだ。"
  },
  {
    "start": 2751366,
    "end": 2783300,
    "text": "paperspaceを使うことをお勧めするのは、事前にすべての設定をするのがとても簡単だからだ。"
  },
  {
    "start": 2799260,
    "end": 2817970,
    "text": "両方のコンピューターに同じリポジトリをクローンし、トレーニング用に同じコードを実行する。"
  },
  {
    "start": 2821540,
    "end": 2838240,
    "text": "さて、これで重みとバイアスを設定してログインし、両方のコンピューターでトレーニングを実行する準備ができた。"
  },
  {
    "start": 2838660,
    "end": 2849652,
    "text": "さて、どちらのマシンでもトレーニングを実行するために実行するコマンドは同じだが、最初に選択するコンピュータのIPアドレスを取得する必要がある。"
  },
  {
    "start": 2849706,
    "end": 2852416,
    "text": "台のコンピュータのうち1台がrundevマスターになる。"
  },
  {
    "start": 2852528,
    "end": 2857492,
    "text": "つまり、すべての通信はそのノードが管理し、他のノードはそれに合わせるということだ。"
  },
  {
    "start": 2857556,
    "end": 2873500,
    "text": "もちろん、よりフェイルセーフにするために、マスターがクラッシュした場合に備えて、別のマシンにマッピングできるダイナミックIPを使うこともできる。"
  },
  {
    "start": 2874000,
    "end": 2876652,
    "text": "この単純なケースでは、私が手作業で設定する。"
  },
  {
    "start": 2876706,
    "end": 2881384,
    "text": "そうでなければ、オーケストレーション・ツールが必要になり、すべてのシナリオが複雑になる。"
  },
  {
    "start": 2881512,
    "end": 2884352,
    "text": "今回は分散トレーニングの方法を紹介したい。"
  },
  {
    "start": 2884406,
    "end": 2891040,
    "text": "実際のシナリオで理想とされる完璧なインフラを作るのに、あまり時間をかけたくない。"
  },
  {
    "start": 2891460,
    "end": 2899648,
    "text": "このコマンドでわかるように、マスター・ノードのIPアドレスをここに入力する必要がある。"
  },
  {
    "start": 2899814,
    "end": 2901952,
    "text": "どちらをマスターにするか。"
  },
  {
    "start": 2902016,
    "end": 2903652,
    "text": "私の場合はクーダ・ゼロを選ぶ。"
  },
  {
    "start": 2903706,
    "end": 2909720,
    "text": "私が最初に作ったマシンともう1台は、たとえ2台とも同じオペレーションを実行したとしても、スレーブのようなものになる。"
  },
  {
    "start": 2910060,
    "end": 2918516,
    "text": "このスレーブのIPを見つけ、マスターのホスト・ファイルに入れる。"
  },
  {
    "start": 2918708,
    "end": 2922732,
    "text": "スレーブのホスト名も必要です。"
  },
  {
    "start": 2922786,
    "end": 2923390,
    "text": "完璧だ。"
  },
  {
    "start": 2924480,
    "end": 2939730,
    "text": "このノードのIPアドレスとホスト名をここに貼り付ける必要がある。"
  },
  {
    "start": 2942580,
    "end": 2944384,
    "text": "それだけだ。"
  },
  {
    "start": 2944502,
    "end": 2945888,
    "text": "これでトレーニングを開始できる。"
  },
  {
    "start": 2945974,
    "end": 2949316,
    "text": "ここではマスターのIPアドレスを取る。"
  },
  {
    "start": 2949418,
    "end": 2963044,
    "text": "Cuda Zeroがマスターで、これをコマンドのこの位置に置き、CDをトーチに送ってコマンドを実行する。"
  },
  {
    "start": 2963172,
    "end": 2970868,
    "text": "このコマンドで言っているのは、torch runはクラスタを作成し、クラスタの作成と通信をすべて管理する特別なコマンドだということだ。"
  },
  {
    "start": 2971044,
    "end": 2972932,
    "text": "トレーニング・ループを実行する。"
  },
  {
    "start": 2972996,
    "end": 2974104,
    "text": "こちらをご覧いただきたい。"
  },
  {
    "start": 2974222,
    "end": 2978984,
    "text": "まず最初に、このクラスタにいくつのプロセスがあるのかを知る必要がある。"
  },
  {
    "start": 2979032,
    "end": 2983304,
    "text": "台のコンピュータがあり、それぞれのノードにいくつのプロセスを作成したいのか。"
  },
  {
    "start": 2983352,
    "end": 2986524,
    "text": "各コンピュータにいくつのGpusを持っているか。"
  },
  {
    "start": 2986642,
    "end": 2988800,
    "text": "これはコンピューター1台あたりのGpus数である。"
  },
  {
    "start": 2988870,
    "end": 2990076,
    "text": "これはコンピューターの台数である。"
  },
  {
    "start": 2990108,
    "end": 2991570,
    "text": "私たちは2と2を持っている。"
  },
  {
    "start": 2992100,
    "end": 2995948,
    "text": "これはこの特定のクラスターを示す一意のIDである。"
  },
  {
    "start": 2996044,
    "end": 2998156,
    "text": "クラスタごとに一意でなければならない。"
  },
  {
    "start": 2998268,
    "end": 3001812,
    "text": "これは、我々のために通信を管理するバックエンド・ライブラリである。"
  },
  {
    "start": 3001946,
    "end": 3008148,
    "text": "トレーニングに使用するファイル名以降のパラメータはすべて、ここでこのファイルに渡される引数である。"
  },
  {
    "start": 3008234,
    "end": 3010772,
    "text": "この場合、バッチサイズは8である。"
  },
  {
    "start": 3010826,
    "end": 3015624,
    "text": "また、チェックポイントを保存すべきモデルフォルダーも伝えている。"
  },
  {
    "start": 3015662,
    "end": 3019080,
    "text": "これは前に作成した共有フォルダだ。"
  },
  {
    "start": 3019150,
    "end": 3024728,
    "text": "共有ネットワーク・ドライブのマウント・ファイルを作成するために、両方のコンピューターで同じコマンドを実行する。"
  },
  {
    "start": 3024744,
    "end": 3025900,
    "text": "これでトレーニングが始まる。"
  },
  {
    "start": 3025970,
    "end": 3033470,
    "text": "この試合でも、他の試合でもそうしている。"
  },
  {
    "start": 3033940,
    "end": 3036476,
    "text": "見ての通り、このコンピューターは進んでいない。"
  },
  {
    "start": 3036508,
    "end": 3037712,
    "text": "もう一方を待っている。"
  },
  {
    "start": 3037766,
    "end": 3042320,
    "text": "ここでも実行する。"
  },
  {
    "start": 3047900,
    "end": 3051740,
    "text": "そう、だから今はどちらも進んでいる。"
  },
  {
    "start": 3052800,
    "end": 3057852,
    "text": "おっと、このコンピューターにホストファイルを設定するのを忘れていた。"
  },
  {
    "start": 3057986,
    "end": 3065856,
    "text": "こちらのIPを取得し、こちらのIPを取得し、こちらのホスト名を取得する。"
  },
  {
    "start": 3065878,
    "end": 3068048,
    "text": "もう一方のコンピュータのホスト・ファイルに置く。"
  },
  {
    "start": 3068134,
    "end": 3093144,
    "text": "もう一度走ろう"
  },
  {
    "start": 3093182,
    "end": 3114472,
    "text": "トレーニングは進んでいるようだ。"
  },
  {
    "start": 3114536,
    "end": 3120524,
    "text": "どちらもデータセットを作っているんだ。"
  },
  {
    "start": 3120562,
    "end": 3121496,
    "text": "今度はトークナイザーだ。"
  },
  {
    "start": 3121528,
    "end": 3133184,
    "text": "トランスフォーマーモデルをゼロからコーディングする方法についての以前のビデオをご覧になった方は、分散トレーニングを管理するためにいくつか追加した点を除けば、これはまったく同じコードですが、コードの変更はごくわずかです。"
  },
  {
    "start": 3133222,
    "end": 3135884,
    "text": "後ほど、その方法を順を追ってお見せしよう。"
  },
  {
    "start": 3135942,
    "end": 3138688,
    "text": "このように、トレーニングは並行して行われている。"
  },
  {
    "start": 3138864,
    "end": 3148248,
    "text": "最初に気づくのは、幅とバイアスが1つのノードでしか初期化されていないことです。なぜなら、複数のノードからメトリクスを送信すると、互いに干渉してしまうからです。"
  },
  {
    "start": 3148334,
    "end": 3152952,
    "text": "そのノードとはランクがゼロのノードである。"
  },
  {
    "start": 3153006,
    "end": 3155130,
    "text": "この情報をどのようにチェックするかは後述する。"
  },
  {
    "start": 3155660,
    "end": 3158712,
    "text": "ご覧の通り、両者ともデータのサブセットでトレーニングを行っている。"
  },
  {
    "start": 3158766,
    "end": 3162424,
    "text": "こちらは910バッチのトレーニングで、こちらも910バッチ。"
  },
  {
    "start": 3162472,
    "end": 3168350,
    "text": "合計で1820バッチということになる。"
  },
  {
    "start": 3168800,
    "end": 3175644,
    "text": "それぞれが局所的な勾配を計算し、それをもう一方に送る。"
  },
  {
    "start": 3175772,
    "end": 3178556,
    "text": "実際、ここには4つのGpuがあるので、4つのノードがある。"
  },
  {
    "start": 3178588,
    "end": 3193872,
    "text": "各GPUはローカル勾配を計算し、各勾配はランク番号ゼロに送られ、ランク番号ゼロはreduce演算を使ってこれらの勾配の総和を計算する。"
  },
  {
    "start": 3193936,
    "end": 3204468,
    "text": "実際、\"all reduce \"操作は、他のすべてのノードに合計を送り返し、そのノードは受け取った勾配の合計を使ってパラメーターを更新するからだ。"
  },
  {
    "start": 3204644,
    "end": 3211724,
    "text": "もうひとつ間違えたのは、この910が2倍になっていないことだ。"
  },
  {
    "start": 3211842,
    "end": 3215128,
    "text": "ローカルランクとグローバルランクの違いについては後述する。"
  },
  {
    "start": 3215224,
    "end": 3216536,
    "text": "ノードは4つある。"
  },
  {
    "start": 3216568,
    "end": 3220270,
    "text": "各ノードは910バッチのデータを処理している。"
  },
  {
    "start": 3220640,
    "end": 3224948,
    "text": "TQDMがそうしないから、私は1つしか見せていない。"
  },
  {
    "start": 3224984,
    "end": 3229632,
    "text": "そうしないと、両方のGPUのTQDMを表示すると、お互いに干渉してしまう。"
  },
  {
    "start": 3229686,
    "end": 3231296,
    "text": "このプログレスバーは基本的にここにある。"
  },
  {
    "start": 3231398,
    "end": 3236544,
    "text": "各コンピューターには2つのGpusがあるので、プログレスバーは2つではなく、1つのコンピューターにつき1つしか表示しない。"
  },
  {
    "start": 3236592,
    "end": 3239636,
    "text": "本当はプログレスバーは2つあるはずなのに、1つしか表示されていない。"
  },
  {
    "start": 3239658,
    "end": 3242150,
    "text": "そうでなければ、視覚化は非常に悪い。"
  },
  {
    "start": 3242520,
    "end": 3245976,
    "text": "まずは、このコードがどのように機能するのかを理解するために、コードをナビゲートしてみよう。"
  },
  {
    "start": 3246078,
    "end": 3247850,
    "text": "プロジェクトを開いてみよう。"
  },
  {
    "start": 3262790,
    "end": 3266114,
    "text": "さて、ここで見てみよう。"
  },
  {
    "start": 3266232,
    "end": 3268450,
    "text": "列車ファイルから始めよう。"
  },
  {
    "start": 3269990,
    "end": 3270740,
    "text": "オーケー。"
  },
  {
    "start": 3271270,
    "end": 3278280,
    "text": "前のビデオで作ったオリジナルのコードと比べた主な違いは、同じですが。"
  },
  {
    "start": 3278650,
    "end": 3282662,
    "text": "ここで紹介する変更は、あなたが構築したどのトレーニングループにも適用できる。"
  },
  {
    "start": 3282716,
    "end": 3286138,
    "text": "このコードだけでなく、誰にでも当てはまる。"
  },
  {
    "start": 3286304,
    "end": 3291418,
    "text": "さて、最初にすることは、この2つの変数を読み込むことだ。"
  },
  {
    "start": 3291584,
    "end": 3299774,
    "text": "torch runでコードを実行すると、torch runが環境変数を環境に挿入してくれる。"
  },
  {
    "start": 3299892,
    "end": 3302426,
    "text": "ひとつはランクと呼ばれるもので、もうひとつはローカルランクと呼ばれるものだ。"
  },
  {
    "start": 3302458,
    "end": 3303600,
    "text": "その違いを見てみよう。"
  },
  {
    "start": 3304450,
    "end": 3305200,
    "text": "オーケー。"
  },
  {
    "start": 3306370,
    "end": 3320798,
    "text": "ローカルランクは、基本的にローカルコンピュータ内のGPUの数を示し、グローバルランク（単にランクとも呼ばれる）は、すべてのクラスタの中でGPUのユニークなIDの数を示します。"
  },
  {
    "start": 3320894,
    "end": 3330006,
    "text": "もし4つのGpusがあれば、ランクはすべてのクラスタの中で一意になるが、ローカルランクは一意ではなく、ローカルコンピュータに一意である。"
  },
  {
    "start": 3330188,
    "end": 3344170,
    "text": "ローカル・ランクは、たとえば、各コンピューターごとに1つのGPUだけで印刷したい場合に便利であり、グローバル・ランクは、他のすべてのGPUの中で1つのGPUだけに処理を実行させたい場合に便利である。"
  },
  {
    "start": 3344320,
    "end": 3356160,
    "text": "例えば、重みとバイアスを初期化したい場合、あるいはクラスタ内の1つのノードからのみ初期化されるべき他のサービスを初期化したい場合、グローバルランクを使用する。"
  },
  {
    "start": 3356850,
    "end": 3370050,
    "text": "一方、例えば印刷のために何かを使いたい場合、あるいはTQDMやプログレス・バーなど、ローカル・コンピューター上で互いに干渉しあう可能性のあるものは、ローカル・ランクを使う。"
  },
  {
    "start": 3370630,
    "end": 3375830,
    "text": "まず最初にすることは、この2つの環境変数をロードしてコンフィギュレーションに保存することだ。"
  },
  {
    "start": 3376170,
    "end": 3379010,
    "text": "次にすることは、設定を印刷することだ。"
  },
  {
    "start": 3379170,
    "end": 3385258,
    "text": "まず最初にクラスターを初期化する必要があるが、ここでトーチの動作は停止する。"
  },
  {
    "start": 3385344,
    "end": 3389898,
    "text": "すべてのノードが接続するのを待つには、ここでこの関数を呼び出す必要がある。"
  },
  {
    "start": 3390064,
    "end": 3396922,
    "text": "このinitプロセスグループは、ここでインポートしたtorch distributedというパッケージに属している。"
  },
  {
    "start": 3397066,
    "end": 3401598,
    "text": "これらは、分散トレーニングを使用するために必要なインポートである。"
  },
  {
    "start": 3401684,
    "end": 3404234,
    "text": "トーチユーティルデータ配布"
  },
  {
    "start": 3404282,
    "end": 3410478,
    "text": "分散サンプラー、分散データ、initプロセスグループ、destroyプロセスグループが必要だ。"
  },
  {
    "start": 3410644,
    "end": 3412226,
    "text": "これが最初にすることだ。"
  },
  {
    "start": 3412248,
    "end": 3417326,
    "text": "環境変数を読み込んだら、それをどこかに保存し、ローカルとグローバルのランクにアクセスできるようにする。"
  },
  {
    "start": 3417438,
    "end": 3421282,
    "text": "ここでこの関数を呼び出し、使用するバックエンドを指定する。"
  },
  {
    "start": 3421416,
    "end": 3426070,
    "text": "私はCUDAを使っているので、NCCLであるニコルを使いたい。"
  },
  {
    "start": 3426410,
    "end": 3431522,
    "text": "また、ローカルランクを使用して、トレーニングを行うGPUをCUDAに伝えることもできます。"
  },
  {
    "start": 3431586,
    "end": 3438458,
    "text": "各コンピューターには、現在のコンピューターからの相対的なローカルランクが与えられ、各GPUには、現在のコンピューターからの相対的なローカルランクが与えられる。"
  },
  {
    "start": 3438544,
    "end": 3445850,
    "text": "1番目のGPUにはローカルランク0が割り当てられ、2番目のGPUにはローカルランク1が割り当てられます。"
  },
  {
    "start": 3446000,
    "end": 3452478,
    "text": "そしてトレーニングループを実行し、トレーニングループが終了したら、このトライ・プロセス・グループを実行する。"
  },
  {
    "start": 3452564,
    "end": 3454800,
    "text": "このトレーニンググループの詳細を見てみよう。"
  },
  {
    "start": 3455410,
    "end": 3462718,
    "text": "トレーニング・ループを実行するとき、まず、分散データ・パラレルを使っているので、ここではCPUでのトレーニングを無効にする。"
  },
  {
    "start": 3462734,
    "end": 3465950,
    "text": "バックエンドニッケルのみで、CuDAでのみ機能する。"
  },
  {
    "start": 3466030,
    "end": 3468290,
    "text": "CPUを無効にしている。"
  },
  {
    "start": 3468630,
    "end": 3472882,
    "text": "もうひとつは、データ・ローダーの作成だ。"
  },
  {
    "start": 3472946,
    "end": 3477430,
    "text": "ここでは、訓練データ・ローダーと検証データ・ローダーがある。"
  },
  {
    "start": 3477930,
    "end": 3483394,
    "text": "データ・ローダーのシャッフリングを無効にして、このパラメーター・サンプラーを導入する必要がある。"
  },
  {
    "start": 3483442,
    "end": 3484082,
    "text": "サンプラー"
  },
  {
    "start": 3484146,
    "end": 3490090,
    "text": "ここで分散サンプラーのインスタンスを渡す必要がある。"
  },
  {
    "start": 3490160,
    "end": 3491626,
    "text": "シャッフルしたい。"
  },
  {
    "start": 3491648,
    "end": 3495820,
    "text": "ここではデータローダーではなく、分散サンプラーを使ってシャッフルしている。"
  },
  {
    "start": 3497150,
    "end": 3503610,
    "text": "次にすることは、チェックポイントをプリロードするロジックを作ることだ。"
  },
  {
    "start": 3503690,
    "end": 3505994,
    "text": "チェックポイントをプリロードするかどうかをチェックする。"
  },
  {
    "start": 3506042,
    "end": 3511070,
    "text": "私の場合、デフォルトの設定では、常に最新のチェックポイントをロードすることになっている。"
  },
  {
    "start": 3511150,
    "end": 3512082,
    "text": "ここで見ることができる。"
  },
  {
    "start": 3512136,
    "end": 3518820,
    "text": "コンフィギュレーションでは、デフォルトのコンフィギュレーションでは、利用可能な最新のチェックポイントを事前に訓練したものをロードすることになっている。"
  },
  {
    "start": 3519430,
    "end": 3525186,
    "text": "コマンドで渡したパスを使って、最新のチェックポイント・ファイルを取得する。"
  },
  {
    "start": 3525218,
    "end": 3533800,
    "text": "チェックポイントを保存するディレクトリを示すパスがあり、これを使う。"
  },
  {
    "start": 3534910,
    "end": 3538650,
    "text": "最新のチェックポイントがあれば、それがモデルにロードされる。"
  },
  {
    "start": 3538720,
    "end": 3541434,
    "text": "我々のモデルはここで作られる。"
  },
  {
    "start": 3541472,
    "end": 3561060,
    "text": "モデルのインスタンスを作成します。基本的には、モデルのインスタンスを取得し、ここでステート・ディクティクとオプティマイザ・ステート・ディクティクをプリロードします。"
  },
  {
    "start": 3562790,
    "end": 3568430,
    "text": "グローバル・コンフィギュレーションのランクがゼロの場合、ウェイトやバイアスなどのサービスも初期化する。"
  },
  {
    "start": 3568590,
    "end": 3574082,
    "text": "ウェイトとバイアスの場合、最後にクラッシュした同じランからトレーニングを再開することもできる。"
  },
  {
    "start": 3574146,
    "end": 3580150,
    "text": "チェックポイントを保存するたびに、重みとバイアスのランIDも保存されます。"
  },
  {
    "start": 3580220,
    "end": 3583270,
    "text": "チェックポイントを復元すれば、復元できる。"
  },
  {
    "start": 3584910,
    "end": 3590282,
    "text": "分散型並列トレーニングを導入する大きなポイントはこれだ。"
  },
  {
    "start": 3590336,
    "end": 3592762,
    "text": "これでモデルはできた。"
  },
  {
    "start": 3592816,
    "end": 3595322,
    "text": "私のコードの場合は、トランスフォーマーのモデルである。"
  },
  {
    "start": 3595376,
    "end": 3599086,
    "text": "前のビデオで作った特別なクラスだ。"
  },
  {
    "start": 3599268,
    "end": 3601790,
    "text": "こちらはnnモデルだ。"
  },
  {
    "start": 3601860,
    "end": 3606846,
    "text": "これは分散データモデルのインスタンスに包む必要がある。"
  },
  {
    "start": 3606948,
    "end": 3607822,
    "text": "こちらをご覧いただきたい。"
  },
  {
    "start": 3607876,
    "end": 3610834,
    "text": "また、使用するデバイスIDも示します。"
  },
  {
    "start": 3610872,
    "end": 3617362,
    "text": "GPU idは、グローバルランクをゼロとしたローカルランクです。"
  },
  {
    "start": 3617416,
    "end": 3619074,
    "text": "他のものを初期化することもできる。"
  },
  {
    "start": 3619192,
    "end": 3621106,
    "text": "この場合はウェイトとバイアスだけだ。"
  },
  {
    "start": 3621218,
    "end": 3630310,
    "text": "トレーニング・ループは非並列コードと同じだが、モデルを直接実行しない点が異なる。"
  },
  {
    "start": 3630380,
    "end": 3637290,
    "text": "モデル・フォワードを行う前であれば、モデル・モジュール・フォワードを行う必要がある。"
  },
  {
    "start": 3637440,
    "end": 3654730,
    "text": "モデルのエンコードメソッド（例えばこのメソッド）にアクセスする必要がある場合、model encodeにアクセスすることはできない。"
  },
  {
    "start": 3654890,
    "end": 3658590,
    "text": "元のモデルを取得したい場合は、モデルモジュールを行う必要がある。"
  },
  {
    "start": 3659090,
    "end": 3676978,
    "text": "このモジュールでlost backwardを実行するたびに、Pytorchはこれをインターセプトし、ローカル勾配を計算する。ローカル勾配を計算した後、それを他のすべてのノードに送信して蓄積し、蓄積された勾配を受信する。"
  },
  {
    "start": 3677074,
    "end": 3693622,
    "text": "この累積勾配は、オプティマイザー・ステップを使用するときに使用され、チェックポイントを保存するときには、オプティマイザー・ゼロがこれをゼロにリセットする。"
  },
  {
    "start": 3693686,
    "end": 3706138,
    "text": "私の場合、エポックごとにチェックポイントを保存するのですが、すべてのノードにチェックポイントを保存すると、お互いのチェックポイントが上書きされてしまうので、グローバル・ランク番号ゼロにのみ保存しています。"
  },
  {
    "start": 3706234,
    "end": 3710500,
    "text": "ここにあるように、私はグローバル・ランクゼロの時だけやっている。"
  },
  {
    "start": 3711110,
    "end": 3714562,
    "text": "これが、私たちがやるべきことのほとんどだ。"
  },
  {
    "start": 3714696,
    "end": 3721734,
    "text": "分散データ・パラレルを既存のコードに統合する方法について、今後のプロジェクトで使えるテンプレートをお見せしよう。"
  },
  {
    "start": 3721772,
    "end": 3722760,
    "text": "見てみよう。"
  },
  {
    "start": 3724650,
    "end": 3730706,
    "text": "よし、これは今後のプロジェクトに従うべきテンプレートだ。"
  },
  {
    "start": 3730818,
    "end": 3735538,
    "text": "最初にすることは、ローカルランクとランクと呼ばれる2つの環境変数を読み込むことだ。"
  },
  {
    "start": 3735714,
    "end": 3744022,
    "text": "最初の数字はローカルランクを示し、先ほど見た数字と同じで、クラスタ全体ではなくローカルコンピュータに対するGPUの相対的な数字です。"
  },
  {
    "start": 3744086,
    "end": 3751066,
    "text": "2番目はグローバルランクを示し、クラスタのすべてのGPUの中で、この特定のGPUを一意に識別します。"
  },
  {
    "start": 3751258,
    "end": 3753454,
    "text": "次に、関数initプロセスグループを呼び出す。"
  },
  {
    "start": 3753492,
    "end": 3762062,
    "text": "Cudaの場合、使用するバックエンドを指定するのですが、ほとんどの場合はニッケルだと思います。"
  },
  {
    "start": 3762206,
    "end": 3767150,
    "text": "もうひとつは、CudAがどのデバイスを使うかを設定することだ。"
  },
  {
    "start": 3767230,
    "end": 3772262,
    "text": "次に、グローバル・ランク番号ゼロに対してのみトレーニング・ループを実行する。"
  },
  {
    "start": 3772316,
    "end": 3776626,
    "text": "ウェイトやバイアスなどのサービスを初期化する。"
  },
  {
    "start": 3776818,
    "end": 3790698,
    "text": "データ・ローダーは、サンプラーとして分散サンプラーを使うように指示し、データ・ローダー上にモデルのインスタンスを作成する。"
  },
  {
    "start": 3790784,
    "end": 3805150,
    "text": "最新のチェックポイントがあれば、それをロードすることができる。最新のチェックポイントをロードした後は、分散データパラレルのインスタンスにモデルをラップする必要がある。"
  },
  {
    "start": 3805490,
    "end": 3811246,
    "text": "グローバルランクがゼロであることを除けば、あとはすべて同じである。"
  },
  {
    "start": 3811278,
    "end": 3827026,
    "text": "例えば、重みとバイアスにいくつかの統計情報を送信し、グローバル・ランク番号がゼロの場合のみ、エポックごとにモデルの状態を保存することができる。"
  },
  {
    "start": 3827218,
    "end": 3829350,
    "text": "クラッシュをシミュレートしてみよう。"
  },
  {
    "start": 3830650,
    "end": 3833622,
    "text": "さあ、トレーニングの様子を見に行こう。"
  },
  {
    "start": 3833676,
    "end": 3837514,
    "text": "おわかりのように、私たちはすでにエポック・ナンバーワンのトレーニングを行っている。"
  },
  {
    "start": 3837552,
    "end": 3849360,
    "text": "エポックはすでに終了しており、コードは、私がここで作成したコードを見てわかるように、グローバル・ランク番号ゼロに対してのみ検証を実行するような形にする必要がある。"
  },
  {
    "start": 3850610,
    "end": 3855022,
    "text": "実は、この分散トレーニング中にバリデーションを行う必要はない。"
  },
  {
    "start": 3855076,
    "end": 3875842,
    "text": "例えば、最新のチェックポイントを読み込み、検証を非同期で実行する別のノードを作成することで、gpuが直接作業でき、常にトレーニングに集中でき、検証のために時間を浪費することがなくなります。"
  },
  {
    "start": 3875906,
    "end": 3879270,
    "text": "大型モデルには高額になることもある。"
  },
  {
    "start": 3879850,
    "end": 3881990,
    "text": "非同期でできる。"
  },
  {
    "start": 3883530,
    "end": 3890746,
    "text": "これで、すべてのノードがエポック1をトレーニングしていることがわかる。"
  },
  {
    "start": 3890848,
    "end": 3902362,
    "text": "クラッシュをシミュレートして、分散トレーニングがすでに終了したエポック番号ゼロのチェックポイントから再開されることを確認してみる。"
  },
  {
    "start": 3902426,
    "end": 3904842,
    "text": "クラッシュさせよう"
  },
  {
    "start": 3904986,
    "end": 3909730,
    "text": "マスターノードを直接クラッシュさせるので、最悪のシナリオを試すことができる。"
  },
  {
    "start": 3910630,
    "end": 3912494,
    "text": "これはクラッシュした。"
  },
  {
    "start": 3912542,
    "end": 3917780,
    "text": "そのノードを殺すと、しばらくしてこのノードも殺されるはずだとわかる。"
  },
  {
    "start": 3920330,
    "end": 3922738,
    "text": "よし、これも殺された。"
  },
  {
    "start": 3922914,
    "end": 3926680,
    "text": "前と同じコマンドで再開できる。"
  },
  {
    "start": 3935220,
    "end": 3945130,
    "text": "ご覧のように、データセットのロード、トークナイザーのロード、モデルのプリロードを行っている。"
  },
  {
    "start": 3945200,
    "end": 3950042,
    "text": "ご覧のように、以前はグローバルランク0番で保存されていたモデルである。"
  },
  {
    "start": 3950096,
    "end": 3955310,
    "text": "この場合、0番目のエポックからではなく、最初のエポックから学習を再開する必要がある。"
  },
  {
    "start": 3960330,
    "end": 3963398,
    "text": "そう、彼らはエポック・ナンバー1からスタートしている。"
  },
  {
    "start": 3963484,
    "end": 3969702,
    "text": "というのも、エポック数はすでに実行されており、これがフェイルオーバーの仕組みだからだ。"
  },
  {
    "start": 3969836,
    "end": 3975814,
    "text": "基本的には、たまにチェックポイントを保存し、そのチェックポイントからトレーニングを再開する。"
  },
  {
    "start": 3975942,
    "end": 3981210,
    "text": "チェックポイントを保存する際には、トレーニングを再開するために必要なすべての変数も保存する必要があります。"
  },
  {
    "start": 3981360,
    "end": 3989134,
    "text": "例えば、グローバル・ステップ・カウンターのようなステート変数がある場合、あるいは他のカウンターを追跡する必要がある場合。"
  },
  {
    "start": 3989172,
    "end": 3993070,
    "text": "チェックポイントに保存しておけば、チェックポイントをロードしたときに復元できる。"
  },
  {
    "start": 3997160,
    "end": 3998996,
    "text": "よし、トレーニングはここでやめよう。"
  },
  {
    "start": 3999098,
    "end": 4002520,
    "text": "紙のスペースを使って自分で実験してみるといい。"
  },
  {
    "start": 4002590,
    "end": 4003592,
    "text": "簡単だと思うよ。"
  },
  {
    "start": 4003646,
    "end": 4005112,
    "text": "何か問題があったら言ってくれ。"
  },
  {
    "start": 4005166,
    "end": 4006568,
    "text": "力になれるよう努力するよ。"
  },
  {
    "start": 4006734,
    "end": 4013896,
    "text": "では、分散並列トレーニング、つまり分散データ並列がどのようにPytorchに統合されたかを見てみよう。"
  },
  {
    "start": 4013928,
    "end": 4019676,
    "text": "というのも、非常に速くするために、いくつかの巧妙な設計上の選択があるからだ。"
  },
  {
    "start": 4019858,
    "end": 4023580,
    "text": "まず最初に、Pytorchはいつ勾配を同期させるのですか？"
  },
  {
    "start": 4023740,
    "end": 4037568,
    "text": "というのも、ロスト・バックワードと呼ぶと、各ノードがローカル勾配を計算することになり、これは計算グラフの各ノードに関する損失関数の微分だからだ。"
  },
  {
    "start": 4037744,
    "end": 4048112,
    "text": "各ノードは、そのローカル勾配をグローバル・ランク番号ゼロである中央ノードに送り、すでに使用されている演算によって累積勾配を受信する。"
  },
  {
    "start": 4048266,
    "end": 4070492,
    "text": "各ノードは重みを更新し、累積勾配ともちろんローカル・オプティマイザの学習率を使用してモデルのパラメータを更新します。Pytorchが後方ステップごとに勾配を同期するのを避け、代わりに数ステップ、例えば同期なしのコンテキストを使用して数バッチ分、勾配を累積させることができます。"
  },
  {
    "start": 4070626,
    "end": 4077920,
    "text": "通常、フォワードとフォワードステップを走り、次にバックワードステップを走る。"
  },
  {
    "start": 4077990,
    "end": 4079756,
    "text": "これが同調につながる。"
  },
  {
    "start": 4079868,
    "end": 4084700,
    "text": "その後、オプティマイザー・ステップを行い、オプティマイザー・ゼログラッドを行う。"
  },
  {
    "start": 4084860,
    "end": 4090870,
    "text": "しかし、数エポックごとに同期を取りたいのであれば、ステップごとに同期を取る必要はない。"
  },
  {
    "start": 4091480,
    "end": 4100040,
    "text": "これは分散データ・パラレルが提供するメソッドで、我々のモデルのラッパーである。"
  },
  {
    "start": 4100190,
    "end": 4103108,
    "text": "基本的には、このコンテキスト・マネージャーを作成する。"
  },
  {
    "start": 4103284,
    "end": 4113484,
    "text": "フォワード・ステップとバックワード・ステップを実行し、このコンテキストの外にいるときはオプティマイザー・ステップを呼び出さない。"
  },
  {
    "start": 4113522,
    "end": 4116072,
    "text": "そして、オプティマイザーのステップを実行し、グラッドをゼロにすることができる。"
  },
  {
    "start": 4116136,
    "end": 4127360,
    "text": "基本的に、この同期なしはグラデーションの同期を無効にするが、しばらくの間はローカルに蓄積させ、しばらくしたら同期できるようにする。"
  },
  {
    "start": 4128820,
    "end": 4134188,
    "text": "また、Pytorchにはもうひとつ、計算通信のオーバーラップという非常に巧妙なトリックがある。"
  },
  {
    "start": 4134364,
    "end": 4145396,
    "text": "GPUはグラジェントを中央のノードに送って蓄積する必要があるため、GPUが通信している間、アイドルタイムが発生する可能性があります。"
  },
  {
    "start": 4145418,
    "end": 4163452,
    "text": "各GPUは前方ステップを実行し、次に後方ステップを実行します。各GPUは互いに勾配を同期させ、1つのノードで累積を計算し、累積を受信する必要があるため、通信オーバーヘッドが発生します。"
  },
  {
    "start": 4163586,
    "end": 4172590,
    "text": "この操作を逐次的に行うと、gpuに大きな遅延が発生する。"
  },
  {
    "start": 4173760,
    "end": 4181248,
    "text": "Pytorがすることは、後方ステップを実行しながら通信をオーバーラップさせることだ。"
  },
  {
    "start": 4181414,
    "end": 4182864,
    "text": "どう動くか見てみよう。"
  },
  {
    "start": 4182982,
    "end": 4187524,
    "text": "覚えているように、我々は計算グラフを持っているよね？"
  },
  {
    "start": 4187562,
    "end": 4197056,
    "text": "Pytorchはノードの勾配が利用可能になり次第、そのノードの勾配を伝える。覚えているように、我々は各重みに関して損失関数の勾配を計算するからだ。"
  },
  {
    "start": 4197088,
    "end": 4204208,
    "text": "各重みに関する損失関数の勾配を計算するために、中間ノードに関する損失関数の勾配を計算する必要がある。"
  },
  {
    "start": 4204304,
    "end": 4209192,
    "text": "そこで例えば、まず出力に対する損失関数の勾配を計算する。"
  },
  {
    "start": 4209256,
    "end": 4217420,
    "text": "次に、この層の重み（重みとバイアス）に対する損失関数を計算する。"
  },
  {
    "start": 4217760,
    "end": 4223852,
    "text": "これらのノードはすでに利用可能なので、他のノードに送信し、累積したものを取り戻すことができる。"
  },
  {
    "start": 4223906,
    "end": 4226636,
    "text": "これはすでにこの作戦として実行できる。"
  },
  {
    "start": 4226748,
    "end": 4237152,
    "text": "そしてPytorchが次のレイヤーを計算し、このレイヤーはすでに利用可能なので、すでに他のノードに送信し、累積されたレイヤーを受信することができる。"
  },
  {
    "start": 4237216,
    "end": 4247512,
    "text": "Pytorchが後方ステップを計算している間に、我々はすでに計算した勾配を他のノードに伝え、累積した勾配を受け取ることができる。"
  },
  {
    "start": 4247646,
    "end": 4250570,
    "text": "これは非常に速いスピードアップにつながる。"
  },
  {
    "start": 4251420,
    "end": 4259844,
    "text": "通信をさらに高速化するために、Pytorchは一度に1つの勾配を送信する代わりに、基本的に勾配のバケットを作成する。"
  },
  {
    "start": 4259892,
    "end": 4265976,
    "text": "バケットが利用可能になるたびに、そのバケットを他のノードに送信し、そのバケットの累積勾配を受信する。"
  },
  {
    "start": 4266088,
    "end": 4271508,
    "text": "そして、2つ目のバケットが利用可能になった後、2つ目のバケットを送信し、累積を受信する。"
  },
  {
    "start": 4271704,
    "end": 4277264,
    "text": "最後のバケットが利用可能になると、他のノードにバケットを送信し、バケットを受信する。"
  },
  {
    "start": 4277382,
    "end": 4287196,
    "text": "こうすることで、前に見たように、通信のオーバーヘッドと後進の計算をオーバーラップさせることができる。"
  },
  {
    "start": 4287238,
    "end": 4300890,
    "text": "勾配を計算している間に、すでに勾配を送信しているので、前方、後方、通信、更新の合計の処理時間は、2つのステップが互いに重なっているので短くなる。"
  },
  {
    "start": 4301820,
    "end": 4311452,
    "text": "Pytorchはバケットのサイズとして25メガバイトを推奨しているが、これはバケットごとの通信のオーバーヘッドが大きくなりすぎるため、あまり小さくしたくないからだ。"
  },
  {
    "start": 4311506,
    "end": 4320220,
    "text": "各バケツには多くのオーバーヘッドがあるので、このオーバーヘッドをより大きなバケツに分散させることで、数は少なくても大きなバケツを作ることができる。"
  },
  {
    "start": 4320640,
    "end": 4331040,
    "text": "そうでなければ、グラデーションの計算中に通信チャネルを使用しないことになるからだ。"
  },
  {
    "start": 4331540,
    "end": 4333712,
    "text": "僕のビデオを見てくれてありがとう。"
  },
  {
    "start": 4333766,
    "end": 4335168,
    "text": "多くのことを学んでいただけたと思う。"
  },
  {
    "start": 4335254,
    "end": 4346304,
    "text": "このビデオでは、データ並列トレーニングについて紹介し、最初のインフラの作成方法と、作成したインフラ上で分散トレーニングのコードを実行する方法を紹介する。"
  },
  {
    "start": 4346432,
    "end": 4355652,
    "text": "また、グラデーションがどのように同期されるのか、数学的なレベルでも理解できるように、Pytorchがボンネットの中でどのように動作するのかも紹介する。"
  },
  {
    "start": 4355706,
    "end": 4356950,
    "text": "どのように機能するのか？"
  },
  {
    "start": 4357400,
    "end": 4361964,
    "text": "もし気に入っていただけたなら、そしてお役に立ったなら、ぜひ「いいね！」とビデオを購読してください。"
  },
  {
    "start": 4362002,
    "end": 4371772,
    "text": "また、私の他のビデオも見ることをお勧めする。なぜなら、私は毎回、多くの知識を提供する長いビデオを作るからだ。"
  },
  {
    "start": 4371826,
    "end": 4372250,
    "text": "ありがとう。"
  }
]