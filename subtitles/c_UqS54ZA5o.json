[
  {
    "start": 570,
    "end": 4682,
    "text": "ガシュバル・ベゴスは、言語学者としてのllmについて語るだろう。"
  },
  {
    "start": 4826,
    "end": 5854,
    "text": "本当にありがとう。"
  },
  {
    "start": 5972,
    "end": 6640,
    "text": "ありがとう。"
  },
  {
    "start": 7970,
    "end": 9194,
    "text": "金曜日の午後。"
  },
  {
    "start": 9322,
    "end": 17486,
    "text": "今日はllmsの金属言語能力についてお話ししたいと思いますが、これからお話しする論文はすべてここにアップロードされています。"
  },
  {
    "start": 17588,
    "end": 22640,
    "text": "これまでのところ、私たちが学んだことは、llmsはかなりうまく言語を操れるということだ。"
  },
  {
    "start": 23330,
    "end": 26630,
    "text": "今では比較的受け入れられていると思う。"
  },
  {
    "start": 27050,
    "end": 32898,
    "text": "カリフォルニア大学バークレー校で開催されるllmsのワークショップについて詩を書いてもらうことができる。"
  },
  {
    "start": 32914,
    "end": 34040,
    "text": "その通りだ。"
  },
  {
    "start": 34410,
    "end": 37574,
    "text": "この文章を理解するように頼むことができる。"
  },
  {
    "start": 37612,
    "end": 42540,
    "text": "犬が描いた猫の口、トッドの歌、誰が何をした？"
  },
  {
    "start": 45150,
    "end": 47722,
    "text": "GPTは問題ない。"
  },
  {
    "start": 47776,
    "end": 52210,
    "text": "犬は猫を描き、猫はネズミに教え、ネズミは歌った。"
  },
  {
    "start": 52230,
    "end": 53578,
    "text": "ここは寝具の中心だ。"
  },
  {
    "start": 53674,
    "end": 59930,
    "text": "彼らはこれを認知モデルとしてよく理解している。"
  },
  {
    "start": 60090,
    "end": 63102,
    "text": "人間の言語学習のモデルとして。"
  },
  {
    "start": 63236,
    "end": 66690,
    "text": "あのトランスフォーマーが最高のモデルだとは思わない。"
  },
  {
    "start": 67030,
    "end": 67442,
    "text": "なぜですか？"
  },
  {
    "start": 67496,
    "end": 70930,
    "text": "テキストの山から学ぶ赤ちゃんはいない。"
  },
  {
    "start": 71080,
    "end": 75460,
    "text": "GPT4のように、たくさんのテキストから学ぶ赤ちゃんはいない。"
  },
  {
    "start": 76390,
    "end": 79154,
    "text": "赤ちゃんは、生産知覚のループなしに学ぶことはできない。"
  },
  {
    "start": 79202,
    "end": 79462,
    "text": "そうだね。"
  },
  {
    "start": 79516,
    "end": 82200,
    "text": "私たちが言葉を学ぶ方法は、話すことと聞くことだ。"
  },
  {
    "start": 83370,
    "end": 91286,
    "text": "最初の5年、7年は文字の代わりに音声を使いますが、読み始める時期にもよります。"
  },
  {
    "start": 91478,
    "end": 94054,
    "text": "どんな赤ちゃんも、コミュニケーションの意図なしに学ぶことはない。"
  },
  {
    "start": 94182,
    "end": 99286,
    "text": "だから実際、言語モデリングをしようとするときは、ガンスのほうがいい。"
  },
  {
    "start": 99398,
    "end": 105994,
    "text": "さて、このトークはトランスフォーマーのワークショップなので、ガンズについて話すものではない。"
  },
  {
    "start": 106122,
    "end": 111534,
    "text": "コグニティブ・モデリングでは、連続的な音声データから人間のように学習する。"
  },
  {
    "start": 111652,
    "end": 119410,
    "text": "人間が言語を学ぶのと同じような方法で、象徴的な表現を得るのだ。"
  },
  {
    "start": 119750,
    "end": 123326,
    "text": "知覚の生産ループがあるモデルを作ることができる。"
  },
  {
    "start": 123438,
    "end": 130950,
    "text": "ガンの本当に面白いところは、模倣的想像力によって学習すること、コミュニケーションの意図を持っていることなどだ。"
  },
  {
    "start": 131100,
    "end": 137382,
    "text": "認知的言語発達のモデルとして、私はllmsが素晴らしいとは思わない。"
  },
  {
    "start": 137516,
    "end": 140246,
    "text": "つまり、彼らともいろいろなことができる。"
  },
  {
    "start": 140428,
    "end": 145594,
    "text": "音声のもう一つの利点は、音声はテキストよりも多くの点で解釈しやすいということだ。"
  },
  {
    "start": 145632,
    "end": 150460,
    "text": "後ほど少しお話ししますが、このようなイントロスペクションの解釈可能性を実現することができます。"
  },
  {
    "start": 151970,
    "end": 160190,
    "text": "私は、現実的な人間のような言語学習モデルという点では、llmsに特に魅力を感じていない。"
  },
  {
    "start": 160340,
    "end": 169026,
    "text": "人工神経計算の可能性を教えてくれるという点で、私は彼らに魅了されているんだ。"
  },
  {
    "start": 169128,
    "end": 171090,
    "text": "明らかに言語だ。"
  },
  {
    "start": 171990,
    "end": 173442,
    "text": "彼らは語学がかなりできる。"
  },
  {
    "start": 173496,
    "end": 184306,
    "text": "言語能力は、ニューロンやその他のデバイスのような言語を持たない人工的な神経回路網に現れる可能性がある。"
  },
  {
    "start": 184498,
    "end": 189270,
    "text": "アンの可能性を教えてくれる素晴らしい存在だ。"
  },
  {
    "start": 189770,
    "end": 198566,
    "text": "次のフロンティアは何だろうかと考えたとき、言語というものがよく知られている今、私たちは皆、LMSが言語をうまく使うことに同意している。"
  },
  {
    "start": 198758,
    "end": 209694,
    "text": "歳児を考えてみると、彼らはかなり上手に話せるし、言葉も上手だが、名詞が何なのか、動詞が何なのか、音声が何なのかを伝えることはできないだろう。"
  },
  {
    "start": 209732,
    "end": 213380,
    "text": "フリカティブとは声門停止のことだが、彼らはそれを使っている。"
  },
  {
    "start": 214470,
    "end": 221906,
    "text": "私たちが検証したかったのは、このような大規模な言語モデルは言語そのものを推論できるのか、ということだ。"
  },
  {
    "start": 222088,
    "end": 233394,
    "text": "これはLLMのメタ認知能力をテストしているようなもので、LLMができるメタ認知能力で最も簡単なのは金属言語学だろう。"
  },
  {
    "start": 233442,
    "end": 233750,
    "text": "なぜですか？"
  },
  {
    "start": 233820,
    "end": 237110,
    "text": "彼らは基本的に言語について訓練されているからね。"
  },
  {
    "start": 237180,
    "end": 239318,
    "text": "彼らのトレーニングデータは言語である。"
  },
  {
    "start": 239414,
    "end": 243660,
    "text": "彼らは言語そのものを分析できるのだろうか？"
  },
  {
    "start": 244830,
    "end": 246986,
    "text": "なぜこの質問が重要なのか？"
  },
  {
    "start": 247168,
    "end": 252126,
    "text": "基本的には、次のレベルの能力のためにネットワークをテストすることができる、ということだね。"
  },
  {
    "start": 252148,
    "end": 257950,
    "text": "認知的には、金属言語学は発達の後半に来るため、より複雑である。"
  },
  {
    "start": 258850,
    "end": 276718,
    "text": "また、言語形式論、つまり、チョムスキーやそれ以前の人々によって開発された言語形式論が、これらのモデルの行動解釈可能性を実現するための非常に優れたツールであることを示そうと思います。"
  },
  {
    "start": 276814,
    "end": 284434,
    "text": "今はもう内省的な解釈はできないし、簡単にはできない。"
  },
  {
    "start": 284562,
    "end": 293130,
    "text": "GPD4が言語構造にアクセスできるのか、あるいは言語構造を学習できるのか、モデル自身に尋ねることができる。"
  },
  {
    "start": 293200,
    "end": 293434,
    "text": "そうだね。"
  },
  {
    "start": 293472,
    "end": 295958,
    "text": "これは一種の言語理論だ。"
  },
  {
    "start": 296134,
    "end": 302918,
    "text": "フォーマリズムは、モデルのビヘイビアをイントロスペクトするのにとてもいいツールで、私がビヘイビア・インタープリタビリティと呼んでいるものだ。"
  },
  {
    "start": 303094,
    "end": 307694,
    "text": "だから、昔、モデルがまだ小さかった頃は、今でもそれができたんだと思う。"
  },
  {
    "start": 307812,
    "end": 313380,
    "text": "解釈可能性とは、ニューロンの内部を見て、ああ、このニューロンはそんなことはしていない、と言えるということだ。"
  },
  {
    "start": 313750,
    "end": 330758,
    "text": "今、モデルは独自に開発された巨大なもので、高度な計算をするのは本当に難しい。しかし、行動解釈可能性という別のツールがある。"
  },
  {
    "start": 330844,
    "end": 332550,
    "text": "あるいは、どうやってこの答えを導き出したのですか？"
  },
  {
    "start": 332700,
    "end": 338002,
    "text": "金属言語学的な側面は、その最も簡単な方法の一つである。"
  },
  {
    "start": 338156,
    "end": 339740,
    "text": "最も簡単な方法だ。"
  },
  {
    "start": 341150,
    "end": 344422,
    "text": "これまでのところ、モデルは金属言語学には向いていなかった。"
  },
  {
    "start": 344486,
    "end": 344666,
    "text": "そうだね。"
  },
  {
    "start": 344688,
    "end": 349820,
    "text": "GPT-3は禁止され、他のモデルもあまり良くなく、一貫した答えが得られない。"
  },
  {
    "start": 352210,
    "end": 354560,
    "text": "彼らは言語そのものを分析することはできなかった。"
  },
  {
    "start": 355730,
    "end": 363382,
    "text": "私たちは、GPT4が金属言語分析を首尾一貫して行うことができる最初のモデルであるかもしれないと主張する。"
  },
  {
    "start": 363466,
    "end": 370382,
    "text": "基本的には言語学者として、言語理論、言語形式論を使って文章を分析することができる。"
  },
  {
    "start": 370526,
    "end": 372018,
    "text": "これはどう見える？"
  },
  {
    "start": 372104,
    "end": 379618,
    "text": "文の中で誰が何をしたのか、ネズミが、猫が、犬が、トッドの歌を歌った。"
  },
  {
    "start": 379714,
    "end": 385250,
    "text": "また、チョムスキーの統語論的形式論を使って、この文章を分析することもできる。"
  },
  {
    "start": 385410,
    "end": 401950,
    "text": "これは、言語学者がトリプル・セントラル・アベッティング・センテンスをどのように分析するのかを、ラテックスで表現したものである。"
  },
  {
    "start": 402370,
    "end": 406366,
    "text": "これでテストできることはいろいろある。"
  },
  {
    "start": 406388,
    "end": 416354,
    "text": "つまり、何十年もの間、シンタクトの研究者たちは、人々がどれくらいの構造を持っているのかを調べるために、とてもクールな例を示してきたんだ。"
  },
  {
    "start": 416392,
    "end": 420798,
    "text": "双眼鏡で象を見た。"
  },
  {
    "start": 420894,
    "end": 422334,
    "text": "この文章には2つの読み方がある。"
  },
  {
    "start": 422382,
    "end": 426434,
    "text": "象が双眼鏡を持っているか、双眼鏡で見たか。"
  },
  {
    "start": 426482,
    "end": 426982,
    "text": "そうだろう？"
  },
  {
    "start": 427116,
    "end": 436194,
    "text": "GPT-3にこの文章を分析させても、どちらの文章も同じ構造を示すだけだ。"
  },
  {
    "start": 436322,
    "end": 451242,
    "text": "さて、GPT4では、双眼鏡が動詞を修飾している第1文と、双眼鏡が象を修飾している第2文を見事に区別している。"
  },
  {
    "start": 451306,
    "end": 451582,
    "text": "そうだね。"
  },
  {
    "start": 451636,
    "end": 453706,
    "text": "安定したディフュージョンではできなかった。"
  },
  {
    "start": 453738,
    "end": 459310,
    "text": "エレファントV双眼鏡で安定した拡散ドローを作る方法は見つからなかった。"
  },
  {
    "start": 460530,
    "end": 478402,
    "text": "しかし、それを回避して、言語学の教科書にはあまり出てこないような他の文章を思いつく方法がある。"
  },
  {
    "start": 478466,
    "end": 480146,
    "text": "私は子ガメに餌をやった。"
  },
  {
    "start": 480258,
    "end": 483990,
    "text": "これは少し不適切な領域に入っている。"
  },
  {
    "start": 485130,
    "end": 487766,
    "text": "このセンテンス2には2つの読み方があるよね？"
  },
  {
    "start": 487868,
    "end": 493930,
    "text": "小さな子ガメがいて、その子ガメに餌をやったり、赤ちゃんがいて、その子ガメに餌をやったりする。"
  },
  {
    "start": 494910,
    "end": 500490,
    "text": "GPT4では、両方の読み方をうまく取り入れ、言語学者らしく分析している。"
  },
  {
    "start": 500640,
    "end": 512298,
    "text": "私は安定拡散でこれをやろうと必死になって、誰かがカメの赤ちゃんに餌をやっている、人間のカメの赤ちゃんに餌をやっている写真をどうやって作ろうかと言ったんだ。"
  },
  {
    "start": 512394,
    "end": 520674,
    "text": "悩んだ末に、スタイルを変えようかと思ったんだ。"
  },
  {
    "start": 520712,
    "end": 523710,
    "text": "明白な答えはヒロニーモス・ボッシュだ。"
  },
  {
    "start": 523790,
    "end": 531266,
    "text": "ヒエロニモス・ボス風に子亀をフィットさせたんだ。"
  },
  {
    "start": 531298,
    "end": 534054,
    "text": "これは最も悪いものでもない。"
  },
  {
    "start": 534092,
    "end": 535842,
    "text": "もっとひどい写真はある。"
  },
  {
    "start": 535906,
    "end": 541850,
    "text": "安定した拡散は、どうやらヒエロニムス・ボスのスタイルでしかできなかったようだ。"
  },
  {
    "start": 542590,
    "end": 546906,
    "text": "英語だけでなく、おそらくトレーニングでもできるだろう。"
  },
  {
    "start": 547008,
    "end": 554190,
    "text": "つまり、モデルには訓練で多くのラベル付きデータ、構文データがあるので、他の言語もできる可能性がある。"
  },
  {
    "start": 554530,
    "end": 556800,
    "text": "できることはいろいろある。"
  },
  {
    "start": 557650,
    "end": 570078,
    "text": "ドイツ語で、Vaskat hangagesenhat、ハンスは昨日何を食べたと言ったか、それは木を生み出す。"
  },
  {
    "start": 570254,
    "end": 578180,
    "text": "それは、言語学者にとっては、この背後にある構造を本当によく表していることを明らかにする良いことだろう。"
  },
  {
    "start": 578870,
    "end": 583382,
    "text": "モデルに確認させることができる、本当に細かいディテールなんだ。"
  },
  {
    "start": 583436,
    "end": 593898,
    "text": "私たちが歴史の中で学んできた、理論的な言語学的アプローチの数々を痕跡として残すことができる。"
  },
  {
    "start": 594064,
    "end": 603886,
    "text": "と言われるかもしれないが、これはすべて暗記したものであり、ここから一般化できるのであれば、さほど大きな問題ではない。"
  },
  {
    "start": 603988,
    "end": 606846,
    "text": "幸い、我々には音韻論がある。"
  },
  {
    "start": 606948,
    "end": 613650,
    "text": "そこでは、ネットワークが持っていないおもちゃの言語を作り上げることができる。"
  },
  {
    "start": 613800,
    "end": 628406,
    "text": "音韻理論にはあまり興味がないかと思いますが、例えば最適性理論など、大学院レベルの本当に複雑な音韻理論について、本当に有効な説明を与えてくれます。"
  },
  {
    "start": 628588,
    "end": 630946,
    "text": "私は意味分析もできる。"
  },
  {
    "start": 631058,
    "end": 637586,
    "text": "要するに、私が言いたいのは、言語形式論を使えば、私たちがこれまでテストしてきたようなあらゆることを本当にテストできるということだ。"
  },
  {
    "start": 637618,
    "end": 640666,
    "text": "本稿で取り上げたのは、そのほんの一部である。"
  },
  {
    "start": 640848,
    "end": 653102,
    "text": "もう1つ、本当に興味深いテストケースを挙げるとすれば、人間の言語だけが持っていると考えられている再帰性だ。"
  },
  {
    "start": 653156,
    "end": 661646,
    "text": "ある構成要素を取り出して、同じタイプの別の構成要素に無限に埋め込んでいくプロセスですね？"
  },
  {
    "start": 661668,
    "end": 664058,
    "text": "それは言葉の無限性だ。"
  },
  {
    "start": 664154,
    "end": 668622,
    "text": "例えば、メアリーはジョンがクジラには言語があると言ったと言った。"
  },
  {
    "start": 668766,
    "end": 672638,
    "text": "であれば、いつでもそれを上位の文に埋め込むことができる。"
  },
  {
    "start": 672814,
    "end": 680182,
    "text": "デビッドはメアリーが、ジョンはクジラにはこれがあり、人間にはこれがあると言った。"
  },
  {
    "start": 680236,
    "end": 686146,
    "text": "今、人工ニューラルネットワークをテストすることができる。"
  },
  {
    "start": 686258,
    "end": 688322,
    "text": "文章はいくつでも書ける。"
  },
  {
    "start": 688386,
    "end": 691466,
    "text": "これは再帰的な文章ですか、そうではありませんか？"
  },
  {
    "start": 691488,
    "end": 699580,
    "text": "そして、これらのセンテンスに再帰を追加してください。"
  },
  {
    "start": 700030,
    "end": 704890,
    "text": "例えば、猫がマーサの犬の尻尾を噛んだ。"
  },
  {
    "start": 704970,
    "end": 708734,
    "text": "猫がマーサの隣人の妹の犬の尻尾を噛んだ、とかね。"
  },
  {
    "start": 708772,
    "end": 710750,
    "text": "本当に長くなることもある。"
  },
  {
    "start": 710900,
    "end": 712926,
    "text": "視覚的再帰性についてもテストした。"
  },
  {
    "start": 712958,
    "end": 722766,
    "text": "視覚的な再帰性をどのように扱うことができるかというと、どうやら再帰的な構造でとても美しい絵を描くらしい。"
  },
  {
    "start": 722878,
    "end": 733506,
    "text": "このことから学べるのは、人間にしかできないと思われていた明示的再帰の能力が、このような大規模な言語モデルに現れる可能性があるということだ。"
  },
  {
    "start": 733538,
    "end": 746502,
    "text": "認知的にありえないモデルだとは言わないが、何が可能かを検証することはできるし、言語理論を彼らの内部表現への窓として持つこともできる。"
  },
  {
    "start": 746646,
    "end": 751594,
    "text": "今はモデルが巨大なため、内省はより難しくなっている。"
  },
  {
    "start": 751712,
    "end": 754602,
    "text": "もちろん、論文の中で論じているような落とし穴もある。"
  },
  {
    "start": 754746,
    "end": 758510,
    "text": "モデル・アーキテクチャがどのようなものなのか、正確にはわからない。"
  },
  {
    "start": 759170,
    "end": 760766,
    "text": "トレーニングデータが何だったのかはわからない。"
  },
  {
    "start": 760788,
    "end": 763594,
    "text": "それらは乗り越えられない課題ではないと述べた。"
  },
  {
    "start": 763642,
    "end": 766494,
    "text": "音韻を使うこともできるし、言葉を作ることもできる。"
  },
  {
    "start": 766622,
    "end": 769758,
    "text": "暗記は明らかに再現性に問題がある。"
  },
  {
    "start": 769934,
    "end": 787878,
    "text": "結論から言いますと、もう時間がありませんので、質問の時間を設けますが、つまり、LLMは初めて金属言語学を行うことができ、メタ認知能力があり、彼らの内部構造とそれをどのように使っているかを知る窓となり得るということです。"
  },
  {
    "start": 788044,
    "end": 790470,
    "text": "だからllmsはかなり優秀な言語学者なのだ。"
  },
  {
    "start": 790630,
    "end": 793942,
    "text": "同僚に、このアウトプットをどう評価するか聞いてみた。"
  },
  {
    "start": 794006,
    "end": 800060,
    "text": "大学院生がやったのなら、プラスかマイナスか、そんなところだろう。"
  },
  {
    "start": 800750,
    "end": 805074,
    "text": "そう、彼らは優れた言語学者なんだ。"
  },
  {
    "start": 805142,
    "end": 806718,
    "text": "何が残るのだろうか？"
  },
  {
    "start": 806884,
    "end": 810618,
    "text": "もし彼らが斬新な分析を提供してくれるなら。"
  },
  {
    "start": 810714,
    "end": 810974,
    "text": "そうだね。"
  },
  {
    "start": 811012,
    "end": 816082,
    "text": "もし、彼らが私たちに新たな洞察を与えてくれるなら、今利用できるものだけでかなりうまくやれるだろう。"
  },
  {
    "start": 816216,
    "end": 820542,
    "text": "あとは、彼らが革新的でいられるかどうかだ。"
  },
  {
    "start": 820686,
    "end": 821090,
    "text": "オーケー。"
  },
  {
    "start": 821160,
    "end": 825430,
    "text": "お持ち帰りも可能で、QRコードも付いている。"
  },
  {
    "start": 825500,
    "end": 828040,
    "text": "質問の時間があると思う。"
  },
  {
    "start": 828810,
    "end": 833382,
    "text": "私たちは短い質問を受け、他の、あるいは次の発言者がセットアップを行うことができます。"
  },
  {
    "start": 833436,
    "end": 834280,
    "text": "ありがとう。"
  },
  {
    "start": 837210,
    "end": 855550,
    "text": "より良い分析英語は、それがいくつかの例を持っていますが、または動作。"
  },
  {
    "start": 859330,
    "end": 860046,
    "text": "ああ、そういうことか。"
  },
  {
    "start": 860068,
    "end": 863050,
    "text": "まだテストしていないんだ。"
  },
  {
    "start": 863140,
    "end": 864498,
    "text": "それは興味深いことだ。"
  },
  {
    "start": 864584,
    "end": 867918,
    "text": "もうひとつの疑問は、その言語がどの程度表現されていたか、ということだ。"
  },
  {
    "start": 868014,
    "end": 871780,
    "text": "トレーニングデータに違いがある。"
  },
  {
    "start": 874070,
    "end": 876358,
    "text": "ありがとうございました。"
  },
  {
    "start": 876444,
    "end": 877880,
    "text": "楽しい話をありがとう。"
  },
  {
    "start": 899890,
    "end": 931430,
    "text": "スピーカーはウェイ・ジスーで、ニューラルネットワークにおけるデータ分離の経験則について話してくれる。"
  },
  {
    "start": 933050,
    "end": 933574,
    "text": "ありがとう。"
  },
  {
    "start": 933612,
    "end": 939160,
    "text": "ディープラーニングに関する私の研究についてお話しできることを大変嬉しく思います。"
  },
  {
    "start": 939610,
    "end": 944634,
    "text": "なるべく大きな言語モデルとの関連性を持たせるようにしたい。"
  },
  {
    "start": 944752,
    "end": 952110,
    "text": "これは、ロチェスター大学の助教授になった私の元教え子、ハン・フェン・フーとの共同研究である。"
  },
  {
    "start": 953010,
    "end": 954350,
    "text": "これはとてもシンプルなことだ。"
  },
  {
    "start": 954420,
    "end": 963730,
    "text": "10個の異なるクラスを持つファッション・リストに対して、8層のフィードフォワード・ニューラル・ネットワークを訓練する、2つの小さな不利な実験。"
  },
  {
    "start": 964310,
    "end": 968286,
    "text": "ここで、各点は画像を表す。"
  },
  {
    "start": 968318,
    "end": 980454,
    "text": "第1層、第2層、最終層とうまく連鎖したニューラルネットワークの埋め込みを2次元平面上に投影する。"
  },
  {
    "start": 980572,
    "end": 983106,
    "text": "各ポイントはイメージである。"
  },
  {
    "start": 983298,
    "end": 986690,
    "text": "色によってクラスが違うんだ。"
  },
  {
    "start": 986770,
    "end": 988310,
    "text": "クラスは10種類ある。"
  },
  {
    "start": 988390,
    "end": 996170,
    "text": "最初のレイヤーから最後のレイヤーまで見ることができ、画像はそれぞれのクラスに応じて徐々に分離される。"
  },
  {
    "start": 998030,
    "end": 1002110,
    "text": "ちなみに、これはトレーニングの終了を意味する。"
  },
  {
    "start": 1002180,
    "end": 1004430,
    "text": "ネットワークは個別に訓練されている。"
  },
  {
    "start": 1004770,
    "end": 1010650,
    "text": "分離しているように見えるが、はっきりと説明できるような正確な形ではない。"
  },
  {
    "start": 1010730,
    "end": 1015950,
    "text": "では、別の実験をしてみよう。"
  },
  {
    "start": 1016030,
    "end": 1026382,
    "text": "同じ実験だが、ここでは各ポイント（Y軸）が、異なるクラスに従ってデータがどの程度分離されているかを示している。"
  },
  {
    "start": 1026526,
    "end": 1030178,
    "text": "これは元のデータ、レイヤーゼロを示す。"
  },
  {
    "start": 1030264,
    "end": 1035158,
    "text": "これは、最初のレイヤーであるレイヤー1を通過したデータである。"
  },
  {
    "start": 1035244,
    "end": 1036840,
    "text": "これがレイヤー8だ。"
  },
  {
    "start": 1037610,
    "end": 1041346,
    "text": "ユリイカ、そんなものを見たことがあるかい？"
  },
  {
    "start": 1041378,
    "end": 1044234,
    "text": "単純なZの正方形の線を当てはめることができる。"
  },
  {
    "start": 1044352,
    "end": 1046474,
    "text": "相関関係はほぼ完璧だ。"
  },
  {
    "start": 1046592,
    "end": 1052910,
    "text": "これは実験をしている最中の私たちにとって、ちょっとした驚きだった。"
  },
  {
    "start": 1053730,
    "end": 1059662,
    "text": "さて、今この瞬間、私はまだyが何を表しているのかについて話していない。"
  },
  {
    "start": 1059716,
    "end": 1062506,
    "text": "大雑把に言えば、yはデータの分離度を表す。"
  },
  {
    "start": 1062698,
    "end": 1065406,
    "text": "データが十分に分離されていない場合、この値は大きくなる。"
  },
  {
    "start": 1065438,
    "end": 1068158,
    "text": "クラスによると、うまく分離させれば小さくなる。"
  },
  {
    "start": 1068254,
    "end": 1071410,
    "text": "正確な定義は近々発表される。"
  },
  {
    "start": 1071560,
    "end": 1074270,
    "text": "そうか、同じ実験なんだ。"
  },
  {
    "start": 1074350,
    "end": 1081794,
    "text": "この部分は非常にラフだが、この部分は非常に正確だ。"
  },
  {
    "start": 1081842,
    "end": 1090150,
    "text": "この点はこのデータに対応し、この点は最初のビールをパスした後のデータに対応する。"
  },
  {
    "start": 1092590,
    "end": 1101626,
    "text": "我々は、異なる最適化方法と異なるレイヤー数を用いて、より多くの実験を行った。"
  },
  {
    "start": 1101738,
    "end": 1105130,
    "text": "このような線形パターンは一貫して発生する。"
  },
  {
    "start": 1105210,
    "end": 1108718,
    "text": "物理法則のようなものだ。"
  },
  {
    "start": 1108884,
    "end": 1114530,
    "text": "では、Y軸は何を示しているのか、正式に紹介しよう。"
  },
  {
    "start": 1114870,
    "end": 1117490,
    "text": "つまり、分類の問題だ。"
  },
  {
    "start": 1117560,
    "end": 1121346,
    "text": "k個の異なるクラスがあり、これはクラスの平均である。"
  },
  {
    "start": 1121528,
    "end": 1128134,
    "text": "これは例えば平均的な猫を意味し、これは世界平均である。"
  },
  {
    "start": 1128252,
    "end": 1131986,
    "text": "ここで、2つの異なる行列を表す。"
  },
  {
    "start": 1132098,
    "end": 1133874,
    "text": "最初の行列は信号を表す。"
  },
  {
    "start": 1133922,
    "end": 1138794,
    "text": "基本的に、これは古いクラスのコバレント・マトリックスである。"
  },
  {
    "start": 1138992,
    "end": 1146666,
    "text": "さて、基本的には平均的な猫と平均的な犬との違いを測るものだ。"
  },
  {
    "start": 1146768,
    "end": 1149978,
    "text": "お互いに離れているなら、それはいいことだ。"
  },
  {
    "start": 1150144,
    "end": 1152502,
    "text": "この行列は固有値が大きくなる。"
  },
  {
    "start": 1152566,
    "end": 1153834,
    "text": "これはノイズだ。"
  },
  {
    "start": 1153962,
    "end": 1156906,
    "text": "基本的に、これはクラス内変動を示す。"
  },
  {
    "start": 1157018,
    "end": 1166078,
    "text": "典型的な猫が平均的な猫とどれほど違うか、もしこれが大きければ、その猫は濃縮されていないことを意味する。"
  },
  {
    "start": 1166254,
    "end": 1169586,
    "text": "最後に、この尺度をdと定義する。"
  },
  {
    "start": 1169768,
    "end": 1172894,
    "text": "これは2つの行列のトレースである。"
  },
  {
    "start": 1173022,
    "end": 1177186,
    "text": "基本的に、これはオーバーシグナルで示されるノイズである。"
  },
  {
    "start": 1177218,
    "end": 1179990,
    "text": "これは基本的に逆S/N比である。"
  },
  {
    "start": 1180490,
    "end": 1191530,
    "text": "基本的には、クラス内のばらつきをノイズとして、k個の異なるクラスが使用するkマイナス1の列空間に投影することである。"
  },
  {
    "start": 1192670,
    "end": 1208190,
    "text": "というのも、このdの対数スケールでは、最初のレイヤーから最後のレイヤーまでの改善は基本的に等しいことを示しているからだ。"
  },
  {
    "start": 1209410,
    "end": 1226290,
    "text": "大雑把に言えば、このdtは、物理学で起こっていること、例えば放射線のようなもの、例えばゼロから1のべき乗の間の定数倍の値tは、データが何層を通過したかを示している。"
  },
  {
    "start": 1227430,
    "end": 1229842,
    "text": "ここでは、非線形の線形性が重要である。"
  },
  {
    "start": 1229986,
    "end": 1234200,
    "text": "もしニューラルネットワークが線形であれば、そのようなことは起こらない。"
  },
  {
    "start": 1237130,
    "end": 1239190,
    "text": "この法則はどのようにして生まれるのか？"
  },
  {
    "start": 1239270,
    "end": 1243370,
    "text": "最初のうちは、エポックゼロで測定値が増加することがある。"
  },
  {
    "start": 1243440,
    "end": 1249430,
    "text": "例えば、最初はウェイトがIdガウシアンである。"
  },
  {
    "start": 1249590,
    "end": 1254054,
    "text": "しばらくの間トレーニングした後は、減っていく。"
  },
  {
    "start": 1254182,
    "end": 1259614,
    "text": "エンディング値をトレーニングすればするほど、エンディング値は小さくなる。"
  },
  {
    "start": 1259652,
    "end": 1265650,
    "text": "わずか100エポックから、パターンは極めて直線的である。"
  },
  {
    "start": 1266950,
    "end": 1269726,
    "text": "今のところ、この法律は浸透しているのだろうか？"
  },
  {
    "start": 1269758,
    "end": 1274590,
    "text": "我々は、ほとんどの視覚分類タスクについて多くの実験を行った。"
  },
  {
    "start": 1274670,
    "end": 1277522,
    "text": "そう、それは広く浸透しているが、普遍的なものではない。"
  },
  {
    "start": 1277586,
    "end": 1287878,
    "text": "この法則が現れない仕事もあり、なぜそうなるのか、いくつかの洞察や直感がある。"
  },
  {
    "start": 1287964,
    "end": 1288600,
    "text": "そうだ。"
  },
  {
    "start": 1289210,
    "end": 1290706,
    "text": "この法則を証明できるだろうか？"
  },
  {
    "start": 1290828,
    "end": 1291354,
    "text": "まだだ。"
  },
  {
    "start": 1291392,
    "end": 1300938,
    "text": "通常、このような直線的なパターンを目にするときはいつも、この直線的な減衰を支配している、非常に強力で非常に単純な根本的メカニズムがあるに違いないからだ。"
  },
  {
    "start": 1301034,
    "end": 1303758,
    "text": "現時点では、それを証明することはできない。"
  },
  {
    "start": 1303844,
    "end": 1308030,
    "text": "というのが、皆さんのコメントから私が期待していることです。"
  },
  {
    "start": 1308450,
    "end": 1313886,
    "text": "では、異なるデータ、異なるバランスレベル、異なる学習率でテストをしてみよう。"
  },
  {
    "start": 1313918,
    "end": 1320078,
    "text": "線形減衰は一貫しており、さまざまなアーキテクチャに対応している。"
  },
  {
    "start": 1320174,
    "end": 1325730,
    "text": "コンボリューション・ニューラル・ネットワークは、フィーダーフォワード・ニューラル・ネットワークに比べると、まだ線形で、少し遠い。"
  },
  {
    "start": 1327290,
    "end": 1331670,
    "text": "では、あと5分ほど試してみよう。"
  },
  {
    "start": 1331820,
    "end": 1339670,
    "text": "建築のトレーニング、この役割からの解釈について話そう。"
  },
  {
    "start": 1340110,
    "end": 1344650,
    "text": "まず、これはネットワークが本当に深くなければならないことを示しているよね？"
  },
  {
    "start": 1344800,
    "end": 1346874,
    "text": "これがすべてではない。"
  },
  {
    "start": 1346992,
    "end": 1352110,
    "text": "vcampは深さの異なる法則をプロットする。"
  },
  {
    "start": 1352690,
    "end": 1358494,
    "text": "より単純なデータセットの場合、最適な深さは5、6といったところだろう。"
  },
  {
    "start": 1358692,
    "end": 1363242,
    "text": "少し複雑なデータの場合、最適な深さは12になる。"
  },
  {
    "start": 1363396,
    "end": 1364830,
    "text": "深さによるね。"
  },
  {
    "start": 1364990,
    "end": 1368126,
    "text": "このスロープは本質的に、実際には単なる畝のロックである。"
  },
  {
    "start": 1368238,
    "end": 1375798,
    "text": "ロックの列が大きくなり、列が1つに近くなるのがわかるだろう。"
  },
  {
    "start": 1375884,
    "end": 1387522,
    "text": "ここで深さが大きければ、幅が十分な限り、飽和現象が起こる。"
  },
  {
    "start": 1387666,
    "end": 1389814,
    "text": "負荷はあまり関係ない。"
  },
  {
    "start": 1389852,
    "end": 1393742,
    "text": "さらに深さを100から1000に増やしても、そうはならない。"
  },
  {
    "start": 1393826,
    "end": 1405500,
    "text": "もし深さが本当に20であれば、20ニューロンのように、10ニューロンは本当に小さく、分類のための十分な情報を渡すことができませんお願いします。"
  },
  {
    "start": 1407010,
    "end": 1408000,
    "text": "とても興味深い。"
  },
  {
    "start": 1409170,
    "end": 1415042,
    "text": "縦軸にある指標はトレーニングデータのもので、同じようなものです。"
  },
  {
    "start": 1415096,
    "end": 1417682,
    "text": "もし私たちがデータを持ち出していたら、それもそうなるのだろうか？"
  },
  {
    "start": 1417816,
    "end": 1418770,
    "text": "ああ、いい質問だ。"
  },
  {
    "start": 1418840,
    "end": 1423060,
    "text": "テスト領域では、線形減衰はそれほど明確ではない。"
  },
  {
    "start": 1424230,
    "end": 1428302,
    "text": "大まかにはまだ減少しているが、直線的なものではないんだ。"
  },
  {
    "start": 1428366,
    "end": 1429618,
    "text": "には違う。"
  },
  {
    "start": 1429704,
    "end": 1437158,
    "text": "たとえパフォーマンスがよくても、汎化がうまくいっても、ここではすべてがトレーニングの中にある。"
  },
  {
    "start": 1437244,
    "end": 1440118,
    "text": "トレーニングは線形パターンである。"
  },
  {
    "start": 1440214,
    "end": 1440762,
    "text": "とても強い。"
  },
  {
    "start": 1440816,
    "end": 1446810,
    "text": "リニアのテストに移ると、減少パターンが見られるだけで、リニアとは言えない。"
  },
  {
    "start": 1450050,
    "end": 1451086,
    "text": "ありがとう。"
  },
  {
    "start": 1451268,
    "end": 1452000,
    "text": "オーケー。"
  },
  {
    "start": 1455730,
    "end": 1457550,
    "text": "なぜこの法則が起こり得るのか、直感的に理解できる。"
  },
  {
    "start": 1457620,
    "end": 1466566,
    "text": "これは例えば、ニューラルネットワークに摂動を与えるようなもので、通常Stdは局所的な最小値を見つけようとする。"
  },
  {
    "start": 1466618,
    "end": 1466978,
    "text": "そうだろう？"
  },
  {
    "start": 1467064,
    "end": 1472878,
    "text": "ウェイトに摂動をかけると、それぞれの分数がεの分だけずれるとする。"
  },
  {
    "start": 1472974,
    "end": 1479538,
    "text": "全体的な積を行う場合、摂動は最小化される。"
  },
  {
    "start": 1479634,
    "end": 1486690,
    "text": "これは、積が固定されている場合、他の分数が互いに等しくなるところである。"
  },
  {
    "start": 1486770,
    "end": 1490710,
    "text": "これは単純な幾何学的不等式である。"
  },
  {
    "start": 1490870,
    "end": 1502862,
    "text": "これは、例えば10年後にGBTを2倍にしたい場合、毎年GBTを7％ずつ、多すぎず少なすぎず増やす必要があることを示している。"
  },
  {
    "start": 1502996,
    "end": 1507310,
    "text": "しかし、それは証明にはならない。"
  },
  {
    "start": 1508210,
    "end": 1517970,
    "text": "この法則が発生すれば、一般化もうまくいき、一般化は発生しない場合よりもうまくいくことになる。"
  },
  {
    "start": 1519110,
    "end": 1524850,
    "text": "Resnetの場合、各ブロックを1つのレイヤーとして扱えば、この法則を回復することができる。"
  },
  {
    "start": 1525770,
    "end": 1533654,
    "text": "あまり時間がないのだが、ラージ・ランゲージ・モデルに話を移そう。"
  },
  {
    "start": 1533692,
    "end": 1536680,
    "text": "このワークショップのテーマは、大規模な言語モデルだ。"
  },
  {
    "start": 1537390,
    "end": 1539766,
    "text": "私たちはバートで実験を行った。"
  },
  {
    "start": 1539878,
    "end": 1547366,
    "text": "まず第一に、一般的な言語モデルでは、残念ながらこのような明確な線形減衰は見られない。"
  },
  {
    "start": 1547558,
    "end": 1558154,
    "text": "というのも、言語モデルには、注意のメカニズムがあるため、層内非線形性があるからだ。"
  },
  {
    "start": 1558202,
    "end": 1569982,
    "text": "非直線性は各層の中でも起こるし、しかもそれは連続したもので、横の関係があり、識別性はない。"
  },
  {
    "start": 1570046,
    "end": 1572078,
    "text": "別の手段が必要だ。"
  },
  {
    "start": 1572174,
    "end": 1578882,
    "text": "もし言語モデルにこのような法則があれば、根本的なメカニズムを理解する助けになると思う。"
  },
  {
    "start": 1578946,
    "end": 1580162,
    "text": "よし、これが参考資料だ。"
  },
  {
    "start": 1580226,
    "end": 1581480,
    "text": "時間を割いてくれてありがとう。"
  },
  {
    "start": 1585690,
    "end": 1587238,
    "text": "楽しい話をありがとう。"
  },
  {
    "start": 1587324,
    "end": 1589960,
    "text": "1、2問質問する時間がある。"
  },
  {
    "start": 1598010,
    "end": 1599330,
    "text": "とても魅力的だ。"
  },
  {
    "start": 1599490,
    "end": 1602080,
    "text": "手始めに、それに続く質問だ。"
  },
  {
    "start": 1603730,
    "end": 1619170,
    "text": "合成データ、非現実的なデータ、合成データでこれを行ったわけですが、実は、非常に合成的なデータを生成した場合、それほど複雑なデータでない場合、このような直線的な減衰は見られないのです。"
  },
  {
    "start": 1620390,
    "end": 1627766,
    "text": "合成データが十分に複雑で実データに類似している場合、低スケールだけが合成データ上で発生する。"
  },
  {
    "start": 1627868,
    "end": 1631222,
    "text": "じゃあ、休憩時間に聞くよ。"
  },
  {
    "start": 1631276,
    "end": 1632520,
    "text": "ああ、ありがとう。"
  },
  {
    "start": 1635050,
    "end": 1636040,
    "text": "ありがとう。"
  },
  {
    "start": 1673910,
    "end": 1680790,
    "text": "次のスピーカーはファレシャ・カニで、NLPモデルの共同開発について話してくれる。"
  },
  {
    "start": 1681690,
    "end": 1682582,
    "text": "皆さん、こんにちは。"
  },
  {
    "start": 1682716,
    "end": 1684514,
    "text": "私の名前はファレシェ。"
  },
  {
    "start": 1684562,
    "end": 1690870,
    "text": "私はマイクロソフトのリサーチ・サイエンティストで、NLPモデルの共同開発について話したいと思います。"
  },
  {
    "start": 1691790,
    "end": 1696938,
    "text": "おそらく誰もが耳にしたことのあるこの話から話を始めたい。"
  },
  {
    "start": 1697104,
    "end": 1706366,
    "text": "暗闇の中に象がいて、象を見たことがない人がたくさんいる。"
  },
  {
    "start": 1706468,
    "end": 1711434,
    "text": "部屋が暗かったり、ヘッドバンドをしていたりすると、象の全体像が見えない。"
  },
  {
    "start": 1711482,
    "end": 1715858,
    "text": "象を触った場所によって、象がそう見えたと思うのだ。"
  },
  {
    "start": 1715944,
    "end": 1721950,
    "text": "象の尻尾を触った人は、ああ、象はロープのようだと言うだろう。"
  },
  {
    "start": 1722110,
    "end": 1724580,
    "text": "これは、私たちが機械学習で行っていることと似ている。"
  },
  {
    "start": 1725110,
    "end": 1732486,
    "text": "トレーニングデータを集め、モデルを当てはめ、その結果、どこもかしこもこんな感じだろうということになる。"
  },
  {
    "start": 1732668,
    "end": 1740114,
    "text": "そして、おそらく、このようなスプリアスフィーチャーが起こることや、興味深いエラーが現れることをよく耳にしたことだろう。"
  },
  {
    "start": 1740242,
    "end": 1746678,
    "text": "例えば、棚からセンチメント分析をして、例えばマルコはテロリストだと言う。"
  },
  {
    "start": 1746774,
    "end": 1748310,
    "text": "ネガティブだと書いてある。"
  },
  {
    "start": 1748470,
    "end": 1758640,
    "text": "マルコがバルーンヘアのテロリストであることを付け加えれば、急にニュートラルになる。"
  },
  {
    "start": 1759010,
    "end": 1764158,
    "text": "それを黒髪に戻すと、またマイナスになる。"
  },
  {
    "start": 1764254,
    "end": 1773410,
    "text": "面白いことに、僕のファレシュデという名前はイラン人で、イスラム教とも関係があるから、髪を染めてもネガティブなんだ。"
  },
  {
    "start": 1774950,
    "end": 1780870,
    "text": "この話のために、私たちは暗闇の中でこのトレーニングにどう対処するつもりなのか？"
  },
  {
    "start": 1781210,
    "end": 1784502,
    "text": "最初の動機は、そうだ、行こうということだ。"
  },
  {
    "start": 1784556,
    "end": 1788646,
    "text": "私たちはいくつかのデータを収集し、この象がどのように見えるかを学ぶ。"
  },
  {
    "start": 1788748,
    "end": 1795674,
    "text": "しかし、例えば、ゾウの体から多くのデータが得られた。"
  },
  {
    "start": 1795792,
    "end": 1807678,
    "text": "では、この講演で私がやりたいことは、どうすれば多くの専門家がモデルに来て、このモデルはどうあるべきかを教えてくれるのか、ということだ。"
  },
  {
    "start": 1807764,
    "end": 1815810,
    "text": "私の目標は、多くの人にゾウのさまざまな部分を知ってもらい、モデルと交流してもらうことだ。"
  },
  {
    "start": 1815960,
    "end": 1824530,
    "text": "そして願わくば、一日の終わりには、そのモデルがすべての異なる人々の専門知識と一致するようなものを完成させたい。"
  },
  {
    "start": 1825190,
    "end": 1838310,
    "text": "アライメントが気に入らないのなら、もうひとつの動機は、ソフトウェア2.0について聞いたことがあるだろうが、モデルを出荷して何らかのエラーが起きたとき、どうするかということだ。"
  },
  {
    "start": 1838380,
    "end": 1841514,
    "text": "これらのエラーを見つけ、一般化すべきだ。"
  },
  {
    "start": 1841552,
    "end": 1844538,
    "text": "トレーニングデータに入れて最善を望むだけではだめだ。"
  },
  {
    "start": 1844624,
    "end": 1847100,
    "text": "一般化してボックスを修正すべきだ。"
  },
  {
    "start": 1847710,
    "end": 1850380,
    "text": "これが今回の講演の動機である。"
  },
  {
    "start": 1851010,
    "end": 1853182,
    "text": "どう対処するつもりなのか？"
  },
  {
    "start": 1853316,
    "end": 1855742,
    "text": "課題は主に2つある。"
  },
  {
    "start": 1855876,
    "end": 1863630,
    "text": "まず1つ目は、これらの人間が自分たちのコンセプトを運用し、デバッグするのをどのように手助けするかということだ。"
  },
  {
    "start": 1864450,
    "end": 1867538,
    "text": "通常、彼らは非常に暗黙的な考えを持っている。"
  },
  {
    "start": 1867624,
    "end": 1872750,
    "text": "例えば、国籍は中立であるべきだが、どうすればそれを明示できるのか？"
  },
  {
    "start": 1872830,
    "end": 1875140,
    "text": "それを機械学習モデルに教えるのだ。"
  },
  {
    "start": 1875610,
    "end": 1878050,
    "text": "第二に、妨害に対処することだ。"
  },
  {
    "start": 1878210,
    "end": 1882290,
    "text": "機械学習のように、通常はローカルで何かを変更することはできない。"
  },
  {
    "start": 1882370,
    "end": 1886760,
    "text": "何かを変えれば、モデルのさまざまな部分を変えることになる。"
  },
  {
    "start": 1887710,
    "end": 1891878,
    "text": "では、最初の「コンセプトの運用」に焦点を当てよう。"
  },
  {
    "start": 1892054,
    "end": 1894620,
    "text": "非常に単純な例を考えてみよう。"
  },
  {
    "start": 1895150,
    "end": 1903298,
    "text": "宗教はそれ自体であるべきで、何の感情も持つべきでない。"
  },
  {
    "start": 1903414,
    "end": 1911498,
    "text": "もしこのモデルが彼らの信念に沿ったものであれば、問題は人間があまり創造的ではないということだ。"
  },
  {
    "start": 1911594,
    "end": 1915010,
    "text": "彼らに、これはあなたの信念に沿ったものですか？"
  },
  {
    "start": 1915080,
    "end": 1920894,
    "text": "彼らはおそらく、私はムスリムに中立的で、ムスリム・ポジティブを愛している、というような文章をいくつか思いつくだろう。"
  },
  {
    "start": 1921022,
    "end": 1923140,
    "text": "すべてをカバーすることはできない。"
  },
  {
    "start": 1923510,
    "end": 1930006,
    "text": "例えば、棚からぼた餅のようなセンチメント分析をすれば、たいていうまくいく。"
  },
  {
    "start": 1930108,
    "end": 1935346,
    "text": "もっと深く取り組めば、もっと深くやってみれば、失敗する例を見つけることができる。"
  },
  {
    "start": 1935458,
    "end": 1939674,
    "text": "人間が気にかけるという概念は、通常、非常に大きい。"
  },
  {
    "start": 1939792,
    "end": 1943740,
    "text": "ある部分はチェックできても、別の部分を見逃すかもしれない。"
  },
  {
    "start": 1944750,
    "end": 1948106,
    "text": "もう一つの問題は、これらのモデルが本当に大きいということだ。"
  },
  {
    "start": 1948208,
    "end": 1953358,
    "text": "バグを見つけても、それを模型の中に入れても、彼らはそれを記憶するだけだ。"
  },
  {
    "start": 1953444,
    "end": 1959840,
    "text": "彼らはそれを暗記し、あなたが見つけたものについては問題ないが、別のものを見逃してしまうかもしれない。"
  },
  {
    "start": 1960290,
    "end": 1965394,
    "text": "この2つが私たちが抱えている課題であり、それにどのように対処していくのか。"
  },
  {
    "start": 1965592,
    "end": 1969790,
    "text": "このワークショップはllmsに関するものなので、llmsを使うことにする。"
  },
  {
    "start": 1969950,
    "end": 1978120,
    "text": "私たちが得た最初の洞察は、この大きな不動産空間を探索するために、このllmsを利用できるということだ。"
  },
  {
    "start": 1978890,
    "end": 1980920,
    "text": "どうやってやるんだ？"
  },
  {
    "start": 1982490,
    "end": 1985974,
    "text": "これらのLLMが持つ良い特性のひとつがある。"
  },
  {
    "start": 1986012,
    "end": 1998122,
    "text": "気になるコンセプトについて5～7つの文章から始め、それをプロンプトとして置くと、気になるコンセプトについて100以上の例を生み出すことができる。"
  },
  {
    "start": 1998176,
    "end": 2008954,
    "text": "国籍が中立であることを気にするとしたら、例えば、私はアフガニスタン出身で、私はイランで育ち、彼女はアメリカに住んでいる。"
  },
  {
    "start": 2009002,
    "end": 2016146,
    "text": "そして、この3つをエレナに渡すと、エレナは私のために100の例を生成してくれるんだ。"
  },
  {
    "start": 2016248,
    "end": 2023874,
    "text": "その中からまたひとつを選び、それから探索を始め、ステイタスのあるスペースでランダムに仕事をする。"
  },
  {
    "start": 2023912,
    "end": 2030726,
    "text": "そうすれば毎回、私がまだ彼らのステータス・スペースにいるのか、それとも出ているのか、人間に尋ねることができる。"
  },
  {
    "start": 2030908,
    "end": 2035320,
    "text": "もし私が退団していれば、彼らは私が入団しているかどうかを教えてくれるだろう。"
  },
  {
    "start": 2035690,
    "end": 2039802,
    "text": "何が問題かというと、この地位空間が非常に大きいということだ。"
  },
  {
    "start": 2039936,
    "end": 2047610,
    "text": "こんな適当な仕事をしていたら、バグを見つけるのに時間がかかってしまう。"
  },
  {
    "start": 2049310,
    "end": 2054558,
    "text": "どこにバグがあるのかがわかれば最高なんだけど。"
  },
  {
    "start": 2054644,
    "end": 2059680,
    "text": "ランダムウォークではなく、ガイドウォークをしている。"
  },
  {
    "start": 2060130,
    "end": 2064370,
    "text": "エラーはどこで発生するのでしょうか？"
  },
  {
    "start": 2066470,
    "end": 2074610,
    "text": "エラーの場所がわかっていれば、ランダムウォークの代わりに、エラーに向かってガイドウォークをすることができる。"
  },
  {
    "start": 2075670,
    "end": 2078610,
    "text": "どうすればこの高エラー領域を見つけることができるのか？"
  },
  {
    "start": 2079770,
    "end": 2089942,
    "text": "私たちの2つ目の洞察は、これらのモデルは非常に複雑だが、この非常にローカルな地域に注目すれば、物事は簡単になるということだ。"
  },
  {
    "start": 2090006,
    "end": 2101018,
    "text": "おそらくテイラー展開で見たように、機械学習における解釈可能性の結果の多くは、ある局所的な近傍に焦点を当てれば、より単純なモデルができるというものだ。"
  },
  {
    "start": 2101104,
    "end": 2106942,
    "text": "より単純なモデルということは、そのモデルを学習するのに必要な例数が少なくて済むということだ。"
  },
  {
    "start": 2107076,
    "end": 2112190,
    "text": "この2つ目の洞察を、エラー領域を見つけるのに役立てたい。"
  },
  {
    "start": 2113010,
    "end": 2118830,
    "text": "要約すると、ユーザーが自分のコンセプトからサンプリングできないという問題がある。"
  },
  {
    "start": 2118990,
    "end": 2125922,
    "text": "私たちの最初の洞察は、llmsを使うことで、ランダムな作業とガイドされた作業のどちらにも役立てることができるということだった。"
  },
  {
    "start": 2126056,
    "end": 2133574,
    "text": "そして2つ目の洞察は、ローカルな領域で関数を学習することで、おそらく必要な例が少なくなるということだった。"
  },
  {
    "start": 2133772,
    "end": 2143690,
    "text": "私たちの解決策は、局所的な領域で局所的な関数を学習し、この局所的な関数を使って不一致の方向へ導くことです。"
  },
  {
    "start": 2144350,
    "end": 2146090,
    "text": "これはどのように機能するのだろうか？"
  },
  {
    "start": 2146240,
    "end": 2155818,
    "text": "あなたが来て、あなたが気にかけているコンセプトからほんの少し例を挙げてくれて、私はあなたのコンセプトについてごく小さなモデルを学ぶ。"
  },
  {
    "start": 2155994,
    "end": 2164766,
    "text": "その後、バグを見つけたいグローバルモデルがあり、そしてあなたのコンセプトでうまく機能するローカルモデルがある。"
  },
  {
    "start": 2164878,
    "end": 2173502,
    "text": "そこで、GPT-3を使って、不一致領域に向かって歩くガイドウォークを生成する。"
  },
  {
    "start": 2173646,
    "end": 2182290,
    "text": "いくつかの文章が生成されるたびに、ローカルとグローバルの不一致度が高いような、より近い文章を選んだ。"
  },
  {
    "start": 2182370,
    "end": 2186162,
    "text": "そして、最終的にこの2つのモデルが一致しない文章を見つける。"
  },
  {
    "start": 2186306,
    "end": 2190358,
    "text": "そして、それが見つかったら、どちらが正しいかを人間に問う。"
  },
  {
    "start": 2190524,
    "end": 2197734,
    "text": "ローカルモデルがまだ十分ではないので、ローカルモデルを改善するか、エラーを見つけたかのどちらかだ。"
  },
  {
    "start": 2197782,
    "end": 2200380,
    "text": "我々はグローバル・モデルを改善するつもりだ。"
  },
  {
    "start": 2201650,
    "end": 2216580,
    "text": "その後、ローカルモデルとグローバルモデルを更新し、ローカルモデルとグローバルモデルが収束するまで、このBCDループを続ける。"
  },
  {
    "start": 2218630,
    "end": 2228146,
    "text": "例えば、私はイスラム教徒で、モスクでお祈りをします。"
  },
  {
    "start": 2228178,
    "end": 2234774,
    "text": "しばらくすると、簡単な文章で完全に揃い、それから難しい文章が現れるのがわかる。"
  },
  {
    "start": 2234812,
    "end": 2239150,
    "text": "例えば、ISISについて話し始め、ヒズボラについて話し始める。"
  },
  {
    "start": 2239330,
    "end": 2252730,
    "text": "GPT-3を使っているのは、コンセプトについて知っているのと同じで、1枚のスライドにすべてをまとめることで、より多くのコンセプトをカバーすることができる。"
  },
  {
    "start": 2252890,
    "end": 2258762,
    "text": "私たちは、高速で、言語生成に非常に優れたllmsを持っている。"
  },
  {
    "start": 2258906,
    "end": 2266254,
    "text": "私たちは、スピードに優れ、タスクについて知っているグローバルモデルを持っていますが、ユーザーのコンセプトについては非常に悪い考えを持っています。"
  },
  {
    "start": 2266382,
    "end": 2272878,
    "text": "ユーザーコンセプトを知っているユーザーはいるが、言語生成が下手でスピードがない。"
  },
  {
    "start": 2272974,
    "end": 2279662,
    "text": "そこで私たちが行ったのは、より高速でユーザーコンセプトの高いプロキシモデルを用意することだ。"
  },
  {
    "start": 2279726,
    "end": 2283682,
    "text": "グローバル、ローカル、LLMSの間で多くの相互作用があるだろう。"
  },
  {
    "start": 2283746,
    "end": 2286658,
    "text": "そして、意見の相違があれば、いつでもユーザーに尋ねる。"
  },
  {
    "start": 2286674,
    "end": 2290090,
    "text": "だから矢は細くなっている。"
  },
  {
    "start": 2291390,
    "end": 2296454,
    "text": "講演の最初の部分は、申し上げたように、コンセプトの運用についてでした。"
  },
  {
    "start": 2296502,
    "end": 2303726,
    "text": "私たちは、ユーザーが自分のデータセットにサンプリングしたり、何を望んでいるのかを説明したりするのが本当に下手だという問題を抱えている。"
  },
  {
    "start": 2303828,
    "end": 2311626,
    "text": "私たちの解決策は、llmsを使うことと、ローカル関数の方が簡単だということを利用することでした。"
  },
  {
    "start": 2311738,
    "end": 2316210,
    "text": "この問題を解決するために、今度はハンドリングの妨害を見てみよう。"
  },
  {
    "start": 2316950,
    "end": 2320194,
    "text": "文献には、彼らが示した多くの研究がある。"
  },
  {
    "start": 2320232,
    "end": 2323442,
    "text": "何かを直せば、別の何かを壊すことになる。"
  },
  {
    "start": 2323496,
    "end": 2333350,
    "text": "敵対的なトレーニングをすると、汎化が低下し、スプリアスな特徴を修正すると、他のことでも精度が低下する。"
  },
  {
    "start": 2333500,
    "end": 2337666,
    "text": "このことは、公正さや文学を見ればわかる。"
  },
  {
    "start": 2337698,
    "end": 2339986,
    "text": "何かを修正すれば、他の何かが壊れる。"
  },
  {
    "start": 2340108,
    "end": 2341834,
    "text": "どう対処するつもりなのか？"
  },
  {
    "start": 2341872,
    "end": 2343462,
    "text": "例えば、何かを修正し、整列する。"
  },
  {
    "start": 2343526,
    "end": 2347130,
    "text": "この妨害にどう対処するつもりなのか？"
  },
  {
    "start": 2347870,
    "end": 2357070,
    "text": "干渉について直感的に説明すると、例えば、2つのガウシアンがあって、それを分類したいとする。"
  },
  {
    "start": 2357220,
    "end": 2365374,
    "text": "この場合、確率の高い例が1つか2つあれば、非常に精度の高い分類器ができることになる。"
  },
  {
    "start": 2365502,
    "end": 2370290,
    "text": "ほんの数例でいいんだ。"
  },
  {
    "start": 2370440,
    "end": 2380246,
    "text": "しかし、新しいユーザーが新しいデータセットを持ってくると、突然、以前のデータに干渉し始める。"
  },
  {
    "start": 2380348,
    "end": 2387426,
    "text": "今、私はこれらのデータからサンプリングする確率が非常に低いデータをサンプリングする必要がある。"
  },
  {
    "start": 2387548,
    "end": 2390780,
    "text": "今、私は彼らからサンプルを取る必要がある。"
  },
  {
    "start": 2391230,
    "end": 2394314,
    "text": "またどうやって対処するつもりなんだ？"
  },
  {
    "start": 2394432,
    "end": 2404320,
    "text": "私は各ローカルユーザーのプロキシを持っているので、それを使って再び意見の相違に集中し、これに対処することができる。"
  },
  {
    "start": 2404770,
    "end": 2418418,
    "text": "ここでは、これらのユーザーに対して1つのローカル・コンセプトがあり、これに対して別のローカル分類器があることがわかります。"
  },
  {
    "start": 2418504,
    "end": 2424340,
    "text": "それなら、この問題を解決するために私がすべきことは、この意見の相違に集中することだ。"
  },
  {
    "start": 2426070,
    "end": 2437990,
    "text": "今のモデルは以前のものと同じで、1人のユーザーではなく、異なるユーザーがいて、それぞれがプロキシを持っているので、干渉を処理することができる。"
  },
  {
    "start": 2438830,
    "end": 2457358,
    "text": "要約すると、私たちはこのようなユーザーがサンプリングできない運用の問題を抱えており、LLMに依存し、LLMとこれらのローカル関数が使えるという事実に頼ることで解決している。"
  },
  {
    "start": 2457444,
    "end": 2465330,
    "text": "干渉に対処するために、我々はまた、このローカルな関数があるという事実を利用する。"
  },
  {
    "start": 2467190,
    "end": 2473060,
    "text": "たくさんの実験をしたが、それを見ている時間はないだろう。"
  },
  {
    "start": 2474310,
    "end": 2479842,
    "text": "そうだね。だから、いつも暗闇の中でやっているようなトレーニングから始めよう。"
  },
  {
    "start": 2479906,
    "end": 2482002,
    "text": "私たちは共同開発を行いたい。"
  },
  {
    "start": 2482066,
    "end": 2484434,
    "text": "私たちは、コンセプトを運用する方法を示している。"
  },
  {
    "start": 2484482,
    "end": 2486578,
    "text": "私たちは妨害の処理に徹する。"
  },
  {
    "start": 2486754,
    "end": 2488146,
    "text": "私はいくつかの実験を見せた。"
  },
  {
    "start": 2488178,
    "end": 2490234,
    "text": "新聞を見れば、それがうまくいっていることがわかる。"
  },
  {
    "start": 2490352,
    "end": 2504734,
    "text": "結論として、私は、これらのモデルがどのように振る舞うかを単一の団体が決めるのではなく、これらのモデルのためのウィキペディアのようなものがあれば、それらがどのように運営されるべきかを決めることができ、それは素晴らしいことだと思う。"
  },
  {
    "start": 2504852,
    "end": 2505680,
    "text": "ありがとう。"
  },
  {
    "start": 2510370,
    "end": 2512490,
    "text": "楽しい話をありがとう。"
  },
  {
    "start": 2512580,
    "end": 2531560,
    "text": "その間に1つ質問する時間がありますが、なければ、もう一度フェアなショーに感謝しましょう。"
  },
  {
    "start": 2601370,
    "end": 2607210,
    "text": "次のスピーカーはジア・シュウで、無限ホライズンのリザーバー・トランスフォーマーについて話してくれる。"
  },
  {
    "start": 2609070,
    "end": 2612590,
    "text": "みなさん、こんにちは。"
  },
  {
    "start": 2613410,
    "end": 2620794,
    "text": "今日は、私の博士課程の学生であるアミット・コーシャと一緒にこの研究を発表するつもりだ。"
  },
  {
    "start": 2620922,
    "end": 2628610,
    "text": "今回は、任意のものを扱うことができる新しいタイプのトランスフォーマー、リザーバー・トランスフォーマーについてお話します。"
  },
  {
    "start": 2632950,
    "end": 2641798,
    "text": "私たちは皆、トランスフォーマーが大規模な言語モデルを含む広範な能力を発揮していることを知っている。"
  },
  {
    "start": 2641964,
    "end": 2652814,
    "text": "しかし、Transformerなどで実装されている言語モデルの制限としてよく知られているのが、インプリメントである。"
  },
  {
    "start": 2652962,
    "end": 2661154,
    "text": "これまでのところ、トランスフォーマー自体は前バージョンの124に対応している。"
  },
  {
    "start": 2661302,
    "end": 2679970,
    "text": "以前のバージョンでは、入力としてのトークンは、例えばt 5、3.5、NGBT 4など、より多くのコンテキストを考慮するように、トランスフォーマーの入力長を増やそうとする多くの作業があった。"
  },
  {
    "start": 2680040,
    "end": 2685838,
    "text": "また、50万ドルを処理できるリミテッド・フォーマーと呼ばれる最近の作品もある。"
  },
  {
    "start": 2686024,
    "end": 2688674,
    "text": "それでも、これらはすべて制限された長さだ。"
  },
  {
    "start": 2688802,
    "end": 2699214,
    "text": "理論的には、入力の長さに明確な制限がほとんどないものを見つけることができると主張しているのだ。"
  },
  {
    "start": 2699282,
    "end": 2701340,
    "text": "その方法をお見せしよう。"
  },
  {
    "start": 2702990,
    "end": 2707046,
    "text": "その前に、なぜ文脈が重要なのかについて話したい。"
  },
  {
    "start": 2707158,
    "end": 2712426,
    "text": "ここに、西李から引用した小話がある。"
  },
  {
    "start": 2712608,
    "end": 2717594,
    "text": "当初、私たちはパパイヤについて話し、リンゴの木に適応した。"
  },
  {
    "start": 2717722,
    "end": 2726014,
    "text": "ラビット・ホワイトは、都合よくリンゴの木の下に横たわっている。"
  },
  {
    "start": 2726142,
    "end": 2729762,
    "text": "突然、リンゴが落ちて音を立てた。"
  },
  {
    "start": 2729896,
    "end": 2731870,
    "text": "例えば、音はグドン。"
  },
  {
    "start": 2732030,
    "end": 2740934,
    "text": "その時、ウサギは何か変だと思い、大声を出すことにした。"
  },
  {
    "start": 2741132,
    "end": 2750134,
    "text": "そしてウサギはサルに、サルはフォックスに、フォックスはビール、シカ、トラに言った。"
  },
  {
    "start": 2750182,
    "end": 2756140,
    "text": "彼らは皆、3つの目を持つ怪物を思い浮かべた。"
  },
  {
    "start": 2756590,
    "end": 2763150,
    "text": "この文脈では、ちょっとした質問に答えたいとしよう。"
  },
  {
    "start": 2763490,
    "end": 2776466,
    "text": "後半部分、つまり最後の短いセンテンスだけを知っている場合、私たちは最初を読むのに十分な記憶がなく、最後だけを読む。"
  },
  {
    "start": 2776568,
    "end": 2781780,
    "text": "この質問に対して、何が見つかるか、何が最も来るような答えになる。"
  },
  {
    "start": 2782310,
    "end": 2791590,
    "text": "しかし、もし全文を読むことができれば、リンゴが木から落ちていることがわかる。"
  },
  {
    "start": 2793530,
    "end": 2801020,
    "text": "その場合、正しい答えを得るためには長いコンテクストが必要になる。"
  },
  {
    "start": 2803390,
    "end": 2809610,
    "text": "さて、このレッスンから何を学ぶかというと、最後から最初に戻って読むのだ。"
  },
  {
    "start": 2812530,
    "end": 2828910,
    "text": "コンテキストは非常に重要であるため、これまで長いコンテキストを使うことを妨げてきたのは、トランスフォーマーのメモリと時間がシーケンスの長さに応じて二次関数的に増大するからである。"
  },
  {
    "start": 2829070,
    "end": 2834210,
    "text": "そのため、トレーニングは非常に高額になる。"
  },
  {
    "start": 2835850,
    "end": 2837560,
    "text": "では、どうしようか？"
  },
  {
    "start": 2840010,
    "end": 2841880,
    "text": "トレーニングを外すのはどうだろう？"
  },
  {
    "start": 2844570,
    "end": 2847400,
    "text": "私たちは今、機械学習のワークショップに参加していないのだろうか？"
  },
  {
    "start": 2848010,
    "end": 2858746,
    "text": "もちろん、トレーニングを完全に排除したわけではないが、トレーニングを必要としない建築家のようなものを紹介したい。"
  },
  {
    "start": 2858928,
    "end": 2861638,
    "text": "これは私が発明したものではない。"
  },
  {
    "start": 2861814,
    "end": 2865178,
    "text": "すでに別の分野で使われている。"
  },
  {
    "start": 2865354,
    "end": 2872378,
    "text": "このリザーバーをリザーバー層のトランスに導入する。"
  },
  {
    "start": 2872554,
    "end": 2881822,
    "text": "リザーバー層のニューロン内部では、固定された重みがあり、これらの重みは最初はランダム化されている。"
  },
  {
    "start": 2881966,
    "end": 2885300,
    "text": "この部分のトレーニングの問題はない。"
  },
  {
    "start": 2885830,
    "end": 2891534,
    "text": "あなたが考えることができるのは、あなたが読んでいること、たくさんのものを読んでいること、そしてそれらのウェイトが固定されていることです。"
  },
  {
    "start": 2891582,
    "end": 2897730,
    "text": "例えば、リニアでもノンリニアでもいいのなら、一緒に読んだものを組み合わせればいい。"
  },
  {
    "start": 2897890,
    "end": 2900238,
    "text": "ウェイトを鍛え直す必要はない。"
  },
  {
    "start": 2900274,
    "end": 2904620,
    "text": "あなたは大規模なコーパスに頼っている。"
  },
  {
    "start": 2904990,
    "end": 2908970,
    "text": "最後に、読み出し層でトレーニングする必要がある。"
  },
  {
    "start": 2910750,
    "end": 2918090,
    "text": "読み出し層は1層だけで、通常はもともとリニアな読み出し層だ。"
  },
  {
    "start": 2918250,
    "end": 2920746,
    "text": "これをトランスフォーマーと組み合わせるのはどうだろう。"
  },
  {
    "start": 2920778,
    "end": 2921966,
    "text": "つまり、2人いるということだ。"
  },
  {
    "start": 2921988,
    "end": 2925374,
    "text": "パート1は文言依存。"
  },
  {
    "start": 2925502,
    "end": 2930590,
    "text": "つまり、例えばリザーバーと一緒に読む本など、文書全体を指す。"
  },
  {
    "start": 2930750,
    "end": 2938850,
    "text": "文中では、入力トークンが1000個以下なので、やはりトランスフォーマーで読む。"
  },
  {
    "start": 2939010,
    "end": 2955370,
    "text": "この2つを組み合わせれば、非常に長い、非常に長いメモリーを持つことになり、計算コストが少なくなる。"
  },
  {
    "start": 2955790,
    "end": 2966590,
    "text": "私は、文章内ではより正確な学習をし、文書全体や長い記事では文章を横断してより大まかな学習をする。"
  },
  {
    "start": 2968210,
    "end": 2973626,
    "text": "これは基本的なアイデアだが、ただ差し込むだけではあまりうまくいかない。"
  },
  {
    "start": 2973748,
    "end": 2978878,
    "text": "私たちが最初に直面する課題は、リニア読み出しである。"
  },
  {
    "start": 2979054,
    "end": 2987058,
    "text": "リザーバーの出力サイズはトランスの入力サイズに等しいので、出力はトランスの入力に向かう。"
  },
  {
    "start": 2987154,
    "end": 3005190,
    "text": "したがって、トランスフォーマーの入力サイズは、あまり大きくできないので、リザーバーの出力サイズを軽視し、リザーバーで使用できるニューロンの数を制限することはできない。"
  },
  {
    "start": 3005350,
    "end": 3014926,
    "text": "したがって、線形読み出しを非線形読み出しに変更する必要がある。"
  },
  {
    "start": 3015028,
    "end": 3022714,
    "text": "通常、ここで注目のニューラルネットワークに入れることができる線形読み出しである。"
  },
  {
    "start": 3022842,
    "end": 3030130,
    "text": "ここでは、これをレイヤーを持つ自己緊張型ニューラルネットワークに置き換える。"
  },
  {
    "start": 3030550,
    "end": 3032370,
    "text": "これが最初の挑戦だ。"
  },
  {
    "start": 3032950,
    "end": 3046870,
    "text": "2つ目の課題は、非常に長い予測、例えば70回の逆予測を子システムで行う場合、バタフライ効果と呼ばれるものが発生することだ。"
  },
  {
    "start": 3047020,
    "end": 3054906,
    "text": "ある時期が過ぎると、予測は本当に難しくなる。"
  },
  {
    "start": 3055088,
    "end": 3061100,
    "text": "これは入力状態の初期状態に大きく依存している。"
  },
  {
    "start": 3061730,
    "end": 3065870,
    "text": "この感度は、予測を非常に難しくしている。"
  },
  {
    "start": 3066210,
    "end": 3078930,
    "text": "そこで、異なる入力の初期化をアンサンプリングするためにグループリザーバーを導入し、結果をよりロバストにした。"
  },
  {
    "start": 3081190,
    "end": 3083490,
    "text": "よし、実験に戻ろう。"
  },
  {
    "start": 3084390,
    "end": 3089798,
    "text": "ディープエコー・センシティブ・データセットの結果である。"
  },
  {
    "start": 3089964,
    "end": 3093106,
    "text": "ここにリザーバー・トランスフォーマーがある。"
  },
  {
    "start": 3093298,
    "end": 3107020,
    "text": "このパラメーターの数は、例えばLCMのトランスなどに比べて非常に少なく、損失も小さい。"
  },
  {
    "start": 3107550,
    "end": 3109340,
    "text": "残りはここにある。"
  },
  {
    "start": 3109870,
    "end": 3115226,
    "text": "時系列予測のために、いくつかのテストを行った。"
  },
  {
    "start": 3115338,
    "end": 3123754,
    "text": "一つは、ウェブサイトの訪問者金価格と需要価格ビットコイン履歴データセットです。"
  },
  {
    "start": 3123892,
    "end": 3130130,
    "text": "MSEから減点され、他の準備からも改善された。"
  },
  {
    "start": 3132230,
    "end": 3140386,
    "text": "例えば、他の為替レートや他の銅貨も試してみた。"
  },
  {
    "start": 3140498,
    "end": 3151766,
    "text": "例えば、リニア・デリニア等と比較して、また、トランスの多くの種類のバリエーション。"
  },
  {
    "start": 3151878,
    "end": 3163886,
    "text": "その結果、全体的な改善と空気の質の改善が得られ、予測も改善された。"
  },
  {
    "start": 3164068,
    "end": 3170778,
    "text": "私たちが適応させたリザーバーバードは、最も当惑の少ない鳥である。"
  },
  {
    "start": 3170954,
    "end": 3174160,
    "text": "これはヴィッキーのテキストでテストされている。"
  },
  {
    "start": 3175570,
    "end": 3178278,
    "text": "最後に私たちはチャペルにも挑戦した。"
  },
  {
    "start": 3178314,
    "end": 3185358,
    "text": "マルチモーダル機能とともに、通話時間も長くなった。"
  },
  {
    "start": 3185534,
    "end": 3194582,
    "text": "これは会話時間のゴールみたいなもので、20分くらいかな。"
  },
  {
    "start": 3194716,
    "end": 3199926,
    "text": "これが、マルチモーダルインプットとともに私たちが今成し遂げていることなのだ。"
  },
  {
    "start": 3200118,
    "end": 3207340,
    "text": "この結果は、このサイコロのリザーバーだけのものではなく、他のいくつかの新しい手法も一緒に組み合わせたものである。"
  },
  {
    "start": 3208990,
    "end": 3219070,
    "text": "さて、要約すると、我々は非常に長いコンテクストを扱うことができ、高価ではないリザーバータ変圧器を導入した。"
  },
  {
    "start": 3219410,
    "end": 3225380,
    "text": "私たちは遠く離れた出来事を完全にキャスティングすることができる。"
  },
  {
    "start": 3225910,
    "end": 3232770,
    "text": "我々は、時系列タスクといくつかのNRPタスクで実験的にいくつかの改善を示した。"
  },
  {
    "start": 3233110,
    "end": 3234100,
    "text": "ありがとう。"
  },
  {
    "start": 3240010,
    "end": 3241480,
    "text": "質問の時間だ。"
  },
  {
    "start": 3250510,
    "end": 3258410,
    "text": "トランスフォーマーの文脈依存のために何かを見逃していた。"
  },
  {
    "start": 3258750,
    "end": 3274580,
    "text": "トレーニングという点では、あなたは避けているとおっしゃいましたが、実行という点でも、私たちはトレーニングをしていますが、データ全体に対してトレーニングをしているわけではなく、その一部に対してトレーニングをしているのです。"
  },
  {
    "start": 3274950,
    "end": 3277970,
    "text": "この写真を見てみよう。"
  },
  {
    "start": 3279110,
    "end": 3283410,
    "text": "例えば、本全体を一つのサンプルとして持っているとしよう。"
  },
  {
    "start": 3284150,
    "end": 3286420,
    "text": "よし、これで鍛えられた。"
  },
  {
    "start": 3288090,
    "end": 3290360,
    "text": "文章はここで鍛えられる。"
  },
  {
    "start": 3291050,
    "end": 3294120,
    "text": "私たちは、この本全体をここで訓練することを避けている。"
  },
  {
    "start": 3294890,
    "end": 3299430,
    "text": "文のトレーニングからのバックプロップはない。"
  },
  {
    "start": 3300170,
    "end": 3301314,
    "text": "元に戻らない。"
  },
  {
    "start": 3301372,
    "end": 3305398,
    "text": "再教育を受けるのはここだけだ。"
  },
  {
    "start": 3305494,
    "end": 3306860,
    "text": "これは戻らない。"
  },
  {
    "start": 3307230,
    "end": 3311050,
    "text": "この固定は再教育されている。"
  },
  {
    "start": 3314130,
    "end": 3315360,
    "text": "他に質問は？"
  },
  {
    "start": 3316610,
    "end": 3324320,
    "text": "次のスピーカーがセッティングを始めている間に1つ質問があるのですが、リザーバーモデルの限界は何だと思いますか？"
  },
  {
    "start": 3338690,
    "end": 3339440,
    "text": "それだ。"
  },
  {
    "start": 3343330,
    "end": 3356160,
    "text": "モデルの限界、それはあなたの基準次第です。"
  },
  {
    "start": 3357890,
    "end": 3363310,
    "text": "より効率的に、より質の高い結果を出したいのであれば。"
  },
  {
    "start": 3363690,
    "end": 3374630,
    "text": "これまでのところ、トランスと比較して、効率と精度が向上している。"
  },
  {
    "start": 3375290,
    "end": 3391230,
    "text": "より効率的に、より正確に、例えばある特定の仕事、例えばある特定の仕事をこなすには、適応が必要だ。"
  },
  {
    "start": 3391570,
    "end": 3398030,
    "text": "例えば、鳥を作るときに、この鳥のデザインを変えなければならないとしよう。"
  },
  {
    "start": 3398770,
    "end": 3401810,
    "text": "直接使うことはできない。"
  },
  {
    "start": 3402390,
    "end": 3407460,
    "text": "これはワードアプリケーション用に再設計されなければならない。"
  },
  {
    "start": 3409190,
    "end": 3412862,
    "text": "これが限界のひとつであることは明らかだが、他にも限界はあるだろう。"
  },
  {
    "start": 3412926,
    "end": 3414440,
    "text": "見つけた。"
  },
  {
    "start": 3415290,
    "end": 3416566,
    "text": "オーケー、素晴らしい。"
  },
  {
    "start": 3416748,
    "end": 3418390,
    "text": "ありがとう、ケン。"
  },
  {
    "start": 3451540,
    "end": 3456980,
    "text": "次のスピーカーはソン・マイで、統計学者としてのトランスフォーマーについて話してくれる。"
  },
  {
    "start": 3457880,
    "end": 3460432,
    "text": "主催者と観客に感謝する。"
  },
  {
    "start": 3460576,
    "end": 3465200,
    "text": "今日は、トランスフォーマーは統計学者であるという話をしようと思う。"
  },
  {
    "start": 3465360,
    "end": 3471076,
    "text": "さて、2日前、ジェイコブは言語モデルは統計学者であるとも話していた。"
  },
  {
    "start": 3471108,
    "end": 3474724,
    "text": "彼は主に、より応用的な観点から話をした。"
  },
  {
    "start": 3474852,
    "end": 3479736,
    "text": "例えば、彼は変圧器が仮説の生成に使えることを示した。"
  },
  {
    "start": 3479928,
    "end": 3493324,
    "text": "今日は理論的な観点に重点を置き、トランスフォーマーが所得税の学習と所得税のアルゴリズム選択を実行できることを証明するつもりだ。"
  },
  {
    "start": 3493452,
    "end": 3499040,
    "text": "これはどちらかというと、ニューラルネットワークの近似理論のような視点だ。"
  },
  {
    "start": 3500180,
    "end": 3508644,
    "text": "これは、平大学の学部生であるフェン・チェンと、セールスフォース・リサーチの長期共同研究者であるユー・バイとの共同研究である。"
  },
  {
    "start": 3508842,
    "end": 3518570,
    "text": "このプロジェクトは、この2人の協力者、そしてセールスフォース・リサーチのホァン・ワンとテ・ミンソンなしでは成り立たない。"
  },
  {
    "start": 3521180,
    "end": 3533132,
    "text": "この所得税の学習については、スーリヤとグレッグが詳しく話してくれたので、改めて詳しく紹介する必要はないだろう。"
  },
  {
    "start": 3533186,
    "end": 3541500,
    "text": "一方、インコンテクスト学習とは、ある分布に従ったidのデータセットXiyiがあるとする。"
  },
  {
    "start": 3542160,
    "end": 3555984,
    "text": "私たちができることは、このXiyiの連結とこのx nプラス1をプロンプトとして悲劇のBtまたはトランスフォーマーに入力することである。"
  },
  {
    "start": 3556112,
    "end": 3563968,
    "text": "ということは、この悲劇的なBtは、y nプラス1ハッチという答えを出すことができる。"
  },
  {
    "start": 3564064,
    "end": 3569108,
    "text": "答えがこのYとNに1を足したものに近いことを願っている。"
  },
  {
    "start": 3569274,
    "end": 3573096,
    "text": "この例では、リンゴはx個、果物はy個である。"
  },
  {
    "start": 3573198,
    "end": 3578464,
    "text": "ソファは家具であり、鳥である。"
  },
  {
    "start": 3578532,
    "end": 3581100,
    "text": "それなら、この変圧器が動物に応えてくれるだろう。"
  },
  {
    "start": 3582800,
    "end": 3593564,
    "text": "グレッグとスーリヤは、トランスフォーマーが線形回帰やロジスティクス回帰を行うことができるといういくつかの数字を示した。"
  },
  {
    "start": 3593612,
    "end": 3599120,
    "text": "少なくとも、これらの非常に優れたアルゴリズムと同様のパフォーマンスを持っている。"
  },
  {
    "start": 3599540,
    "end": 3606480,
    "text": "今回は、さらなる実験をお見せしよう。"
  },
  {
    "start": 3607480,
    "end": 3611152,
    "text": "ミタのタスクが2つあるとする。"
  },
  {
    "start": 3611296,
    "end": 3618560,
    "text": "あるミタのタスクは回帰タスクで、ベータ、つまりパラメータは通常のゼロ恒等式のようなものである。"
  },
  {
    "start": 3618720,
    "end": 3628976,
    "text": "Yはこのベータに関連したxの一次関数であり、同じベータから生成されたX-I-Yのペアであるデータセットzドラッグを形成する。"
  },
  {
    "start": 3629108,
    "end": 3633400,
    "text": "単一のデータセットに対して、単一のベータに関連付ける。"
  },
  {
    "start": 3633480,
    "end": 3637352,
    "text": "そして、idデータセットを生成する。"
  },
  {
    "start": 3637416,
    "end": 3644860,
    "text": "これらは、トレーニング前変換器の入力のメタデータ・ポイントである。"
  },
  {
    "start": 3645300,
    "end": 3653052,
    "text": "もう一つのタスクは、βが通常のゼロ同一性、yが二値である因果関係のタスクである。"
  },
  {
    "start": 3653196,
    "end": 3659990,
    "text": "X-I-Yのペアをデータセットとして、あるいはメタデータポイントとして持っている。"
  },
  {
    "start": 3661320,
    "end": 3663936,
    "text": "私たちは3人の変圧器をトレーニングしている。"
  },
  {
    "start": 3664128,
    "end": 3672052,
    "text": "多くの回帰データ（回帰データセット）を使って、トランスフォーマーのTFラックをトレーニングする。"
  },
  {
    "start": 3672116,
    "end": 3682860,
    "text": "これらのデータセットはidであるが、1つのデータセットについては、このベータを条件としてよくidであるX-I-Yのアパレルで構成されている。"
  },
  {
    "start": 3683280,
    "end": 3697404,
    "text": "異なるタスクに関しては、ベータ値は異なっており、この因果関係データセットを使用した別のトランスフォーマーtfclsと、混合データセットを使用した第3のトランスフォーマーとの間でも異なっている。"
  },
  {
    "start": 3697452,
    "end": 3706530,
    "text": "データ・ポイントの半分はこれらの回帰データ・セット、データ・セットの半分、これらのメタデータ・ポイントの半分はこのカスケイド・データのものである。"
  },
  {
    "start": 3707800,
    "end": 3716592,
    "text": "私たちが期待するように、最初の変圧器は、スーリヤとグレッグの図が示すように、線形回帰と同様の性能を持つ。"
  },
  {
    "start": 3716736,
    "end": 3722116,
    "text": "TS分類はロジスティック回帰と同様の性能を持つ。"
  },
  {
    "start": 3722228,
    "end": 3729980,
    "text": "問題は、3番目のトランスの性能はどうなのかということだ。"
  },
  {
    "start": 3730050,
    "end": 3732156,
    "text": "これが実験結果だ。"
  },
  {
    "start": 3732258,
    "end": 3738104,
    "text": "左側は、これら3つのトランスのタスク・パフォーマンスである。"
  },
  {
    "start": 3738152,
    "end": 3739608,
    "text": "リグレッション・タスクについて"
  },
  {
    "start": 3739704,
    "end": 3743388,
    "text": "右側は因果関係タスクのパフォーマンス。"
  },
  {
    "start": 3743564,
    "end": 3752364,
    "text": "ご覧のように、これらのオレンジ色の曲線は、予想通り線形回帰の性能と一致している。"
  },
  {
    "start": 3752412,
    "end": 3762660,
    "text": "TFCLsは最適ではないが、TFアルゴリズムの選択は、これは第3の変換器である一方で、線形回帰と同じTFrecの性能に一致する。"
  },
  {
    "start": 3764040,
    "end": 3769156,
    "text": "右手側では、このtfclsはロジスティクス回帰のパフォーマンスと一致する。"
  },
  {
    "start": 3769188,
    "end": 3778760,
    "text": "予想されたように、TF回帰は最適ではないが、TFアルゴリズム選択はロジスティクス回帰の性能と一致した。"
  },
  {
    "start": 3779600,
    "end": 3791540,
    "text": "というのも、このTFアルゴリズム選択には、どのタスクなのか伝えていないので、ただX-I-Yのペアをたくさん入力しただけだからだ。"
  },
  {
    "start": 3791640,
    "end": 3798368,
    "text": "このyは実数かもしれないし、2進数かもしれないが、どのアルゴリズムを実行すべきかは、この変換器にはよくわからない。"
  },
  {
    "start": 3798534,
    "end": 3805460,
    "text": "であれば、この変換器はどのようなタスクに対しても適切なアルゴリズムを選択することができる。"
  },
  {
    "start": 3805800,
    "end": 3815540,
    "text": "つまり、このトランスフォーマーは、統計学者のようにデータ分析やアルゴリズム選択を行うことができるのだ。"
  },
  {
    "start": 3817500,
    "end": 3822360,
    "text": "今日は、トランスがなぜ2つの役割を果たすことができるのかを説明しよう。"
  },
  {
    "start": 3822430,
    "end": 3825284,
    "text": "まず、基本的な所得税の学習アルゴリズムである。"
  },
  {
    "start": 3825332,
    "end": 3827800,
    "text": "第二に、所得税アルゴリズムの選択である。"
  },
  {
    "start": 3830320,
    "end": 3832332,
    "text": "だから、これは理論的な話なんだ。"
  },
  {
    "start": 3832386,
    "end": 3842000,
    "text": "では、なぜトランスフォーマーが所得税のアルゴリズム選択を行うことができるのかという疑問に答えるためには、トランスフォーマーの内部構造を調べる必要がある。"
  },
  {
    "start": 3843860,
    "end": 3849600,
    "text": "では、まず、このコンストラクションのインプット・アウトプット・フォーマットについて説明しよう。"
  },
  {
    "start": 3850260,
    "end": 3855350,
    "text": "つまり、入力は行列hである。"
  },
  {
    "start": 3857000,
    "end": 3860832,
    "text": "さて、各トークンはxi yのペアである。"
  },
  {
    "start": 3860896,
    "end": 3866324,
    "text": "最初のトークンはX-I-Xの1、最後のトークンはYの1、Xのnプラス1。"
  },
  {
    "start": 3866362,
    "end": 3869640,
    "text": "ここ、このYの場所は、ゼロのままにしておいた。"
  },
  {
    "start": 3869790,
    "end": 3873000,
    "text": "まあ、ここはアウトプットのための場所だからね。"
  },
  {
    "start": 3873580,
    "end": 3879816,
    "text": "ここで、スクラッチパッドとしてゼロを挿入する。"
  },
  {
    "start": 3879928,
    "end": 3882124,
    "text": "このスクラッチパッドはとても重要だ。"
  },
  {
    "start": 3882242,
    "end": 3889100,
    "text": "後述するように、ほとんどの整流はこのスクラッチパッドで行われる。"
  },
  {
    "start": 3889840,
    "end": 3899148,
    "text": "だから、この入力フォーマットは、グレッグやスーリヤのトークとは少し違うフォーマットになっていることに注目してほしい。"
  },
  {
    "start": 3899244,
    "end": 3911728,
    "text": "さて、入力トークンはx yだが、ここでは入力フォーマットは異なるが、彼らの入力フォーマットをこのフォーマットに非常に簡単に変換することができる。"
  },
  {
    "start": 3911824,
    "end": 3917860,
    "text": "だから、一般性を損なうことなく、変圧器を作りたいと考えている。"
  },
  {
    "start": 3918380,
    "end": 3921224,
    "text": "トランスフォーマーはシーケンスからシーケンスへの機能だ。"
  },
  {
    "start": 3921342,
    "end": 3924820,
    "text": "トランスの出力はマトリックスのままである。"
  },
  {
    "start": 3924980,
    "end": 3930730,
    "text": "私たちは、このゼロの場所が、このYの高さnに1を足したものになることを願っている。"
  },
  {
    "start": 3931100,
    "end": 3933932,
    "text": "さて、データセットが一般化線形モデルだとしよう。"
  },
  {
    "start": 3933986,
    "end": 3942530,
    "text": "私たちは、このY hype n plus oneが一般化線形モデルに適合し、y n plus oneに近いものを出力することを望んでいる。"
  },
  {
    "start": 3943380,
    "end": 3952720,
    "text": "我々は、トランスフォーマーが、いくつかの仮想的な経験的リスクに対して近似的な勾配降下を実行することによって、このタスクを達成できることを主張する。"
  },
  {
    "start": 3953880,
    "end": 3961776,
    "text": "これが一般化線形モデルの回帰の経験的リスクであるとする。"
  },
  {
    "start": 3961888,
    "end": 3964980,
    "text": "グラデーションの砂はこのような形式になっている。"
  },
  {
    "start": 3966360,
    "end": 3975560,
    "text": "私たちは、このトランスフォーマーが、そのアーキテクチャにおいて、コンテキストの中でこのアルゴリズムを実装できることを示したい。"
  },
  {
    "start": 3976700,
    "end": 3978996,
    "text": "トランスの構造とは？"
  },
  {
    "start": 3979028,
    "end": 3983500,
    "text": "トランスフォーマーは、フィードフォワード層とアテンション層の反復的な組み合わせである。"
  },
  {
    "start": 3984400,
    "end": 3987084,
    "text": "フィードフォワード層はあまり重要ではない。"
  },
  {
    "start": 3987202,
    "end": 3992480,
    "text": "これは、各トークンを2層のニューラルネットワークにしたもので、残差接続構造になっている。"
  },
  {
    "start": 3994340,
    "end": 3997772,
    "text": "重要なのはアテンション層である。"
  },
  {
    "start": 3997916,
    "end": 4002636,
    "text": "さて、これはアテンション層の数学的定式化である。"
  },
  {
    "start": 4002748,
    "end": 4007968,
    "text": "各トークンhiは、これらのqkb相互作用によって更新される。"
  },
  {
    "start": 4008144,
    "end": 4019960,
    "text": "これはqクエリキーの内積であり、次に非線形性を通過させ、トークンの値行列平均とヘッドの値行列和をかける。"
  },
  {
    "start": 4020940,
    "end": 4035276,
    "text": "つまり、このシグマは、ソフトマックス関数ではなく、バリュー関数とみなすということだ。"
  },
  {
    "start": 4035378,
    "end": 4042160,
    "text": "定量的な誤差をコントロールするためには、これはある意味重要なことなのだ。"
  },
  {
    "start": 4044980,
    "end": 4050960,
    "text": "さて、ではこのトランスフォーマーが勾配降下を実装できることを示したい。"
  },
  {
    "start": 4051300,
    "end": 4058032,
    "text": "アテンション・レイヤーとグラディエント・セント・アルゴリズムのアーキテクチャーと定式化について、比較してみよう。"
  },
  {
    "start": 4058096,
    "end": 4065380,
    "text": "アテンション・レイヤーがQkvの相互作用によってトークンを更新しているのがわかるだろう。"
  },
  {
    "start": 4065900,
    "end": 4075540,
    "text": "勾配アルゴリズムを書くと、パラメータwはxwyの相互作用によって更新される。"
  },
  {
    "start": 4075700,
    "end": 4082780,
    "text": "この表現には多くの共通点がある。"
  },
  {
    "start": 4083520,
    "end": 4098480,
    "text": "つまり、このQKV行列を構築するだけで、この注目層とグラディエント定式化はまったく同じになることがわかった。"
  },
  {
    "start": 4098550,
    "end": 4107776,
    "text": "このhをxywとし、このゼロの場所をスクラッチパッドとすればいい。"
  },
  {
    "start": 4107808,
    "end": 4113140,
    "text": "ここでは、勾配降下の重みの更新を保存する。"
  },
  {
    "start": 4113480,
    "end": 4120250,
    "text": "となれば、qkvのいくつかの構成によって、この2つの式が一致することを示すことができる。"
  },
  {
    "start": 4123900,
    "end": 4128404,
    "text": "つまり、1つのアテンション・レイヤーで1ステップのグリーン・デサントを実行できる。"
  },
  {
    "start": 4128452,
    "end": 4135420,
    "text": "これらのアテンション・レイヤーを連結させれば、L個のテンション・レイヤーを使って、Lステップのグリーン・センスを実行することができる。"
  },
  {
    "start": 4136640,
    "end": 4138296,
    "text": "フィードフォワード層についてはどうだろう？"
  },
  {
    "start": 4138328,
    "end": 4142800,
    "text": "我々は、これらのフィードフォワード層がこの近接関数を実装するのに適していることを示すことができる。"
  },
  {
    "start": 4142870,
    "end": 4151490,
    "text": "つまり、この変換器アーキテクチャは、この問題を解決するために使用できる近接グリッド降下を実装することができる。"
  },
  {
    "start": 4152660,
    "end": 4169656,
    "text": "理論的には、エンベッディングの次元、層の数、アテンションヘッドのフィード数、フォワード層の幅、パラメータのノルムを制御した変換器があり、これらの変換器は回帰ロジスティクス、回帰、およびそれ以下を実行できることを示すことができる。"
  },
  {
    "start": 4169838,
    "end": 4179580,
    "text": "これらのアルゴリズムは、特定のデータ分布、標準的なデータ分布で最小最適誤差を達成することができます。"
  },
  {
    "start": 4180960,
    "end": 4193132,
    "text": "さらに、この変換器を事前に訓練し、最小化するだけで、このアルゴリズムを同等の誤差で効率的に実行する変換器を見つけることができる。"
  },
  {
    "start": 4193196,
    "end": 4209140,
    "text": "まあ、これは教師ありのメタ学習みたいなもので、経験的なリスクを最小化し、汎化誤差を制御するものだ。"
  },
  {
    "start": 4211000,
    "end": 4219400,
    "text": "さて、これが我々の理論的な結果であり、トランスフォーマーがどのように個人所得税の学習アルゴリズムを実装できるかを示している。"
  },
  {
    "start": 4220220,
    "end": 4230600,
    "text": "トランスフォーマーがこのようなアルゴリズム選択を実行できること、あるいは回帰タスクには回帰を、分類タスクには分類を実装できることも示したい。"
  },
  {
    "start": 4230760,
    "end": 4233068,
    "text": "トランスフォーマーはどのようにこれを実装できるのか？"
  },
  {
    "start": 4233234,
    "end": 4234984,
    "text": "私たちは2つのメカニズムを提案している。"
  },
  {
    "start": 4235032,
    "end": 4237980,
    "text": "メカニズム1、ポストセル検証。"
  },
  {
    "start": 4238400,
    "end": 4244748,
    "text": "このトランスフォーマーは、k個のアルゴリズムを並行して実行し、検証誤差の少ないアルゴリズムを選択することができる。"
  },
  {
    "start": 4244924,
    "end": 4264310,
    "text": "これを達成するためには、アテンションレイヤーを1層追加し、最後にトランスフォーマーを3層ほど追加するだけでよい。"
  },
  {
    "start": 4264840,
    "end": 4271560,
    "text": "2つ目のメカニズムは、事前テストであり、アルゴリズムを選択するための仮説を形成することができる。"
  },
  {
    "start": 4272620,
    "end": 4284184,
    "text": "例えば、この回帰と分類の問題をトランスフォーマーに実装させたい場合、まずトランスフォーマーはy'sに対してバイナリテストを実行すればいい。"
  },
  {
    "start": 4284312,
    "end": 4287116,
    "text": "これらのYが回帰であれば、単なる実数である。"
  },
  {
    "start": 4287218,
    "end": 4291708,
    "text": "さて、トランスフォーマーはこの回帰アルゴリズムを実装する。"
  },
  {
    "start": 4291804,
    "end": 4296080,
    "text": "これらのYが2進数であれば、トランスフォーマーはこのプレゼンテーションを実行することができる。"
  },
  {
    "start": 4298420,
    "end": 4304640,
    "text": "これは施工結果であり、誤差は定量的にコントロールできる。"
  },
  {
    "start": 4305640,
    "end": 4310320,
    "text": "ポストセルバリデーションと呼ばれる別のメカニズムがある。"
  },
  {
    "start": 4310480,
    "end": 4324600,
    "text": "基本的には、訓練検証分割だけを実行し、この訓練データセットで2つの異なるアルゴリズムを実行し、これらの検証データセットで評価されたテスト誤差を見てアルゴリズムを選択することができます。"
  },
  {
    "start": 4327660,
    "end": 4339368,
    "text": "要約すると、我々は、トランスフォーマーが勾配降下メカニズムを用いて単純なSAアルゴリズムを効率的に実装でき、統計学者と同様のアルゴリズム選択を効率的に実装できることを証明した。"
  },
  {
    "start": 4339464,
    "end": 4342860,
    "text": "このような変換器は、統計的に効率よく事前学習することができる。"
  },
  {
    "start": 4343520,
    "end": 4345184,
    "text": "これが私の話の要約である。"
  },
  {
    "start": 4345382,
    "end": 4346290,
    "text": "ありがとう。"
  },
  {
    "start": 4349300,
    "end": 4350896,
    "text": "素晴らしい話をありがとう。"
  },
  {
    "start": 4350998,
    "end": 4362564,
    "text": "データに対する勾配降下について1、2問質問する時間がある。"
  },
  {
    "start": 4362682,
    "end": 4366256,
    "text": "今日の話の中で、二重降下のような現象があったと思う。"
  },
  {
    "start": 4366288,
    "end": 4370504,
    "text": "Dスクエアを正確に解くというより、ほとんどそうだ。"
  },
  {
    "start": 4370622,
    "end": 4373972,
    "text": "勾配降下は、レイヤーの数に依存していると思う。"
  },
  {
    "start": 4374036,
    "end": 4374504,
    "text": "そうだね。"
  },
  {
    "start": 4374622,
    "end": 4378584,
    "text": "あるいは、この構造ではこうだ。"
  },
  {
    "start": 4378702,
    "end": 4384388,
    "text": "ノイズのない回帰タスクを考えているので、二重降下はない。"
  },
  {
    "start": 4384484,
    "end": 4393250,
    "text": "私の理解では、各レイヤーはグラデーション・デザインの1ステップを実行する。"
  },
  {
    "start": 4393620,
    "end": 4402892,
    "text": "レイヤー数が例えば20であれば、最適に近い状態に収束することは保証できないと思う。"
  },
  {
    "start": 4403036,
    "end": 4406612,
    "text": "線形回帰だから、収束は指数関数的に速いような気がする。"
  },
  {
    "start": 4406666,
    "end": 4406836,
    "text": "そうだね。"
  },
  {
    "start": 4406858,
    "end": 4410550,
    "text": "20レイヤー、誤差はすでに非常に小さいような気がする。"
  },
  {
    "start": 4412280,
    "end": 4413990,
    "text": "問題ないと思う。"
  },
  {
    "start": 4414920,
    "end": 4417120,
    "text": "すでに20のレイヤーが収束していると思う。"
  },
  {
    "start": 4417130,
    "end": 4417544,
    "text": "いいね。"
  },
  {
    "start": 4417662,
    "end": 4422890,
    "text": "私たちのアーキテクチャーは、あまり8層のプラットフォームではないと思う。"
  },
  {
    "start": 4423580,
    "end": 4424330,
    "text": "ありがとう。"
  },
  {
    "start": 4427020,
    "end": 4430730,
    "text": "ヤン・ソン、素晴らしい話をありがとう。"
  },
  {
    "start": 4440900,
    "end": 4463510,
    "text": "なかなかうまくいかない。"
  },
  {
    "start": 4464280,
    "end": 4466420,
    "text": "よし、手動でクリックしてみよう。"
  },
  {
    "start": 4467180,
    "end": 4469048,
    "text": "何か故障しているのか？"
  },
  {
    "start": 4469134,
    "end": 4470456,
    "text": "別の使い方はありますか？"
  },
  {
    "start": 4470478,
    "end": 4471610,
    "text": "好きでいる必要があるのか。"
  },
  {
    "start": 4472060,
    "end": 4475770,
    "text": "オーケー、何？"
  },
  {
    "start": 4479680,
    "end": 4481230,
    "text": "それが何を意味するのかは分からない。"
  },
  {
    "start": 4484720,
    "end": 4485820,
    "text": "スライドショー"
  },
  {
    "start": 4486960,
    "end": 4487692,
    "text": "これでよし。"
  },
  {
    "start": 4487746,
    "end": 4491816,
    "text": "さて、私はボブ・カーペンターだ。"
  },
  {
    "start": 4491848,
    "end": 4500160,
    "text": "私はフラットアイアン研究所の計算数学センターから来たが、このセンターもサイモンの財団が主催している。"
  },
  {
    "start": 4500900,
    "end": 4508752,
    "text": "今回お話ししたいのは、私たちが今やっている標準的な強化学習を少し柔らかくしたものです。"
  },
  {
    "start": 4508806,
    "end": 4510004,
    "text": "両方のモチベーションを上げたい。"
  },
  {
    "start": 4510042,
    "end": 4519460,
    "text": "それがどういうことなのか、また、そうすることで何が得られると私が考えているのか、その両方をお話ししたいと思います。これが非常にうまくいった他の事例から一般化できれば、かなり多くのことが得られると思います。"
  },
  {
    "start": 4519610,
    "end": 4519972,
    "text": "そうだね。"
  },
  {
    "start": 4520026,
    "end": 4521012,
    "text": "我々は何をしているのか？"
  },
  {
    "start": 4521066,
    "end": 4525976,
    "text": "これまでのところ、GPT-3までのことは彼らが書いていたので知っているが、その後は書かなくなってしまった。"
  },
  {
    "start": 4525998,
    "end": 4527912,
    "text": "その時点で彼らが何をしたかを話すだけだ。"
  },
  {
    "start": 4527966,
    "end": 4534924,
    "text": "彼らは大量のデータで変換器を大量に事前学習させ、それをまた再学習させた。"
  },
  {
    "start": 4534962,
    "end": 4539900,
    "text": "彼らは、少なくとも可能な限り、役に立ち、無害で、真実であるようにウェイトを再教育した。"
  },
  {
    "start": 4540050,
    "end": 4543944,
    "text": "アライメントデータは、人間のフィードバックに基づいて決定される。"
  },
  {
    "start": 4544072,
    "end": 4549724,
    "text": "具体的には、GPTの出力を使って、ここに2つの出力があると言っているんだ。"
  },
  {
    "start": 4549772,
    "end": 4552512,
    "text": "出力aと出力b、どちらが良いですか？"
  },
  {
    "start": 4552566,
    "end": 4556784,
    "text": "人間の判断は、どちらが優れているかという形になる。"
  },
  {
    "start": 4556982,
    "end": 4561396,
    "text": "クリス・マニングが説明したように、そのためのトレーニング・ロスは、ブラッドリー・テリーのモデルのようなものだ。"
  },
  {
    "start": 4561578,
    "end": 4565024,
    "text": "私たちは基本的に、それぞれのアウトプットに報酬モデルを持っている。"
  },
  {
    "start": 4565072,
    "end": 4571496,
    "text": "私たちがやっているのは、これらの報酬の違いを物流規模で見ることです。"
  },
  {
    "start": 4571518,
    "end": 4572884,
    "text": "我々はこの敗戦を得た。"
  },
  {
    "start": 4573012,
    "end": 4577976,
    "text": "つまり、aのスコアがbのスコアよりずっと高くなるようにしたい、ということだ。"
  },
  {
    "start": 4578078,
    "end": 4581450,
    "text": "もし人間の注釈者がaの方がbより優れていると言ったとしたら。"
  },
  {
    "start": 4582080,
    "end": 4584972,
    "text": "正確な形はどうでもいい。"
  },
  {
    "start": 4585026,
    "end": 4588124,
    "text": "ここで計算の細部にこだわってはいけない。"
  },
  {
    "start": 4588242,
    "end": 4593144,
    "text": "ひとつ指摘しておきたいのは、人間のフィードバックは比較的安価だということだ。"
  },
  {
    "start": 4593272,
    "end": 4596164,
    "text": "アップワークで40人の請負業者を雇うことでこれを実現した。"
  },
  {
    "start": 4596232,
    "end": 4604528,
    "text": "雇用期間は言わなかったが、仮に1年間雇ったとしても、1人年間5万ドルで、200万ドルにしかならない。"
  },
  {
    "start": 4604694,
    "end": 4606112,
    "text": "大金のようだ。"
  },
  {
    "start": 4606166,
    "end": 4608628,
    "text": "私がプロジェクトに費やせる金額よりも多い。"
  },
  {
    "start": 4608794,
    "end": 4616292,
    "text": "AI研究者たちは、彼らが持っている5億ドルのハードウェアに比べ、少なくとも年間50万ドルを支払っている。"
  },
  {
    "start": 4616346,
    "end": 4620372,
    "text": "すべてのデータ・ライセンス・サーバーは、小銭みたいなものだろう？"
  },
  {
    "start": 4620426,
    "end": 4624120,
    "text": "これは、彼らがこのために費やしている金額のノイズのようなものだ。"
  },
  {
    "start": 4624190,
    "end": 4632428,
    "text": "強化トレーニングという点では、もっと投資できる余地があると思う。"
  },
  {
    "start": 4632514,
    "end": 4648336,
    "text": "今、私たちが持っているスケーリング結果について考えてみると、どれだけのデータを持っているか、どれだけのパラメーターを持っているか、計算機に対してどれだけのスケーリング結果があるのか、私は、どれだけのデータやトレーニングを行ったか、どれだけの人間のフィードバックを行ったか、ドルに対してスケーリング法則があると推測している。"
  },
  {
    "start": 4648438,
    "end": 4655430,
    "text": "私たちはおそらく、人間のフィードバックに十分な資金を投入していないし、可能な限り最適な方法でそれを行っていないと思う。"
  },
  {
    "start": 4656360,
    "end": 4656772,
    "text": "そうだろう？"
  },
  {
    "start": 4656826,
    "end": 4664788,
    "text": "OpenAIのアライメント論文で報告されていることのひとつに、アノテーター間の合意はわずか73％というものがある。"
  },
  {
    "start": 4664874,
    "end": 4670516,
    "text": "このようなものを大量に人々に与え、これが彼らの手で選ばれ、訓練された注釈者たちだった。"
  },
  {
    "start": 4670708,
    "end": 4676890,
    "text": "その結果、「aの方がbより優れている」という意見に対する一致率は70％程度にとどまった。"
  },
  {
    "start": 4678220,
    "end": 4686412,
    "text": "ここでの問題のひとつは、彼らが評価するよう求めている目標、有益、無害、真実が互いに対立していることだろう？"
  },
  {
    "start": 4686466,
    "end": 4693340,
    "text": "役に立つこと、答えを提供することは、私がそれをあなたに求める内容によっては、時として真実性や有害性の邪魔になることがある。"
  },
  {
    "start": 4693410,
    "end": 4699372,
    "text": "OpenAIは、有益であることを優先し、有害性や真実性については後でフィルターをかけたという。"
  },
  {
    "start": 4699436,
    "end": 4701520,
    "text": "それが何を意味するのかはよくわからない。"
  },
  {
    "start": 4701590,
    "end": 4704130,
    "text": "彼らの論文の付録には注釈があるだけだ。"
  },
  {
    "start": 4704900,
    "end": 4717172,
    "text": "複数のアノテーターがいる場合、伝統的なマルチアノテーションのアプローチでは、アノテーションを行わず、ただ一人の人間にデータをアノテーションさせる。"
  },
  {
    "start": 4717226,
    "end": 4722952,
    "text": "彼らはおそらく、注釈者の内輪の合意を把握するためにちょっとした研究をして、ああ、70％だ、これで十分だと言ったのだろう。"
  },
  {
    "start": 4723006,
    "end": 4730504,
    "text": "単一注釈にしましょう。その方が、注釈者のトレーニング時間を効率的に使えることがありますからね。"
  },
  {
    "start": 4730542,
    "end": 4736590,
    "text": "また、多数決を取ることもできる。おそらく機械学習で最も一般的に行われていることだろう。"
  },
  {
    "start": 4737120,
    "end": 4740824,
    "text": "もうひとつ、機械学習でよくあるのは、一致しないものを検閲することだ。"
  },
  {
    "start": 4740872,
    "end": 4748096,
    "text": "トレーニング・デッキ・セットの中にある項目で、アノテーターが同意しないものがあれば、それを捨てて使わないことだ。"
  },
  {
    "start": 4748118,
    "end": 4750288,
    "text": "質の低いデータなのかもしれないね。"
  },
  {
    "start": 4750374,
    "end": 4753420,
    "text": "私は、これらすべてが悪いアプローチだと主張するつもりだ。"
  },
  {
    "start": 4753580,
    "end": 4754832,
    "text": "どれもやってはいけない。"
  },
  {
    "start": 4754886,
    "end": 4756896,
    "text": "もっといい方法があるはずだ。"
  },
  {
    "start": 4757078,
    "end": 4760496,
    "text": "分類子を使った簡単な例で、このモチベーションを高めてみよう。"
  },
  {
    "start": 4760528,
    "end": 4762484,
    "text": "みんなが僕のために仕掛けてくれたんだと思う。"
  },
  {
    "start": 4762602,
    "end": 4765910,
    "text": "ここではベイズ・ロジスティック回帰を並べるだけだ。"
  },
  {
    "start": 4766600,
    "end": 4774084,
    "text": "yを結果、xを共変量または特徴量、αとβを回帰係数とする。"
  },
  {
    "start": 4774212,
    "end": 4778116,
    "text": "ここでは共変量に正規分布があると仮定する。"
  },
  {
    "start": 4778148,
    "end": 4780984,
    "text": "そんなことはどうでもよくて、これらに何らかの先行策を施すつもりだ。"
  },
  {
    "start": 4781022,
    "end": 4783380,
    "text": "繰り返しになるが、それはここでの論点の一部ではない。"
  },
  {
    "start": 4783470,
    "end": 4790424,
    "text": "このことを考えるには、これが1に等しいというロジットは、予測変数の一次関数になるということだ。"
  },
  {
    "start": 4790472,
    "end": 4792636,
    "text": "それがロジスティック回帰なのだ。"
  },
  {
    "start": 4792738,
    "end": 4795292,
    "text": "問題は、どうやって金本位制を作るかだ。"
  },
  {
    "start": 4795426,
    "end": 4795736,
    "text": "そうだろう？"
  },
  {
    "start": 4795778,
    "end": 4797216,
    "text": "金本位制とはどのようなものか？"
  },
  {
    "start": 4797238,
    "end": 4801008,
    "text": "y個のnをゼロか1に量子化する。"
  },
  {
    "start": 4801174,
    "end": 4804656,
    "text": "y nが1になる確率がある程度あってもね。"
  },
  {
    "start": 4804678,
    "end": 4809284,
    "text": "ここで、私が金本位制を作る時点では、ゼロか1のどちらかを言うことになるよね？"
  },
  {
    "start": 4809322,
    "end": 4811716,
    "text": "私は2つの伝統的な方法でそれを行うことができる。"
  },
  {
    "start": 4811818,
    "end": 4820064,
    "text": "もし、すべての項目に対して明確な答えがあるような金字塔のようなものを作りたいのであれば、私は最善の推測をすることができる。"
  },
  {
    "start": 4820202,
    "end": 4825512,
    "text": "1になる確率が2分の1より大きければ、1にすればいい。"
  },
  {
    "start": 4825646,
    "end": 4828216,
    "text": "これは、機械学習の専門家が通常行うことだ。"
  },
  {
    "start": 4828318,
    "end": 4829352,
    "text": "これは本当にひどい。"
  },
  {
    "start": 4829406,
    "end": 4830490,
    "text": "そんなことはするな。"
  },
  {
    "start": 4830860,
    "end": 4832040,
    "text": "この方がずっといい。"
  },
  {
    "start": 4832110,
    "end": 4833996,
    "text": "これが統計学者の仕事だ。"
  },
  {
    "start": 4834098,
    "end": 4836444,
    "text": "を1にしてくださいと言う代わりに。"
  },
  {
    "start": 4836482,
    "end": 4839244,
    "text": "確率が半分以上なら、サンプリングする。"
  },
  {
    "start": 4839362,
    "end": 4840828,
    "text": "試食したい理由は"
  },
  {
    "start": 4840834,
    "end": 4845504,
    "text": "推論プロセスを通じて不確実性をできるだけ伝播させたい。"
  },
  {
    "start": 4845702,
    "end": 4848064,
    "text": "どっちなのかよくわからないということだ。"
  },
  {
    "start": 4848102,
    "end": 4850048,
    "text": "最も可能性の高い1つに絞る。"
  },
  {
    "start": 4850134,
    "end": 4852780,
    "text": "推定値にバイアスを導入する。"
  },
  {
    "start": 4852860,
    "end": 4854016,
    "text": "ずっといい。"
  },
  {
    "start": 4854198,
    "end": 4860452,
    "text": "ロジスティック回帰を使ったシミュレーションなら、GPTの助けを借りれば、パソコンで1時間もあればできる。"
  },
  {
    "start": 4860586,
    "end": 4865252,
    "text": "このようなことを簡単なケースで実証するのはとても簡単でしょう？"
  },
  {
    "start": 4865386,
    "end": 4870472,
    "text": "私たちが作る基準は、どれも愚者の金本位制のようなものでしょう？"
  },
  {
    "start": 4870526,
    "end": 4876520,
    "text": "私たちはシステムから何らかの確率的な出力があることを知っているのに、ラベルを1か0に固定している。"
  },
  {
    "start": 4876590,
    "end": 4879548,
    "text": "私たちは1かゼロかにはそれほど自信を持っていない。"
  },
  {
    "start": 4879714,
    "end": 4883852,
    "text": "前にも言ったように、サンプリングが支配的で、最善の策を講じる。"
  },
  {
    "start": 4883986,
    "end": 4886604,
    "text": "オーバーサンプリングの方がもっといいでしょ？"
  },
  {
    "start": 4886642,
    "end": 4900224,
    "text": "この確率に従って1つのyをサンプリングすることもできるが、もっとサンプリングして、異なるラベルを持つ複数のものを得ることもできる。"
  },
  {
    "start": 4900342,
    "end": 4902624,
    "text": "ウエイトトレーニングは本当にいい方法だ。"
  },
  {
    "start": 4902662,
    "end": 4909860,
    "text": "もし、あなたがこれにアクセスできて、これができるのであれば、これはあなたができる他のどんなことよりもはるかに優れているよね？"
  },
  {
    "start": 4909930,
    "end": 4918356,
    "text": "損失が0か1かではなく、1になる確率と同じにするんだ。"
  },
  {
    "start": 4918458,
    "end": 4925752,
    "text": "であれば、1であれば加重ペナルティを、0であれば加重ペナルティを与えるつもりだ。"
  },
  {
    "start": 4925886,
    "end": 4929400,
    "text": "そうですね、ここで報酬の順番を入れ替えました。"
  },
  {
    "start": 4929550,
    "end": 4930056,
    "text": "そうだね。"
  },
  {
    "start": 4930158,
    "end": 4931352,
    "text": "これは何をするものなのか？"
  },
  {
    "start": 4931486,
    "end": 4932844,
    "text": "なぜこんなことをするのか？"
  },
  {
    "start": 4932962,
    "end": 4935244,
    "text": "タスクドリブンの正則化だね。"
  },
  {
    "start": 4935282,
    "end": 4936344,
    "text": "私たちは回帰について考える。"
  },
  {
    "start": 4936392,
    "end": 4945676,
    "text": "回帰は、正則化するか、正則化のようなある種のシュリンクを適用すると、よりロバストになる傾向がある。"
  },
  {
    "start": 4945868,
    "end": 4949440,
    "text": "平均的な収縮は、物事をゼロにするだけだ。"
  },
  {
    "start": 4949590,
    "end": 4957408,
    "text": "これは、anとBNの特定のインスタンスについて、anがBNより優れていることを70％しか確信していないと言うのだ。"
  },
  {
    "start": 4957504,
    "end": 4961636,
    "text": "それは、クラシファイアにそれを尊重させようとするものだ。"
  },
  {
    "start": 4961818,
    "end": 4974104,
    "text": "これは、私がトレーニングしている確率に近くなるように、分類器がそれらのものに対する報酬を近づけようとするものだ。"
  },
  {
    "start": 4974142,
    "end": 4978936,
    "text": "もし70％の確率で0か1だとしたら、私はそれでトレーニングしたい。"
  },
  {
    "start": 4978958,
    "end": 4982716,
    "text": "その答えが出るように、クラシファイアを後押しすることになる。"
  },
  {
    "start": 4982818,
    "end": 4990540,
    "text": "極端な話ではないが、機械学習の分類器の多くは、予測確率をゼロや1に押しやってしまうため、非常に較正が悪い。"
  },
  {
    "start": 4990690,
    "end": 4994604,
    "text": "その理由のひとつは、彼らがこの種の訓練を受けていないからだ。"
  },
  {
    "start": 4994802,
    "end": 4995164,
    "text": "そうだね。"
  },
  {
    "start": 4995202,
    "end": 4995928,
    "text": "私たちに何ができるのか？"
  },
  {
    "start": 4995954,
    "end": 4997712,
    "text": "スライドはあと2、3枚しかない。"
  },
  {
    "start": 4997846,
    "end": 5000284,
    "text": "アノテーションのモデルを作ることができる。"
  },
  {
    "start": 5000332,
    "end": 5001264,
    "text": "私はこれに取り組んできた。"
  },
  {
    "start": 5001302,
    "end": 5012960,
    "text": "この問題は、私が自然言語処理に携わっていた会社にいたとき、データセットを作り続けなければならず、ベイジアン統計学に取り組まなければならなかったので、初めて私を自然言語処理から追い出した問題である。"
  },
  {
    "start": 5013120,
    "end": 5017716,
    "text": "その非常にシンプルなモデルが、1978年のデビッドとスキームである。"
  },
  {
    "start": 5017898,
    "end": 5028324,
    "text": "私たちがしたいことは、評価者の正確さと偏りのモデルを提供し、anがBNより大きい確率を予測させることです。"
  },
  {
    "start": 5028452,
    "end": 5033880,
    "text": "基礎となる係数を与えるのでもなく、基礎となる予測因子を与えるのでもなく、ただ人間のフィードバックを与えるのだ。"
  },
  {
    "start": 5034300,
    "end": 5039716,
    "text": "私は多くの人間に尋ね、彼らは私に、私はanがBNより大きい確率を持っている、と言う。"
  },
  {
    "start": 5039828,
    "end": 5042064,
    "text": "また同じことができるだろう？"
  },
  {
    "start": 5042102,
    "end": 5044944,
    "text": "さっき言ったのは、シミュレーションのようなものだ。"
  },
  {
    "start": 5044982,
    "end": 5046192,
    "text": "これが私たちが本当にやることだ。"
  },
  {
    "start": 5046246,
    "end": 5047696,
    "text": "これらのことを評価してもらうつもりだ。"
  },
  {
    "start": 5047798,
    "end": 5048736,
    "text": "彼らにこれをやらせるつもりだ。"
  },
  {
    "start": 5048758,
    "end": 5050524,
    "text": "今、私たちには同じ選択肢がある。"
  },
  {
    "start": 5050572,
    "end": 5051520,
    "text": "私たちはこれを取ることができる。"
  },
  {
    "start": 5051590,
    "end": 5052988,
    "text": "これは確率になるだろう。"
  },
  {
    "start": 5053164,
    "end": 5058800,
    "text": "これを重み付けトレーニングに使うか、サンプリングするか、最も高い確率を取るかだ。"
  },
  {
    "start": 5058960,
    "end": 5061572,
    "text": "この2つの間には大きな隔たりがある。"
  },
  {
    "start": 5061706,
    "end": 5065008,
    "text": "この2つと効率の間にはかなり大きな隔たりがある。"
  },
  {
    "start": 5065184,
    "end": 5065968,
    "text": "そうだね。"
  },
  {
    "start": 5066154,
    "end": 5073204,
    "text": "多重サンプリングは、サンプルサイズが大きくなるにつれて、重み付けに収束していく。"
  },
  {
    "start": 5073252,
    "end": 5074820,
    "text": "たくさんのサンプルが必要かもしれない。"
  },
  {
    "start": 5074900,
    "end": 5083404,
    "text": "ああ、申し訳ないが、ダビドや978の上のモデルでは誰のフィードバックが使われているのだろう？"
  },
  {
    "start": 5083602,
    "end": 5085740,
    "text": "大勢の人間の襲撃があるんだ。"
  },
  {
    "start": 5086400,
    "end": 5093480,
    "text": "アップワークでもどこでも、私たちが集めた人たちを連れて行き、彼らにたくさんの例を示して、イエス、ノー、何でもいいと言ってもらう。"
  },
  {
    "start": 5093560,
    "end": 5097120,
    "text": "それは彼らの精度やバイアスなのか、それともモデルの精度やバイアスなのか？"
  },
  {
    "start": 5098820,
    "end": 5102764,
    "text": "これは、人間のフィードバックに基づいて確率を推定することになる。"
  },
  {
    "start": 5102812,
    "end": 5110448,
    "text": "これが正解だと決めつけることはできないが、通常、ゼロか1と仮定したり、多数決を取ったりするよりは、ずっと近い答えになるはずだ。"
  },
  {
    "start": 5110544,
    "end": 5112470,
    "text": "一般的に、これらのモデルはかなり良い。"
  },
  {
    "start": 5114520,
    "end": 5116324,
    "text": "ウエイトトレーニングは満身創痍だ。"
  },
  {
    "start": 5116362,
    "end": 5118708,
    "text": "ラルフがサンプリングをブラックウェル化。"
  },
  {
    "start": 5118804,
    "end": 5119112,
    "text": "完璧だ。"
  },
  {
    "start": 5119166,
    "end": 5120696,
    "text": "もう少しで終わる。"
  },
  {
    "start": 5120718,
    "end": 5121736,
    "text": "デヴィッド・ブラックウェルがここにいた。"
  },
  {
    "start": 5121758,
    "end": 5123496,
    "text": "寮の名前も彼にちなんで付けられたばかりだ。"
  },
  {
    "start": 5123598,
    "end": 5124250,
    "text": "でもね。"
  },
  {
    "start": 5125180,
    "end": 5131608,
    "text": "一般的な多数決は、ある種の退化したモデルに関して最善の推測をすることと同じだ。"
  },
  {
    "start": 5131774,
    "end": 5132104,
    "text": "そうだろう？"
  },
  {
    "start": 5132142,
    "end": 5135544,
    "text": "このウェイトトレーニングの結果、規則正しいプレーができるようになるのだ。"
  },
  {
    "start": 5135592,
    "end": 5142296,
    "text": "2010年のJMLRにヴィカス・レイカーとシーメンスの他の人たちによる画像認識に関する素晴らしい論文がある。"
  },
  {
    "start": 5142488,
    "end": 5147424,
    "text": "彼らが示したのは、分類器とデイヴィッド・スキーム・モデルの両方を共同で推定することが可能だということだ。"
  },
  {
    "start": 5147462,
    "end": 5160164,
    "text": "さらに重要なのは、この確率を理論的に示すのは非常に簡単であるにもかかわらず、彼らはこれを実際の問題に適用し、単なる統計ジャーナルではなく、MLジャーナルに掲載されるようにし、これが実際に機能することを示したことである。"
  },
  {
    "start": 5160362,
    "end": 5177832,
    "text": "というのも、正則化され、システムが真のデータからレイダーが言った確率と等しい確率を割り当てた時点で、設定した損失を最小化するからです。"
  },
  {
    "start": 5177886,
    "end": 5181050,
    "text": "あ、ごめん、あそこで表記を変えたからため息になるべきだったね。"
  },
  {
    "start": 5182460,
    "end": 5184250,
    "text": "それしかないんだ。"
  },
  {
    "start": 5184640,
    "end": 5186220,
    "text": "参考文献に残しておくよ。"
  },
  {
    "start": 5189520,
    "end": 5190236,
    "text": "ありがとう。"
  },
  {
    "start": 5190338,
    "end": 5192030,
    "text": "質問は1つだけです。"
  },
  {
    "start": 5200020,
    "end": 5210640,
    "text": "あなたが物事を変えるべきだと言ったスキームでは、確率的に行動し、統計や予想をあまり変えないようにする。"
  },
  {
    "start": 5210720,
    "end": 5224010,
    "text": "もし、シグナルが非常に大きい場合にのみ行動したいのであれば、それを条件とするのであれば、そのように変更することができる。"
  },
  {
    "start": 5224540,
    "end": 5229316,
    "text": "このシグナルは、レイダーからのシグナルやプレディクターからのシグナルから見ると非常に大きい。"
  },
  {
    "start": 5229508,
    "end": 5231560,
    "text": "デビッド・シャイーンモデルがそうだ。"
  },
  {
    "start": 5231630,
    "end": 5231912,
    "text": "そうだね。"
  },
  {
    "start": 5231966,
    "end": 5238268,
    "text": "これは基本的に、レイダーの精度とバイアスを推定し、それを調整するものだ。"
  },
  {
    "start": 5238434,
    "end": 5241660,
    "text": "基本的にスパム的なタイプならね。"
  },
  {
    "start": 5241730,
    "end": 5246016,
    "text": "基本的に彼らの貢献は相殺され、彼らは何も持っていない。"
  },
  {
    "start": 5246118,
    "end": 5250272,
    "text": "最も多くの情報を引き出そうとする。"
  },
  {
    "start": 5250326,
    "end": 5252944,
    "text": "これらもすべて再発見されている。"
  },
  {
    "start": 5252982,
    "end": 5257056,
    "text": "私がここにいる間に、スタンフォード大学のジョン・ドゥッチがこの件について論文を書いたと誰かが教えてくれた。"
  },
  {
    "start": 5257158,
    "end": 5260816,
    "text": "これは、このテーマについて書かれた他の10本の論文と非常によく似ている。"
  },
  {
    "start": 5260848,
    "end": 5266916,
    "text": "多くの人がこの問題に取り組んできたということを知らないで、この問題に入ってくるような気がするんだ。"
  },
  {
    "start": 5266938,
    "end": 5273352,
    "text": "ここにはもう少し理論的なことが書かれているが、ここ10年か15年の文献への言及をすべて見逃している。"
  },
  {
    "start": 5273406,
    "end": 5275464,
    "text": "これらに沿った別の論文だ。"
  },
  {
    "start": 5275502,
    "end": 5278520,
    "text": "これはベッキー・パサノと書いた語感に関する論文だ。"
  },
  {
    "start": 5278590,
    "end": 5283000,
    "text": "デビッド・スキーム・モデルがどのように機能するのか、そのハイレベルな見取り図をお見せしよう。"
  },
  {
    "start": 5283070,
    "end": 5285370,
    "text": "残りは論文で引用したものだ。"
  },
  {
    "start": 5286220,
    "end": 5287080,
    "text": "オーケー、素晴らしい。"
  },
  {
    "start": 5287150,
    "end": 5287672,
    "text": "ありがとう。"
  },
  {
    "start": 5287726,
    "end": 5288330,
    "text": "ありがとう。"
  },
  {
    "start": 5290620,
    "end": 5291152,
    "text": "だから"
  },
  {
    "start": 5291246,
    "end": 5295230,
    "text": "最終セッションのショートトークは4時にここで再会しよう。"
  }
]