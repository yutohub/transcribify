[
  {
    "start": 90,
    "end": 4350,
    "text": "ウェビナー中に質問があれば、1日か2日中に。"
  },
  {
    "start": 5090,
    "end": 8126,
    "text": "チャットボックスがあり、おそらくほとんどの人が今そこにいる。"
  },
  {
    "start": 8148,
    "end": 11310,
    "text": "その下を見ると、クエスチョンマークが付いた小さなボックスがある。"
  },
  {
    "start": 11380,
    "end": 20702,
    "text": "そこに質問を書き込んで、最も気に入ったもの、最も答えてほしいものをアップヴォートしてくれれば、そこで事後的に多くの質問に答えることになる。"
  },
  {
    "start": 20756,
    "end": 24250,
    "text": "スケジュール的には、簡単な自己紹介のようなものだ。"
  },
  {
    "start": 24330,
    "end": 33734,
    "text": "アンストラクチャード、クロマ、ラング・チェインと、5分から10分程度で手短にプレゼンテーションを行い、その後、質問がたくさんあると思うので、すぐに質疑応答に入ります。"
  },
  {
    "start": 33852,
    "end": 38534,
    "text": "そのチャンネルにはすでに多くのものがあるのだから、そこにさらに多くのものを入れればいい。"
  },
  {
    "start": 38572,
    "end": 43020,
    "text": "答えてほしいものをアップロードしてください。"
  },
  {
    "start": 44430,
    "end": 53098,
    "text": "ああ、今日はラングチェーンにいろいろあるんだ。リトリーバルについて話すから、リトリーバルに関連した質問をするようにしてくれ。"
  },
  {
    "start": 53274,
    "end": 55920,
    "text": "それがロジスティクスのすべてだと思う。"
  },
  {
    "start": 58850,
    "end": 59834,
    "text": "かなり軽量だ。"
  },
  {
    "start": 59882,
    "end": 62830,
    "text": "始める前に簡単な自己紹介をしよう。"
  },
  {
    "start": 62900,
    "end": 64206,
    "text": "マット、行くかい？"
  },
  {
    "start": 64388,
    "end": 64878,
    "text": "そうだね。"
  },
  {
    "start": 64964,
    "end": 67130,
    "text": "こんにちは、Unstructuredのマット・ロビンソンです。"
  },
  {
    "start": 67210,
    "end": 70286,
    "text": "私はオープンソースライブラリの開発者の一人だ。"
  },
  {
    "start": 70398,
    "end": 73742,
    "text": "我々はLLMSのデータ前処理に重点を置いている。"
  },
  {
    "start": 73886,
    "end": 79618,
    "text": "ロニー・ホザダも会場のどこかにいて、我々の開発者支持者の一人だ。"
  },
  {
    "start": 79714,
    "end": 81320,
    "text": "本当に楽しみだよ。"
  },
  {
    "start": 82330,
    "end": 82742,
    "text": "素晴らしい。"
  },
  {
    "start": 82796,
    "end": 83826,
    "text": "アントン？"
  },
  {
    "start": 84018,
    "end": 85474,
    "text": "やあ、僕はアントンだ。"
  },
  {
    "start": 85522,
    "end": 88002,
    "text": "私はクロマの共同設立者の一人です。"
  },
  {
    "start": 88066,
    "end": 90390,
    "text": "私たちはAIのための検索システムを構築しています。"
  },
  {
    "start": 91630,
    "end": 92186,
    "text": "完璧だ。"
  },
  {
    "start": 92288,
    "end": 92714,
    "text": "分かった。"
  },
  {
    "start": 92752,
    "end": 95478,
    "text": "ラングチェーンの共同設立者の一人、ハリソンです。"
  },
  {
    "start": 95574,
    "end": 98102,
    "text": "それでは、プレゼンテーションに入りましょう。"
  },
  {
    "start": 98166,
    "end": 99418,
    "text": "マット、始めるかい？"
  },
  {
    "start": 99584,
    "end": 101726,
    "text": "よし、ここから始めよう。"
  },
  {
    "start": 101908,
    "end": 106160,
    "text": "早速、私の画面をお見せしよう。"
  },
  {
    "start": 108690,
    "end": 109262,
    "text": "分かった。"
  },
  {
    "start": 109316,
    "end": 110400,
    "text": "スクリーンを見たか？"
  },
  {
    "start": 111890,
    "end": 112590,
    "text": "そうだ。"
  },
  {
    "start": 112740,
    "end": 113858,
    "text": "よし、完璧だ。"
  },
  {
    "start": 114024,
    "end": 118882,
    "text": "まずは、アンストラクチャーとは何か、そして我々が何をしているのかを簡単に紹介しよう。"
  },
  {
    "start": 119016,
    "end": 124334,
    "text": "だから、さっき言ったように、私たちはLLMアプリケーションのためのデータ前処理に焦点を当てている。"
  },
  {
    "start": 124462,
    "end": 135490,
    "text": "しかし、高度な検索テクニックの前に、文書を生のフォーマットからベクターデータベースに取り込む必要がある。"
  },
  {
    "start": 135650,
    "end": 138038,
    "text": "だから、私たちはそこに集中している。"
  },
  {
    "start": 138124,
    "end": 143382,
    "text": "私たちはオープンソースのレポを持っていて、あらゆる種類の文書を前処理している。"
  },
  {
    "start": 143446,
    "end": 145226,
    "text": "こちらで見ることができる。"
  },
  {
    "start": 145328,
    "end": 152266,
    "text": "現在、約25種類のドキュメント・タイプがあり、APIを通じて利用できるようになっている。"
  },
  {
    "start": 152298,
    "end": 157280,
    "text": "ローカルで立ち上げて実行する手間をかけたくなければ、それを使えばいい。"
  },
  {
    "start": 158530,
    "end": 166814,
    "text": "私たちはLangchainとたくさんの統合をしているので、Langchainサイトの統合ページをチェックしてください。"
  },
  {
    "start": 166852,
    "end": 169138,
    "text": "たくさん見ることができる。"
  },
  {
    "start": 169304,
    "end": 180710,
    "text": "ファイルローダーを使用する場合は、ファイルの種類を検出し、適切なパーティショナーにルーティングして、ベクターデータベースに入れる準備をします。"
  },
  {
    "start": 181610,
    "end": 183910,
    "text": "私たちのことをご存知の方もいらっしゃるでしょう。"
  },
  {
    "start": 183980,
    "end": 192858,
    "text": "ここでは、生原稿からクロマ・ベクター・データベースまでのワークフロー例を説明する。"
  },
  {
    "start": 192944,
    "end": 199900,
    "text": "また、最近追加されたいくつかの新機能もご紹介します。"
  },
  {
    "start": 200270,
    "end": 207360,
    "text": "ここでやろうとしているのは、非常にシンプルに今日のニュースを要約するアプリケーションを書くことだ。"
  },
  {
    "start": 207890,
    "end": 229682,
    "text": "このようなツールがなければ、構造化されていないHTMLブリックを使った、実に複雑なプロジェクトになっていただろう。コア・ライブラリーのパーティションHTMLブリックを使えば、CNN Liteのウェブサイトに行って、リンクの束を取得するだけだ。"
  },
  {
    "start": 229826,
    "end": 233000,
    "text": "このロジックはこちらをご覧いただきたい。"
  },
  {
    "start": 233450,
    "end": 243930,
    "text": "データを前処理する際、ベクターデータベースに追加されるメタデータを取得する。"
  },
  {
    "start": 244080,
    "end": 251494,
    "text": "最近、特にウェブサイトに追加したメタデータのひとつに、リンクの取得がある。"
  },
  {
    "start": 251622,
    "end": 263760,
    "text": "だから、そのウェブサイトに行き、すべてのリンクを見つけるのは本当に簡単だ。そして、この小さな新しい要約アプリケーションのためにクロールできるURLのリストを手に入れることができる。"
  },
  {
    "start": 264370,
    "end": 268526,
    "text": "ページ番号のような他の種類のメタデータも取得している。"
  },
  {
    "start": 268628,
    "end": 276070,
    "text": "ベクターデータベースで検索しやすくするために、セクション番号のようなものを考え始めている。"
  },
  {
    "start": 276730,
    "end": 285042,
    "text": "これができたら、Langchainライブラリーからローダーのひとつを取り出そう。"
  },
  {
    "start": 285186,
    "end": 288418,
    "text": "この場合は、構造化されていないURLローダーを使用する。"
  },
  {
    "start": 288514,
    "end": 291750,
    "text": "これらのURLをすべて渡して、それをリッピングさせればいい。"
  },
  {
    "start": 291830,
    "end": 296678,
    "text": "今はただ、ニュース記事のテキストをすべて探しているところだ。"
  },
  {
    "start": 296774,
    "end": 302910,
    "text": "それが終われば、ラングチェーン・ドキュメント・オブジェクトの束ができる。"
  },
  {
    "start": 303490,
    "end": 311002,
    "text": "一度その形にしてしまえば、Chromaのようなベクターデータベースにアップロードするのは本当に簡単だ。"
  },
  {
    "start": 311146,
    "end": 332306,
    "text": "Langchainライブラリのベクトルストアを使い、それをアップロードし、類似性検索を実行して関心のあるニューストピックを見つけ、Langchain要約チェーンを通して要約を得る。"
  },
  {
    "start": 332498,
    "end": 339770,
    "text": "このワークフローを使えば、ちょっとした今日のニュース要約アプリを作ることができる。"
  },
  {
    "start": 339840,
    "end": 343242,
    "text": "数えてみたら、20数行にも満たなかったと思う。"
  },
  {
    "start": 343376,
    "end": 347180,
    "text": "実にシンプルで素晴らしいワークフローだ。"
  },
  {
    "start": 348910,
    "end": 349514,
    "text": "見てみよう。"
  },
  {
    "start": 349552,
    "end": 353760,
    "text": "次に進む前に、質問があるかどうか確認します。"
  },
  {
    "start": 354290,
    "end": 355630,
    "text": "私は高いレベルのものを持っている。"
  },
  {
    "start": 355700,
    "end": 355994,
    "text": "マットだ。"
  },
  {
    "start": 356042,
    "end": 357200,
    "text": "ああ、頑張れ。"
  },
  {
    "start": 359250,
    "end": 362320,
    "text": "少し基本的な話に聞こえるかもしれないが、ここには多くのニュアンスが含まれているはずだ。"
  },
  {
    "start": 362630,
    "end": 367778,
    "text": "パーティションHTMLとパーティションマークダウンのような違いは、実際には何をするのですか？"
  },
  {
    "start": 367944,
    "end": 370290,
    "text": "異なるタイプの要素を引き出しているか？"
  },
  {
    "start": 372630,
    "end": 376638,
    "text": "なぜなら、HTMLのマークダウンはすべて文字列のように表現できるからだ。"
  },
  {
    "start": 376734,
    "end": 379570,
    "text": "あなたたちは具体的に何を追加して、何をしているんですか？"
  },
  {
    "start": 379640,
    "end": 396346,
    "text": "ドキュメントの種類によって、異なるロジックを適用して要素の種類を特定し、「これはタイトル、これはリスト、これは本文のようだ。"
  },
  {
    "start": 396528,
    "end": 399978,
    "text": "ドキュメントの種類によって、私たちはさまざまな方法でそれを行います。"
  },
  {
    "start": 400144,
    "end": 409162,
    "text": "PDFであれば、文書画像解析モデルを使って、これは太字で下線が引かれている、といった視覚的な手がかりを探します。"
  },
  {
    "start": 409226,
    "end": 410298,
    "text": "おそらくタイトルだろう。"
  },
  {
    "start": 410394,
    "end": 413840,
    "text": "ここに箇条書きのようなものがあるが、おそらくリストだろう。"
  },
  {
    "start": 414290,
    "end": 419650,
    "text": "HTMLのようなものを使っている場合、タグやそのような情報を使っている。"
  },
  {
    "start": 419800,
    "end": 426802,
    "text": "プレーンテキストを見るのであれば、テキストの構造そのものを見て、その手がかりを得ることもできるだろう。"
  },
  {
    "start": 426936,
    "end": 435494,
    "text": "これにより、セクションのようなものを識別し、テキストを簡単にチャンクしてグループ化することができる。"
  },
  {
    "start": 435692,
    "end": 445558,
    "text": "重要なのは、私たちが行っているのは、これらすべての文書タイプについて前処理を行い、それらをすべて同じフォーマットで出力することです。"
  },
  {
    "start": 445654,
    "end": 450006,
    "text": "あなたの立場からすれば、それがHTML文書であろうとマークダウン文書であろうと関係ない。"
  },
  {
    "start": 450038,
    "end": 457470,
    "text": "PDFは構造化されていない状態で入力され、同じ構造化されたフォーマットで出力されます。"
  },
  {
    "start": 458050,
    "end": 459578,
    "text": "そうしたら、pdfのことをおっしゃいましたね。"
  },
  {
    "start": 459594,
    "end": 462910,
    "text": "最もポピュラーなドキュメントの種類だと思う。"
  },
  {
    "start": 463330,
    "end": 465326,
    "text": "そういうのが一番厄介なんだ。"
  },
  {
    "start": 465348,
    "end": 467554,
    "text": "だから、私たちが質問を受ける中で最も人気のあるものなんだ。"
  },
  {
    "start": 467672,
    "end": 468958,
    "text": "ボンネットの下では何を使っている？"
  },
  {
    "start": 468974,
    "end": 470254,
    "text": "別のパッケージをお使いですか？"
  },
  {
    "start": 470302,
    "end": 472020,
    "text": "あなた独自の技術みたいなものはありますか？"
  },
  {
    "start": 474230,
    "end": 477522,
    "text": "このロジックは実は少しニュアンスが違う。"
  },
  {
    "start": 477586,
    "end": 484070,
    "text": "私たちは実際に、ユーザーが何をしようとしているかに応じて、異なるPDF処理技術を使用しています。"
  },
  {
    "start": 484220,
    "end": 490030,
    "text": "そこで、モデル主導のハイレゾ・オプションと呼んでいるものを用意した。"
  },
  {
    "start": 490130,
    "end": 501260,
    "text": "これを使えば、ドキュメント内のバウンディング・ボックスなどを探してラベルを付け、その下にあるテキストを抽出することができる。"
  },
  {
    "start": 501630,
    "end": 506378,
    "text": "そのほかの機能のひとつに、テーブル抽出がある。"
  },
  {
    "start": 506554,
    "end": 519090,
    "text": "その一環として、私たちはテーブル・トランスフォーマー・モデルと呼ばれるものを用意し、テーブルを検索して抽出し、プレーン・テキストとHTMLの両方で利用できるようにしています。"
  },
  {
    "start": 519990,
    "end": 522754,
    "text": "必要ない文書もある。"
  },
  {
    "start": 522952,
    "end": 527190,
    "text": "場合によっては、本当に速く処理したいだけで、モデルドリブンなものは必要ないこともある。"
  },
  {
    "start": 527340,
    "end": 541226,
    "text": "その場合は、PDFマイナーなどのアンダーフードロジックを使ってテキストを取り出し、基本的にプレーンテキストを処理します。"
  },
  {
    "start": 541408,
    "end": 552110,
    "text": "あなたがそこから何を得ようとしているか、何を優先するかによって、PDFを処理するためのいくつかの異なるオプションがあります。"
  },
  {
    "start": 552450,
    "end": 553200,
    "text": "クールだ。"
  },
  {
    "start": 557660,
    "end": 563156,
    "text": "では、チャットで他に質問はありますか？"
  },
  {
    "start": 563348,
    "end": 564232,
    "text": "そうでなければ、私たちが見せる。"
  },
  {
    "start": 564286,
    "end": 568140,
    "text": "最後にもうひとつだけ、本当に手短にお見せしよう。"
  },
  {
    "start": 568290,
    "end": 582124,
    "text": "最近、生文書からDownstream LLMのユースケースに対応した文書への移行をより簡単にするために追加したものに、コネクターというものがあります。"
  },
  {
    "start": 582252,
    "end": 598980,
    "text": "このアイデアは、多くの人がドキュメントをシェアポイントやS three、Azure Blob Storageなどに置いていて、そのドキュメントソースを私たちに見せて、すべてを処理して、出力を利用できるようにしたいというものです。"
  },
  {
    "start": 599130,
    "end": 603696,
    "text": "そこで私たちは、コネクターというものに取り組み始めた。"
  },
  {
    "start": 603808,
    "end": 607208,
    "text": "というわけで、これはS3を使った例を示している。"
  },
  {
    "start": 607374,
    "end": 624300,
    "text": "PDFやHTML文書、パワーポイントやワード文書でも構いません。"
  },
  {
    "start": 624720,
    "end": 635504,
    "text": "そして反対側には、すべてのクリーンな出力が入ったディレクトリができるので、ここでdocxファイルをいくつか見てみよう。"
  },
  {
    "start": 635542,
    "end": 641010,
    "text": "をクリックすると、そこにある各文書のJSOn出力が表示される。"
  },
  {
    "start": 641620,
    "end": 658090,
    "text": "長期的なアイデアとしては、基本的にCLIを持ち、最終的にはUI駆動のツールで、ドキュメントの束があるソースから、クロマのようなデータベース同期まで、検索ベースのアプリケーションを本当に簡単に立ち上げて実行できるようにすることです。"
  },
  {
    "start": 660060,
    "end": 662760,
    "text": "もう10分しかない。"
  },
  {
    "start": 662830,
    "end": 671870,
    "text": "ベクター・データベースにドキュメントを取り込んだので、疑問が残らない限り、クロマに移行してもいいと思う。"
  },
  {
    "start": 672720,
    "end": 676476,
    "text": "質問は山ほどあるが、この後の時間で解決できると思う。"
  },
  {
    "start": 676578,
    "end": 678028,
    "text": "よし、いい感じだ。"
  },
  {
    "start": 678194,
    "end": 678936,
    "text": "ありがとう、マシュー。"
  },
  {
    "start": 678968,
    "end": 679772,
    "text": "素晴らしかったよ。"
  },
  {
    "start": 679906,
    "end": 681696,
    "text": "ハリソン、呼んでくれてありがとう。"
  },
  {
    "start": 681718,
    "end": 682690,
    "text": "皆さん、こんにちは。"
  },
  {
    "start": 683220,
    "end": 690576,
    "text": "シンクの未来について少し話したい。"
  },
  {
    "start": 690598,
    "end": 695540,
    "text": "linechainを使っている人なら、ほとんどの人が知っていると思う。"
  },
  {
    "start": 695610,
    "end": 699936,
    "text": "私は、この方向で多くの研究が行われていることを地域社会に知ってもらうことが重要だと思う。"
  },
  {
    "start": 699968,
    "end": 706376,
    "text": "今日はその一部についてお話ししたいと思いますので、私のスライドを引っ張り出して、すべてが瞬時に壊れないことを祈ります。"
  },
  {
    "start": 706558,
    "end": 711000,
    "text": "オーディオビジュアル・ソフトウェアは、コンピューター・サイエンスの中で最も難しい問題である。"
  },
  {
    "start": 712540,
    "end": 713816,
    "text": "ちょっとこれを出してみよう。"
  },
  {
    "start": 713918,
    "end": 716510,
    "text": "よし、クールだ。"
  },
  {
    "start": 716960,
    "end": 718312,
    "text": "スライドが見えるようにする。"
  },
  {
    "start": 718376,
    "end": 721340,
    "text": "そうでないなら、人々は叫び、叫ぶべきだ。"
  },
  {
    "start": 721680,
    "end": 722364,
    "text": "我々はいいのか？"
  },
  {
    "start": 722402,
    "end": 722990,
    "text": "素晴らしい。"
  },
  {
    "start": 723360,
    "end": 726536,
    "text": "そうだ、高度な検索アーキテクチャについて話そう。"
  },
  {
    "start": 726568,
    "end": 728876,
    "text": "これらは、今まさに実現しようとしていることだ。"
  },
  {
    "start": 728898,
    "end": 738000,
    "text": "これらの多くは、まだ非常に実験的なものですが、私たちがどのように検索システムを構築し、それをどの程度モデルと緊密に統合するかに影響を与えるので、考える価値があります。"
  },
  {
    "start": 738070,
    "end": 740044,
    "text": "基本的なことから始めよう。"
  },
  {
    "start": 740092,
    "end": 746740,
    "text": "langchainを使っている人なら誰でも、このかなり基本的な検索拡張生成ループをよく知っているだろう。"
  },
  {
    "start": 747240,
    "end": 749780,
    "text": "これは、文書とチャットしたいときにすることだ。"
  },
  {
    "start": 751240,
    "end": 758680,
    "text": "ドキュメントをクロマに埋め込むか、あるいはEtlしてから埋め込んでクロマに読み込みます。"
  },
  {
    "start": 759180,
    "end": 763064,
    "text": "その結果、エンベッディングのセットが生成され、Chromaによって保存・管理されます。"
  },
  {
    "start": 763182,
    "end": 764680,
    "text": "それからクエリーを入れる。"
  },
  {
    "start": 765420,
    "end": 769656,
    "text": "Chromaはそのクエリを埋め込み、最近傍の結果を返す処理を行います。"
  },
  {
    "start": 769678,
    "end": 776700,
    "text": "そしてモデルは、あなたのクエリに基づいて答えを生成し、クエリに答えるか、モデルに実行させたいタスクを実行する。"
  },
  {
    "start": 776850,
    "end": 778216,
    "text": "ここではOpenAIだ。"
  },
  {
    "start": 778248,
    "end": 781756,
    "text": "実際、私はオープンソースモデルの台頭には非常に強気だ。"
  },
  {
    "start": 781788,
    "end": 786400,
    "text": "私たちも積極的にllamaを使い、検索拡張世代の文脈でどれだけうまく機能するか試している。"
  },
  {
    "start": 787220,
    "end": 794768,
    "text": "Chromaのようなオープンソースで、オープンソースの大規模な言語モデルとラングチェインがあれば、完全にローカルで実行できる。"
  },
  {
    "start": 794944,
    "end": 803188,
    "text": "クラウドにデータを移行する必要はありません。これは、特に個人データを扱っている場合、多くの組織や開発者が心配していることだと思います。"
  },
  {
    "start": 803274,
    "end": 815640,
    "text": "私がいつも考えているのは、親密な会話アシスタントが欲しいが、その親密な情報の多くをOpenAIや世界中の好きな人に送りたくない、というようなことだ。"
  },
  {
    "start": 815790,
    "end": 817156,
    "text": "これが基本的なループだろ？"
  },
  {
    "start": 817198,
    "end": 819208,
    "text": "クロマで試すのは本当に簡単だ。"
  },
  {
    "start": 819224,
    "end": 821784,
    "text": "クロマはラングチェーンに組み込まれている。"
  },
  {
    "start": 821832,
    "end": 823596,
    "text": "ベクターストアのページから入手できる。"
  },
  {
    "start": 823778,
    "end": 825150,
    "text": "次に何が来るのか？"
  },
  {
    "start": 826080,
    "end": 833804,
    "text": "AIの検索や大規模な言語モデルは、まだ始まったばかりだ。"
  },
  {
    "start": 833932,
    "end": 847744,
    "text": "現在の検索システムは、セマンティック検索やレコメンダー・システムと同じように、埋め込みに基づくベクトル検索が基本となっている。"
  },
  {
    "start": 847872,
    "end": 853616,
    "text": "それは、推論タスクを実行する大規模な言語モデル全体がここにあるという事実を考慮していないからだ。"
  },
  {
    "start": 853648,
    "end": 857076,
    "text": "私たちは基本的に情報を取得し、それをモデルのコンテキスト・ウィンドウにロードしている。"
  },
  {
    "start": 857108,
    "end": 858570,
    "text": "我々はもっと多くのことができるはずだ。"
  },
  {
    "start": 858940,
    "end": 861352,
    "text": "いくつか違う質問もありますよね？"
  },
  {
    "start": 861406,
    "end": 865444,
    "text": "何を取得するかについて話しているのだが、デフォルトではこれらのテキストチャンクを取得するようになっている。"
  },
  {
    "start": 865492,
    "end": 874012,
    "text": "ドキュメントを受け取り、さまざまなデータ・ローダーを使ってチャンク化し、それらのテキスト・チャンクを取得してモデルのコンテキスト・ウィンドウに貼り付ける。"
  },
  {
    "start": 874146,
    "end": 878824,
    "text": "トークン・レベルで検索しているのかもしれないし、まったく別のものを検索しているのかもしれない。"
  },
  {
    "start": 878872,
    "end": 881596,
    "text": "実際、タスクによって取り出すものを変えることができる。"
  },
  {
    "start": 881628,
    "end": 886096,
    "text": "となると、検索を使うポイントも違ってくる。"
  },
  {
    "start": 886198,
    "end": 893220,
    "text": "例えば、私たちが現在行っている方法は、検索したチャンクをコンテキスト・ウィンドウに入れ、大規模言語モデルの入力に入れるというものだ。"
  },
  {
    "start": 893370,
    "end": 905652,
    "text": "例えば、デコーダー層のアテンション・ヘッドを使って、どのトークンを取り出すかを判断する。"
  },
  {
    "start": 905796,
    "end": 911364,
    "text": "あるいは、検索結果を出力レイヤーでモデルの出力にも注入することもできる。"
  },
  {
    "start": 911412,
    "end": 921580,
    "text": "我々は基本的に、モデルがこれまでに生成したものによって重み付けされた追加の埋め込みを注入し、実際に何を取り出すかのシグナルとしてモデルの生成を使用する。"
  },
  {
    "start": 921650,
    "end": 935164,
    "text": "その一例として、仮説的な文書埋め込みという考え方があります。これは、クエリに対するモデルの応答を実際に利用するというもので、基本的な情報にはアクセスできないものの、そのクエリに対する応答となりうるものを生成し、その生成を検索に利用するというものです。"
  },
  {
    "start": 935212,
    "end": 936848,
    "text": "というのも一つの見方だ。"
  },
  {
    "start": 937014,
    "end": 939964,
    "text": "もちろん、いつ回収するかという問題もある。"
  },
  {
    "start": 940012,
    "end": 943184,
    "text": "一般的に今日のやり方は、ビッグバンの回収ステップだ。"
  },
  {
    "start": 943222,
    "end": 946756,
    "text": "言い換えれば、コンテクスト・ウィンドウにすべてを入れたら検索を実行し、出発する。"
  },
  {
    "start": 946858,
    "end": 951108,
    "text": "例えば、世代交代が行われている最中に検索できない理由はない。"
  },
  {
    "start": 951194,
    "end": 955430,
    "text": "新しいトークンが生成されるたびに、新しい検索ステップを実行し、それをモデルに入力する。"
  },
  {
    "start": 955800,
    "end": 958004,
    "text": "あるいは、実際に条件付きで検索することもできる。"
  },
  {
    "start": 958052,
    "end": 962628,
    "text": "このモデルは、例えば、次に生成されるトークンのパープレキシティが高い。"
  },
  {
    "start": 962724,
    "end": 966488,
    "text": "これは、検索された情報を自分の中に取り込む良い機会なのかもしれない。"
  },
  {
    "start": 966574,
    "end": 968164,
    "text": "探検することはたくさんある。"
  },
  {
    "start": 968292,
    "end": 972504,
    "text": "つい最近、ACLでこれに関するワークショップがあり、多くの素晴らしい論文が検討された。"
  },
  {
    "start": 972552,
    "end": 975676,
    "text": "スライドにソースを載せておきます。"
  },
  {
    "start": 975698,
    "end": 981420,
    "text": "もし、このようなことに興味があるのであれば、ぜひ調べてみることをお勧めする。"
  },
  {
    "start": 981500,
    "end": 991270,
    "text": "これは、特定のベンチマークでモデルが非常に良い結果を出すのに役立つことが実証されており、この仕組みを解明することは非常に重要になるだろう。"
  },
  {
    "start": 991960,
    "end": 996260,
    "text": "この件に関しては、今、たくさんの論文が発表されている。"
  },
  {
    "start": 996410,
    "end": 999776,
    "text": "単なるドキュメント・チャンクではなく、エンティティを取り出すことができる。"
  },
  {
    "start": 999808,
    "end": 1015452,
    "text": "トークンを取り出すには、このニーズネイバーのアプローチのように直接取り出すこともできるし、適応的にアテンションヘッドを使うこともできる。先ほど言ったように、中間層に直接トークンを送り込んだり、トークンを取り出したり、トークンの埋め込みを取り出したりすることができる。"
  },
  {
    "start": 1015506,
    "end": 1021900,
    "text": "エンコーダー・ヘッドやデコーダーのみのアーキテクチャーの最上位ではなく、デコーダー・ヘッドに組み込まれる。"
  },
  {
    "start": 1022240,
    "end": 1041612,
    "text": "また、基本的にモデルのコンテキスト・ウィンドウ自体から検索し、それを検索戦略の一部として適切に取り込むこともできる。これは、長いコンテキスト・ウィンドウを持つモデルにとって非常に興味深い。"
  },
  {
    "start": 1041676,
    "end": 1052100,
    "text": "大きなコンテクストウィンドウに関する最近の論文をいくつか見て、それらが実際にどの程度うまく機能しているかを見てみると、注意のメカニズムはかなり限定的であり、検索に基づく戦略を使って、より長いコンテクストウィンドウにわたって補強することができる。"
  },
  {
    "start": 1052520,
    "end": 1055584,
    "text": "そして最後に、回収のタイミングについて話した。"
  },
  {
    "start": 1055632,
    "end": 1057144,
    "text": "すべてを一度に取り出すことができる。"
  },
  {
    "start": 1057182,
    "end": 1065464,
    "text": "トークンを端から端まで取得することもできるし、先ほど言ったように、実際に取得したいタイミングを適応的に決定して、それをモールズ・コンテキスト・ウィンドウに注入することもできる。"
  },
  {
    "start": 1065512,
    "end": 1069180,
    "text": "これはすべて正しい。"
  },
  {
    "start": 1069600,
    "end": 1081088,
    "text": "これらについて特に興味深いのは、一般的に、あるいは少なくともこれらのストラテジーの多くについては、既存の大規模言語モデルを利用し、そこにこれらのストラテジーを追加することができるということだ。"
  },
  {
    "start": 1081094,
    "end": 1093856,
    "text": "unlimiformerのような論文もある。この論文では、どんなエンコーダ・デコーダ変換器でも、基本的にはクエリーベクトルとしてアテンションメカニズムを使った検索セットアップを統合することができる。"
  },
  {
    "start": 1094048,
    "end": 1096068,
    "text": "ここで遊ぶことはたくさんある。"
  },
  {
    "start": 1096154,
    "end": 1097616,
    "text": "早くから有望視されている。"
  },
  {
    "start": 1097728,
    "end": 1110116,
    "text": "最終的には、このような緊密な統合は非常に可能性が高く、非常に有用だと考えていますが、検索システムをどのように構築するのか、GPUメモリにこれらの情報をどのように取り込むのかなど、アーキテクチャに関する多くの疑問が生じます。"
  },
  {
    "start": 1110308,
    "end": 1112664,
    "text": "これらの部分はすべて、まだ解決しなければならない。"
  },
  {
    "start": 1112862,
    "end": 1117752,
    "text": "ああ、いつもの検索拡張世代の話やデモとはちょっと違うね。"
  },
  {
    "start": 1117806,
    "end": 1123100,
    "text": "今回のアドバンスド・リトリーバル・ウェビナーのテーマにはぴったりだと思った。"
  },
  {
    "start": 1123760,
    "end": 1127576,
    "text": "今すぐQAに任せるか、ハリソン、君に譲るよ。"
  },
  {
    "start": 1127768,
    "end": 1130044,
    "text": "では、ひとつ質問させてください。"
  },
  {
    "start": 1130082,
    "end": 1132796,
    "text": "ところで、これは素晴らしいと思う。"
  },
  {
    "start": 1132818,
    "end": 1140240,
    "text": "何をリトリーブするのか、どうリトリーブするのか、いつリトリーブするのか。"
  },
  {
    "start": 1141220,
    "end": 1151860,
    "text": "言語モデルの人気が高まっているのは、APIを使うのが簡単だからだと思います。"
  },
  {
    "start": 1152360,
    "end": 1155444,
    "text": "そうだね、ローカルモデルもあるし、それも楽しみだね。"
  },
  {
    "start": 1155482,
    "end": 1161480,
    "text": "APIの背後にあるモデルを多くの人がまだ使っている。その方が優れているからというだけでなく、一般的にその方が簡単だからだ。"
  },
  {
    "start": 1162460,
    "end": 1170264,
    "text": "これらのメソッドの多くは、大規模なAPIプロバイダーが現在公開していないモデルへのアクセスのようなものに依存している。"
  },
  {
    "start": 1170392,
    "end": 1171070,
    "text": "どうやって？"
  },
  {
    "start": 1172080,
    "end": 1173228,
    "text": "イエスでもありノーでもある。"
  },
  {
    "start": 1173394,
    "end": 1182476,
    "text": "トークンを中間レイヤーに直接注入する必要があるものは、API経由でモデルにアクセスしている場合は明らかに利用できません。"
  },
  {
    "start": 1182588,
    "end": 1187692,
    "text": "例えば、トークンが生成されたときにそれを取り出すというようなアイデアは、完全に利用可能だ。"
  },
  {
    "start": 1187756,
    "end": 1196064,
    "text": "ジェネレーションをリスタートしたり、ジェネレーションの途中で追加のコンテクストを注入したりすることは、それがより高価であることを知るために絶対に利用可能である。"
  },
  {
    "start": 1196112,
    "end": 1198624,
    "text": "ただし、APIへのアクセス回数は増える。"
  },
  {
    "start": 1198672,
    "end": 1209336,
    "text": "もうひとつは、検索をモデル生成自体の文脈で制御できるようにすることで、これらのコストの一部を削減し始めることができる。"
  },
  {
    "start": 1209518,
    "end": 1221164,
    "text": "例えば、AIの研究所は検索を非常に積極的に追求している。"
  },
  {
    "start": 1221282,
    "end": 1227836,
    "text": "そのような回収補強を行うべきかどうかはかなり不透明で、今は誰にとっても不透明だと思う。"
  },
  {
    "start": 1227858,
    "end": 1232976,
    "text": "今、このスペースでビルドする楽しみのひとつは、まだ決定していないこと、解明されていないことがたくさんあることだ。"
  },
  {
    "start": 1232998,
    "end": 1241024,
    "text": "オープンソースを使い始めることで、基本的に何が作られるかを左右する余地がたくさんある。"
  },
  {
    "start": 1241062,
    "end": 1247972,
    "text": "もし、それが本当に素晴らしいものであれば、ラボに選択の余地はなく、APIプロバイダーもそのバージョンを提供するしかないだろう。"
  },
  {
    "start": 1248106,
    "end": 1250150,
    "text": "我々はその未来に強気だ。"
  },
  {
    "start": 1250600,
    "end": 1260708,
    "text": "ああ、これは文脈を読み解くための論文なのか、それとも別のものなのかわからないが、フレア論文というのがあって、これはいつ読み解くべきかということに関するものだ。"
  },
  {
    "start": 1260804,
    "end": 1270284,
    "text": "彼らはOpenAIを使用していますが、トークンの確率を使用して、確率が低いと判断し、生成を停止し、検索ステップを実行し、投入します。"
  },
  {
    "start": 1270402,
    "end": 1275576,
    "text": "これがエンドトークンを使った適応検索だ。"
  },
  {
    "start": 1275768,
    "end": 1276556,
    "text": "そうだね。"
  },
  {
    "start": 1276738,
    "end": 1280312,
    "text": "だから、トークンの確率を返すAPIなら可能だ。"
  },
  {
    "start": 1280376,
    "end": 1283376,
    "text": "実際、チャットモデルが戻ってくることは少なくなってきていると思う。"
  },
  {
    "start": 1283398,
    "end": 1285650,
    "text": "だから、情報という点では同じようなものだ。"
  },
  {
    "start": 1286260,
    "end": 1287008,
    "text": "そうだね。"
  },
  {
    "start": 1287174,
    "end": 1295540,
    "text": "もちろん、彼らがそうし始めた理由は、ログに問題がある場合に蒸留を助けるためであり、彼らはあなたが彼らのモデルを蒸留することを本当に望んでいない。"
  },
  {
    "start": 1296200,
    "end": 1298260,
    "text": "私の考えでは、スキルの問題だ。"
  },
  {
    "start": 1300040,
    "end": 1300790,
    "text": "クールだ。"
  },
  {
    "start": 1302460,
    "end": 1303210,
    "text": "素晴らしい。"
  },
  {
    "start": 1304380,
    "end": 1313432,
    "text": "ラングチェインで行っている検索について簡単に話した後、質問を受け付けます。"
  },
  {
    "start": 1313486,
    "end": 1315192,
    "text": "これもまた、行けということだ。"
  },
  {
    "start": 1315246,
    "end": 1321900,
    "text": "右側のQAサイドバーに質問を追加し、最も回答を聞きたいものをアップロードしてください。"
  },
  {
    "start": 1322640,
    "end": 1326780,
    "text": "私の画面を簡単にお見せしよう。"
  },
  {
    "start": 1328980,
    "end": 1331440,
    "text": "アントン、君のをシェアするのは止めた方がいいかもしれない。"
  },
  {
    "start": 1342550,
    "end": 1343058,
    "text": "クールだ。"
  },
  {
    "start": 1343144,
    "end": 1360166,
    "text": "さて、あまり長い時間はかけませんが、基本的には、古典的なセマンティック検索のエッジケースについて、ごく簡単にお話しします。"
  },
  {
    "start": 1360348,
    "end": 1363782,
    "text": "アントンとは少し違うアプローチだ。"
  },
  {
    "start": 1363846,
    "end": 1378010,
    "text": "プロンプトに取り込むという点では、まだボロ雑巾のようなものにこだわっている。ラングチェインのユーザーの多くがそうしているのを見たからだ。"
  },
  {
    "start": 1378090,
    "end": 1381600,
    "text": "私たちが取り組んでいる興味深い代替案は何か？"
  },
  {
    "start": 1383810,
    "end": 1387906,
    "text": "セマンティック検索のいくつかのエッジケースについて、もう少し詳しく説明しよう。"
  },
  {
    "start": 1388008,
    "end": 1396674,
    "text": "コサインの類似性だけで、80％くらいは達成できるかもしれない。"
  },
  {
    "start": 1396872,
    "end": 1401894,
    "text": "より高い信頼性を求めるようになると、多くの問題が山積みになってくる。"
  },
  {
    "start": 1402092,
    "end": 1405720,
    "text": "私たちが目にすることのひとつに、繰り返される情報がある。"
  },
  {
    "start": 1406250,
    "end": 1409306,
    "text": "基本的に、いくつかの文書は同じ情報を持っている。"
  },
  {
    "start": 1409408,
    "end": 1411174,
    "text": "もしかしたら、文書が重複しているかもしれない。"
  },
  {
    "start": 1411302,
    "end": 1417206,
    "text": "これには、基本的に文脈のようなものを占有するだけという欠点がいくつかある。"
  },
  {
    "start": 1417398,
    "end": 1423910,
    "text": "を検索していないかもしれないし、1種類の文書しか検索していないかもしれない。"
  },
  {
    "start": 1423990,
    "end": 1432910,
    "text": "たとえ2種類の書類を回収するとしても、1つの書類が5つもあったら、ちょっと圧倒されてしまうし、気が散ってしまうかもしれない。"
  },
  {
    "start": 1433570,
    "end": 1441406,
    "text": "基本的に、私たちがここで実装しているより基本的な解決策のひとつは、最大限界関連性のようなものです。"
  },
  {
    "start": 1441518,
    "end": 1444462,
    "text": "これは基本的にラッパーみたいなものだ。"
  },
  {
    "start": 1444606,
    "end": 1448398,
    "text": "これらの多くは、標準的なベクターインデックスのようなものをボンネットの中で使っている。"
  },
  {
    "start": 1448494,
    "end": 1449586,
    "text": "それを包むものだ。"
  },
  {
    "start": 1449608,
    "end": 1468086,
    "text": "コサイン類似度によって上位100のドキュメントを選択し、次に、クエリとの類似度だけでなく、すでに選択されている以前のドキュメントとの差に基づいてドキュメントを選択する、ほとんど再ランキングステップのような別のステップを行う。"
  },
  {
    "start": 1468118,
    "end": 1472140,
    "text": "多様性が生まれ、多様な情報が入ってくる。"
  },
  {
    "start": 1473390,
    "end": 1476270,
    "text": "相反する情報は興味深いものだ。"
  },
  {
    "start": 1476420,
    "end": 1479950,
    "text": "複数の情報源から同じ答えが返ってくることもある。"
  },
  {
    "start": 1480290,
    "end": 1485842,
    "text": "私がここで使いたい例は、あなたの会社の概念データベースのようなものだ。"
  },
  {
    "start": 1485976,
    "end": 1498082,
    "text": "トップページにバケーション・ポリシーの説明があるかもしれないし、個人的なメモにバケーション・ポリシーに関する文章があるかもしれない。"
  },
  {
    "start": 1498136,
    "end": 1501826,
    "text": "ところで、これと非常に関連しているのが、時間性という考え方だ。"
  },
  {
    "start": 1501858,
    "end": 1506680,
    "text": "情報は時間の経過とともに更新され、時間の経過とともに矛盾することもある。"
  },
  {
    "start": 1507050,
    "end": 1508998,
    "text": "解決策は似ている。"
  },
  {
    "start": 1509084,
    "end": 1513222,
    "text": "ひとつは、文書に基づいて重要度を重み付けするようなものだ。"
  },
  {
    "start": 1513286,
    "end": 1521018,
    "text": "おそらく、検索された結果に多くのメタデータを含めて、言語モデルに推論させることもできるだろう。"
  },
  {
    "start": 1521184,
    "end": 1527150,
    "text": "一般的には、より関連性の高い、あるいはより新しい情報がより適切であると推論することができるだろう。"
  },
  {
    "start": 1527730,
    "end": 1530062,
    "text": "それ以上の重要性を持っているのであれば、それを信じるべきだろう。"
  },
  {
    "start": 1530116,
    "end": 1545166,
    "text": "マットが話していたインジェストに関することや、ドキュメントにメタデータを適切に追加すること、そしてドキュメントの読み込みや分割、ドキュメントに適切なメタデータがあるかどうかの確認には、多くのニュアンスが必要だと思います。"
  },
  {
    "start": 1545198,
    "end": 1548054,
    "text": "これらはすべて、与えることが本当に重要になる。"
  },
  {
    "start": 1548092,
    "end": 1555640,
    "text": "ある文書がいつ書かれたのか、どの程度重要なものなのか、どの程度信頼されるべきものなのか、そういった適切な文脈のようなものだ。"
  },
  {
    "start": 1561290,
    "end": 1564310,
    "text": "これは、リンクチェーンにあるものの中でも特に気に入っている。"
  },
  {
    "start": 1564830,
    "end": 1566998,
    "text": "これを解決するのが、自己クエリー検索である。"
  },
  {
    "start": 1567014,
    "end": 1572090,
    "text": "基本的な考え方は、あなたが受ける質問は、コンテンツよりもメタデータに関するものかもしれないということです。"
  },
  {
    "start": 1572160,
    "end": 1593490,
    "text": "コサイン類似度のようなアプローチで、クエリの意味的な意味だけを見ている場合、1980年の宇宙人についての映画とか、そういうクエリがあったとして、本当に検索したいのは、映画のようなデータベースがあるとして、宇宙人についての説明とか、そういうものを検索したいわけです。"
  },
  {
    "start": 1593560,
    "end": 1599720,
    "text": "であれば、1980はメタデータ属性のようなもので、明示的にフィルタリングするようなものであるべきだ。"
  },
  {
    "start": 1600250,
    "end": 1605202,
    "text": "つまりこのアイデアは、基本的に言語モデルを使ってメタデータを抽出するということだ。"
  },
  {
    "start": 1605266,
    "end": 1610326,
    "text": "クロマを含むほとんどのベクターストアには、関連付けることができるメタデータのようなものがあり、フィルタをかけることができます。"
  },
  {
    "start": 1610348,
    "end": 1617002,
    "text": "イコールやグレイザーなど、さまざまな演算ができるんだ。"
  },
  {
    "start": 1617136,
    "end": 1624750,
    "text": "つまり、クエリからセマンティック・ビットとともにメタデータを抽出し、それを下流で使うというアイデアだ。"
  },
  {
    "start": 1626850,
    "end": 1634538,
    "text": "そして最後のものは、基本的に複数のクエリーを必要とするような質問やクエリーである。"
  },
  {
    "start": 1634714,
    "end": 1639234,
    "text": "これはマルチホップ的な質問かもしれない。"
  },
  {
    "start": 1639432,
    "end": 1647218,
    "text": "その一例として、「誰が勝ったのか？"
  },
  {
    "start": 1647304,
    "end": 1652674,
    "text": "あるいは、2017年の全米オープン・チャンピオンの出身地は？"
  },
  {
    "start": 1652722,
    "end": 1653366,
    "text": "みたいな感じかな。"
  },
  {
    "start": 1653388,
    "end": 1663302,
    "text": "だから、まず2017年の全米オープン・チャンピオンを検索し、次に彼の故郷を検索したい。"
  },
  {
    "start": 1663446,
    "end": 1672062,
    "text": "つまり、1つのクエリですべてを得るのではなく、まず1つ目のクエリの答えを調べてから、2つ目のクエリを行うということだ。"
  },
  {
    "start": 1672116,
    "end": 1692782,
    "text": "ある種のエージェントのような、あるいはループのようなアプローチが適切だと思います。"
  },
  {
    "start": 1692926,
    "end": 1702066,
    "text": "ここでは、まずドキュメントの束をロードする。"
  },
  {
    "start": 1702168,
    "end": 1703350,
    "text": "ページのコンテンツがある。"
  },
  {
    "start": 1703420,
    "end": 1704646,
    "text": "これは映画データベースのものだ。"
  },
  {
    "start": 1704668,
    "end": 1707106,
    "text": "私たちには、映画の説明であるページコンテンツがあります。"
  },
  {
    "start": 1707138,
    "end": 1709126,
    "text": "そうすれば、フィルタリングできるメタデータの束ができる。"
  },
  {
    "start": 1709148,
    "end": 1722806,
    "text": "そして、それをChromaにロードして、メタデータ・フィールドが何であるかについての情報を提供し、セルフ・クエリー・リトリーバをロードする。"
  },
  {
    "start": 1722918,
    "end": 1727050,
    "text": "これで、与えられたクエリーに対して、クエリーとフィルターのようなものを抽出することができる。"
  },
  {
    "start": 1727130,
    "end": 1728286,
    "text": "どんな映画ですか？"
  },
  {
    "start": 1728308,
    "end": 1729002,
    "text": "恐竜。"
  },
  {
    "start": 1729066,
    "end": 1730474,
    "text": "クエリーは恐竜になった。"
  },
  {
    "start": 1730522,
    "end": 1733150,
    "text": "ここには本当にフィルターは指定されていない。"
  },
  {
    "start": 1733300,
    "end": 1736158,
    "text": "8.5点以上の映画を観たい。"
  },
  {
    "start": 1736324,
    "end": 1737274,
    "text": "これは逆だ。"
  },
  {
    "start": 1737322,
    "end": 1739710,
    "text": "ここには本当のクエリはないが、フィルターがある。"
  },
  {
    "start": 1739870,
    "end": 1744786,
    "text": "ということは、このコンパレーターは8.5点以上ということになる。"
  },
  {
    "start": 1744968,
    "end": 1746674,
    "text": "そして、それらを組み合わせたものがたくさんある。"
  },
  {
    "start": 1746712,
    "end": 1749166,
    "text": "グレタ・ガーウィグは女性についての映画を監督したことがありますか？"
  },
  {
    "start": 1749198,
    "end": 1750030,
    "text": "クエリーウーマン？"
  },
  {
    "start": 1750110,
    "end": 1751186,
    "text": "なら、このフィルターだ。"
  },
  {
    "start": 1751298,
    "end": 1752626,
    "text": "これはかなり複雑になる。"
  },
  {
    "start": 1752658,
    "end": 1754994,
    "text": "今、私たちは映画を持っている。"
  },
  {
    "start": 1755042,
    "end": 1757190,
    "text": "1990年以降の映画とは？"
  },
  {
    "start": 1757260,
    "end": 1758294,
    "text": "2005年以前？"
  },
  {
    "start": 1758332,
    "end": 1760642,
    "text": "それがおもちゃのすべてで、できればアニメーションがいい。"
  },
  {
    "start": 1760706,
    "end": 1762566,
    "text": "ここでは、クエリーがおもちゃであることがわかる。"
  },
  {
    "start": 1762678,
    "end": 1767980,
    "text": "そうなると、この複雑な、まるで他のすべてのものの組み合わせのようなものがある。"
  },
  {
    "start": 1770270,
    "end": 1773440,
    "text": "ここには他のレトリーバーがたくさんいる。"
  },
  {
    "start": 1774370,
    "end": 1782474,
    "text": "アントンが発表したようなものと少し比較すると、私はこれらをヒューリスティックのようなものに分類したい。"
  },
  {
    "start": 1782522,
    "end": 1788962,
    "text": "ラグ・アーキテクチャーの多くを根本的に変更するのではなく、ラグ・アーキテクチャーの上で行うことができる。"
  },
  {
    "start": 1789016,
    "end": 1797826,
    "text": "一番近いのはflareの実装で、これは動的に検索を行うようなものだ。"
  },
  {
    "start": 1797858,
    "end": 1801574,
    "text": "これらの多くは、根本的な構造をあまり変えないことに依存している。"
  },
  {
    "start": 1801612,
    "end": 1811242,
    "text": "プロンプトの内容に何かを注入していることに変わりはないし、インタラクションをシンプルに保つためのデザインでもある。"
  },
  {
    "start": 1811296,
    "end": 1815594,
    "text": "多くの人がAPIを使っている。"
  },
  {
    "start": 1815792,
    "end": 1819180,
    "text": "うん、だから、そういうのは面白いと思うよ。"
  },
  {
    "start": 1820110,
    "end": 1826880,
    "text": "APIがどのように進化していくのか、また、ヒューリスティックな技術だけでなく、他のどのような技術が利用できるようになるのか、本当に興味深いことだと思う。"
  },
  {
    "start": 1827890,
    "end": 1830606,
    "text": "基本的に私が持っているのはそれだけだ。"
  },
  {
    "start": 1830788,
    "end": 1833198,
    "text": "何か追加したいことがあれば言ってくれ。"
  },
  {
    "start": 1833364,
    "end": 1834066,
    "text": "そうだね。"
  },
  {
    "start": 1834168,
    "end": 1834980,
    "text": "私は持っている。"
  },
  {
    "start": 1835510,
    "end": 1845650,
    "text": "ハリソンが言ったように、よりヒューリスティックな検索パイプラインに注目する人が増えていると思う。"
  },
  {
    "start": 1846630,
    "end": 1857986,
    "text": "ロボット工学に7年ほど携わってきた私の経験から言うと、ヒューリスティックなパイプラインを手作業でチューニングしていると、エッジケースに対処するためのラットレースに身を置くことになる。"
  },
  {
    "start": 1858018,
    "end": 1860682,
    "text": "やがてそういう時代に入ると思う。"
  },
  {
    "start": 1860736,
    "end": 1870762,
    "text": "私は、この問題に対する長期的な正しい解決策は、柔軟な検索指向のモデルを構築し、これらをより緊密に組み合わせる方法を見つけ出すことだと思う。"
  },
  {
    "start": 1870816,
    "end": 1889694,
    "text": "繰り返しますが、私の経験では、ほとんどの場合うまくいくようなものを手に入れることは可能です。ヒューリスティックを増やすことの罠のようなものは、より頻繁にうまくいくように見えますが、ヒューリスティックを増やせば増やすほどエッジケースの種類が増えるということです。"
  },
  {
    "start": 1889742,
    "end": 1891780,
    "text": "ただ、気をつけなければならないことがある。"
  },
  {
    "start": 1892790,
    "end": 1905686,
    "text": "私たちが本当に必要としているのは、この特定のものがここで機能し、この特定のものがあそこで機能するという話ではなく、あらゆる種類の異なる文脈で機能する非常に一般的なアプローチや一般的な方法だと思う。"
  },
  {
    "start": 1905708,
    "end": 1910774,
    "text": "と同時に、ヒューリスティックが正しい方向を指し示してくれるかもしれないのだから、多くのことを探求する価値は大いにあると思う。"
  },
  {
    "start": 1910902,
    "end": 1911770,
    "text": "ロングランだ。"
  },
  {
    "start": 1911920,
    "end": 1913980,
    "text": "それは、言っておこうと思ったことなんだ。"
  },
  {
    "start": 1922350,
    "end": 1925438,
    "text": "このようなことのスケジュールについて、どうお考えですか？"
  },
  {
    "start": 1925524,
    "end": 1944110,
    "text": "仮に6ヵ月後とした場合、人々はまだコサイン類似のようなことをやっているだけで、6ヵ月後も主要なモデル・プロバイダーによるAPIは、トークン・レベルの操作をあまり許さないままなのだろうか？"
  },
  {
    "start": 1944190,
    "end": 1958470,
    "text": "ええ、もし私が経験豊かな推測をするとしたら、6ヶ月というのは本当に興味深いものだと思いますが、6ヶ月後にはまだ、ほとんどの組織や開発者が検索機能拡張世代をまったく採用していない世界に生きていることになると思います。"
  },
  {
    "start": 1958620,
    "end": 1959320,
    "text": "そうだね。"
  },
  {
    "start": 1959770,
    "end": 1971754,
    "text": "このようなことに取り組むだけで、積極的に取り組んだり、そのことについて常に考えたりしていない他の人たちの3、4カ月先が見えてくることを忘れてしまいがちだ。"
  },
  {
    "start": 1971792,
    "end": 1979306,
    "text": "半年後には、基本的なリトリーブ・ロックマンディジェネレーションでさえも、まだ採用のロングテールに入っていると思う。"
  },
  {
    "start": 1979328,
    "end": 1979514,
    "text": "そうだね。"
  },
  {
    "start": 1979552,
    "end": 1985406,
    "text": "私たちはこのような高度な方法について話していると思うが、ここでの基本的な考え方は今でも非常に強力であることを忘れてはいけないと思う。"
  },
  {
    "start": 1985518,
    "end": 1992846,
    "text": "大規模なテキスト・コーパスと会話的かつ非線形に対話する能力は、さまざまな業界やユースケースにおいて非常に有用である。"
  },
  {
    "start": 1992878,
    "end": 1996994,
    "text": "今、クロマが採用されていることで、我々はそれを目の当たりにしている。"
  },
  {
    "start": 1997032,
    "end": 2000942,
    "text": "とはいえ、最先端ではそうなると思う。"
  },
  {
    "start": 2001016,
    "end": 2017610,
    "text": "あと半年もすれば、最先端では、より直接的に統合された検索戦略の実用的な展開が、このことに非常に前向きで、戦略としてこれを追求することを確約している組織に対して、初めて見られるようになるだろう。"
  },
  {
    "start": 2018510,
    "end": 2021894,
    "text": "そのような組織ではなく、AIを使って何かをしなければならない。"
  },
  {
    "start": 2022022,
    "end": 2026606,
    "text": "もちろん、それを否定するつもりはないが。"
  },
  {
    "start": 2026628,
    "end": 2031694,
    "text": "AI研究所がこれからやろうとしていることは、実はとてつもないことだと思う。"
  },
  {
    "start": 2031732,
    "end": 2037122,
    "text": "私は、それが彼らのためになると思うし、彼らが積極的に取り組んでいることも知っている。"
  },
  {
    "start": 2037176,
    "end": 2045090,
    "text": "ビジネスとして、研究グループとして、そのインターフェイスがどのようなものかを知ることは非常に興味深い問題だ。"
  },
  {
    "start": 2045240,
    "end": 2045940,
    "text": "そうだろう？"
  },
  {
    "start": 2046950,
    "end": 2056920,
    "text": "それに影響を与える最善の方法は、何がうまくいくかをできるだけ早く示すことだと思う。だからこそ、繰り返しになるが、私たちがオープンソースモデルに特に強気なのはそのためだ。"
  },
  {
    "start": 2059070,
    "end": 2070470,
    "text": "そうですね。6ヶ月以内に、APIプロバイダーから何らかの検索インターフェースが提供されないとしたら、とても驚きだと思います。"
  },
  {
    "start": 2070550,
    "end": 2082906,
    "text": "しかし、外部リトリーバーにインターフェースを提供するよりも、データがAzureやGCPにあり、それをモデルにフックアップするほうが、よりよく見えると思います。"
  },
  {
    "start": 2083098,
    "end": 2094740,
    "text": "長期的には、ソフトウェア、ソフトウェア・ビジネスが実際にどのように運営されているかに基づいて、特に企業レベルでは、特にデータ製品レベルでは、最終的に検索システムはデータ製品だと思います。"
  },
  {
    "start": 2096630,
    "end": 2098414,
    "text": "企業は自社のデータをコントロールしたい。"
  },
  {
    "start": 2098472,
    "end": 2109714,
    "text": "企業は、APIプロバイダーのインフラにきちんと適合するものではなく、ビジネスとして実際に行っていることにきちんと適合するインフラにデータが置かれることを望んでいる。"
  },
  {
    "start": 2109842,
    "end": 2118042,
    "text": "だから、自分のVPC内やクラウド内でさまざまな検索を行えるようにしたいという需要は大いにあると思う。"
  },
  {
    "start": 2118096,
    "end": 2128906,
    "text": "APIプロバイダーがどのようにそれを提供するかに関わらず、誰もが持つ疑問だと思う。"
  },
  {
    "start": 2129018,
    "end": 2129774,
    "text": "どうすればいいんだ？"
  },
  {
    "start": 2129812,
    "end": 2140146,
    "text": "自分のデータを他人に渡さない、あるいは外に持ち出さないようにするにはどうすればいいのか。ラボが自分のデータについてトレーニングする心配があろうとも、ラボはそれをしないと約束している。"
  },
  {
    "start": 2140168,
    "end": 2141810,
    "text": "彼らがあなたのデータでトレーニングしていないことを証明できますか？"
  },
  {
    "start": 2141880,
    "end": 2142820,
    "text": "分からないよ。"
  },
  {
    "start": 2147210,
    "end": 2148294,
    "text": "コストがかかりますよね？"
  },
  {
    "start": 2148332,
    "end": 2154470,
    "text": "イグレス・コスト、ネットワーク・コスト、これらは企業規模になると非常に大きくなり、自明なことではなくなります。"
  },
  {
    "start": 2155610,
    "end": 2166102,
    "text": "もう1つ、一般的なことなんだけど、あなたが持っていたのは何だったっけ？"
  },
  {
    "start": 2166166,
    "end": 2180880,
    "text": "テキストやトークンの検索であろうと、一度だけであろうと毎ステップであろうと、何らかの形で検索を行っていることに変わりはない。"
  },
  {
    "start": 2181330,
    "end": 2188526,
    "text": "今のところ、一般的にはコサイン類似度のようなものだが、他の検索メカニズムがあるかもしれない。"
  },
  {
    "start": 2188558,
    "end": 2195262,
    "text": "どこで何が起ころうが、何を回収しようが、その回収は進化していくものだと思うが？"
  },
  {
    "start": 2195326,
    "end": 2200422,
    "text": "というのも、あなたの講演の多くは、検索したものをさまざまな方法で使うことができるという内容だったと思うからです。"
  },
  {
    "start": 2200556,
    "end": 2200950,
    "text": "そうだね。"
  },
  {
    "start": 2201020,
    "end": 2203026,
    "text": "コサイン類似性についてはこうだ。"
  },
  {
    "start": 2203058,
    "end": 2204886,
    "text": "それは固定された指標でしょう？"
  },
  {
    "start": 2204988,
    "end": 2207746,
    "text": "AIの要点は柔軟性と適応性だ。"
  },
  {
    "start": 2207778,
    "end": 2217494,
    "text": "関連性をどう扱うかは、最終的にはクエリ、タスク、ターゲットモデルに応じて条件付ける必要があると思います。"
  },
  {
    "start": 2217622,
    "end": 2229466,
    "text": "例えば、ベクターベースの検索をする場合、それは6ヵ月後にはそうなっていると思うが、なぜなら、ベクターベースの検索は非常に柔軟だからだ。"
  },
  {
    "start": 2229658,
    "end": 2230750,
    "text": "私たちはまだそうであろう。"
  },
  {
    "start": 2230820,
    "end": 2256998,
    "text": "これを見る1つの方法は、余弦類似度対L2対何でなく、起こりうることの1つの例として、今すでに見ていますが、デコーダーの頭の注目メカニズムを潜在空間へのクエリーベクトルとして使うことができます。"
  },
  {
    "start": 2257084,
    "end": 2261050,
    "text": "それは空間を適応的に変化させるようなものだ。"
  },
  {
    "start": 2261120,
    "end": 2272266,
    "text": "別の方法としては、例えば、基本的にベクトル空間に線形変換を適用するようなモデルを用意し、クエリーが来たときにそれを条件とする。"
  },
  {
    "start": 2272288,
    "end": 2281262,
    "text": "このモデルを訓練して、こういうクエリならOKだ、と言うんだ。例えば、僕がいつもやっていた例で言うと、怒りのツイートを探しているんだ。"
  },
  {
    "start": 2281316,
    "end": 2287686,
    "text": "埋め込みベクトルの怒った次元を広げ、他の次元を減らす必要がある。"
  },
  {
    "start": 2287738,
    "end": 2292302,
    "text": "ある次元を拡大し、他の次元を縮小するとき、それはフィとトランスフォームだ。"
  },
  {
    "start": 2292446,
    "end": 2297138,
    "text": "私たちがやっているのは、フィオン変換を生成できるモデルを学習することだ。"
  },
  {
    "start": 2297224,
    "end": 2298340,
    "text": "それはまったく違う。"
  },
  {
    "start": 2298790,
    "end": 2304706,
    "text": "COVIDに関するすべてのツイートを教えてくださいというようなクエリに答えたいのですが、怒りのツイートをすべて教えてくれるのを待つつもりです。"
  },
  {
    "start": 2304818,
    "end": 2305046,
    "text": "そうだろう？"
  },
  {
    "start": 2305068,
    "end": 2307346,
    "text": "つまり、ベクター空間をその場で変えているのだ。"
  },
  {
    "start": 2307458,
    "end": 2317980,
    "text": "というのも、アフィン変換、特に反転可能な変換の優れた点は、ベクトル空間そのものを再計算する代わりに、その変換をクエリーに適用できることだからだ。"
  },
  {
    "start": 2318430,
    "end": 2320646,
    "text": "それは非常に有望で、視野に入っていると思う。"
  },
  {
    "start": 2320678,
    "end": 2329514,
    "text": "トランスフォーマーのアテンション・メカニズムが実際に何をするのか考えてみると、そのひとつの方法は、レイヤーを伝搬するときにベクトルの重みを調整することだ。"
  },
  {
    "start": 2329642,
    "end": 2335006,
    "text": "ある種の基本的なアテンション・ベースのモデルは、クエリ側で非常に役に立つだろう。"
  },
  {
    "start": 2335188,
    "end": 2337474,
    "text": "すぐに何かが見えてくると思う。"
  },
  {
    "start": 2337592,
    "end": 2340414,
    "text": "コサイン相似のまま、フードの奥深くにある。"
  },
  {
    "start": 2340542,
    "end": 2340834,
    "text": "そうだね。"
  },
  {
    "start": 2340872,
    "end": 2342580,
    "text": "それをどうするかで変わるんだ。"
  },
  {
    "start": 2346520,
    "end": 2350440,
    "text": "もういいよ、僕の下手な質問は。"
  },
  {
    "start": 2350510,
    "end": 2352410,
    "text": "観客からの質問に移ろう。"
  },
  {
    "start": 2353820,
    "end": 2362760,
    "text": "会場のルイーズから、HTMLからタイトルと本文を見つける一般的な方法はないかという質問があった。"
  },
  {
    "start": 2362840,
    "end": 2367870,
    "text": "そのことについて、ちょっとお見せしたいことがあるんだ。"
  },
  {
    "start": 2371600,
    "end": 2375856,
    "text": "構造化されていないものを引き出すのは、実はとても簡単なことなんだ。"
  },
  {
    "start": 2375958,
    "end": 2390356,
    "text": "今、例のために処理していたリンクの1つを取り出したところですが、例えば、タイトルやナレーション・テキスト（本文と同じようなもの）を分類しているのがわかります。"
  },
  {
    "start": 2390538,
    "end": 2397092,
    "text": "この2つに絞るのは簡単だ。"
  },
  {
    "start": 2397226,
    "end": 2398948,
    "text": "私たちはここでタイトルをつかむだけだ。"
  },
  {
    "start": 2399034,
    "end": 2409320,
    "text": "この記事はドッキング・スポットをめぐる争いについてのもので、記事の本文を得るために、すべての物語文の項目を簡単につなぎ合わせることができる。"
  },
  {
    "start": 2409660,
    "end": 2425240,
    "text": "繰り返しになるが、非構造化で行っていることの威力は、これはHTMLの記事に対して示しているのだが、PDFでもパワーポイントでもワード文書でも何でも、非構造化でも同じように機能するということだ。"
  },
  {
    "start": 2425320,
    "end": 2426876,
    "text": "質問ありがとう。"
  },
  {
    "start": 2426898,
    "end": 2429888,
    "text": "ただ、その例をすぐに示したかっただけなんだ。"
  },
  {
    "start": 2430054,
    "end": 2432336,
    "text": "マット、この件について質問してもいいかな？"
  },
  {
    "start": 2432438,
    "end": 2433484,
    "text": "お薦めはありますか？"
  },
  {
    "start": 2433532,
    "end": 2437852,
    "text": "ラングチェーンでは、たぶん、このようなことをやっていると思うし、もしやっていないのなら、もっとやるべきだと思う。"
  },
  {
    "start": 2437926,
    "end": 2444944,
    "text": "ベクターデータベースに保存するために、これらの要素をテキストのチャンクにまとめる推奨の方法はありますか？"
  },
  {
    "start": 2445072,
    "end": 2449684,
    "text": "ああ、だから今、実はその辺りのことに取り組んでいるんだ。"
  },
  {
    "start": 2449722,
    "end": 2456488,
    "text": "従来は、アウトライン・チェーンには2つの方法があった。"
  },
  {
    "start": 2456574,
    "end": 2461828,
    "text": "ひとつはシングルモードと呼ばれるもので、文書全体を掴んでそこに放り込むようなものだ。"
  },
  {
    "start": 2461934,
    "end": 2476272,
    "text": "例えば、タイトルが個々のエントリーになり、物語文の段落がそこに入るセクションになります。"
  },
  {
    "start": 2476406,
    "end": 2484540,
    "text": "私たちが今取り組んでいることのひとつは、エレメントタイプを使って良いチャンクを考え出すことです。"
  },
  {
    "start": 2484700,
    "end": 2492836,
    "text": "その結果、タイトルや小見出しが見つかった。"
  },
  {
    "start": 2492858,
    "end": 2495908,
    "text": "その下に本文を表示する。"
  },
  {
    "start": 2495994,
    "end": 2501600,
    "text": "それが1つの塊になり、ドキュメントを見ながら、スマートに分解していくような感じだ。"
  },
  {
    "start": 2501770,
    "end": 2510410,
    "text": "今はまだ入っていないが、積極的に取り組んでいることであり、今後2、3週間のうちにここで何か発表できるはずだ。"
  },
  {
    "start": 2511200,
    "end": 2511996,
    "text": "いいね。"
  },
  {
    "start": 2512178,
    "end": 2513676,
    "text": "それを見るのが楽しみだ。"
  },
  {
    "start": 2513858,
    "end": 2515470,
    "text": "それは本当にいいことだと思う。"
  },
  {
    "start": 2519360,
    "end": 2528460,
    "text": "では、一番上の質問と、その下にある別の質問を見てください。"
  },
  {
    "start": 2528540,
    "end": 2534380,
    "text": "一番上の質問、非常に大規模なデータベースを検索するためのベストプラクティスは何か？"
  },
  {
    "start": 2534460,
    "end": 2537452,
    "text": "例えば、4,000万件のニュース記事を持つデータベース？"
  },
  {
    "start": 2537516,
    "end": 2543536,
    "text": "その下にもうひとつ質問がある。それは、本番で使用するためにすべてをどのようにデプロイするのか、ということだ。"
  },
  {
    "start": 2543568,
    "end": 2552036,
    "text": "この2つをひとくくりにして、基本的にはベクター・データベースとインジェスト側の両方でプロダクション検索を行うことにする。"
  },
  {
    "start": 2552218,
    "end": 2554344,
    "text": "皆さんはそのことをどう考え、どう取り組んでいますか？"
  },
  {
    "start": 2554542,
    "end": 2556170,
    "text": "僕が行こうか？"
  },
  {
    "start": 2556860,
    "end": 2558744,
    "text": "つまり、私たちは今、多くの時間を費やしている。"
  },
  {
    "start": 2558782,
    "end": 2564924,
    "text": "実は、Chromaが今エンジニアリングで力を入れているのは、AIアプリケーションのための検索をプロダクション化することなんだ。"
  },
  {
    "start": 2564962,
    "end": 2568584,
    "text": "そのスケールの問題は、私たちが取り組んでいることの第1番目だ。"
  },
  {
    "start": 2568632,
    "end": 2581372,
    "text": "4,000万件ものエントリーを、つまりニュース記事に分割して、簡単に水平方向にスケールさせることができる。"
  },
  {
    "start": 2581436,
    "end": 2584912,
    "text": "1つから3つか4つのチャンクが得られるだろう。"
  },
  {
    "start": 2585046,
    "end": 2587716,
    "text": "120,000,000のオーダーになる。"
  },
  {
    "start": 2587818,
    "end": 2589700,
    "text": "とても合理的な規模だ。"
  },
  {
    "start": 2590200,
    "end": 2593072,
    "text": "それはまったく理不尽なことではない。"
  },
  {
    "start": 2593136,
    "end": 2603524,
    "text": "現在、シングルノードクロマでは、検索効率という点で、メモリに制約があるからだ。"
  },
  {
    "start": 2603572,
    "end": 2609316,
    "text": "その理由は、データベースのベクトル検索部分がメモリ上で実行されるからだ。"
  },
  {
    "start": 2609348,
    "end": 2612008,
    "text": "近似最近傍を効率的に行う方法だ。"
  },
  {
    "start": 2612184,
    "end": 2617704,
    "text": "4,000万件のニュース記事から1億2,000万チャンクを抽出するのは、無理からぬことだ。"
  },
  {
    "start": 2617752,
    "end": 2630160,
    "text": "現在でも、経験則だが、私の16ギガのM、1台のマックでは、メモリーの半分が常にランダムなアプリケーションに使用されている。"
  },
  {
    "start": 2631700,
    "end": 2635596,
    "text": "さらに、より効率的な戦略もある。"
  },
  {
    "start": 2635628,
    "end": 2642084,
    "text": "もしそれが必要なら、基本的には、複数のノードを複数のノードに、簡単に、水平方向にスケールできるものを使うことだ。"
  },
  {
    "start": 2642122,
    "end": 2645540,
    "text": "そうでなければ、1つの大きなノードをつかんで、その方法でやればいい。"
  },
  {
    "start": 2645690,
    "end": 2647284,
    "text": "ここで勝つための効率は他にもある。"
  },
  {
    "start": 2647322,
    "end": 2657780,
    "text": "次元削減があり、これは明らかにメモリが少なくてすむことを意味する。実際に検索するベクトルは次元数が少なく、メモリに格納する浮動小数点数が少ないからだ。"
  },
  {
    "start": 2657940,
    "end": 2661856,
    "text": "また、インデックスの一部をディスクに書き込み、その一部だけをメモリに保持することもある。"
  },
  {
    "start": 2661908,
    "end": 2664488,
    "text": "クエリーパターンに応じて適応的に行うことができる。"
  },
  {
    "start": 2664504,
    "end": 2672456,
    "text": "今日の答えは、基本的には、より多くのラムを本番に配備するのが良いというものだ。"
  },
  {
    "start": 2672488,
    "end": 2675890,
    "text": "つまり、この辺りにはたくさんの配慮があるんだ。"
  },
  {
    "start": 2676820,
    "end": 2680050,
    "text": "Chromeは現在、シングルノードのサービスとして本番稼動している。"
  },
  {
    "start": 2680820,
    "end": 2689008,
    "text": "1台のマシン上で複数のDockerコンテナを動作させることで、仮想分散システムや仮想マルチテナントシステムのように運用することもできる。"
  },
  {
    "start": 2689104,
    "end": 2698176,
    "text": "一例として、本番へのデプロイは現時点でできる限り簡単にできるようにしましたが、すべてにおいて、少し骨抜きにしすぎました。"
  },
  {
    "start": 2698208,
    "end": 2700224,
    "text": "それをより強固なものにするために、我々は間違いなく取り組んでいる。"
  },
  {
    "start": 2700272,
    "end": 2708184,
    "text": "自分のサーバーの後ろに置いて、自分で認証し、自分でトークンの受け渡しをしなければならない。"
  },
  {
    "start": 2708302,
    "end": 2712300,
    "text": "この機能を実現するための主な考慮点は、十分なラムを搭載したマシンを用意することだ。"
  },
  {
    "start": 2714240,
    "end": 2718910,
    "text": "マットさん、データ収集の面ではどのように取り組んでいますか？"
  },
  {
    "start": 2719600,
    "end": 2722316,
    "text": "今、僕たちは本当に好きなんだ。"
  },
  {
    "start": 2722338,
    "end": 2727970,
    "text": "これはオープンソースのコンテナで、好きなところから引っ張ってきて動かすことができる。"
  },
  {
    "start": 2728420,
    "end": 2743252,
    "text": "インフラ面で最も負担が大きいのはPDFとイメージで、一部のワークロードはモデルベースなので、Gpusの可用性が助けになる。"
  },
  {
    "start": 2743386,
    "end": 2755592,
    "text": "しかし、内部でこれを動かしてみてわかったのは、多くのインスタンスを並列にCPUを使って動かすことができるということだ。"
  },
  {
    "start": 2755726,
    "end": 2771150,
    "text": "私たちの観点では、とにかくシンプルに、好きな場所に持っていけるようなコンテナを作り、それが稼働したら、文書化され、構造化され、jsonで出力されるようにしようとしてきました。"
  },
  {
    "start": 2771520,
    "end": 2780530,
    "text": "また、クライアント・チェーンのようなものを使いやすくするための統合もあります。"
  },
  {
    "start": 2781620,
    "end": 2789796,
    "text": "下の方に1つ質問があるのですが、お二人の見解を聞くのは面白いと思います。"
  },
  {
    "start": 2789978,
    "end": 2794244,
    "text": "文脈に依存する質問や時間ベースの情報を検索するためのアドバイスはありますか？"
  },
  {
    "start": 2794442,
    "end": 2797220,
    "text": "XYZの最近の動向は？"
  },
  {
    "start": 2797720,
    "end": 2808088,
    "text": "クエリそのものが、セマンティックに調べたいだけでなく、何か他のものへの言及があるような場合に、このような分類になるのかもしれない。"
  },
  {
    "start": 2808174,
    "end": 2817084,
    "text": "ベクターデータベースに何を保存すべきか、また、インジェスト時にどのように情報を抽出する手助けをするか。"
  },
  {
    "start": 2817282,
    "end": 2825128,
    "text": "ドキュメントの前処理におけるメタデータの構成要素について、私たちは多くのことを考えました。"
  },
  {
    "start": 2825224,
    "end": 2831884,
    "text": "ですから、特に時間に依存するもの、例えばドキュメントが最後に更新されたのはいつなのか、といったようなものを抽出することができます。"
  },
  {
    "start": 2832012,
    "end": 2837920,
    "text": "もし文書から日付を取り出して保存することができれば、そのようなことは本当に役に立つ。"
  },
  {
    "start": 2838080,
    "end": 2848452,
    "text": "私たちが社内で実験していることのひとつは、基本的に時間減衰を伴うコサイン類似性のようなものです。"
  },
  {
    "start": 2848516,
    "end": 2858936,
    "text": "基本的には、より最近の情報に偏った情報を得るために、とてもシンプルで簡単に実装できることを発見したんだ。"
  },
  {
    "start": 2859118,
    "end": 2864444,
    "text": "もっと複雑な検索方法があるはずだ。"
  },
  {
    "start": 2864642,
    "end": 2877472,
    "text": "データの前処理という観点から言えば、コンディショニング・ステップに使用できるすべての情報を記事や文書から引き出すことだ。"
  },
  {
    "start": 2877606,
    "end": 2880210,
    "text": "それが僕らにとっての核心なんだ。"
  },
  {
    "start": 2884740,
    "end": 2889520,
    "text": "アントンさんは、人々がメタデータをどのように使っているのか、何かご存知ですか？"
  },
  {
    "start": 2889940,
    "end": 2895812,
    "text": "そうだね、時間的なことに関する疑問は僕らにもある。"
  },
  {
    "start": 2895866,
    "end": 2899364,
    "text": "レジデントのハッカーの一人が、時間の経過とともに更新が必要なものに取り組んでいた。"
  },
  {
    "start": 2899402,
    "end": 2902488,
    "text": "だから、私たちはこの問題についてずっと考えてきた。"
  },
  {
    "start": 2902574,
    "end": 2907332,
    "text": "ジャーナリングをベクトルベースの検索という文脈で考え始める。"
  },
  {
    "start": 2907476,
    "end": 2909770,
    "text": "メタデータのフィルタリングは重要だと思う。"
  },
  {
    "start": 2911180,
    "end": 2913620,
    "text": "クエリの範囲を広げるのに役立つことは間違いないと思う。"
  },
  {
    "start": 2913700,
    "end": 2922936,
    "text": "興味深いのは、基本的にモデルを使ってエンティティを抽出し、それをクエリの関連性のための追加メタデータ・フィルターとして注入することだ。"
  },
  {
    "start": 2923128,
    "end": 2926776,
    "text": "繰り返しになるが、私にとっては短期的なストップギャップという感じだ。"
  },
  {
    "start": 2926808,
    "end": 2928204,
    "text": "モデルがそれを計算してくれるはずだ。"
  },
  {
    "start": 2928242,
    "end": 2932076,
    "text": "そのため、ベクターのこれらの部分を適切に待機させる。"
  },
  {
    "start": 2932108,
    "end": 2935010,
    "text": "とりあえず、こういうことを試してみるのは面白いと思う。"
  },
  {
    "start": 2935780,
    "end": 2945060,
    "text": "私の簡単な回答としては、このようなさまざまなことを可能な限り試して、あなたのアプリケーションでそうするために可能な限り軽量化し、それがどの程度うまくいくかを見てみる、というようなことだ。"
  },
  {
    "start": 2945210,
    "end": 2947956,
    "text": "私たちが積極的に考えているのは時間のことだ。"
  },
  {
    "start": 2948058,
    "end": 2962372,
    "text": "もちろん、クロマはメタデータの時間フィールドをサポートしていますし、時間範囲内を検索することもできます。しかし、自然言語でのやり取りを考えた場合、1月26日とか、その間の情報を知りたいとは言いません。"
  },
  {
    "start": 2962436,
    "end": 2968476,
    "text": "例えば、弟の誕生日が近づいていて、その2週間以内だったことをシステムに知らせたいとかね。"
  },
  {
    "start": 2968498,
    "end": 2973788,
    "text": "例えば、彼にプレゼントを用意するよう促すべきだ。"
  },
  {
    "start": 2973874,
    "end": 2974510,
    "text": "そうだね。"
  },
  {
    "start": 2975920,
    "end": 2978116,
    "text": "今は少し不便に感じる。"
  },
  {
    "start": 2978168,
    "end": 2987424,
    "text": "モデルへの信頼が足りないか、効果的な使い方がまだ見つかっていないか、あるいはモデルにはその能力がないかのように感じる。"
  },
  {
    "start": 2987462,
    "end": 2990820,
    "text": "だから、メタデータでギャップを埋めているんだ。"
  },
  {
    "start": 2993160,
    "end": 3000420,
    "text": "ロング・コンテクスト・ウインドウは、人々の検索作業をどのように変えていますか？"
  },
  {
    "start": 3001160,
    "end": 3005450,
    "text": "ロング・コンテクストを検索に使っている人はまだあまり見たことがない。"
  },
  {
    "start": 3005820,
    "end": 3012250,
    "text": "長いコンテクストというのは、実は、可能なコンテクストにすべてを詰め込むという意味ではないということを覚えておくことが重要だと思う。"
  },
  {
    "start": 3012780,
    "end": 3016504,
    "text": "ハリソンという論文があるんだが、後でリンクする。"
  },
  {
    "start": 3016622,
    "end": 3020296,
    "text": "今日のこの分野で興味深いのは、何が効果的で何が効果的でないかについて、多くの言い伝えがあることだ。"
  },
  {
    "start": 3020328,
    "end": 3025784,
    "text": "やがて、その結論を実証的に支持または反証する論文が発表される。"
  },
  {
    "start": 3025832,
    "end": 3035596,
    "text": "しばらくの間、人々は直感的に、固定された注意メカニズムでより長いコンテクストウィンドウは、そのコンテクストウィンドウ内のすべてのトークンにモデルがそれほど効果的に注意できないことを意味することを知っていた。"
  },
  {
    "start": 3035628,
    "end": 3039810,
    "text": "それは証明されているし、ディストラクターが本当に悪いことも証明されている。"
  },
  {
    "start": 3040580,
    "end": 3048580,
    "text": "偶発的に無関係な情報を加えると、モデルの性能はあっという間に崖から落ちてしまう。"
  },
  {
    "start": 3049160,
    "end": 3062184,
    "text": "というのは、長いコンテクストは、より多くの関連情報をコンテクストに当てはめることができ、モデルが理解し理解できるように適切に提示することができるからだ。"
  },
  {
    "start": 3062382,
    "end": 3069272,
    "text": "つまり、文脈が長ければ長いほど、検索できる情報が多ければ多いほど、関連性がより重要になるということだ。"
  },
  {
    "start": 3069416,
    "end": 3074216,
    "text": "というのも、ディストラクターを回収するたびに、模範演技は崖から落ちるからだ。"
  },
  {
    "start": 3074248,
    "end": 3081228,
    "text": "kとkの最近接値を10ではなく100にチューニングして、それを全部詰め込めばいいという問題ではないのだ。"
  },
  {
    "start": 3081314,
    "end": 3085008,
    "text": "関連性には細心の注意を払わなければならない。"
  },
  {
    "start": 3085094,
    "end": 3090960,
    "text": "個人的には、より長いコンテクストウィンドウは検索にとって素晴らしいことだと思う。"
  },
  {
    "start": 3092680,
    "end": 3095408,
    "text": "その上で、マットにひとつ質問がある。"
  },
  {
    "start": 3095584,
    "end": 3102356,
    "text": "コンテクストウィンドウを長くすることで、チャンキングに変化はありますか？"
  },
  {
    "start": 3102378,
    "end": 3112564,
    "text": "アントンも言っていたように、より長いチャンクを入れたり、より長いチャンクに気を取られたりして、リトリーブのステップを悪くしている。"
  },
  {
    "start": 3112612,
    "end": 3116430,
    "text": "どのようにバランスを取っているのですか？"
  },
  {
    "start": 3117200,
    "end": 3120940,
    "text": "ああ、コスト面も考慮する必要があると思う。"
  },
  {
    "start": 3121010,
    "end": 3131360,
    "text": "多くの文書を処理する場合、トークン単位で支払うようなもので、コンテクスト・ウィンドウに多くのものを放り込むと、割高になる可能性がある。"
  },
  {
    "start": 3133380,
    "end": 3140770,
    "text": "つまり、モデルによって、より長いコンテクストのウィンドウが出てきたことで、それがより一般的になってきていると思う。"
  },
  {
    "start": 3141240,
    "end": 3165870,
    "text": "Antonが言ったような理由もありますし、ただ、たくさんのドキュメントを処理するのであれば、モデルの設定に入れるトークンの数とか、ホスティングされたものを使うのであれば、そういったことに気をつけたいところです。"
  },
  {
    "start": 3167760,
    "end": 3168604,
    "text": "クールだ。"
  },
  {
    "start": 3168802,
    "end": 3169710,
    "text": "分かった。"
  },
  {
    "start": 3171840,
    "end": 3182620,
    "text": "この回答がどのくらいになるかにもよりますが、基本的にはさまざまなタイプの検索に戻ることになりますが、グラフ検索の組み合わせについてどう思いますか？"
  },
  {
    "start": 3182700,
    "end": 3186880,
    "text": "あるいは、ベクトル検索と組み合わせた知識グラフ検索についてはどう思いますか？"
  },
  {
    "start": 3188740,
    "end": 3190300,
    "text": "これは有効な解決策なのだろうか？"
  },
  {
    "start": 3190380,
    "end": 3194432,
    "text": "長い目で見れば、結局のところすべてが、変形を伴う埋め込み空間のようなことになるのだろうか？"
  },
  {
    "start": 3194496,
    "end": 3199460,
    "text": "つまり、これは特定のトークンに重み付けをするのと同じことなのだ。"
  },
  {
    "start": 3199800,
    "end": 3200996,
    "text": "これをどう考える？"
  },
  {
    "start": 3201098,
    "end": 3202730,
    "text": "ああ、興味深い質問だ。"
  },
  {
    "start": 3204060,
    "end": 3206840,
    "text": "ナレッジグラフを重ね合わせるというこの種のアイデア。"
  },
  {
    "start": 3207340,
    "end": 3211204,
    "text": "私たちは、再ランキング戦略として、この方法が使われているのを少し見てきた。"
  },
  {
    "start": 3211252,
    "end": 3216092,
    "text": "セマンティック検索を行った後、ナレッジグラフを通して関連するエンティティを見つけるのですか？"
  },
  {
    "start": 3216226,
    "end": 3231616,
    "text": "素朴に言えば、エンベッディング、バニラエンベッディングモデル、対照的に事前学習されたエンベッディングモデルは、エンティティ間の関係をエンコードしてくれない。"
  },
  {
    "start": 3231718,
    "end": 3232032,
    "text": "そうだね。"
  },
  {
    "start": 3232086,
    "end": 3236460,
    "text": "クルマと鳥という2つの概念をどのように関連づけるのか、まったく知らないのだ。"
  },
  {
    "start": 3236620,
    "end": 3237040,
    "text": "そうだね。"
  },
  {
    "start": 3237110,
    "end": 3240230,
    "text": "あなたの特定のタスクやアプリケーションに関連するかもしれない。"
  },
  {
    "start": 3241720,
    "end": 3246464,
    "text": "まあ、それは単なる関連性のハックに過ぎない。"
  },
  {
    "start": 3246512,
    "end": 3253860,
    "text": "あなたの特定のアプリケーションで必要なのは、必要な埋め込みがより近くになるように、空間を折りたたんで圧迫することだ。"
  },
  {
    "start": 3253930,
    "end": 3259832,
    "text": "ナレッジグラフで関連するエンティティは、ベクトル検索で類似して表示されるはずです。"
  },
  {
    "start": 3259886,
    "end": 3268936,
    "text": "良い答えがあるのかどうか分からないが、これは本当に疑問の一つだと思う。"
  },
  {
    "start": 3268968,
    "end": 3274956,
    "text": "あるいは、このような重み付けされた関係さえも、一般的なAIにどのようにエンコードすればいいのだろうか？"
  },
  {
    "start": 3275138,
    "end": 3275736,
    "text": "そうだね。"
  },
  {
    "start": 3275858,
    "end": 3277410,
    "text": "そのいい方法がないんだ。"
  },
  {
    "start": 3278420,
    "end": 3291168,
    "text": "いろいろな意味で、トレーニング配分のようなものを敗戦の目標にするだけでは、片手を後ろに縛って戦っているようなものだと感じる。"
  },
  {
    "start": 3291264,
    "end": 3294208,
    "text": "論理的な関係性のようなものはエンコードされていない。"
  },
  {
    "start": 3294224,
    "end": 3295844,
    "text": "統計的なものだけをエンコードする。"
  },
  {
    "start": 3295882,
    "end": 3300116,
    "text": "最終的には、もちろん、私たちは創発的な行動を見ることになる。"
  },
  {
    "start": 3300218,
    "end": 3303416,
    "text": "これらのモデルでプレーしている人なら、おそらく私と同じ感覚を持っているはずだ。"
  },
  {
    "start": 3303518,
    "end": 3314088,
    "text": "統計的な行動の結果として論理的な関係が現れるが、実際の論理的な関係はそこにない。"
  },
  {
    "start": 3314174,
    "end": 3315276,
    "text": "それが幻覚だ。"
  },
  {
    "start": 3315298,
    "end": 3321868,
    "text": "幻覚とは、現実世界の論理的あるいは根拠のある表現を無視した、統計的に可能性の高い世代のことである。"
  },
  {
    "start": 3321954,
    "end": 3323804,
    "text": "ナレッジグラフはひとつの方法かもしれない。"
  },
  {
    "start": 3323922,
    "end": 3330976,
    "text": "結局のところ、AIにとって読みやすく、AIが作業できるような方法で情報を表現するにはどうすればいいかという問題に行き着く。"
  },
  {
    "start": 3330998,
    "end": 3335330,
    "text": "誰もが取り組んでいる、実に広範で興味深い研究課題だと思う。"
  },
  {
    "start": 3336900,
    "end": 3345396,
    "text": "ただひとつ付け加えるとすれば、ナレッジグラフを使った補強とか、そういうものには間違いなく価値がある。"
  },
  {
    "start": 3345498,
    "end": 3349072,
    "text": "難しいのは、知識グラフを構築するのが本当に難しいということだ。"
  },
  {
    "start": 3349136,
    "end": 3354568,
    "text": "ベクター検索を利用したアプリケーションのようなもので、立ち上げるのも実行するのもずっと簡単だ。"
  },
  {
    "start": 3354654,
    "end": 3365236,
    "text": "ベクター・ストアベースのアプリケーションを、ゼロからスタートさせるために使う人もいると思います。"
  },
  {
    "start": 3365268,
    "end": 3375470,
    "text": "その後、システムが成熟するにつれて、ナレッジグラフのような高コストのコンポーネントを追加することになる。"
  },
  {
    "start": 3378180,
    "end": 3381756,
    "text": "それがどのように発展していくのか、間違いなく興味がある。"
  },
  {
    "start": 3381948,
    "end": 3393060,
    "text": "でも、それと同時に、現在のようなラグ・タイプのアーキテクチャーに取って代わるのは難しいとも思う。"
  },
  {
    "start": 3395320,
    "end": 3397812,
    "text": "よし、これで終わりにしよう。"
  },
  {
    "start": 3397866,
    "end": 3399984,
    "text": "ということで、参加してくれてありがとう。"
  },
  {
    "start": 3400032,
    "end": 3400904,
    "text": "とても楽しかった。"
  },
  {
    "start": 3400942,
    "end": 3401752,
    "text": "多くのことを学んだ。"
  },
  {
    "start": 3401806,
    "end": 3407316,
    "text": "楽しいことを学んだときは、ウェビナーが一番楽しい。"
  },
  {
    "start": 3407348,
    "end": 3410090,
    "text": "来てくれてありがとう。"
  },
  {
    "start": 3413500,
    "end": 3414424,
    "text": "お招きいただきありがとうございます。"
  },
  {
    "start": 3414462,
    "end": 3419532,
    "text": "ああ、ここで発明や実験を続けることを楽しみにしているよ。"
  },
  {
    "start": 3419586,
    "end": 3426460,
    "text": "ああ、君が言った \"いろいろ試してみるのが一番いい \"という言葉はとても気に入ったよ。"
  },
  {
    "start": 3427600,
    "end": 3428460,
    "text": "興奮している。"
  },
  {
    "start": 3429040,
    "end": 3429772,
    "text": "強く同意する。"
  },
  {
    "start": 3429826,
    "end": 3434616,
    "text": "このウェビナーに参加している全員が、最終的には実験のためのツールを作っている。"
  },
  {
    "start": 3434648,
    "end": 3438710,
    "text": "それはクロマの作り方、ラングチェーンの作り方の大きな部分だと思う。"
  },
  {
    "start": 3439720,
    "end": 3442964,
    "text": "だから、人々がこのようなものを簡単に試せるようにするだけでも、大きな意味があると思う。"
  },
  {
    "start": 3443002,
    "end": 3443590,
    "text": "そうだね。"
  },
  {
    "start": 3446360,
    "end": 3449670,
    "text": "観客のみんなは、何でも試してみるべきだ。"
  },
  {
    "start": 3450120,
    "end": 3450676,
    "text": "そうだ。"
  },
  {
    "start": 3450778,
    "end": 3451956,
    "text": "チャンネルを合わせてくれてありがとう。"
  },
  {
    "start": 3451978,
    "end": 3453540,
    "text": "何かヒントが得られるといいね。"
  },
  {
    "start": 3454680,
    "end": 3456032,
    "text": "生きているのは楽しい時間だ。"
  },
  {
    "start": 3456176,
    "end": 3456532,
    "text": "そうだね。"
  },
  {
    "start": 3456586,
    "end": 3457856,
    "text": "どうもありがとう、ハリソン。"
  },
  {
    "start": 3457968,
    "end": 3458370,
    "text": "また会おう。"
  }
]