[
  {
    "start": 10410,
    "end": 14350,
    "text": "午後の最初のスピーカーはジェイコブ・スタインハートだ。"
  },
  {
    "start": 14690,
    "end": 22318,
    "text": "ジェイコブは、クレイジーな創造性と技術的なノウハウを兼ね備えた、驚くべき研究者なんだ。"
  },
  {
    "start": 22484,
    "end": 28390,
    "text": "彼のおかげで、技術的な面でも社会的な面でも、多くの問題についてこれまでとはまったく違った考え方をするようになった。"
  },
  {
    "start": 28890,
    "end": 31238,
    "text": "とても興味深い話になると予想している。"
  },
  {
    "start": 31324,
    "end": 31960,
    "text": "ありがとう。"
  },
  {
    "start": 36090,
    "end": 37586,
    "text": "ありがとう、サーシャ。"
  },
  {
    "start": 37698,
    "end": 45942,
    "text": "サイモンのワークショップの精神に則って、何か新しいことを話したいと思ったんだ。"
  },
  {
    "start": 46006,
    "end": 49062,
    "text": "これらのスライドは、実は完全にゼロから準備されている。"
  },
  {
    "start": 49126,
    "end": 52458,
    "text": "私のノートパソコンで見る以外、誰も見たことがない。"
  },
  {
    "start": 52634,
    "end": 54160,
    "text": "私たちが面白くなることを願っている。"
  },
  {
    "start": 54930,
    "end": 71022,
    "text": "少なくとも、世界中に配備されているMLシステムが何をしているのか、どのように動作しているのか、ボンネットの下で何が起こっているのかを理解したい。"
  },
  {
    "start": 71166,
    "end": 75026,
    "text": "新しいものがたくさんあるので、とてもやりがいがある。"
  },
  {
    "start": 75208,
    "end": 81522,
    "text": "毎月のように新しいモデルが発表され、より大きく、より高性能で、より複雑になっていくのかもしれない。"
  },
  {
    "start": 81666,
    "end": 93866,
    "text": "特に、規模を拡大するたびに、新たな能力や質的な行動が出現することがよくある。"
  },
  {
    "start": 93968,
    "end": 99690,
    "text": "だから、答えは1つではないと思う。"
  },
  {
    "start": 99760,
    "end": 119586,
    "text": "なぜなら、より優れたLLMが発表されるたびに、理解しなければならない新しいことが出てくるからだ。"
  },
  {
    "start": 119688,
    "end": 122242,
    "text": "そういうことだ。"
  },
  {
    "start": 122296,
    "end": 124130,
    "text": "この好循環を得ることができるだろうか？"
  },
  {
    "start": 126630,
    "end": 129894,
    "text": "モデルが良くなれば、理解も深まるだろう。"
  },
  {
    "start": 130012,
    "end": 135138,
    "text": "これは、実際に多くの異なる協力者との仕事に基づいている。"
  },
  {
    "start": 135234,
    "end": 140742,
    "text": "私が注目したいのは、生徒のラチ、エリック、コリンの3人だ。"
  },
  {
    "start": 140806,
    "end": 149180,
    "text": "特に、この講演にあるような統計学者としてのLLMの視点の多くは、LLMによって開発されたものである。"
  },
  {
    "start": 151230,
    "end": 154250,
    "text": "統計学者としてのLLMSとは？"
  },
  {
    "start": 154330,
    "end": 165042,
    "text": "私が主張したいのは、我々が関心を持ちうる理解の多くの形態は、本質的にある種の統計学やデータ科学の問題に還元されるということだ。"
  },
  {
    "start": 165096,
    "end": 173022,
    "text": "私たちはモデルを与えられ、それが膨大な数の入力に対して何を出力するかを見るだけなのかもしれない。"
  },
  {
    "start": 173086,
    "end": 177538,
    "text": "私たちが持っているすべてのデータセットを使って、モデルが何をするか見るだけで、それは簡単にできる。"
  },
  {
    "start": 177624,
    "end": 179926,
    "text": "だったら、パターンを特定したいよね？"
  },
  {
    "start": 179948,
    "end": 181974,
    "text": "モデルが得意とすることはありますか？"
  },
  {
    "start": 182012,
    "end": 185750,
    "text": "驚くようなことがある場合は苦手なこともある。"
  },
  {
    "start": 186170,
    "end": 191258,
    "text": "そうであれば、それを統計的仮説として定式化し、検証することができるだろう。"
  },
  {
    "start": 191344,
    "end": 193914,
    "text": "これは統計的な問題だ。"
  },
  {
    "start": 194112,
    "end": 201630,
    "text": "トレーニングセットを理解し、何が重要な変動要因なのかを理解したいのかもしれない。"
  },
  {
    "start": 203170,
    "end": 212430,
    "text": "もし、データセットの大部分が64ベースという奇妙な言語で書かれていることが判明したら、そのことを知りたいと思うだろう。"
  },
  {
    "start": 212580,
    "end": 223314,
    "text": "アクティブ・ラーニングやアクティブ・サンプリングのような、問題行動を誘発するような新しい入力を生成して、それを特定して修正するような問題もありますね。"
  },
  {
    "start": 223352,
    "end": 228774,
    "text": "これらはすべて、あるレベルでは統計やデータの問題だと考えている。"
  },
  {
    "start": 228972,
    "end": 241994,
    "text": "だから、ある種の一般的な意味で、大規模な言語モデルに統計処理をさせることができれば、これらの問題や、もちろん他の多くの有用な問題にも取り組むことができる。"
  },
  {
    "start": 242192,
    "end": 245418,
    "text": "そのためにはどうすればいいのだろう？"
  },
  {
    "start": 245504,
    "end": 252454,
    "text": "統計のパイプラインはどうなっているのか、非常にハイレベルな視点から見ていこうと思う。"
  },
  {
    "start": 252582,
    "end": 255470,
    "text": "4つのステップがあるんだ。"
  },
  {
    "start": 255890,
    "end": 258750,
    "text": "まず、最初のデータを見てみよう。"
  },
  {
    "start": 258900,
    "end": 266418,
    "text": "これはトレーニングデータとして考えたいのかもしれないが、このデータから方向性を見出すのに役立つ、ある種のデータだ。"
  },
  {
    "start": 266584,
    "end": 277902,
    "text": "私たちは何らかの仮説を立てたいと思う。例えば、モデルは短いインプットよりも長いインプットの方が成績が悪い、というような仮説だ。"
  },
  {
    "start": 277976,
    "end": 282438,
    "text": "そしてそれを定量的に定式化し、新しいデータでテストする。"
  },
  {
    "start": 282524,
    "end": 285890,
    "text": "このデータは、同じ分布から取り残されたものかもしれない。"
  },
  {
    "start": 285970,
    "end": 296170,
    "text": "新たな領域への一般化を気にするかもしれないし、仮説を本当にストレステストするために積極的にデータを集めたいかもしれない。"
  },
  {
    "start": 296590,
    "end": 305950,
    "text": "そこで、このような構造を持つ問題をいくつかケーススタディとして取り上げ、それぞれのステップをllmsで自動化していこうと思う。"
  },
  {
    "start": 306530,
    "end": 314066,
    "text": "従来の統計の見方との決定的な違いは、この仮説Hにある。"
  },
  {
    "start": 314168,
    "end": 327226,
    "text": "重要な違いは、hが数学的な関数として表現されることである。"
  },
  {
    "start": 327278,
    "end": 330680,
    "text": "私はこれを、ある特徴的な関数への期待のように書くことができる。"
  },
  {
    "start": 331050,
    "end": 336466,
    "text": "ここでは言語モデルを使っているので、hは自然言語の文字列となる。"
  },
  {
    "start": 336578,
    "end": 353200,
    "text": "というのも、例えば自然言語の文字列がデータセットに対して真であるかどうか、その意味を定式化しなければならないからです。"
  },
  {
    "start": 353970,
    "end": 359182,
    "text": "抽象的な説明になってしまったが、すぐにケーススタディに入るので心配はいらない。"
  },
  {
    "start": 359236,
    "end": 360686,
    "text": "実際、今すぐだ。"
  },
  {
    "start": 360788,
    "end": 368558,
    "text": "さて、最初にお話しするケーススタディは、クリップというモデルの故障を見つけることです。"
  },
  {
    "start": 368734,
    "end": 374178,
    "text": "ご存じない方のために説明すると、クリップはエンコーダーモデルである。"
  },
  {
    "start": 374264,
    "end": 380322,
    "text": "これは入力を取り込み、ある種の特徴ベクトルとして埋め込む。"
  },
  {
    "start": 380466,
    "end": 384466,
    "text": "後の多くのモデルのバックボーンとして使われているようなものだ。"
  },
  {
    "start": 384498,
    "end": 384646,
    "text": "そうだね。"
  },
  {
    "start": 384668,
    "end": 387138,
    "text": "良いエンベッディングがあると便利なことが多い。"
  },
  {
    "start": 387234,
    "end": 391146,
    "text": "多くのモデルは、これらの埋め込みを使い、それを使って何かをする。"
  },
  {
    "start": 391248,
    "end": 401280,
    "text": "クリップが特別なのは、画像とテキストの両方をある種の共有スペースに埋め込むことだ。"
  },
  {
    "start": 401650,
    "end": 407630,
    "text": "このようなことを効果的に行った初期のマルチモーダルモデルのひとつである。"
  },
  {
    "start": 408290,
    "end": 411998,
    "text": "ここにあるように、多くのモデルが使っている。"
  },
  {
    "start": 412004,
    "end": 415154,
    "text": "ミッドジャーニーは、それを最初のエンベデッドステップとして使う。"
  },
  {
    "start": 415272,
    "end": 421060,
    "text": "ドリーもそうだし、安定したディフュージョンもそうだし、多くのビデオモデルもそうだ。"
  },
  {
    "start": 421430,
    "end": 425806,
    "text": "これらのエンベッディングを使えば、かなり素晴らしい結果を得ることができる。"
  },
  {
    "start": 425918,
    "end": 429890,
    "text": "多くの場合、テキストから画像への変換に使われる。"
  },
  {
    "start": 429970,
    "end": 432934,
    "text": "何が欲しいのか、テキストで説明してください。"
  },
  {
    "start": 432972,
    "end": 439960,
    "text": "そして、これらのモデルは、何らかの方法でこの記述に一致する画像を生成しようとする。"
  },
  {
    "start": 440490,
    "end": 446294,
    "text": "少し小さいかもしれないが、空のグラスと書いてある。"
  },
  {
    "start": 446342,
    "end": 449450,
    "text": "このグラスは5人家族だ。"
  },
  {
    "start": 449520,
    "end": 450860,
    "text": "そうすれば、こうなる。"
  },
  {
    "start": 451230,
    "end": 453354,
    "text": "男は山を送るだけだ。"
  },
  {
    "start": 453472,
    "end": 457326,
    "text": "これらはすべて素晴らしいが、問題もある。"
  },
  {
    "start": 457428,
    "end": 457742,
    "text": "そうだね。"
  },
  {
    "start": 457796,
    "end": 459610,
    "text": "これはフルグラスだ。"
  },
  {
    "start": 459690,
    "end": 461406,
    "text": "6人家族である。"
  },
  {
    "start": 461588,
    "end": 463594,
    "text": "これは私たちが山を送る誰かだ。"
  },
  {
    "start": 463722,
    "end": 468146,
    "text": "これは夜空に星がないことを示し、天の川を示している。"
  },
  {
    "start": 468328,
    "end": 475170,
    "text": "そのため、素晴らしい画像が得られるが、意味的に非常に明白な失敗をすることが多い。"
  },
  {
    "start": 477130,
    "end": 486710,
    "text": "失敗作の数々を見つけることができたという事実はさておき、実はこれらの失敗作を見つけることができなかったという筋書きのようなものだ。"
  },
  {
    "start": 487130,
    "end": 488790,
    "text": "LLMはこれらの失敗を発見した。"
  },
  {
    "start": 488870,
    "end": 502170,
    "text": "これらはすべて、1人のLLMではなく、複数のLLMがそれぞれの強みを生かした補完的なタスクを共同でこなすパイプラインのようなものによって自動生成されたものだ。"
  },
  {
    "start": 502330,
    "end": 511950,
    "text": "クリップを与えるだけで、これらの失敗をすべて大規模に自動生成できるようなシステムを実際に構築するにはどうすればいいのかについて話そう。"
  },
  {
    "start": 512770,
    "end": 516500,
    "text": "この詳細を説明する前に、何か質問はありますか？"
  },
  {
    "start": 518150,
    "end": 519394,
    "text": "はい、1つだけ簡単な質問を。"
  },
  {
    "start": 519432,
    "end": 521570,
    "text": "なぜドリーは新しい存在だと言うのですか？"
  },
  {
    "start": 521720,
    "end": 523330,
    "text": "この文脈ではどういう意味なのか？"
  },
  {
    "start": 525370,
    "end": 541818,
    "text": "ドリーのバージョンはさまざまで、そのうちのひとつは、詳細はよくわからないのですが、ドリーはオープンAIが開発したものだと思います。"
  },
  {
    "start": 541904,
    "end": 551050,
    "text": "というわけで、私たちが使っているのはこれです。"
  },
  {
    "start": 555090,
    "end": 558430,
    "text": "このプロセスによって、新しいタイプのエラーが発生することはありますか？"
  },
  {
    "start": 558500,
    "end": 562714,
    "text": "例えば、カウントエラーとか、方向性のエラーとか？"
  },
  {
    "start": 562762,
    "end": 564686,
    "text": "それらはすでに知られていることだ。"
  },
  {
    "start": 564718,
    "end": 564914,
    "text": "そうだね。"
  },
  {
    "start": 564952,
    "end": 568130,
    "text": "この過程で新たに形成された仮説はあるのか？"
  },
  {
    "start": 568280,
    "end": 569618,
    "text": "ああ、いい質問だね。"
  },
  {
    "start": 569704,
    "end": 572500,
    "text": "数字のことは後で説明する。"
  },
  {
    "start": 573110,
    "end": 577842,
    "text": "エラーは14のカテゴリーに分類される。"
  },
  {
    "start": 577986,
    "end": 582482,
    "text": "私たちは、これらのエラーを記述した論文を探した。"
  },
  {
    "start": 582546,
    "end": 586950,
    "text": "すでに文献で紹介されているものは、ほんの一握りだったと思う。"
  },
  {
    "start": 587450,
    "end": 589030,
    "text": "他は文献になかった。"
  },
  {
    "start": 589110,
    "end": 596646,
    "text": "おそらく、このようなモデルを弄ることを本職としている人なら、このようなエラーに精通しているのだろう。"
  },
  {
    "start": 596838,
    "end": 604190,
    "text": "いいことは、たくさんの時間を使わなくても、これができるということだ。"
  },
  {
    "start": 604260,
    "end": 616480,
    "text": "実際、レビュアーからこのパイプラインに新しいシステムを追加するよう依頼され、30分ほどでそのシステムが持つ新たなエラーをすべて把握したケースもあったと思う。"
  },
  {
    "start": 617650,
    "end": 622702,
    "text": "今はそれが利点だと思う。"
  },
  {
    "start": 622766,
    "end": 629880,
    "text": "モデルが良くなるにつれて、多くの時間を費やした専門家でも見つけられないようなものが出てくることを期待している。"
  },
  {
    "start": 630570,
    "end": 631798,
    "text": "ああ、いい質問だね。"
  },
  {
    "start": 631964,
    "end": 633160,
    "text": "他に質問は？"
  },
  {
    "start": 636250,
    "end": 638386,
    "text": "じゃあ、どうすればいいんだ？"
  },
  {
    "start": 638508,
    "end": 644620,
    "text": "まず、ここでの重要な考え方の概要を説明しよう。"
  },
  {
    "start": 645070,
    "end": 649974,
    "text": "クリップは、テキストと画像の両方をエンコードする機能エンコーダーであることを忘れないでください。"
  },
  {
    "start": 650102,
    "end": 664314,
    "text": "エンコーダーにおけるハッシュの衝突と呼ぶべき概念があって、エンコーダーにおけるハッシュの衝突を自動で特定する方法を考え出すんだ。"
  },
  {
    "start": 664362,
    "end": 674500,
    "text": "衝突した場合、どちらが悪いかわからないが、少なくともどちらかが間違っているはずだ。"
  },
  {
    "start": 676390,
    "end": 704302,
    "text": "そして、これらの失敗をllmsを使って首尾一貫したパターンに分類し、これらのパターンから新しい例を生成することで、これらのパターンが実際に正しいかどうかをテストする。"
  },
  {
    "start": 704436,
    "end": 706382,
    "text": "というのが高いレベルだ。"
  },
  {
    "start": 706516,
    "end": 709646,
    "text": "ひとつひとつ説明していこう。"
  },
  {
    "start": 709748,
    "end": 710014,
    "text": "そうだろう？"
  },
  {
    "start": 710052,
    "end": 717586,
    "text": "私たちは、あるデータを入手し、仮説を立て、仮説を定式化し、新しいデータでそれを検証するという統計的なパイプラインを持っていた。"
  },
  {
    "start": 717688,
    "end": 719762,
    "text": "ひとつひとつ見ていこう。"
  },
  {
    "start": 719816,
    "end": 723474,
    "text": "まず、この初期データをどこから入手するのかについて話そう。"
  },
  {
    "start": 723672,
    "end": 725778,
    "text": "このようなハッシュの衝突のアイデアは何なのか？"
  },
  {
    "start": 725944,
    "end": 730914,
    "text": "この話をするには、クリップの背景をもう少し説明する必要がある。"
  },
  {
    "start": 731042,
    "end": 736680,
    "text": "前にも言ったように、クリップは画像IかテキストTを埋め込む。"
  },
  {
    "start": 737130,
    "end": 738966,
    "text": "実際に何をするために設計されているのか？"
  },
  {
    "start": 738988,
    "end": 740458,
    "text": "あるいは、何に訓練されていたのか？"
  },
  {
    "start": 740544,
    "end": 744342,
    "text": "これは実際に、画像とそのキャプションのペアの束で訓練されている。"
  },
  {
    "start": 744486,
    "end": 758942,
    "text": "一般的には、画像を説明するテキストがある場合、その画像内のテキストは類似した埋め込みを持つべきであり、理想的には他のものよりも互いに類似した埋め込みを持つべきであるという考え方です。"
  },
  {
    "start": 758996,
    "end": 776094,
    "text": "そして、この埋め込みのもとで、ある画像とそのキャプションのコサイン類似度が、その画像と他のキャプションの類似度よりも高くなるようにする。"
  },
  {
    "start": 776142,
    "end": 782120,
    "text": "このドット積の行列を形成する場合、対角線は本当に大きく、それ以外は本当に小さくしたいものだ。"
  },
  {
    "start": 782890,
    "end": 789450,
    "text": "つまり、tがIの記述であれば、両者は似たような埋め込みを持つはずだということだ。"
  },
  {
    "start": 791310,
    "end": 794700,
    "text": "さて、これを使ってどうやって問題を見つけようか？"
  },
  {
    "start": 795390,
    "end": 807870,
    "text": "さて、tとt primeが異なる画像を描写しているにもかかわらず、同じエンベッディングを持つ、あるいは非常によく似たエンベッディングを持つのであれば、少なくともどちらかが何らかの意味で間違っているはずですよね？"
  },
  {
    "start": 807940,
    "end": 817054,
    "text": "それがどんなイメージに対応するものであれ、両方が正しいということはありえないだろう？"
  },
  {
    "start": 817172,
    "end": 817454,
    "text": "そうだ。"
  },
  {
    "start": 817492,
    "end": 820642,
    "text": "アリョーシャは画像とテキストの間に二項対立を仮定しているだけだ。"
  },
  {
    "start": 820696,
    "end": 824820,
    "text": "百聞は一見にしかず。"
  },
  {
    "start": 827050,
    "end": 827462,
    "text": "そうだろう？"
  },
  {
    "start": 827516,
    "end": 832818,
    "text": "私が考えている例は、空のカップと満杯のカップのようなものだ。"
  },
  {
    "start": 832914,
    "end": 839702,
    "text": "もしそれらの文が同じ埋め込みを持っていたとしても、それはすべての文のごく一部である。"
  },
  {
    "start": 839836,
    "end": 843210,
    "text": "多くの類義語、視覚的類義語がある。"
  },
  {
    "start": 844110,
    "end": 844714,
    "text": "その通りだ。"
  },
  {
    "start": 844752,
    "end": 847046,
    "text": "視覚的類義語を気にしなければならない。"
  },
  {
    "start": 847238,
    "end": 855854,
    "text": "そのためには、物事が実際に視覚的に異なっていることを暗示するような、何らかの意味的な違いを測定する方法が必要だ。"
  },
  {
    "start": 855972,
    "end": 858190,
    "text": "次のスライドで説明しよう。"
  },
  {
    "start": 858690,
    "end": 860320,
    "text": "その他の質問もある。"
  },
  {
    "start": 863010,
    "end": 868594,
    "text": "ここでもひとつ言えるのは、テキストを見るだけでいいということだ。"
  },
  {
    "start": 868632,
    "end": 871794,
    "text": "つまり、クリップエンコーダーを使わなければならないが、私はテキストだけをエンコードしている。"
  },
  {
    "start": 871912,
    "end": 873602,
    "text": "なぜテキストだけを見たいのか？"
  },
  {
    "start": 873656,
    "end": 880450,
    "text": "まあ、基本的に言語モデルは本当によく機能するからね。"
  },
  {
    "start": 882490,
    "end": 887862,
    "text": "アリョーシャによれば、イメージモデルはすぐにうまく機能するようになる。"
  },
  {
    "start": 887996,
    "end": 890650,
    "text": "今は言語にこだわりたい。"
  },
  {
    "start": 891710,
    "end": 892858,
    "text": "どうする？"
  },
  {
    "start": 892944,
    "end": 900250,
    "text": "テキスト入力の初期コーパスを収集するつもりだが、これらの入力は視覚的な意味を持つ入力にしたい。"
  },
  {
    "start": 900590,
    "end": 909722,
    "text": "例えば、キャプションのデータセットや、視覚的な説明がある他の種類のデータセットから、それらを取得することが多い。"
  },
  {
    "start": 909866,
    "end": 922030,
    "text": "そして、それらをすべてclipの下に埋め込み、さらにdistill Robertaという別のモデルの下に埋め込みます。"
  },
  {
    "start": 922110,
    "end": 928302,
    "text": "これはテキストのみのモデルであり、またクリップよりも埋め込み空間の次元が高い。"
  },
  {
    "start": 928366,
    "end": 936530,
    "text": "この2つの理由から、クリップはテキストだけに集中でき、より多くのパラメーターがあるため、クリップよりもテキストを理解していると言える。"
  },
  {
    "start": 936690,
    "end": 954382,
    "text": "基本的な考え方は、クリップの埋め込みをすべて持っていて、クリップ空間では非常に近いが、実際にはロベルタ類似度が低い2つの入力があるとしますよね？"
  },
  {
    "start": 954436,
    "end": 956830,
    "text": "ということは、彼らはちょっと違うということだ。"
  },
  {
    "start": 956900,
    "end": 964370,
    "text": "ロベルタは意味的に違う文章だと思っているのに、クリップは同じだと言う。"
  },
  {
    "start": 964710,
    "end": 966466,
    "text": "おそらく、そこがおかしいのだろう。"
  },
  {
    "start": 966568,
    "end": 974530,
    "text": "さて、私もあなたの意見に同意するが、視覚的に重要な点で、これらが本当に意味的に異なっているかどうかをチェックしたい。"
  },
  {
    "start": 975430,
    "end": 979558,
    "text": "経験的には、約90％の確率でそうなる。"
  },
  {
    "start": 979724,
    "end": 986018,
    "text": "これはある種、十分なことであり、私たちが人体実験で検証したことでもある。"
  },
  {
    "start": 986194,
    "end": 987834,
    "text": "ジェイコブ、どうやって見つけたんだい？"
  },
  {
    "start": 987872,
    "end": 991740,
    "text": "クリップベクターは2048次元とかじゃないのか？"
  },
  {
    "start": 993230,
    "end": 999638,
    "text": "そう、だからコサインの類似性を取るだけなんだ。"
  },
  {
    "start": 999734,
    "end": 1003202,
    "text": "これはn乗アルゴリズムである。"
  },
  {
    "start": 1003366,
    "end": 1003742,
    "text": "そうだね。"
  },
  {
    "start": 1003796,
    "end": 1004014,
    "text": "オーケー。"
  },
  {
    "start": 1004052,
    "end": 1013266,
    "text": "この2048次元の空間で衝突を探すとしたら、天文学的な時間がかかるだろう。"
  },
  {
    "start": 1013368,
    "end": 1022930,
    "text": "テキスト入力が衝突の可能性を高めるから、実際にはもっと短い時間で済むということですね。"
  },
  {
    "start": 1023350,
    "end": 1025026,
    "text": "ああ、いくつかあるね。"
  },
  {
    "start": 1025048,
    "end": 1030486,
    "text": "第一に、余弦類似度が十分に大きければ、正確な衝突は必要ない。"
  },
  {
    "start": 1030588,
    "end": 1037880,
    "text": "経験的に、ゼロ点88より大きければ、問題を起こす可能性がかなり高いことがわかった。"
  },
  {
    "start": 1039370,
    "end": 1041322,
    "text": "全く同じである必要はない。"
  },
  {
    "start": 1041376,
    "end": 1045738,
    "text": "そうすることで、何となく救われるんだ。"
  },
  {
    "start": 1045904,
    "end": 1049706,
    "text": "つまり、ゼロ点88の内積を持つ2つの単位ベクトルだ。"
  },
  {
    "start": 1049808,
    "end": 1056000,
    "text": "2048次元の空間では、その時点で衝突と呼んでもいいかもしれない。"
  },
  {
    "start": 1056450,
    "end": 1060750,
    "text": "彼はあなたのためにn乗の時間を想定している。"
  },
  {
    "start": 1062210,
    "end": 1062766,
    "text": "わかったよ。"
  },
  {
    "start": 1062788,
    "end": 1066180,
    "text": "スコットは指数関数的に大きなデータセットが必要だと主張しているが、これは違う。"
  },
  {
    "start": 1067990,
    "end": 1071250,
    "text": "ああ、わかったよ。"
  },
  {
    "start": 1071400,
    "end": 1078710,
    "text": "基本的に、衝突が起こる理由は、空間とのハトの穴の原理とは何の関係もない。"
  },
  {
    "start": 1078780,
    "end": 1079014,
    "text": "そうだね。"
  },
  {
    "start": 1079052,
    "end": 1089910,
    "text": "ただ、このマッピングが特別なものであるために、衝突が起きてしまうのだ。"
  },
  {
    "start": 1089990,
    "end": 1090842,
    "text": "そう、その通りだ。"
  },
  {
    "start": 1090896,
    "end": 1091162,
    "text": "オーケー。"
  },
  {
    "start": 1091216,
    "end": 1099210,
    "text": "気になるのであれば、同じようなATSWインデックスをすべてのエンベッディングに使えば、もっと速くできるのでは？"
  },
  {
    "start": 1100110,
    "end": 1102986,
    "text": "そうだね、nの2乗よりずっと速くできる。"
  },
  {
    "start": 1103018,
    "end": 1106634,
    "text": "ただ、これがボトルネックではないことが判明した。"
  },
  {
    "start": 1106762,
    "end": 1110602,
    "text": "ボトルネックは、すべてのモデルのフォワードパスを実行することだ。"
  },
  {
    "start": 1110746,
    "end": 1119810,
    "text": "1000次元のベクトルを何組もループさせるようなことは、LLMを実行するのに比べればかなり安上がりだ。"
  },
  {
    "start": 1121990,
    "end": 1122306,
    "text": "そうだね。"
  },
  {
    "start": 1122328,
    "end": 1124014,
    "text": "私たちは2つの異なるコーパスを試した。"
  },
  {
    "start": 1124062,
    "end": 1127960,
    "text": "ひとつはココで、もうひとつはそうだ。"
  },
  {
    "start": 1128410,
    "end": 1129558,
    "text": "もう一つは？"
  },
  {
    "start": 1129644,
    "end": 1130578,
    "text": "SNLI。"
  },
  {
    "start": 1130754,
    "end": 1136310,
    "text": "どちらも視覚的な意味を持つテキストデータセットだ。"
  },
  {
    "start": 1137450,
    "end": 1143690,
    "text": "そして、基本的には、テキストには十分な構造があり、実際に衝突することがあるということだ。"
  },
  {
    "start": 1145070,
    "end": 1146758,
    "text": "nの2乗なんてどうでもいい。"
  },
  {
    "start": 1146854,
    "end": 1148140,
    "text": "わかったよ。"
  },
  {
    "start": 1149150,
    "end": 1150874,
    "text": "オーケー、これが最初のステップだね？"
  },
  {
    "start": 1150912,
    "end": 1157520,
    "text": "これで、2つのペアのどちらかが間違っていることがわかるペアがたくさん出てくる。"
  },
  {
    "start": 1158210,
    "end": 1161134,
    "text": "だから、今度はそれを使って何かをしたい。"
  },
  {
    "start": 1161332,
    "end": 1167554,
    "text": "次の段階は、このペアを基に仮説を立てることだ。"
  },
  {
    "start": 1167592,
    "end": 1172466,
    "text": "ここでは、画像ではなくテキストであることを利用するんだ。"
  },
  {
    "start": 1172488,
    "end": 1176882,
    "text": "個々のフィラーはテキスト入力なので、GPT 4に送ることができる。"
  },
  {
    "start": 1177016,
    "end": 1179830,
    "text": "これが魔法のプロンプトだ。"
  },
  {
    "start": 1180170,
    "end": 1183126,
    "text": "覚えておいてほしい一連のデータを提供します、と書いてある。"
  },
  {
    "start": 1183308,
    "end": 1186194,
    "text": "その後、あなたのパフォーマンスをテストするためにいくつか質問をします。"
  },
  {
    "start": 1186322,
    "end": 1188322,
    "text": "ここに、暗記すべきプロンプトのペアがいくつかある。"
  },
  {
    "start": 1188386,
    "end": 1190822,
    "text": "それなら、すべてを捧げるんだ。"
  },
  {
    "start": 1190876,
    "end": 1198140,
    "text": "そして、「埋め込みモデルとして失敗を見つけたいんだ。"
  },
  {
    "start": 1198670,
    "end": 1202374,
    "text": "これらは、非常によく似た符号化された文のペアである。"
  },
  {
    "start": 1202502,
    "end": 1205194,
    "text": "具体的な例を挙げて、一般的な失敗のタイプはありますか？"
  },
  {
    "start": 1205242,
    "end": 1212346,
    "text": "埋め込みが行われていることに気づき、さらに文脈を理解する。"
  },
  {
    "start": 1212378,
    "end": 1216290,
    "text": "つまり、基本的には、ここにデータがあるから見てくれ、パターンを教えてくれ、と言っているわけだ。"
  },
  {
    "start": 1217590,
    "end": 1222962,
    "text": "そうすれば、かなりいい仕事ができる。"
  },
  {
    "start": 1223016,
    "end": 1227950,
    "text": "否定、時間差、量化詞がある。"
  },
  {
    "start": 1228110,
    "end": 1232914,
    "text": "ただ否定するだけでなく、いろいろと詳しく説明してくれるのがいいところだ。"
  },
  {
    "start": 1232962,
    "end": 1239930,
    "text": "曰く、埋め込みモデルは文中の否定文脈を正しく捉えない可能性があり、否定のある文とない文の類似性をもたらす。"
  },
  {
    "start": 1241710,
    "end": 1247930,
    "text": "画像や映像の生成において、動作の有無は重要であるため、これは誤った視覚表現につながる可能性がある。"
  },
  {
    "start": 1248670,
    "end": 1251920,
    "text": "それがずっと続いている。"
  },
  {
    "start": 1252450,
    "end": 1260000,
    "text": "この場合、このリストには全部で14の明確な失敗があることになる。"
  },
  {
    "start": 1261970,
    "end": 1269790,
    "text": "もうひとつは、経験的に、GPT4は常に一貫したリスト形式を使っているので、自動的に個々の仮説を解析することができる。"
  },
  {
    "start": 1269870,
    "end": 1270066,
    "text": "そうだね。"
  },
  {
    "start": 1270088,
    "end": 1280854,
    "text": "リサ、これらの入力なしでGPTに質問するのと同じように、画像埋め込みモデルでよくある失敗例とかは試してみた？"
  },
  {
    "start": 1280972,
    "end": 1281302,
    "text": "そうだ。"
  },
  {
    "start": 1281356,
    "end": 1286918,
    "text": "これは後で結果を示すベースラインだ。"
  },
  {
    "start": 1287004,
    "end": 1289420,
    "text": "そして、そう、あまりうまくいかない。"
  },
  {
    "start": 1292270,
    "end": 1298106,
    "text": "なるほど、これで仮説が立てられたわけだ。"
  },
  {
    "start": 1298128,
    "end": 1308990,
    "text": "通常、統計学では仮説は数学的な関数のようなものだが、ここでは単なる文章だ。"
  },
  {
    "start": 1309570,
    "end": 1311866,
    "text": "さて、この仮説を定式化する必要がある。"
  },
  {
    "start": 1311978,
    "end": 1312254,
    "text": "そうだね。"
  },
  {
    "start": 1312292,
    "end": 1317546,
    "text": "h1～hkはすべて自然言語による記述である。"
  },
  {
    "start": 1317658,
    "end": 1322740,
    "text": "これらの仮説のいずれかが本当に正しいかどうか、どうやって検証すればいいのだろうか？"
  },
  {
    "start": 1323110,
    "end": 1327174,
    "text": "これはかなり興味深いコンセプトの問題だと思う。"
  },
  {
    "start": 1327292,
    "end": 1329670,
    "text": "観客にポーズをとってみようかな。"
  },
  {
    "start": 1330570,
    "end": 1334120,
    "text": "どなたか、これをどのように正式なものにできるか、アイデアをお持ちの方はいらっしゃいませんか？"
  },
  {
    "start": 1336410,
    "end": 1346506,
    "text": "クリス、DPTの4人に、この仮説に合致するかどうかをペアで尋ねてみて、画像が間違っているかどうかを確認すればいい。"
  },
  {
    "start": 1346688,
    "end": 1350550,
    "text": "DPT4の画像解析は、アクセスさえできれば可能だ。"
  },
  {
    "start": 1350720,
    "end": 1351150,
    "text": "いいね。"
  },
  {
    "start": 1351220,
    "end": 1351840,
    "text": "そうだ。"
  },
  {
    "start": 1356370,
    "end": 1364106,
    "text": "研究仮説について考えてみると、仮説かどうかを分類するのに使える次元がいくつかある。"
  },
  {
    "start": 1364138,
    "end": 1366930,
    "text": "だから、例えば、テスト可能であるべきなんだ。"
  },
  {
    "start": 1367000,
    "end": 1368478,
    "text": "明確なスコープが必要だ。"
  },
  {
    "start": 1368574,
    "end": 1372370,
    "text": "専門家の意見を参考にすれば、いくつかの次元で考えることができると思う。"
  },
  {
    "start": 1373670,
    "end": 1374034,
    "text": "そうだね。"
  },
  {
    "start": 1374072,
    "end": 1379430,
    "text": "そのような特性があるかどうかは、専門家やGPT 4に聞けばわかるだろう。"
  },
  {
    "start": 1380650,
    "end": 1388410,
    "text": "結局のところ、クリスが言ったことと似たようなことをすることになるんだが、分類ではなく生成に注目することになる。"
  },
  {
    "start": 1388750,
    "end": 1401722,
    "text": "その記述を知的エージェント（この場合、人間は高価なので人間ではない）に渡した場合、Hは良い仮説であると言うつもりだ。"
  },
  {
    "start": 1401786,
    "end": 1409630,
    "text": "GPTの4つは、そうでない場合よりも、新たな故障を発生させるのに効果的だ。"
  },
  {
    "start": 1411170,
    "end": 1416274,
    "text": "これを数値化する方法だ。"
  },
  {
    "start": 1416312,
    "end": 1426050,
    "text": "Hが良い仮説であると言えるのは、それが新しい失敗を発生させるために使われ、失敗を発生させるための単なる基本的な方法よりも優れている場合である。"
  },
  {
    "start": 1426390,
    "end": 1429922,
    "text": "リサ、君の質問に答えよう。"
  },
  {
    "start": 1429986,
    "end": 1445180,
    "text": "GPT4にこれらの仮説を渡すか、あるいはGPT4に何のデータもなしに、ビジョンモデルが悪いかもしれない方法をブレインストーミングしてもらい、それらを互いにテストして、どちらがよりうまくいくかを見ることもできる。"
  },
  {
    "start": 1446350,
    "end": 1446714,
    "text": "オーケー。"
  },
  {
    "start": 1446752,
    "end": 1446906,
    "text": "そうだね。"
  },
  {
    "start": 1446928,
    "end": 1449590,
    "text": "hをコンテクストとするLLMをプロンプトして、これをテストしてみよう。"
  },
  {
    "start": 1449670,
    "end": 1451850,
    "text": "では、魔法のプロンプトとは何なのか？"
  },
  {
    "start": 1452430,
    "end": 1459754,
    "text": "魔法のプロンプトとは、次のような故障モードを持つエンベッディングモデルがエンコードしそうなプロンプトのペアを41個書き出せ、というものである。"
  },
  {
    "start": 1459802,
    "end": 1463914,
    "text": "同様に、キャプションとして使用された場合、異なる画像に対応することになる。"
  },
  {
    "start": 1464042,
    "end": 1465274,
    "text": "以下の書式を使用する。"
  },
  {
    "start": 1465322,
    "end": 1476230,
    "text": "プログラム上で抽出できるような書式を与え、さらに動機づけとなるようなことを言う。"
  },
  {
    "start": 1477370,
    "end": 1493850,
    "text": "y41の前に説明したように、基本的には出力コンテキスト・ウィンドウの長さが適合可能な長さである。"
  },
  {
    "start": 1493920,
    "end": 1498220,
    "text": "もし、41人以上欲しいなら、2、3回聞けばいい。"
  },
  {
    "start": 1498910,
    "end": 1502000,
    "text": "これが私たちがやったことだ。"
  },
  {
    "start": 1502690,
    "end": 1503006,
    "text": "そうだね。"
  },
  {
    "start": 1503028,
    "end": 1509966,
    "text": "ニコラス、クリエイティブで慎重であること、こういったことが実際にどれだけ役に立っているのか？"
  },
  {
    "start": 1510068,
    "end": 1514994,
    "text": "それとも、上から振りかける黒魔術のようなもの？"
  },
  {
    "start": 1515192,
    "end": 1518050,
    "text": "慎重なアブレーションはしなかった。"
  },
  {
    "start": 1522950,
    "end": 1525746,
    "text": "うまくいくまで、いろいろなものを追加した。"
  },
  {
    "start": 1525848,
    "end": 1529938,
    "text": "何が本当に必要なのかを確かめるために、いろいろなものを取り除こうとはしなかったと思う。"
  },
  {
    "start": 1530034,
    "end": 1538630,
    "text": "という感じだが、これを必要最低限にまで絞り込めば、もっとシンプルなものができるのではないだろうか。"
  },
  {
    "start": 1539050,
    "end": 1541178,
    "text": "そんなことはしていない。"
  },
  {
    "start": 1541264,
    "end": 1542540,
    "text": "でも、いい質問だね。"
  },
  {
    "start": 1544030,
    "end": 1548234,
    "text": "では、成功率を測定することで定量化したいのですね？"
  },
  {
    "start": 1548272,
    "end": 1554410,
    "text": "私たちは、新しい失敗のはずのプロンプトのペアをすべて手に入れる。"
  },
  {
    "start": 1554570,
    "end": 1556750,
    "text": "これには2つの方法がある。"
  },
  {
    "start": 1556820,
    "end": 1557006,
    "text": "そうだね。"
  },
  {
    "start": 1557028,
    "end": 1563360,
    "text": "先ほどと同じ意味で、ハッシュの衝突によって生成されたものの割合を見ることができる。"
  },
  {
    "start": 1564450,
    "end": 1566740,
    "text": "それは簡単なことだ。"
  },
  {
    "start": 1567590,
    "end": 1576358,
    "text": "ある時点で、私たちはシステムが実際に何かをしていること、そしてその何かが、llmsが彼らの仕事をうまくこなしているという信頼に関わるものではないことを確認したい。"
  },
  {
    "start": 1576524,
    "end": 1593206,
    "text": "また、クリップに依存している下流のシステムを見て、たまたまコサイン類似度が高いだけでなく、実際に失敗していることを確認するために、失敗があるかどうかを人間に尋ねる評価も行っている。"
  },
  {
    "start": 1593398,
    "end": 1595260,
    "text": "この2つが私たちの仕事です。"
  },
  {
    "start": 1595870,
    "end": 1598570,
    "text": "では、結果を確認していこう。"
  },
  {
    "start": 1598990,
    "end": 1610186,
    "text": "そこでまず、ハッシュの衝突を調べるが、新たに生成された入力でテストする。"
  },
  {
    "start": 1610378,
    "end": 1617570,
    "text": "これらの類似性がある閾値以上であれば、入力は成功したと言う。"
  },
  {
    "start": 1618470,
    "end": 1620642,
    "text": "このテーブルは何を言っているのか？"
  },
  {
    "start": 1620776,
    "end": 1626710,
    "text": "これらの行は、システムによって発生したさまざまな故障の一種である。"
  },
  {
    "start": 1626860,
    "end": 1630562,
    "text": "実際には6つの異なるシステムを検討した。"
  },
  {
    "start": 1630626,
    "end": 1636546,
    "text": "さまざまなモデルにデータを見てもらい、仮説を提案してもらうことができる。"
  },
  {
    "start": 1636658,
    "end": 1641594,
    "text": "GPT4クロット、GPT3.5という異なる種類のプロポーザーのモデルだ。"
  },
  {
    "start": 1641712,
    "end": 1648730,
    "text": "その場合、実際に失敗を発見するために使用したデータセットを変えることもできる。"
  },
  {
    "start": 1648800,
    "end": 1653630,
    "text": "この2つは、ココとSNLIの前に人々が質問したデータセットである。"
  },
  {
    "start": 1653970,
    "end": 1656160,
    "text": "いくつか興味深いことがあると思う。"
  },
  {
    "start": 1656930,
    "end": 1675514,
    "text": "ひとつは、チェックマークは、モデルがそのリストで失敗をすべて生成したことを意味し、そして色は、その失敗の説明を条件として新しい入力を生成する成功率のようなものだ。"
  },
  {
    "start": 1675662,
    "end": 1677926,
    "text": "いくつか興味深いことがある。"
  },
  {
    "start": 1678028,
    "end": 1681350,
    "text": "まず第一に、データセットは実際に重要なようだね？"
  },
  {
    "start": 1681420,
    "end": 1685990,
    "text": "GPD4とクロードの両方についてだ。"
  },
  {
    "start": 1687950,
    "end": 1688890,
    "text": "アクション"
  },
  {
    "start": 1690430,
    "end": 1693434,
    "text": "まあいいや、もっと直感的なものを選ぼう。"
  },
  {
    "start": 1693552,
    "end": 1705966,
    "text": "GPT4とクロード、そしてGPD3.5では、SNLIは粒度を失敗として引き出すが、ココは決してそうしない。"
  },
  {
    "start": 1706068,
    "end": 1708810,
    "text": "時には、それほどシステマティックではないこともある。"
  },
  {
    "start": 1708890,
    "end": 1715022,
    "text": "一般的に、これらのデータセットは実際に異なる失敗を引き出しているように思える。"
  },
  {
    "start": 1715086,
    "end": 1719730,
    "text": "少なくともデータにはある程度の依存性がある。"
  },
  {
    "start": 1721270,
    "end": 1728198,
    "text": "もうひとつは、GPT3.5よりもGPD4や一般的なクロットの方が、より多くの故障を見つけることができるということだ。"
  },
  {
    "start": 1728284,
    "end": 1733618,
    "text": "これらの優れたモデルは、実際にはより明確な仮説を生み出す。"
  },
  {
    "start": 1733794,
    "end": 1747622,
    "text": "最後に興味深いのは、同じ故障であっても、大きなモデルの方が成功率が高いということだ。"
  },
  {
    "start": 1747686,
    "end": 1749814,
    "text": "これはいくつかの場所で見ることができる。"
  },
  {
    "start": 1749862,
    "end": 1770340,
    "text": ""
  },
  {
    "start": 1772150,
    "end": 1777314,
    "text": "これらのケースではすべて、GPT 4が新たな障害を引き起こしているものとして修正している。"
  },
  {
    "start": 1777362,
    "end": 1779320,
    "text": "それによる影響はない。"
  },
  {
    "start": 1780330,
    "end": 1785320,
    "text": "このような違いは、モデルによって出力された実際のテキスト記述から来るものだ。"
  },
  {
    "start": 1786570,
    "end": 1795782,
    "text": "では、このデータベースについて何か質問はありますか？"
  },
  {
    "start": 1795926,
    "end": 1802110,
    "text": "GPT4がGPT3.5より優れている場合について、もう少し詳しい見識はありますか？"
  },
  {
    "start": 1802260,
    "end": 1814960,
    "text": "GPP3.5も説明は理解していたが、どういうわけか例が少なかった。"
  },
  {
    "start": 1816310,
    "end": 1817410,
    "text": "ちょっとした好奇心だ。"
  },
  {
    "start": 1817910,
    "end": 1823966,
    "text": "モデルによってどのような質的な違いがあるのか？"
  },
  {
    "start": 1824158,
    "end": 1829542,
    "text": "ああ、だからこのことはあまり考えたことがないんだ。"
  },
  {
    "start": 1829676,
    "end": 1840410,
    "text": "GPD4はコンテクストウィンドウが大きいので、より多くの例を見ることができる。"
  },
  {
    "start": 1841150,
    "end": 1853946,
    "text": "おそらくもっと重要なことは、データセットから仮説を提案するという作業は、実際にはかなり困難な作業だということだ。"
  },
  {
    "start": 1854058,
    "end": 1860174,
    "text": "だから、フロンティアモデルでさえ、それほど得意ではないんだ。"
  },
  {
    "start": 1860212,
    "end": 1871230,
    "text": "GBD4からGBD3.5まで落ちると、おそらく、超一貫性を保つには能力を失いすぎる。"
  },
  {
    "start": 1871390,
    "end": 1873054,
    "text": "それが私の仮説だ。"
  },
  {
    "start": 1873102,
    "end": 1873762,
    "text": "どうだろう。"
  },
  {
    "start": 1873816,
    "end": 1874542,
    "text": "ああ、リッチー。"
  },
  {
    "start": 1874606,
    "end": 1874786,
    "text": "そうだね。"
  },
  {
    "start": 1874808,
    "end": 1885240,
    "text": "つまり、GPT3.5ではデータに対する条件付けがあまりうまくいかないのに対し、GP4ではデータに対する条件付けが実際に行われ、その上でデータに記述されることがわかった。"
  },
  {
    "start": 1888010,
    "end": 1888760,
    "text": "そうだ。"
  },
  {
    "start": 1892090,
    "end": 1898470,
    "text": "モデルが生成したサンプルが実際にこれらのカテゴリーに入るか、あるいは他のカテゴリーと重なるかもしれない。"
  },
  {
    "start": 1898630,
    "end": 1906510,
    "text": "すべての事例がそのカテゴリーに入るかどうかを系統的に評価したわけではないと思う。"
  },
  {
    "start": 1911650,
    "end": 1916260,
    "text": "次のスライドでは、少なくとも暗黙の了解のもとでそれを表現しているアーティストを何人か紹介しよう。"
  },
  {
    "start": 1916630,
    "end": 1919060,
    "text": "誰かが質問しているように見えた。"
  },
  {
    "start": 1920630,
    "end": 1928440,
    "text": "さて、それでは人間的な評価を見てみよう。"
  },
  {
    "start": 1930410,
    "end": 1939180,
    "text": "だから、単にハッシュの衝突が起こるということにこだわらず、それが実際に人間が間違っていると言う画像につながることを示したかった。"
  },
  {
    "start": 1940110,
    "end": 1940666,
    "text": "オーケー。"
  },
  {
    "start": 1940768,
    "end": 1941206,
    "text": "畜生。"
  },
  {
    "start": 1941238,
    "end": 1950406,
    "text": "テキストは少し小さいが、これは私たちが提供したヒューマンアノテーターのインターフェースのようなものだ。"
  },
  {
    "start": 1950528,
    "end": 1958010,
    "text": "橋のある街のスカイラインだ。"
  },
  {
    "start": 1958090,
    "end": 1959866,
    "text": "プロンプト2、橋のない街のスカイライン。"
  },
  {
    "start": 1959898,
    "end": 1960046,
    "text": "そうだろう？"
  },
  {
    "start": 1960068,
    "end": 1962030,
    "text": "これはこの種の衝突ペアである。"
  },
  {
    "start": 1962390,
    "end": 1972046,
    "text": "これは、この2つのプロンプトのどちらかからランダムに選ばれたイメージだ。"
  },
  {
    "start": 1972158,
    "end": 1990006,
    "text": "したがって注釈者は、これはプロンプト1に対応する、これはプロンプト2に対応する、これはそのどちらにも対応しない、あるいはこれらのプロンプトは視覚的に同じ状況を描写している、と言わなければならない。"
  },
  {
    "start": 1990038,
    "end": 1995980,
    "text": "これは、アリョーシャが以前に質問した、意味的に異なるかどうかということにつながるんだ。"
  },
  {
    "start": 1997150,
    "end": 2014770,
    "text": "注釈者が間違っていると言った場合、あるいはプロンプト2だと言ったが実際にはプロンプト1で生成されたものだった場合、あるいはその逆の場合などだ。"
  },
  {
    "start": 2015190,
    "end": 2029186,
    "text": "そこで、2つのプロンプトのクリップの類似度を変えて、どのような割合でミスが起こるかを調べることができる。"
  },
  {
    "start": 2029218,
    "end": 2029366,
    "text": "そうだね。"
  },
  {
    "start": 2029388,
    "end": 2033170,
    "text": "これは、高い類似性が実際に失敗につながることをテストしているようなものだ。"
  },
  {
    "start": 2033250,
    "end": 2038540,
    "text": "ゼロポイント88に変曲点があるのがわかるだろう。"
  },
  {
    "start": 2039630,
    "end": 2053370,
    "text": "これは1つには、実際にかなり高い確率で故障が発生することを確認すること、2つには、先ほどお話しした魔法のような閾値が、実際にはある意味妥当な閾値であることを確認することだ。"
  },
  {
    "start": 2053530,
    "end": 2060350,
    "text": "そして最後に、これらの記述が実際に何かをしているのかどうかという疑問に迫る。"
  },
  {
    "start": 2060500,
    "end": 2069390,
    "text": "これは、失敗が記述と一致しているかどうかをテストしているのではなく、高い失敗率を得るために記述が実際に必要であることをテストしているのだろう。"
  },
  {
    "start": 2069470,
    "end": 2087320,
    "text": "もし、基本的なシステムで、画像に起こりうる失敗をブレインストーミングしてもらい、それを条件にしていくだけなら、失敗率は20％程度にしかならない。"
  },
  {
    "start": 2087790,
    "end": 2094810,
    "text": "これらはモデルによる評価ではなく、人間による評価である。"
  },
  {
    "start": 2095870,
    "end": 2097900,
    "text": "これについて何か質問はありますか？"
  },
  {
    "start": 2102270,
    "end": 2105178,
    "text": "失敗率が高いほうがいいという話だ。"
  },
  {
    "start": 2105344,
    "end": 2105962,
    "text": "そうだ。"
  },
  {
    "start": 2106096,
    "end": 2111440,
    "text": "高い故障率を求めるのは、故障を見つけ、それを修正するためだ。"
  },
  {
    "start": 2112770,
    "end": 2113134,
    "text": "オーケー。"
  },
  {
    "start": 2113172,
    "end": 2123982,
    "text": "そして最後に、言語モデルから得られる大きなボーナスとして、言語モデルは自動的に舵を取ることができる。"
  },
  {
    "start": 2124126,
    "end": 2124482,
    "text": "そうだろう？"
  },
  {
    "start": 2124536,
    "end": 2133430,
    "text": "私はこのように失敗を生成する方法を持っているが、あとはモデルに、ある新しいドメインに関連する失敗を与えてくれるように頼むだけだ。"
  },
  {
    "start": 2134330,
    "end": 2140290,
    "text": "だから今回は、自動運転に関連する故障を発生させるように頼んだんだ。"
  },
  {
    "start": 2140450,
    "end": 2154170,
    "text": "データセットはまだココアとSNLIなので、自動運転に特化したデータを与えたわけではないが、この斬新な領域でこのような失敗を発生させることができ、なおかつ成功率も高い。"
  },
  {
    "start": 2154240,
    "end": 2156730,
    "text": "これらはほんの一例だ。"
  },
  {
    "start": 2156890,
    "end": 2160880,
    "text": "安定した拡散、車は車線の右側にあるが、左側にある。"
  },
  {
    "start": 2161250,
    "end": 2164020,
    "text": "これは青信号を与えるものではない。"
  },
  {
    "start": 2164470,
    "end": 2175006,
    "text": "譲り合いの標識は、少なくとも譲り合いの標識の形をしていないもの、おそらく一時停止の標識、そして赤信号で停車する車を与える。"
  },
  {
    "start": 2175048,
    "end": 2176920,
    "text": "これはテキストからビデオに変換するモデルだ。"
  },
  {
    "start": 2177610,
    "end": 2179960,
    "text": "信号が青。"
  },
  {
    "start": 2180570,
    "end": 2181318,
    "text": "そうだ。"
  },
  {
    "start": 2181484,
    "end": 2185350,
    "text": "ココとスニーのどのデータをパスしていますか？"
  },
  {
    "start": 2185930,
    "end": 2187670,
    "text": "画像でパスするのか？"
  },
  {
    "start": 2188330,
    "end": 2188790,
    "text": "いや。"
  },
  {
    "start": 2188860,
    "end": 2199798,
    "text": "つまり、これは最初の段階で、ハッシュの衝突をチェックするために、たくさんのテキスト入力を与えて埋め込んでいるのだ。"
  },
  {
    "start": 2199894,
    "end": 2207186,
    "text": "これらのハッシュの衝突は、テキストやココアの文章を埋め込んだことによるもので、画像は含まれていない。"
  },
  {
    "start": 2207238,
    "end": 2210910,
    "text": "実際には、システムの出力以外に画像はどこにもない。"
  },
  {
    "start": 2214450,
    "end": 2219966,
    "text": "私はこの仮説の部分に興味があるのですが、それは必要なことなのでしょうか？"
  },
  {
    "start": 2220078,
    "end": 2231110,
    "text": "2、3年前の論文で、このような衝突を見つけようとしたんだけど、文章を与えて衝突を検索し、言語モデルだけを切り出すことはできないかな。"
  },
  {
    "start": 2231180,
    "end": 2233400,
    "text": "その過程で何が追加されるのか？"
  },
  {
    "start": 2235050,
    "end": 2236674,
    "text": "まあ、イニシャルを見つけることだね。"
  },
  {
    "start": 2236802,
    "end": 2238140,
    "text": "ああ、なるほど。"
  },
  {
    "start": 2239710,
    "end": 2254486,
    "text": "ひとつは、ステアラビリティー（操縦性）だと思うんですが、それをやろうとすると、場合によっては難しいかもしれません。"
  },
  {
    "start": 2254608,
    "end": 2257726,
    "text": "そのために自動運転車に関するたくさんの文章は必要ない。"
  },
  {
    "start": 2257748,
    "end": 2262000,
    "text": "もし手動で衝突を探すのであれば、そうしなければならない。"
  },
  {
    "start": 2262310,
    "end": 2263220,
    "text": "なるほど。"
  },
  {
    "start": 2265590,
    "end": 2266290,
    "text": "そうだね。"
  },
  {
    "start": 2266440,
    "end": 2267140,
    "text": "クールだ。"
  },
  {
    "start": 2268710,
    "end": 2272402,
    "text": "さて、要約すると、4つの段階があった。"
  },
  {
    "start": 2272536,
    "end": 2277320,
    "text": "まず、このテキストデータセットからハッシュの衝突をスクレイピングして初期データを取得する。"
  },
  {
    "start": 2277690,
    "end": 2281506,
    "text": "その結果、クリップとディスティルという2つのモデルが生まれた。"
  },
  {
    "start": 2281538,
    "end": 2282322,
    "text": "ロベルタ"
  },
  {
    "start": 2282466,
    "end": 2285720,
    "text": "そして、GPTの4人を促して仮説を立てる。"
  },
  {
    "start": 2286410,
    "end": 2291586,
    "text": "そして、新たな失敗を生み出す成功率を見ることで、これらの仮説を一種の形式化する。"
  },
  {
    "start": 2291698,
    "end": 2295980,
    "text": "失敗の生成にはGPT 4を使用し、評価にはクリップを使用する。"
  },
  {
    "start": 2296590,
    "end": 2301962,
    "text": "そうすれば、アクティブ・ステアリングもできる。"
  },
  {
    "start": 2302016,
    "end": 2316978,
    "text": "ここで強調したいことのひとつは、私たちはしばしば、このひとつの言語モデルを持つことだけを考え、すべてを解決する超賢明なプロンプトを思いつき、思考の連鎖やこの種のことを行うかもしれないということだ。"
  },
  {
    "start": 2317064,
    "end": 2331400,
    "text": "このようなモデルのエコシステムを創造的な方法で利用しようと思えば、もっと遠くまで行くことができると思う。"
  },
  {
    "start": 2331770,
    "end": 2341926,
    "text": "統計学は、パイプラインのさまざまな段階でさまざまなスキルが必要とされるため、特に適したユースケースだと思います。"
  },
  {
    "start": 2342038,
    "end": 2343974,
    "text": "統計学もまた、素晴らしい特性を持っている。"
  },
  {
    "start": 2344022,
    "end": 2344234,
    "text": "そうだね。"
  },
  {
    "start": 2344272,
    "end": 2350578,
    "text": "多くの部分が自動的に測定可能で検証可能であるようにね。"
  },
  {
    "start": 2350694,
    "end": 2379240,
    "text": "昨日アダムが話していたように、コンピュータ・プログラミングでも同じような強みが得られます。私たちはこのようなことをあまりしてきませんでしたが、自己訓練ができるかもしれません。"
  },
  {
    "start": 2380170,
    "end": 2382646,
    "text": "2つ目を説明しよう。"
  },
  {
    "start": 2382748,
    "end": 2388034,
    "text": "このようなコンセプチュアルなアイデアをたくさん作り上げたので、もう少し急ぎましょう。"
  },
  {
    "start": 2388162,
    "end": 2400566,
    "text": "ここでは、言語モデルを理解するための様々な方法で役立つメタ・タスクについてお話しします。"
  },
  {
    "start": 2400758,
    "end": 2404582,
    "text": "このメタ・タスクは、自然言語述語による分類である。"
  },
  {
    "start": 2404646,
    "end": 2408510,
    "text": "ここでは、2つのテキストデータセット、d1とd2が与えられる。"
  },
  {
    "start": 2408660,
    "end": 2411038,
    "text": "両者の違いを見つけたい。"
  },
  {
    "start": 2411204,
    "end": 2415360,
    "text": "この違いは、やはり自然言語文字列hでなければならない。"
  },
  {
    "start": 2416450,
    "end": 2419982,
    "text": "私たちは、これを二進法の分類と同型に考えることができる。"
  },
  {
    "start": 2420126,
    "end": 2425890,
    "text": "私たちはd1とd2を分類しようとしているようなものだが、関数が自然言語で記述されている。"
  },
  {
    "start": 2426550,
    "end": 2429774,
    "text": "このタスクがどのようなものか、例を挙げてみよう。"
  },
  {
    "start": 2429912,
    "end": 2433734,
    "text": "たぶん、これが私の2つのデータセット、d1とd2だ。"
  },
  {
    "start": 2433852,
    "end": 2438746,
    "text": "その違いを自然言語で表現したい。"
  },
  {
    "start": 2438928,
    "end": 2445770,
    "text": "どなたか、これを英語で理解できる方はいらっしゃいますか？"
  },
  {
    "start": 2446110,
    "end": 2446842,
    "text": "オーケー、そうだね。"
  },
  {
    "start": 2446896,
    "end": 2449858,
    "text": "左がフランス語、右が英語。"
  },
  {
    "start": 2449974,
    "end": 2455120,
    "text": "私たちのHは、D2に比べてD1の方がより多くのフランス語の文章を含んでいることになる。"
  },
  {
    "start": 2455970,
    "end": 2457920,
    "text": "では、もっと難しい例を挙げよう。"
  },
  {
    "start": 2459810,
    "end": 2474180,
    "text": "文字サイズの関係で難しい部分もあるかもしれないが、これをしばらく見ていても、何が違うのか分かりにくいと私は主張する。"
  },
  {
    "start": 2474790,
    "end": 2482902,
    "text": "実際、d1の文章には少なくとも2人の女性が登場するが、d2の文章には登場しないという違いがある。"
  },
  {
    "start": 2483036,
    "end": 2494970,
    "text": "というのも、彼女は合計8発の魚雷を積んでいたとか、実際には女性キャラクターではない船を指していたとか、そういうことがあるからだ。"
  },
  {
    "start": 2495710,
    "end": 2499690,
    "text": "マッキータウン教授が女性であることも知っておかなければならない。"
  },
  {
    "start": 2502270,
    "end": 2508000,
    "text": "このような問題を解決するためには、世界の知識や些細なことではないことがたくさんある。"
  },
  {
    "start": 2510130,
    "end": 2514114,
    "text": "それがメタ的な課題なのだろう。"
  },
  {
    "start": 2514152,
    "end": 2519410,
    "text": "まず、llmsをより理解するのに役立つ3つのユースケースを紹介しよう。"
  },
  {
    "start": 2520230,
    "end": 2525006,
    "text": "配給シフトを理解したい。"
  },
  {
    "start": 2525118,
    "end": 2530582,
    "text": "特に、あるモデルの成績が悪い場合、何が違うのかを診断したい。"
  },
  {
    "start": 2530636,
    "end": 2540970,
    "text": "そうすれば、テストの分布がトレーニングの分布よりも正式な文章を多く含んでいることがわかるかもしれないし、失敗の診断や微調整すべき点を教えてくれるかもしれない。"
  },
  {
    "start": 2541120,
    "end": 2544698,
    "text": "ポジティブ・クラスはネガティブ・クラスより多くのURLを含む。"
  },
  {
    "start": 2544864,
    "end": 2557360,
    "text": "もしこれがスパム分類のデータセットだとしたら、このモデルはURLの有無だけを見ているのではないかというスプリアス・キューの可能性を教えてくれるだろう。"
  },
  {
    "start": 2558370,
    "end": 2560014,
    "text": "エラー分析はできるだろう？"
  },
  {
    "start": 2560052,
    "end": 2567330,
    "text": "2つのモデルを用意し、片方がミスをした場合ともう片方がミスをした場合のインプットの違いを見ることができる。"
  },
  {
    "start": 2568070,
    "end": 2572126,
    "text": "そうであれば、私たちはただ \"LLMS \"を理解しようとするだけではない。"
  },
  {
    "start": 2572318,
    "end": 2577780,
    "text": "例えば、社会科学のようなことを始めることもできるだろう？"
  },
  {
    "start": 2578150,
    "end": 2587746,
    "text": "ある年のツイートと別の年のツイートを見て、今年の世論は昨年よりもパンデミックについて楽観的だとわかった。"
  },
  {
    "start": 2587788,
    "end": 2588138,
    "text": "そうだね。"
  },
  {
    "start": 2588224,
    "end": 2592778,
    "text": "私たちは、少なくともこのような記述的な仮説を立てることができる。"
  },
  {
    "start": 2592864,
    "end": 2604320,
    "text": "もちろん、それを検証するためには、因果関係の推論やその他のことを慎重に行う必要があるが、少なくともこれで仮説を立てることができる。"
  },
  {
    "start": 2605810,
    "end": 2607646,
    "text": "じゃあ、どうやってやるんだ？"
  },
  {
    "start": 2607748,
    "end": 2609550,
    "text": "まあ、ISDだ。"
  },
  {
    "start": 2610850,
    "end": 2618658,
    "text": "あなたが持っている例に戻ると、仮説の空間が巨大に感じられるでしょう？"
  },
  {
    "start": 2618744,
    "end": 2625586,
    "text": "ここにはリコール精度の問題があるようだ。"
  },
  {
    "start": 2625768,
    "end": 2631570,
    "text": "例えば、私の仮説はとても簡単な例で、その2つの文の間には何の関係もない。"
  },
  {
    "start": 2631730,
    "end": 2635938,
    "text": "つまり、第2センテンスよりもフランス語が多いということだ。"
  },
  {
    "start": 2636034,
    "end": 2637190,
    "text": "スペースは広そうだ。"
  },
  {
    "start": 2637260,
    "end": 2640470,
    "text": "最終的に欲しいものをどうやって見つけるのか？"
  },
  {
    "start": 2640620,
    "end": 2644678,
    "text": "ほとんどの場合、真実はわからない。"
  },
  {
    "start": 2644774,
    "end": 2653390,
    "text": "ゴールドラベルのような従来の設定でテストできるように、グラウンドトゥルースを作成したケースもいくつかある。"
  },
  {
    "start": 2654050,
    "end": 2659850,
    "text": "ここでは、他の分類器を評価するのと同じような観点で評価することにする。"
  },
  {
    "start": 2660010,
    "end": 2660430,
    "text": "そうだね。"
  },
  {
    "start": 2660500,
    "end": 2673554,
    "text": "そして、d 1とd 2を区別する際のエラーレートが低ければ、ある仮説は他の仮説よりも優れていると言うことにする。"
  },
  {
    "start": 2673672,
    "end": 2678802,
    "text": "だから、決まった真実の根拠を持つのではなく、どのシステムが優れているか劣っているかという話をすればいいのだ。"
  },
  {
    "start": 2678866,
    "end": 2689702,
    "text": "また、総合的なベンチマークを得るために、人間と比較することもできるかもしれない。"
  },
  {
    "start": 2689766,
    "end": 2690378,
    "text": "そうだね。"
  },
  {
    "start": 2690544,
    "end": 2690874,
    "text": "オーケー。"
  },
  {
    "start": 2690912,
    "end": 2691500,
    "text": "そうだね。"
  },
  {
    "start": 2694510,
    "end": 2698198,
    "text": "何か目標があるかどうかも評価した方がいいかもしれない。"
  },
  {
    "start": 2698294,
    "end": 2703226,
    "text": "目標との関連性や新規性を評価するのもよいだろう。"
  },
  {
    "start": 2703418,
    "end": 2705530,
    "text": "これらは主観的になり始める。"
  },
  {
    "start": 2705610,
    "end": 2712990,
    "text": "新規性と関連性についての人間の評価を得るために、我々はこのようなことをいくつか行ってきた。"
  },
  {
    "start": 2715190,
    "end": 2719758,
    "text": "目新しさを定義するのが難しすぎるからだ。"
  },
  {
    "start": 2719934,
    "end": 2726900,
    "text": "いずれにせよ、これは可能だが、ちょっと厄介な問題だとは思う。"
  },
  {
    "start": 2727830,
    "end": 2737074,
    "text": "ディーの質問を補足すると、あなたは仮説の複雑さを制約しているのですか？"
  },
  {
    "start": 2737122,
    "end": 2739130,
    "text": "短い仮説をお探しですか？"
  },
  {
    "start": 2741070,
    "end": 2755120,
    "text": "LLMによって生成され、LLMは長いものしか出力しない。"
  },
  {
    "start": 2755810,
    "end": 2756318,
    "text": "オーケー。"
  },
  {
    "start": 2756404,
    "end": 2761710,
    "text": "ええ、使い勝手を考えれば、これは短く、解釈しやすいものにしたいでしょう。"
  },
  {
    "start": 2765670,
    "end": 2766034,
    "text": "クールだ。"
  },
  {
    "start": 2766072,
    "end": 2767602,
    "text": "じゃあ、どうやってやるんだ？"
  },
  {
    "start": 2767736,
    "end": 2773650,
    "text": "基本的には、以前と同じようにllmsを使うだけだ。"
  },
  {
    "start": 2773800,
    "end": 2774210,
    "text": "そうだね。"
  },
  {
    "start": 2774280,
    "end": 2796602,
    "text": "リッチーが考えた魔法のようなプロンプトの全貌をお見せすることはできませんが、ただ概略的に言うと、最初の分布からたくさんの例を与えてaというラベルを貼り、2番目の分布からたくさんの例を与えてbというラベルを貼り、bのグループと比較してaのグループのそれぞれの文章と言い、それを完成させるように求めるのです。"
  },
  {
    "start": 2796656,
    "end": 2803482,
    "text": "これは、gpT-3を使用していた時点で行われたもので、この補完フォーマットである必要があった。"
  },
  {
    "start": 2803626,
    "end": 2812878,
    "text": "インストラクションのチューニングモデルができたら、もっと素敵なプロンプトができるかもしれないが、これは基本的なアイデアのようなものだ。"
  },
  {
    "start": 2812964,
    "end": 2818882,
    "text": "次に、データの異なるサブサンプルで何度もサンプリングする。"
  },
  {
    "start": 2819016,
    "end": 2823454,
    "text": "コンテキストウィンドウには30ほどの例しか入れられないことを念頭に置いてください。"
  },
  {
    "start": 2823502,
    "end": 2828206,
    "text": "何千もの例を持つデータセットは、ごくわずかなものだ。"
  },
  {
    "start": 2828238,
    "end": 2832230,
    "text": "私たちは、さまざまな仮説を生み出すためにサブサンプリングを続けている。"
  },
  {
    "start": 2833130,
    "end": 2839720,
    "text": "そうすれば、よりポジティブで、より長いチャプターを含むようになる。"
  },
  {
    "start": 2840730,
    "end": 2846102,
    "text": "そのうちのいくつかは実際にそうだし、いくつかはつまらないものに終わる。"
  },
  {
    "start": 2846166,
    "end": 2851630,
    "text": "しかし、このような仮説の候補のセットを得ることができる。"
  },
  {
    "start": 2852290,
    "end": 2858734,
    "text": "これは、統計パイプラインの最初の2ステップをどのように行うかを教えてくれているんだ。"
  },
  {
    "start": 2858772,
    "end": 2869870,
    "text": "この初期データを見て、あるnに対してd1とd2の例でgpt nを促し、それらがどう違うかを問い、これが仮説を形成する。"
  },
  {
    "start": 2870030,
    "end": 2874740,
    "text": "今、私たちはhをどうにかして定量的に定式化し、新しいデータでテストする必要がある。"
  },
  {
    "start": 2875450,
    "end": 2882390,
    "text": "もう一度、質問を投げかけてみるが、どうすれば、このHを定量的に公式化することができるだろうか？"
  },
  {
    "start": 2886890,
    "end": 2888774,
    "text": "定量的にはどうなんだろう？"
  },
  {
    "start": 2888822,
    "end": 2889980,
    "text": "Hの実力は？"
  },
  {
    "start": 2894030,
    "end": 2894826,
    "text": "すみません、何とおっしゃいましたか？"
  },
  {
    "start": 2894848,
    "end": 2896646,
    "text": "一級品。"
  },
  {
    "start": 2896838,
    "end": 2897738,
    "text": "よし、いいぞ。"
  },
  {
    "start": 2897824,
    "end": 2898122,
    "text": "そうだね。"
  },
  {
    "start": 2898176,
    "end": 2906362,
    "text": "良い仮説とは、d1とd2を区別するのに役立つものだと言える。"
  },
  {
    "start": 2906506,
    "end": 2912794,
    "text": "d1から1サンプル、d2から1サンプル。"
  },
  {
    "start": 2912932,
    "end": 2915860,
    "text": "ランダムに混ぜて、どれがどれだかわからないようにする。"
  },
  {
    "start": 2917030,
    "end": 2925060,
    "text": "人間かLLMのどちらかに仮説を伝え、どちらがどちらか言ってもらう。"
  },
  {
    "start": 2925750,
    "end": 2930178,
    "text": "例として、hがよりフォーマルな文章を書くとする。"
  },
  {
    "start": 2930274,
    "end": 2933542,
    "text": "これは基本的に2つの引数を持つ述語だと解釈できるよね？"
  },
  {
    "start": 2933596,
    "end": 2946954,
    "text": "x1とx2の文がある場合、x1, x2のhは、x1がx2よりも正式な文章であることの真理値である二項述語である。"
  },
  {
    "start": 2947152,
    "end": 2950870,
    "text": "だから、これは真か偽でなければならない。"
  },
  {
    "start": 2950950,
    "end": 2957034,
    "text": "だから、人間か言語モデルに真か偽かを尋ねるだけだ。"
  },
  {
    "start": 2957162,
    "end": 2962350,
    "text": "ということは、Hはd1とd2に関する正しい仮説ということになる。"
  },
  {
    "start": 2962500,
    "end": 2971266,
    "text": "d 1からx 1、d 2からx 2のサンプルの期待値であれば、これは0.5よりずっと小さいですよね？"
  },
  {
    "start": 2971288,
    "end": 2972946,
    "text": "0.5はチャンスだろう。"
  },
  {
    "start": 2973128,
    "end": 2977266,
    "text": "もしこれが、分類の誤差を測る指標のようなものだとしたら。"
  },
  {
    "start": 2977298,
    "end": 2983960,
    "text": "もしそれが0.5よりずっと小さければ、d1とd2について何か自明でないことがわかったことになる。"
  },
  {
    "start": 2985050,
    "end": 2987160,
    "text": "じゃあ、どうすればいいんだ？"
  },
  {
    "start": 2987630,
    "end": 2993690,
    "text": "人間に尋ねることもできるし、LLMに問い合わせることもできるだろう。"
  },
  {
    "start": 2995150,
    "end": 2996602,
    "text": "これはどう見える？"
  },
  {
    "start": 2996656,
    "end": 3012106,
    "text": "もしHがd1からのサンプルでd2からのサンプルより陽性であった場合、このケースではチャーリー・スネル（当時バークレー大の学部生で、現在はバークレー大の博士課程に在籍）を挙げることができる。"
  },
  {
    "start": 3012298,
    "end": 3019762,
    "text": "この論文はインパクトのある課題を提案している、あるいはこの論文のアプローチはあまりにつまらない。"
  },
  {
    "start": 3019896,
    "end": 3021890,
    "text": "そして、彼は何かを言う。"
  },
  {
    "start": 3022040,
    "end": 3028680,
    "text": "だったら、チャーリーの時間はかなり貴重だから、代わりにクラウドワーカーを雇えばいい。"
  },
  {
    "start": 3030410,
    "end": 3043814,
    "text": "問題は、この分布から例えば100個のサンプルを平均して、ある程度の精度を得ようとしても、テキスト記述1つにつき10ドルのコストがかかるということだ。"
  },
  {
    "start": 3043862,
    "end": 3046570,
    "text": "これは非常に高価だ。"
  },
  {
    "start": 3048350,
    "end": 3049850,
    "text": "こんなことはしたくないだろう。"
  },
  {
    "start": 3050000,
    "end": 3055934,
    "text": "このパイプラインのコストを1000分の1にすることができる。"
  },
  {
    "start": 3056132,
    "end": 3061870,
    "text": "GPD 3.5ターボを使えば、わずか7セントでこの100サンプルができる。"
  },
  {
    "start": 3062390,
    "end": 3071122,
    "text": "そうすれば、この仮説がどれだけ成功したかを、自動的かつ定量的に測ることができる。"
  },
  {
    "start": 3071256,
    "end": 3075886,
    "text": "人間より再現性が高いのもいいところだ。"
  },
  {
    "start": 3075918,
    "end": 3082546,
    "text": "例えば、モデルが実際に固定されていないため、同じ人間ラベルのエラーが再び返ってくることを心配する必要はない。"
  },
  {
    "start": 3082578,
    "end": 3083798,
    "text": "OpenAIはアップデートを続けている。"
  },
  {
    "start": 3083804,
    "end": 3085106,
    "text": "それはちょっと迷惑だね。"
  },
  {
    "start": 3085298,
    "end": 3090310,
    "text": "もし彼らがモデルの安定したバージョンを提供していれば、これは再現可能だろう。"
  },
  {
    "start": 3094490,
    "end": 3099142,
    "text": "今、我々はこのパイプライン全体を手に入れたようなものだ。"
  },
  {
    "start": 3099286,
    "end": 3111178,
    "text": "全体的なシステムとしては、私たちがこの論文を書いた当初は、候補となる仮説を生成するGPT-3を微調整していた。"
  },
  {
    "start": 3111274,
    "end": 3116878,
    "text": "そして、それぞれの仮説を検証する検証者がいる。"
  },
  {
    "start": 3117054,
    "end": 3119650,
    "text": "当時は微調整され、統一されたQAだった。"
  },
  {
    "start": 3119990,
    "end": 3131042,
    "text": "そして、この分類タスクにおける実際の成功率に基づいて、仮説のランク付けをし直すのだ。"
  },
  {
    "start": 3131186,
    "end": 3133874,
    "text": "なぜこの分解が役に立つのか？"
  },
  {
    "start": 3134002,
    "end": 3143926,
    "text": "エンジニアリングの観点からは、これは非常に重要なことだと思いますが、提案者は30例しか見ていません。"
  },
  {
    "start": 3144038,
    "end": 3158430,
    "text": "その意味では、gpt-3や4つのシステムのように非常に賢いとはいえ、かなり限定されたものである。"
  },
  {
    "start": 3161010,
    "end": 3162560,
    "text": "私は時間的にどうですか？"
  },
  {
    "start": 3162930,
    "end": 3165138,
    "text": "あと5分ほどしかない。"
  },
  {
    "start": 3165224,
    "end": 3166340,
    "text": "オーケー、クールだ。"
  },
  {
    "start": 3167110,
    "end": 3170610,
    "text": "多分、これをいろんなことに使えると言うだけだろう。"
  },
  {
    "start": 3170680,
    "end": 3180950,
    "text": "つまり、分布のシフトを説明するために、MNLIとSNLIという2つのデータセットがあり、SNLIはMNLIのODバージョンのように使われることが多い。"
  },
  {
    "start": 3182410,
    "end": 3188318,
    "text": "以下は4つのサンプルで、2つはSNLI、2つはMNLIのものだ。"
  },
  {
    "start": 3188514,
    "end": 3204554,
    "text": "しかし、SNLIがある絵を描写しているとすれば、緑色の絵がSNLIであることは一目瞭然だ。"
  },
  {
    "start": 3204602,
    "end": 3210714,
    "text": "荷物を持った老人が広告の前でポーズをとる。"
  },
  {
    "start": 3210842,
    "end": 3214580,
    "text": "この分布の変化が何なのか、すぐにわかるだろう。"
  },
  {
    "start": 3216230,
    "end": 3223678,
    "text": "ツイッター、PPTB、QQPの2つの言い換えデータセットがある。"
  },
  {
    "start": 3223854,
    "end": 3227700,
    "text": "ツイッターはニュースについて語り、クオラは質問を含んでいる。"
  },
  {
    "start": 3228310,
    "end": 3229906,
    "text": "これらは一種の健全性チェックだ。"
  },
  {
    "start": 3229938,
    "end": 3236710,
    "text": "こういったデータセットに詳しい人なら誰でも知っているようなことだが、もっと面白いことができる。"
  },
  {
    "start": 3236780,
    "end": 3241226,
    "text": "これは私たちの知る限り、当時としては斬新なものだったと思う。"
  },
  {
    "start": 3241248,
    "end": 3244122,
    "text": "私たちは、データセットからスプリアス・キューを検出することを発見した。"
  },
  {
    "start": 3244256,
    "end": 3249702,
    "text": "主観性分析用のデータセットであるSubjを渡した。"
  },
  {
    "start": 3249846,
    "end": 3253034,
    "text": "そのクラスは映画のプロットを要約するものだった。"
  },
  {
    "start": 3253082,
    "end": 3262510,
    "text": "主観クラスは映画批評からの引用であり、主観性分析に関するデータセットとしては間違っているように思える。"
  },
  {
    "start": 3263170,
    "end": 3269662,
    "text": "実際に論文を読み返してみると、主観的な文章が並んでいる。"
  },
  {
    "start": 3269726,
    "end": 3274114,
    "text": "私たちは、ほぼ客観的なデータを得るために、Rotten Tomatoesから5000の映画レビューの断片を収集した。"
  },
  {
    "start": 3274152,
    "end": 3277986,
    "text": "IMDbから入手可能なプロットサマリーから5000文を抜粋した。"
  },
  {
    "start": 3278098,
    "end": 3285910,
    "text": "実際、このデータセットで好成績を収めた場合、主観に関することよりも、基本的にこのことを学んでいたことになる。"
  },
  {
    "start": 3287370,
    "end": 3289350,
    "text": "私たちが見つけた近道は他にもある。"
  },
  {
    "start": 3289420,
    "end": 3297578,
    "text": "新しいものもあれば、古いものもある。しかし、これらの様々なキューを見つけることができ、エラー分析などに使うことができる。"
  },
  {
    "start": 3297664,
    "end": 3301950,
    "text": "要約すると、このパイプラインには4つのステップがある。"
  },
  {
    "start": 3303010,
    "end": 3305434,
    "text": "初期データは2つのテキスト分布だけだった。"
  },
  {
    "start": 3305482,
    "end": 3307514,
    "text": "GPDを促して仮説を立てる。"
  },
  {
    "start": 3307562,
    "end": 3314850,
    "text": "3つ目は、成功率を測定することで仮説を正式なものとし、その後、新たなサンプルでテストを行う。"
  },
  {
    "start": 3316230,
    "end": 3331350,
    "text": "最後に、分類をはるかに超えて、自然言語の述語を統計モデルの特徴として使用するような、現在進行中の研究があります。"
  },
  {
    "start": 3331770,
    "end": 3342058,
    "text": "この例では、オーストラリア放送協会のニュースヘッドラインの時間的ドリフトを説明しようとしている。"
  },
  {
    "start": 3342224,
    "end": 3358334,
    "text": "このデータセットでは、説明される分散のパーセンテージはまだかなり低いものの、上位5つの主成分がこのデータセットのばらつきを説明していると考えることができる。"
  },
  {
    "start": 3358372,
    "end": 3364740,
    "text": "これは最初の結果と同じだと考えた方がいいと思う。"
  },
  {
    "start": 3365350,
    "end": 3367380,
    "text": "これで終わりにして、質問を受け付けよう。"
  },
  {
    "start": 3381450,
    "end": 3390682,
    "text": "プロポーザルでは、時間をかけて10個の例を選び続け、どこで失敗したかを見て、それをまた見せるというような、迅速な最適化を行うことができます。"
  },
  {
    "start": 3390736,
    "end": 3397980,
    "text": "しばらくすると、良い仮説ができ、それが正しいことを確認する代わりに、どうにか保証できるようになる。"
  },
  {
    "start": 3400830,
    "end": 3404878,
    "text": "基本的には、プロポーザーをどんどん良くしていくための微調整という考えなのだろうか？"
  },
  {
    "start": 3405044,
    "end": 3406570,
    "text": "そう、プロンプトを微調整するんだ。"
  },
  {
    "start": 3406650,
    "end": 3408010,
    "text": "迅速な最適化がお好きなのですか？"
  },
  {
    "start": 3408090,
    "end": 3409390,
    "text": "ああ、迅速な最適化だ。"
  },
  {
    "start": 3411250,
    "end": 3428630,
    "text": "私の一般的な感覚では、プロポーザーを使うだけなら、つまり、プロンプトの完全な最適化は試みていないが、プロポーザーを使うだけのアブレーションはやっていて、一般的にそのほうがずっと成績が悪いと思う。"
  },
  {
    "start": 3429850,
    "end": 3432454,
    "text": "いくつか問題があると思う。"
  },
  {
    "start": 3432572,
    "end": 3436310,
    "text": "ひとつは、提案者は検証者よりもはるかに少ないデータしか得られないということだ。"
  },
  {
    "start": 3438010,
    "end": 3449926,
    "text": "プロンプト最適化を行うと、データ数が少なくなってしまうので、チェックが必要だと思いました。"
  },
  {
    "start": 3450038,
    "end": 3459520,
    "text": "だから、プロンプト最適化をして、すべてを見渡せるようにすれば、この仮説が正しいことを保証できる。"
  },
  {
    "start": 3461730,
    "end": 3462142,
    "text": "そうだね。"
  },
  {
    "start": 3462196,
    "end": 3464042,
    "text": "それは面白いアイデアだ。"
  },
  {
    "start": 3464116,
    "end": 3469460,
    "text": "つまり、プロンプトの最適化を行い、これを実現するプロンプトを見つけようということだ。"
  },
  {
    "start": 3470150,
    "end": 3471922,
    "text": "これについては話し合ったような気がする。"
  },
  {
    "start": 3472056,
    "end": 3475454,
    "text": "あなたの主張は、意味的に意味のある仮説が得られないということだ。"
  },
  {
    "start": 3475582,
    "end": 3478914,
    "text": "仮に、プロンプトにグラデーションをかけたとしよう。"
  },
  {
    "start": 3478962,
    "end": 3482898,
    "text": "そうすると、読めないプロンプトが簡単に出てくる。"
  },
  {
    "start": 3482914,
    "end": 3488626,
    "text": "敵対的な例でよく見られるのは、比較的病的なものだからだ。"
  },
  {
    "start": 3488818,
    "end": 3489126,
    "text": "そうだね。"
  },
  {
    "start": 3489148,
    "end": 3495660,
    "text": "問題は、少なくとも今は、これをやっても自然な言葉を引き出すのが難しいということだと思う。"
  },
  {
    "start": 3496430,
    "end": 3498998,
    "text": "今はGPT4にグラデーションを出すように頼んでいる。"
  },
  {
    "start": 3499094,
    "end": 3509870,
    "text": "素晴らしい話をありがとう。"
  },
  {
    "start": 3510020,
    "end": 3513360,
    "text": "素朴な疑問だが、もしかしたらそうではないかもしれない。"
  },
  {
    "start": 3513890,
    "end": 3517540,
    "text": "あなたは2つのデータを分ける仮説を求めている。"
  },
  {
    "start": 3518150,
    "end": 3524290,
    "text": "あなたがテストしているとき、彼らは、オーケー、2つの例を選んで、一方が他方よりポジティブだと言うようなものだった。"
  },
  {
    "start": 3524440,
    "end": 3541930,
    "text": "片方ではイエス、もう片方ではノーと答えられるような仮説を探すために、2つの比較例を見る必要がないように調整できないだろうか。"
  },
  {
    "start": 3544910,
    "end": 3549020,
    "text": "一例として、どのようなプロンプトがあるのかを理解するために。"
  },
  {
    "start": 3551470,
    "end": 3556922,
    "text": "あなたが示した2つ目の例は、この文章が2人の女性キャラクターについて語っているということです。"
  },
  {
    "start": 3556986,
    "end": 3562346,
    "text": "これは、2つのデータセットから2つの異なるサンプルを見なくても、イエスかノーかで答えられる発言だ。"
  },
  {
    "start": 3562378,
    "end": 3562960,
    "text": "そうだね。"
  },
  {
    "start": 3563330,
    "end": 3572990,
    "text": "異なるデータセットのデータ間の比較ではなく、1つのデータポイントで答えられる仮説を探すように調整できないでしょうか？"
  },
  {
    "start": 3573070,
    "end": 3573410,
    "text": "そうだね。"
  },
  {
    "start": 3573480,
    "end": 3577870,
    "text": "私たちは実際に、両方のバージョンのシステムで仕事をしたと思う。"
  },
  {
    "start": 3577960,
    "end": 3582338,
    "text": "ひとつは単項述語、もうひとつは二項述語だ。"
  },
  {
    "start": 3582514,
    "end": 3587762,
    "text": "実際には、興味深いことの多くは二項述語のようなものだと思う。"
  },
  {
    "start": 3587826,
    "end": 3594630,
    "text": "しかし、比較級を考慮しなければ、何かを失うことになる。"
  },
  {
    "start": 3597770,
    "end": 3599670,
    "text": "では、スピーカーの方にお礼を言いましょう。"
  },
  {
    "start": 3600450,
    "end": 3610490,
    "text": "そうだ。"
  }
]