[
  {
    "start": 170,
    "end": 6378,
    "text": "さて、このビデオでは、いわゆる親ドキュメント・レトリバーという考え方について見ていきたいと思います。"
  },
  {
    "start": 6554,
    "end": 16302,
    "text": "llmsとembeddingsの違いを理解するのはいいことだ。"
  },
  {
    "start": 16436,
    "end": 25570,
    "text": "llmsではエンベッディングが多用されているが、ここでは検索用のエンベッディングを見ている。"
  },
  {
    "start": 25650,
    "end": 37506,
    "text": "LLMの文脈学習は、適切なモデルさえあれば、何が適切で何が適切でないかを判断することができる。"
  },
  {
    "start": 37618,
    "end": 51434,
    "text": "ボロ雑巾のようなまともな品質のモデルを手に入れた場合、そこにいろいろなものを入れれば、混乱させない限り、情報の断片を抽出する能力はかなり優れていることがわかるだろう。"
  },
  {
    "start": 51632,
    "end": 55882,
    "text": "このように、異なる文書がたくさんあるような場合だ。"
  },
  {
    "start": 56026,
    "end": 59120,
    "text": "これはグーグルの決算説明会からの引用である。"
  },
  {
    "start": 59490,
    "end": 67778,
    "text": "ここでは、スンダピシャイがさまざまな製品、業績、その他について最新情報を伝えている。"
  },
  {
    "start": 67944,
    "end": 75154,
    "text": "さて、この特別な通話で、彼らはさまざまな細かいことを話していると想像できるだろう。"
  },
  {
    "start": 75352,
    "end": 80438,
    "text": "全部は入れたくないんだ。"
  },
  {
    "start": 80524,
    "end": 86706,
    "text": "私たちは、言語モデルを可能な限り助け、関連性のない部分を切り捨てたいのです。"
  },
  {
    "start": 86738,
    "end": 88598,
    "text": "それがラグというものだ。"
  },
  {
    "start": 88764,
    "end": 94438,
    "text": "従来の雑巾のようなものであれば、このようにオリジナルの書類を保管することができる。"
  },
  {
    "start": 94614,
    "end": 96342,
    "text": "そして、それらの文書を分割した。"
  },
  {
    "start": 96406,
    "end": 103466,
    "text": "仮にこれがその一つだとすると、これを複数の部分に分割し、それぞれの部分について埋め込みを取る。"
  },
  {
    "start": 103578,
    "end": 112990,
    "text": "さて、この埋め込みは、この特定の部分にあるすべての意味的な詳細を表現していることを覚えておいてほしい。"
  },
  {
    "start": 113140,
    "end": 121794,
    "text": "この分割されたドキュメントがかなり大きくなるのであれば、埋め込みは非常にワサワサしたものになりますよね？"
  },
  {
    "start": 121832,
    "end": 126402,
    "text": "文書のその部分はかなり小さいのに対して、それは非特異的であり得る。"
  },
  {
    "start": 126536,
    "end": 128920,
    "text": "埋め込みは、実際にはかなり特殊なことができる。"
  },
  {
    "start": 129370,
    "end": 149926,
    "text": "例えば、収益について話している文書があり、異なる製品や異なるものを比較している場合、複数の数字が使用され、複数の説明が使用される場合、その特定のものに対する埋め込みは、収益に関するより一般的なものになると想像できます。"
  },
  {
    "start": 150038,
    "end": 168900,
    "text": "広告がいくら儲けたとか、吟遊詩人がいくら儲けたとか、パーム2がいくら儲けたとか、そういう具合に分割すれば、埋め込みはより特定の質問に特化したものになる。"
  },
  {
    "start": 169350,
    "end": 191910,
    "text": "とはいえ、ラージ・ランゲージ・モデルが実際に複数のものを扱うことができるという事実を利用したいことも多い。"
  },
  {
    "start": 192060,
    "end": 197562,
    "text": "そのためには、必要なチャンクの特定のエンベッディングが必要だ。"
  },
  {
    "start": 197696,
    "end": 202878,
    "text": "ということは、ここに全体的なコンテキストの大きな塊を渡したいのだ。"
  },
  {
    "start": 202964,
    "end": 205774,
    "text": "そこで登場するのが親書検索機である。"
  },
  {
    "start": 205892,
    "end": 217998,
    "text": "ここでは、元のドキュメントを適当な大きさのチャンクに分割し、それを親チャンクと呼ぶことにする。"
  },
  {
    "start": 218094,
    "end": 227182,
    "text": "その場合、そのまま埋め込むのではなく、親チャンクを子ドキュメントに分割します。"
  },
  {
    "start": 227246,
    "end": 227426,
    "text": "そうだろう？"
  },
  {
    "start": 227448,
    "end": 230658,
    "text": "親ドキュメントがあり、子ドキュメントがある。"
  },
  {
    "start": 230754,
    "end": 235602,
    "text": "親文書が実際には3つの子文書を持っていることに気づくかもしれない。"
  },
  {
    "start": 235666,
    "end": 240794,
    "text": "覚えておいてほしいのは、これらのコンテンツはすべて、ここにある親ドキュメントから来たものだということだ。"
  },
  {
    "start": 240992,
    "end": 245286,
    "text": "ここで、それぞれの子文書に対して埋め込みを作る。"
  },
  {
    "start": 245478,
    "end": 251694,
    "text": "以前は1つの埋め込みしかなかったものを、3つの異なる埋め込みで表現しているのがわかるだろう。"
  },
  {
    "start": 251812,
    "end": 258606,
    "text": "この考え方は、エンベッディングでより具体的な表現を得るということだ。"
  },
  {
    "start": 258788,
    "end": 266106,
    "text": "最後に、これを実際に使いたいときに、子ドックに並ぶ質問埋め込みを用意します。"
  },
  {
    "start": 266218,
    "end": 276386,
    "text": "そして、単にこの子ドキュメントを返すのではなく、実際に親ドキュメントを返すことで、親ドキュメントに多くのコンテキストを持たせることができる。"
  },
  {
    "start": 276488,
    "end": 286258,
    "text": "その場合、大きな言語モデルは大きな文脈を得るが、埋め込み表現はずっと小さな文脈になる。"
  },
  {
    "start": 286354,
    "end": 288022,
    "text": "もっと具体的になる。"
  },
  {
    "start": 288156,
    "end": 293626,
    "text": "そうすれば、大規模な言語モデルは、そこにある余分なコンテキストを活用することができる。"
  },
  {
    "start": 293728,
    "end": 296234,
    "text": "それが親書検索人の仕事だ。"
  },
  {
    "start": 296352,
    "end": 300330,
    "text": "コードに飛び込んで、langchainでこれをどうやるか見てみよう。"
  },
  {
    "start": 302350,
    "end": 304974,
    "text": "よし、何が起こっているのか見てみよう。"
  },
  {
    "start": 305092,
    "end": 312378,
    "text": "このノートブックで私がやっていることのひとつは、OpenAIのエンベッディングではなく、BGEのエンベッディングを使っていることだ。"
  },
  {
    "start": 312554,
    "end": 323346,
    "text": "ラングチェーンのブログ記事の一部をzipファイルにして持ってきたんだ。"
  },
  {
    "start": 323448,
    "end": 326126,
    "text": "それを検索に使うんだ。"
  },
  {
    "start": 326238,
    "end": 331238,
    "text": "では、親ドキュメント・リトリーバーには2つの使い方がある。"
  },
  {
    "start": 331324,
    "end": 337878,
    "text": "そのうちのひとつは前のセクションで説明したが、この2つの方法をコードで見てみよう。"
  },
  {
    "start": 337964,
    "end": 343734,
    "text": "最初のものは、大きな塊を返すのではなく、完全なドキュメントを返すというものだ。"
  },
  {
    "start": 343862,
    "end": 357770,
    "text": "もしドキュメントがそれほど長くないのであれば、ドキュメントを親ドキュメントのように使うことで、小さなチャンクがルックアップするときに元のドキュメントを返すようにすることもできる。"
  },
  {
    "start": 357850,
    "end": 365298,
    "text": "これは、もしあなたのオリジナル文書がたくさんあるとして、1つ1つはそれほど大きくない場合、とても良い方法です。"
  },
  {
    "start": 365384,
    "end": 378854,
    "text": "例えば、商品説明のようなもので、半ページのテキストで、それぞれのドキュメントに対して1つの記事を書くようなものです。"
  },
  {
    "start": 378972,
    "end": 386566,
    "text": "そして、それらを小さな塊に分割し、それらのルックアップを行いつつ、実際の完全なドキュメントに戻すことができる。"
  },
  {
    "start": 386668,
    "end": 394486,
    "text": "つ目の方法は、前に図で説明したように、小さなチャンクのルックアップから大きなチャンクを返すというものだ。"
  },
  {
    "start": 394598,
    "end": 395626,
    "text": "これらを見てみよう。"
  },
  {
    "start": 395648,
    "end": 398598,
    "text": "我々は標準的なインポートをいくつかやっているだけだ。"
  },
  {
    "start": 398694,
    "end": 401866,
    "text": "ここでは親ドキュメント・レトリバーをインポートしている。"
  },
  {
    "start": 402048,
    "end": 405166,
    "text": "基本的にはテキストを分割したりする予定だ。"
  },
  {
    "start": 405268,
    "end": 413390,
    "text": "OpenAIのエンベッディングに関するものはコメントアウトしましたが、それを使いたければ使えるように残してあります。"
  },
  {
    "start": 413540,
    "end": 417118,
    "text": "ここで使っているエンベッディングは、BGEのエンベッディングだ。"
  },
  {
    "start": 417294,
    "end": 419218,
    "text": "私はスモールを使っている。"
  },
  {
    "start": 419304,
    "end": 424718,
    "text": "これらは最近更新されたばかりで、小さな1.5のエンベデッドも同様だと思う。"
  },
  {
    "start": 424814,
    "end": 426078,
    "text": "これは小さい。"
  },
  {
    "start": 426174,
    "end": 429954,
    "text": "エンベデッドモデル全体が134メガしかないようなものだ。"
  },
  {
    "start": 430082,
    "end": 433286,
    "text": "今、僕はここのコラボでT4で走っている。"
  },
  {
    "start": 433388,
    "end": 439142,
    "text": "GPUが使えない場合は、OpenAIのエンベッディングに戻ればいい。"
  },
  {
    "start": 439276,
    "end": 442474,
    "text": "よし、ではこのブログの記事をいくつか持ってくることにしよう。"
  },
  {
    "start": 442512,
    "end": 449626,
    "text": "ラングスミスと、QAのベンチマークに関するものを持ってきているので、それを見てほしい。"
  },
  {
    "start": 449648,
    "end": 452746,
    "text": "案の定、これを持ち込むと2つの書類がある。"
  },
  {
    "start": 452938,
    "end": 465354,
    "text": "タイトルとURLをメタデータとして保存しておけば、それらをフィルタリングすることができます。"
  },
  {
    "start": 465402,
    "end": 471122,
    "text": "ここでは基本的に、まずURLを書いて、それからブログ記事のタイトルを書きます。"
  },
  {
    "start": 471176,
    "end": 473214,
    "text": "それなら、ブログ用のテキストを手に入れただけだ。"
  },
  {
    "start": 473342,
    "end": 476546,
    "text": "これは私が作ったカスタムスクレーパーを使っている。"
  },
  {
    "start": 476648,
    "end": 478626,
    "text": "もしかしたら、オープンソースとして公開するかもしれない。"
  },
  {
    "start": 478738,
    "end": 481302,
    "text": "実は、これはとても簡単なことなんだ。"
  },
  {
    "start": 481436,
    "end": 485990,
    "text": "この場合、各ドキュメントはここで1つのブログ記事となる。"
  },
  {
    "start": 486140,
    "end": 493114,
    "text": "さて、これからすることは、これらを小さな塊に分割することで、ここでは子分割器を使うことにする。"
  },
  {
    "start": 493152,
    "end": 495430,
    "text": "再帰的文字分割を使おう。"
  },
  {
    "start": 495510,
    "end": 500586,
    "text": "これらの設定は基本的に、ここにあるlangchainのドキュメントから引用しているだけだ。"
  },
  {
    "start": 500688,
    "end": 506094,
    "text": "もちろん、OpenAIのエンベッディングを使用していた場合は、基本的にBGEのエンベッディングを使用するように入れ替えました。"
  },
  {
    "start": 506132,
    "end": 508398,
    "text": "コメントアウトを解除して、これを削除すればいい。"
  },
  {
    "start": 508484,
    "end": 514430,
    "text": "そして、フルサイズのドキュメントは、ここのメモリーに保存される。"
  },
  {
    "start": 514580,
    "end": 527282,
    "text": "ここでは、フルサイズのドキュメント・リトリーバーがベクター・ストアの親ドキュメント・リトリーバーになることがわかります。"
  },
  {
    "start": 527416,
    "end": 529794,
    "text": "となると、子スプリッターを渡しただけだ。"
  },
  {
    "start": 529842,
    "end": 535926,
    "text": "ドキュメントを追加すると、基本的にエンベッディングを作成してくれる。"
  },
  {
    "start": 535948,
    "end": 537318,
    "text": "それですべてがまとまる。"
  },
  {
    "start": 537484,
    "end": 542922,
    "text": "さて、ここにあるストアを見てみると、そこには2つのドキュメントしかないことがわかる。"
  },
  {
    "start": 543056,
    "end": 546362,
    "text": "この場合、ブログ記事は2つしかない。"
  },
  {
    "start": 546416,
    "end": 550186,
    "text": "これらは、この中で大きな塊だということだ。"
  },
  {
    "start": 550368,
    "end": 558958,
    "text": "ベクトルストアの類似検索でラング・スミスとは何かを検索し、kが2つ戻ってくるだけに設定する。"
  },
  {
    "start": 559124,
    "end": 562510,
    "text": "ほら、案の定、2人のドクターが戻ってきた。"
  },
  {
    "start": 562660,
    "end": 571106,
    "text": "これらのドキュメントの1つを見てみると、この最初のドキュメントは基本的に今日ラングスミス・プラットフォームを紹介するものですね？"
  },
  {
    "start": 571208,
    "end": 575346,
    "text": "この文章はそれほど長くはない。"
  },
  {
    "start": 575448,
    "end": 578294,
    "text": "これがその小さな割れ目だ。"
  },
  {
    "start": 578332,
    "end": 580726,
    "text": "そのうちの2人が戻ってくることになった。"
  },
  {
    "start": 580828,
    "end": 589538,
    "text": "ラング・スミスとは何か \"をドク・レトリバーに渡すと、ドク・レトリバーはその小さな塊が何なのかを調べてくれる。"
  },
  {
    "start": 589714,
    "end": 592442,
    "text": "そして、親チャンクが何であるかを計算する。"
  },
  {
    "start": 592576,
    "end": 597210,
    "text": "この場合、その親チャンクは完全なドキュメントであり、それを返す。"
  },
  {
    "start": 597360,
    "end": 600150,
    "text": "ラング・スミスって何だ？"
  },
  {
    "start": 600230,
    "end": 606206,
    "text": "案の定、この最初の1枚と同じようなフルドキュメントがここにある。"
  },
  {
    "start": 606308,
    "end": 614174,
    "text": "こちらはおそらく数百文字の長さだが、こちらは11,600文字の長さであることがわかる。"
  },
  {
    "start": 614292,
    "end": 616378,
    "text": "それは、この記事の全文がここにあるからだ。"
  },
  {
    "start": 616404,
    "end": 620818,
    "text": "案の定、ラングスミスはどのポストで発表されるのだろう。"
  },
  {
    "start": 620904,
    "end": 625246,
    "text": "これは、全体を一発で仕上げることができる一つの方法だ。"
  },
  {
    "start": 625358,
    "end": 628722,
    "text": "もうひとつの方法は、より大きな塊を取り出すことだ。"
  },
  {
    "start": 628866,
    "end": 634390,
    "text": "これは、フルドキュメントを渡す場合に使用するもので、サイズが大きくなりすぎる。"
  },
  {
    "start": 634460,
    "end": 638630,
    "text": "今、あなたの全文書が複数ページの文書だとしよう。"
  },
  {
    "start": 639130,
    "end": 643498,
    "text": "最後に言語モデルに完全なドキュメントを渡したくはないだろう。"
  },
  {
    "start": 643584,
    "end": 645654,
    "text": "今は2つのレイヤーを持つ必要がある。"
  },
  {
    "start": 645702,
    "end": 655742,
    "text": "オリジナル・ドキュメント、親チャンク、子チャンク、あるいは大きなチャンク、小さなチャンクがここになければならない。"
  },
  {
    "start": 655876,
    "end": 664046,
    "text": "もう一度、前にあった子スプリッターを使いますが、今度は親スプリッターを手に入れました。"
  },
  {
    "start": 664148,
    "end": 664414,
    "text": "そうだね。"
  },
  {
    "start": 664452,
    "end": 670846,
    "text": "親スプリッターには2000、子スプリッターには400を用意した。"
  },
  {
    "start": 671038,
    "end": 673694,
    "text": "繰り返しますが、これらはLangchainのドキュメントからの引用です。"
  },
  {
    "start": 673742,
    "end": 677742,
    "text": "あなたの特別なものにとって何が適切なサイズなのか、試行錯誤することになる。"
  },
  {
    "start": 677896,
    "end": 682290,
    "text": "その後、BGEのエンベッディングを使用して、クロマのセッティングをやり直した。"
  },
  {
    "start": 682370,
    "end": 684422,
    "text": "店は以前と同じにしてある。"
  },
  {
    "start": 684556,
    "end": 685702,
    "text": "今は何も変わっていない。"
  },
  {
    "start": 685756,
    "end": 695190,
    "text": "ただひとつ、親ドキュメント・リトリーバーを作成するときに、子スプリッターと親スプリッターの両方を用意することになりました。"
  },
  {
    "start": 695270,
    "end": 698166,
    "text": "私たちは何層ものドキュメントを持つことになる。"
  },
  {
    "start": 698198,
    "end": 701382,
    "text": "今、このドコモショップにあるのは大きな塊だ。"
  },
  {
    "start": 701526,
    "end": 704874,
    "text": "その中に2つのブログ記事がある。"
  },
  {
    "start": 705002,
    "end": 710554,
    "text": "今、店舗を見ると、18の大きな塊に分かれている。"
  },
  {
    "start": 710602,
    "end": 714734,
    "text": "それぞれの文字数はおよそ2000文字だからだ。"
  },
  {
    "start": 714932,
    "end": 719806,
    "text": "サブドクターは、私たちが探すとなると、もっと小さくなる。"
  },
  {
    "start": 719918,
    "end": 723794,
    "text": "今、サブドクターを検索すると、4人がヒットする。"
  },
  {
    "start": 723912,
    "end": 731574,
    "text": "よし、最初の1枚を見ると、確かに今日ラングスミスを紹介していることがわかる。"
  },
  {
    "start": 731692,
    "end": 735382,
    "text": "あそこに戻ってくる数だけKを変えることができるんだ。"
  },
  {
    "start": 735436,
    "end": 735702,
    "text": "そうだね。"
  },
  {
    "start": 735756,
    "end": 737766,
    "text": "標準的なデフォルトは4人。"
  },
  {
    "start": 737868,
    "end": 739770,
    "text": "さっき2本に変更した。"
  },
  {
    "start": 739920,
    "end": 744054,
    "text": "さて、次に大きなドキュメントを検索してみよう。"
  },
  {
    "start": 744102,
    "end": 747670,
    "text": "これは大きな塊だ。"
  },
  {
    "start": 747750,
    "end": 749754,
    "text": "ラングスミスには何が見えるのか。"
  },
  {
    "start": 749792,
    "end": 753340,
    "text": "さて、案の定、戻ってくるドクターは2人だけだ。"
  },
  {
    "start": 753710,
    "end": 760462,
    "text": "見てみると、大きいが、完全な文書ではなく、以前のような完全なブログ記事でもない。"
  },
  {
    "start": 760596,
    "end": 767166,
    "text": "戻ってきた2つを見てみると、案の定、これがそのブログ記事の冒頭である。"
  },
  {
    "start": 767268,
    "end": 774306,
    "text": "2つ目を見ると、おそらくこれもそのブログ記事のものだと思われるが、ブログ記事の別の部分である。"
  },
  {
    "start": 774408,
    "end": 782360,
    "text": "今、私たちはブログ記事の2つのチャンクを2つの別々のものとして、イン・コンテキスト学習に渡そうとしている。"
  },
  {
    "start": 782970,
    "end": 789974,
    "text": "そして最後に、これを完成させ、試してみるために、検索QAチェーンを作成した。"
  },
  {
    "start": 790012,
    "end": 792406,
    "text": "言語モデルにはOpenAIを使っているだけだ。"
  },
  {
    "start": 792588,
    "end": 799398,
    "text": "基本的には、どのようなものでも入れることができるし、そのためにはまともな言語モデルが必要だが、ラマを入れることもできる。"
  },
  {
    "start": 799414,
    "end": 801386,
    "text": "これには2つのモデルが有効だ。"
  },
  {
    "start": 801488,
    "end": 804560,
    "text": "私たちはただ、すべてをイン・コンテキスト学習に渡していくだけだ。"
  },
  {
    "start": 805010,
    "end": 809326,
    "text": "今、レトリーバーは大きな塊でパスしているんだ。"
  },
  {
    "start": 809428,
    "end": 812218,
    "text": "ラングスミスって何？"
  },
  {
    "start": 812314,
    "end": 813242,
    "text": "それは通っている。"
  },
  {
    "start": 813316,
    "end": 819298,
    "text": "クエリーを実行して小さなチャンクを取得し、そこから大きなチャンクを取り戻す。"
  },
  {
    "start": 819464,
    "end": 827614,
    "text": "早い段階で、4つのサブチャンクがあったのに、彼らは2つの大きなチャンクしか返してくれなかった。"
  },
  {
    "start": 827662,
    "end": 830950,
    "text": "それは良い兆候だ。"
  },
  {
    "start": 831100,
    "end": 835894,
    "text": "ラングスミスとは何なのか？"
  },
  {
    "start": 835932,
    "end": 838390,
    "text": "最後に言語モデルを通過するのは？"
  },
  {
    "start": 838460,
    "end": 843094,
    "text": "ラングスミスは、開発者がプロトタイプと製造のギャップを縮めるために設計されたプラットフォームだ。"
  },
  {
    "start": 843142,
    "end": 846314,
    "text": "私たちは今、これに対する完全な答えを得た。"
  },
  {
    "start": 846432,
    "end": 850630,
    "text": "これは親ドキュメントリトリーバの使い方を示しています。"
  },
  {
    "start": 850790,
    "end": 857646,
    "text": "細かい情報をたくさん持っているような、さまざまなことにとても役立つ。"
  },
  {
    "start": 857748,
    "end": 868846,
    "text": "エンベッディングは非常に特殊なものであるべきだが、それに対して首尾一貫した良い答えを出せるように、最後に言語モデルにより大きな文脈を戻したいのだ。"
  },
  {
    "start": 869028,
    "end": 873086,
    "text": "とにかく、いつも通り、質問があれば下のコメントに書いてください。"
  },
  {
    "start": 873268,
    "end": 876050,
    "text": "このビデオがお役に立ちましたら、「いいね！」と「購読」をクリックしてください。"
  },
  {
    "start": 876130,
    "end": 885462,
    "text": "レトリーバーに関するさまざまなことや、ラグにこれを使うコツやヒントについて、これからいくつかビデオを公開する予定だ。"
  },
  {
    "start": 885596,
    "end": 887606,
    "text": "それでは、また次のビデオでお会いしましょう。"
  },
  {
    "start": 887708,
    "end": 888340,
    "text": "とりあえず、さようなら。"
  }
]