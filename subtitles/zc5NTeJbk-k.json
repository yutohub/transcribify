[
  {
    "start": 280,
    "end": 3486,
    "text": "これは人工知能による画像ジェネレーターだ。"
  },
  {
    "start": 3638,
    "end": 10050,
    "text": "写真のテキスト説明があれば、その説明に一致する画像を無から作り出す。"
  },
  {
    "start": 10590,
    "end": 16310,
    "text": "ご覧の通り、あらゆるシーンの高画質画像を生成することができる。"
  },
  {
    "start": 16470,
    "end": 18062,
    "text": "イメージだけではない。"
  },
  {
    "start": 18206,
    "end": 29980,
    "text": "近年では、テキスト、音声、コード、やがて動画も生成できるジェネレーティブAIモデルが開発されている。"
  },
  {
    "start": 31440,
    "end": 37380,
    "text": "これらのモデルはすべて、ディープ・ニューラル・ネットワークという同じ基礎技術に基づいている。"
  },
  {
    "start": 38040,
    "end": 43528,
    "text": "これまでのいくつかのビデオで、ディープ・ニューラル・ネットワークがどのように、そしてなぜうまく機能するのかを説明してきた。"
  },
  {
    "start": 43704,
    "end": 47860,
    "text": "私は、ニューラルネットが予測タスクをどのように解決できるかを説明しただけだ。"
  },
  {
    "start": 48200,
    "end": 58680,
    "text": "予測タスクでは、ニューラルネットは多くの入力例とそのラベルで訓練され、見たことのない新しい入力に対してどのようなラベルになるかを予測しようとする。"
  },
  {
    "start": 59300,
    "end": 73400,
    "text": "例えば、それぞれの画像に写っている物体の種類をラベル付けした画像でニューラルネットを訓練すれば、そのニューラルネットは、見たことのない新しい画像であっても、人間がその画像に写っていると言う物体を予測することを学習するだろう。"
  },
  {
    "start": 74580,
    "end": 84200,
    "text": "ボンネットの下では、予測タスクが解決される方法は、トレーニングデータセットを空間内の点の集合に変換し、それらの点を通る曲線をフィッティングすることである。"
  },
  {
    "start": 84580,
    "end": 88400,
    "text": "予測タスクはカーブフィッティングタスクとしても知られている。"
  },
  {
    "start": 89300,
    "end": 94676,
    "text": "予測は確かにクールで非常に便利だが、それは世代ではないだろう？"
  },
  {
    "start": 94868,
    "end": 98260,
    "text": "このモデルは、点の集合に曲線を当てはめただけである。"
  },
  {
    "start": 98420,
    "end": 100280,
    "text": "新しいイメージを生み出すことはできない。"
  },
  {
    "start": 100740,
    "end": 107600,
    "text": "ニューラルネットがカーブフィッティングしかできないのであれば、こうした生成モデルの創造性はどこから来るのだろうか？"
  },
  {
    "start": 108800,
    "end": 112940,
    "text": "さて、これらの生成モデルはすべて、実際には単なる予測モデルである。"
  },
  {
    "start": 113240,
    "end": 120056,
    "text": "そう、斬新な芸術作品を生み出すプロセスは、カーブフィッティングの練習に還元できることがわかったのだ。"
  },
  {
    "start": 120248,
    "end": 123220,
    "text": "このビデオでは、その具体的な方法を学ぶことができる。"
  },
  {
    "start": 125000,
    "end": 128912,
    "text": "たくさんの画像からなるトレーニングデータセットがあるとする。"
  },
  {
    "start": 129096,
    "end": 135340,
    "text": "私たちは、これらのトレーニング画像に似たスタイルの新しい画像を作成するためにニューラルネットを訓練したい。"
  },
  {
    "start": 136130,
    "end": 141870,
    "text": "最初に試すのは、予測器を訓練するために画像をラベルとして使うことです。"
  },
  {
    "start": 142770,
    "end": 148962,
    "text": "ここでは、入力から出力へのマッピングは気にしないので、入力には好きなものを使えばいい。"
  },
  {
    "start": 149066,
    "end": 151370,
    "text": "例えば、真っ黒な画像。"
  },
  {
    "start": 151530,
    "end": 155538,
    "text": "予測器は、学習データに従って入力を出力にマッピングするように学習する。"
  },
  {
    "start": 155674,
    "end": 164640,
    "text": "この予測器は、一度訓練されれば、ダミーの真っ黒な画像を訓練セットで見たような新しい画像にマッピングできるはずですよね？"
  },
  {
    "start": 168340,
    "end": 170836,
    "text": "いや、ちょっと違うかな。"
  },
  {
    "start": 170988,
    "end": 172532,
    "text": "それはあまりうまくいかなかった。"
  },
  {
    "start": 172676,
    "end": 177200,
    "text": "きれいな写真が撮れるどころか、ぼやけた写真になってしまった。"
  },
  {
    "start": 178020,
    "end": 181276,
    "text": "これは予測因子に関する非常に重要な事実を示している。"
  },
  {
    "start": 181428,
    "end": 188720,
    "text": "同じ入力に対して複数の可能なラベルがある場合、予測器はそれらのラベルの平均を出力するように学習する。"
  },
  {
    "start": 189510,
    "end": 197730,
    "text": "伝統的な分類タスクでは、複数のクラス・ラベルの平均が意味のあるラベルとなりうるので、これはあまり問題ではない。"
  },
  {
    "start": 198670,
    "end": 202774,
    "text": "たとえば、この画像に2つの異なるラベルを貼ることができる。"
  },
  {
    "start": 202862,
    "end": 205730,
    "text": "猫も犬も有効なラベルだろう。"
  },
  {
    "start": 206150,
    "end": 217596,
    "text": "この場合、分類器はこれらのラベルの平均を出力するように学習する。つまり、0.5猫と0.5犬のスコアが得られることになり、これはまだ有用なラベルである。"
  },
  {
    "start": 217788,
    "end": 222080,
    "text": "実際、どちらのオリジナル・レーベルよりも良いレーベルであることは間違いない。"
  },
  {
    "start": 222980,
    "end": 228684,
    "text": "一方、何枚もの画像を平均化しても、意味のある画像は得られない。"
  },
  {
    "start": 228812,
    "end": 230560,
    "text": "ぼやけてしまうだけだ。"
  },
  {
    "start": 231620,
    "end": 234156,
    "text": "今回はもう少し簡単なことをやってみよう。"
  },
  {
    "start": 234308,
    "end": 240720,
    "text": "ゼロから新しい画像を生成する代わりに、一部が欠けている画像を完成させるというのはどうだろう？"
  },
  {
    "start": 241250,
    "end": 243250,
    "text": "実際、これは本当に簡単なことだ。"
  },
  {
    "start": 243290,
    "end": 245810,
    "text": "欠けているピクセルが1つだけあるとする。"
  },
  {
    "start": 245930,
    "end": 247710,
    "text": "例えば、右下のピクセル。"
  },
  {
    "start": 248250,
    "end": 252626,
    "text": "ニューラルネットを訓練して、この欠けている1ピクセルの値を予測できるだろうか？"
  },
  {
    "start": 252818,
    "end": 259510,
    "text": "さて、前回と同様、ニューラルネットは、欠落したピクセルの取りうる値の平均を出力する。"
  },
  {
    "start": 259970,
    "end": 265146,
    "text": "予測するのは1ピクセルだけなので、平均値はまだ意味がある。"
  },
  {
    "start": 265298,
    "end": 268402,
    "text": "たくさんの色の平均は、別の色にすぎない。"
  },
  {
    "start": 268506,
    "end": 269990,
    "text": "ぼかし効果はない。"
  },
  {
    "start": 271890,
    "end": 281790,
    "text": "このモデルはまったく問題なく機能し、このニューラルネットが予測した値を使って、右下のピクセルが欠けている画像を完成させることができる。"
  },
  {
    "start": 283770,
    "end": 284298,
    "text": "素晴らしい。"
  },
  {
    "start": 284394,
    "end": 287522,
    "text": "ピクセルが1つ欠けていても、画像を完成させることができる。"
  },
  {
    "start": 287666,
    "end": 288790,
    "text": "2人なら？"
  },
  {
    "start": 289890,
    "end": 292098,
    "text": "まあ、また同じことをすればいい。"
  },
  {
    "start": 292274,
    "end": 302490,
    "text": "2つの欠損ピクセルのある画像で、2つ目の欠損ピクセルの値をラベルとして別のニューラルネットを訓練し、このニューラルネットを使って2つ目の欠損ピクセルを埋める。"
  },
  {
    "start": 305790,
    "end": 311090,
    "text": "これで、1ピクセルだけ欠けている画像ができたので、それを埋めるために最初のニューラルネットを使うことができる。"
  },
  {
    "start": 312030,
    "end": 312770,
    "text": "素晴らしい。"
  },
  {
    "start": 314870,
    "end": 317750,
    "text": "画像内のすべてのピクセルに対してこれを行うことができる。"
  },
  {
    "start": 317870,
    "end": 323890,
    "text": "そのピクセルとそれに続くすべてのピクセルが欠けているときに、そのピクセルの色を予測するためにニューラルネットを訓練する。"
  },
  {
    "start": 324360,
    "end": 330420,
    "text": "これで、真っ黒な画像から始めて、1ピクセルずつ塗りつぶしていくことで、画像を完成させることができる。"
  },
  {
    "start": 331120,
    "end": 336220,
    "text": "重要なのは、各ニューラルネットが予測するのは1ピクセルだけなので、ぼかし効果がないことだ。"
  },
  {
    "start": 338000,
    "end": 339176,
    "text": "そうだ。"
  },
  {
    "start": 339248,
    "end": 342740,
    "text": "何もないところから、もっともらしいイメージを作り出しただけなのだ。"
  },
  {
    "start": 344280,
    "end": 345984,
    "text": "ただ、一つだけ小さな問題がある。"
  },
  {
    "start": 346152,
    "end": 350062,
    "text": "このモデルをもう一度実行すると、まったく同じ画像が生成される。"
  },
  {
    "start": 350216,
    "end": 351950,
    "text": "あまりクリエイティブではないだろう？"
  },
  {
    "start": 352610,
    "end": 353490,
    "text": "心配はいらない。"
  },
  {
    "start": 353530,
    "end": 356834,
    "text": "ランダムサンプリングを導入することで、これを解決することができる。"
  },
  {
    "start": 357002,
    "end": 362310,
    "text": "すべての予測器は、可能性のあるラベルの確率分布を出力する。"
  },
  {
    "start": 363930,
    "end": 368550,
    "text": "通常は、最も大きな確率のラベルを予測値とする。"
  },
  {
    "start": 369010,
    "end": 375990,
    "text": "出力に多様性が欲しい場合は、代わりにこの確率分布からランダムに値をサンプリングすることができる。"
  },
  {
    "start": 376530,
    "end": 387470,
    "text": "こうすることで、モデルを実行するたびに、各ステップで異なる値をサンプリングすることになり、その結果、後続のステップの予測値が変化し、毎回まったく異なる画像が得られることになる。"
  },
  {
    "start": 388330,
    "end": 396274,
    "text": "さて、興味深い画像ジェネレーターができたが、それでも結局のところ、このモデルは予測子でできている。"
  },
  {
    "start": 396442,
    "end": 401752,
    "text": "部分的にマスクされた画像を入力とし、次のピクセルの値を予測する。"
  },
  {
    "start": 401906,
    "end": 407268,
    "text": "従来の画像分類器との唯一の違いは、学習に使ったラベルである。"
  },
  {
    "start": 407444,
    "end": 415044,
    "text": "私たちのジェネレーターのラベルは、たまたまピクセルの色であり、それは人間のラベラーではなく、オリジナルの画像そのものから得られたものである。"
  },
  {
    "start": 415212,
    "end": 416700,
    "text": "これは非常に重要なポイントだ。"
  },
  {
    "start": 416740,
    "end": 420388,
    "text": "実際には、人間が手作業で画像にラベルを付ける必要はないということだ。"
  },
  {
    "start": 420444,
    "end": 431432,
    "text": "このモデルの場合、インターネットからラベルのない画像をかき集めればいいのだが、ニューラルネットから見れば、ラベルが元の画像から来たものであることを知らないし、気にもしない。"
  },
  {
    "start": 431576,
    "end": 436340,
    "text": "それに関する限り、これはただのカーブフィッティングの練習に過ぎない。"
  },
  {
    "start": 437440,
    "end": 441464,
    "text": "今作った生成モデルは自己回帰モデルと呼ばれる。"
  },
  {
    "start": 441592,
    "end": 451340,
    "text": "ピクセルを1つずつ取り除く除去プロセスがあり、このプロセスを元に戻すためにニューラルネットを訓練し、ピクセルを1つずつ生成して戻す。"
  },
  {
    "start": 452880,
    "end": 455728,
    "text": "これは実は最も古い生成モデルのひとつである。"
  },
  {
    "start": 455784,
    "end": 465402,
    "text": "自己回帰の最も初期の使用は1927年にさかのぼり、いくつかのスポットのタイミングをモデル化するために使用されたが、自己回帰は今日でも使用されている。"
  },
  {
    "start": 465586,
    "end": 469350,
    "text": "最も注目すべきは、チャットGPTが自己回帰関数であることだ。"
  },
  {
    "start": 469690,
    "end": 479190,
    "text": "チャットGPTは、テキストの一部が与えられたときに、変換分類器を用いて、次に起こりうる単語の確率分布を出力することによってテキストを生成する。"
  },
  {
    "start": 480370,
    "end": 490620,
    "text": "その理由は、非常にリアルな画像を生成できる反面、実行に時間がかかりすぎるからだ。"
  },
  {
    "start": 491440,
    "end": 497576,
    "text": "自己回帰でサンプルを生成するためには、すべての要素についてニューラルネットを一度評価する必要がある。"
  },
  {
    "start": 497768,
    "end": 504940,
    "text": "これは、数千語のテキストを生成する分には問題ないが、大きな画像は数千万ピクセルにもなる。"
  },
  {
    "start": 505640,
    "end": 508740,
    "text": "ニューラルネットの評価を少なくするにはどうすればいいのか？"
  },
  {
    "start": 513560,
    "end": 520364,
    "text": "自己回帰器ではピクセルを1つずつ取り除いたが、1ピクセルだけを取り除く必要はない。"
  },
  {
    "start": 520532,
    "end": 529240,
    "text": "例えば、一度に4×4パッチのピクセルを除去し、16個の欠損ピクセルを一度に予測するようにニューラルネットを訓練することができる。"
  },
  {
    "start": 529700,
    "end": 538680,
    "text": "こうすることで、このモデルを使って画像を生成する場合、1回の評価で16ピクセルを生成できるので、生成速度は16倍になる。"
  },
  {
    "start": 541260,
    "end": 542952,
    "text": "これには限界がある。"
  },
  {
    "start": 543116,
    "end": 546216,
    "text": "同時に多くのピクセルを生成することはできない。"
  },
  {
    "start": 546368,
    "end": 553384,
    "text": "極端な話、画像のすべてのピクセルを一度に生成しようとすれば、元の問題に戻ってしまう。"
  },
  {
    "start": 553552,
    "end": 558220,
    "text": "いろいろなレッテルが考えられるが、そのレッテルは混然一体となって、ぼやけたゴチャゴチャになってしまう。"
  },
  {
    "start": 560320,
    "end": 570380,
    "text": "はっきり言って、画質が劣化する理由は、多数のピクセルを同時に予測する場合、モデルはすべてのピクセルの値を一度に決定しなければならないからだ。"
  },
  {
    "start": 571040,
    "end": 578260,
    "text": "この欠落したパッチを埋めるには、もっともらしい方法がたくさんあるので、モデルはそれらの平均値を出力する。"
  },
  {
    "start": 579000,
    "end": 584100,
    "text": "モデルは、生成された値が互いに整合していることを確認することができない。"
  },
  {
    "start": 585000,
    "end": 597540,
    "text": "対照的に、一度に1つのピクセルを予測する場合、モデルは以前に生成されたピクセルを見ることができるので、モデルはこのピクセルに対する予測を変更して、すでに生成されたものと一致させることができる。"
  },
  {
    "start": 597720,
    "end": 599548,
    "text": "これがトレードオフの理由だ。"
  },
  {
    "start": 599684,
    "end": 607320,
    "text": "一度に生成するピクセル数が多ければ多いほど、計算量は少なくて済むが、生成される画像の質は悪くなる。"
  },
  {
    "start": 608780,
    "end": 618948,
    "text": "この問題は、予測する値が互いに関連している場合にのみ生じるが、仮に値が統計的に互いに独立していたとしよう。"
  },
  {
    "start": 619124,
    "end": 623160,
    "text": "つまり、そのうちのひとつを知っていても、他を予測する助けにはならないということだ。"
  },
  {
    "start": 623790,
    "end": 632730,
    "text": "この場合、モデルは以前に生成された値を見る必要はない。なぜなら、それが何であったかを知っても、次の値に対する予測は変わらないからだ。"
  },
  {
    "start": 633150,
    "end": 638410,
    "text": "この場合、クオリティを落とすことなく、すべてを同時に予測することができる。"
  },
  {
    "start": 639310,
    "end": 646130,
    "text": "つまり理想的には、互いに無関係なピクセルの集合を生成するモデルにしたい。"
  },
  {
    "start": 646670,
    "end": 653730,
    "text": "自然画像では、近傍のピクセルは通常同じオブジェクトの一部であるため、最も強く関連する。"
  },
  {
    "start": 654180,
    "end": 659940,
    "text": "あるピクセルの値がわかると、近くのピクセルの色がわかることがよくある。"
  },
  {
    "start": 660020,
    "end": 666000,
    "text": "つまり、連続した塊でピクセルを除去するのは、実は最悪の方法なのだ。"
  },
  {
    "start": 666420,
    "end": 673320,
    "text": "むしろ、互いに離れていて、それゆえ無関係である可能性が高いピクセルを取り除くべきである。"
  },
  {
    "start": 674060,
    "end": 686260,
    "text": "もし各ステップでランダムなピクセルのセットを除去し、それらのピクセルの値を予測するならば、連続したチャンクと比較して、同じ画質の損失で各ステップでより多くのピクセルを除去することができる。"
  },
  {
    "start": 687200,
    "end": 694500,
    "text": "生成に必要なステップ数を最小化するために、各ステップで削除するピクセルをできるだけ分散させたい。"
  },
  {
    "start": 694920,
    "end": 717380,
    "text": "ランダムな順序でピクセルを除去することは、平均的な広がりを最大化するかなり良い方法だが、さらに良い方法がある。生成モデルを2つのプロセスとして考えることができるのだ。"
  },
  {
    "start": 717680,
    "end": 735880,
    "text": "情報の生成と追加 これまでのところ、ピクセルを完全に除去してきたが、ピクセルを完全に除去するのではなく、例えばピクセルに少量のランダムなノイズを加えることで、ピクセルの情報の一部だけを除去することができる。"
  },
  {
    "start": 736980,
    "end": 744280,
    "text": "つまり、元のピクセル値が何であったかは正確にはわからないが、ノイジー値に近いどこかであったことはわかる。"
  },
  {
    "start": 745740,
    "end": 751640,
    "text": "ここで、各ステップでピクセルの束を除去する代わりに、画像全体にノイズを加えることができる。"
  },
  {
    "start": 752060,
    "end": 760960,
    "text": "こうすることで、画像内のすべてのピクセルから情報を一度に取り除くことができる。"
  },
  {
    "start": 761470,
    "end": 768090,
    "text": "より分散されるため、同じ世代品質の損失でも、各ステップでより多くの情報を取り除くことができる。"
  },
  {
    "start": 769990,
    "end": 772094,
    "text": "しかし、これにはひとつ小さな問題がある。"
  },
  {
    "start": 772222,
    "end": 778490,
    "text": "新しい画像を生成する場合、ニューラルネットを最初に空白の画像からスタートさせる必要がある。"
  },
  {
    "start": 778910,
    "end": 784662,
    "text": "ピクセルを除去していた場合、どの画像も最終的には真っ黒な画像になってしまう。"
  },
  {
    "start": 784766,
    "end": 788210,
    "text": "もちろん、そこから世代交代が始まる。"
  },
  {
    "start": 788710,
    "end": 794930,
    "text": "ノイズを加えているので、値はどんどん大きくなり、収束することはない。"
  },
  {
    "start": 795310,
    "end": 798422,
    "text": "世代交代はどこから始めるのか？"
  },
  {
    "start": 798606,
    "end": 806650,
    "text": "ノイズ除去のステップを少し変えて、まず元の値をスケールダウンしてからノイズを加えるようにすれば、この問題を回避できる。"
  },
  {
    "start": 807110,
    "end": 818850,
    "text": "これにより、このノイズ除去ステップを何度も繰り返すと、元の画像からの情報は消え、結果はノイズ分布からの純粋なランダムサンプルと同じになる。"
  },
  {
    "start": 819350,
    "end": 823610,
    "text": "このようなノイズサンプルから生成プロセスを開始することができる。"
  },
  {
    "start": 823990,
    "end": 825206,
    "text": "そうだ。"
  },
  {
    "start": 825278,
    "end": 828446,
    "text": "これはノイズ除去拡散モデルとして知られている。"
  },
  {
    "start": 828638,
    "end": 831966,
    "text": "全体的な形式は自己回帰関数と同じである。"
  },
  {
    "start": 832078,
    "end": 836286,
    "text": "唯一の違いは、各段階で情報を削除する方法だ。"
  },
  {
    "start": 836478,
    "end": 848760,
    "text": "ノイズを加えることで、画像全体にわたって情報の除去を分散させることができ、予測値が可能な限り互いに独立したものになるため、ニューラルネットの評価回数を少なくすることができる。"
  },
  {
    "start": 849460,
    "end": 857920,
    "text": "経験的には、自己回帰モデルでは数百万ステップを要するのに対し、拡散モデルでは約100ステップで高品質なフォトリアリスティック画像を生成できる。"
  },
  {
    "start": 859940,
    "end": 870400,
    "text": "さて、このような生成モデルが概念的なレベルでどのように機能するかを理解したところで、これらのモデルを実際に実装するのであれば、いくつか重要な技術的詳細があるので、それを知っておく必要がある。"
  },
  {
    "start": 870850,
    "end": 877710,
    "text": "まず、自己回帰について説明した手順では、プロセスの各段階で異なるニューラルネットを使用した。"
  },
  {
    "start": 878210,
    "end": 887070,
    "text": "これは確かに最も正確な予測を得るための最良の方法だが、異なるニューラルネットを大量に訓練する必要があるため、非常に非効率的でもある。"
  },
  {
    "start": 887810,
    "end": 891990,
    "text": "実際には、すべてのステップで同じモデルを使うことになる。"
  },
  {
    "start": 892770,
    "end": 898390,
    "text": "この場合、予測値は若干悪くなるが、それを補って余りある計算時間の節約になる。"
  },
  {
    "start": 898720,
    "end": 910660,
    "text": "1つのニューラルネットにすべての生成ステップを実行させるように訓練するには、各入力からランダムな数のピクセルを取り除き、各入力の対応する次のピクセルを予測するようにニューラルネットを訓練することになる。"
  },
  {
    "start": 911280,
    "end": 919860,
    "text": "さらに、どのピクセルを生成すべきかがわかるように、除去したピクセル数をニューラルネットへの入力として与えることもできる。"
  },
  {
    "start": 920560,
    "end": 938556,
    "text": "今説明したセットアップでは、この1つのニューラルネットをすべての生成ステップに使用できます。各トレーニング画像に対して、ニューラルネットはその画像の1つの生成ステップだけでトレーニングされますが、理想的にはすべての画像のすべての生成ステップでトレーニングしたいものです。"
  },
  {
    "start": 938708,
    "end": 941560,
    "text": "そうすれば、トレーニングデータをもっと活用できる。"
  },
  {
    "start": 942180,
    "end": 950366,
    "text": "これを素朴な方法でやると、生成ステップごとにニューラルネットを1回評価しなければならず、計算量が多くなる。"
  },
  {
    "start": 950548,
    "end": 970390,
    "text": "幸いなことに、因果アーキテクチャと呼ばれる特殊なニューラルネット・アーキテクチャが存在し、因果畳み込みニューラルネットや因果変換器など、一般的なニューラルネット・アーキテクチャの因果バージョンが存在する。"
  },
  {
    "start": 970690,
    "end": 981000,
    "text": "しかし実際には、自己回帰はほとんどの場合因果アーキテクチャで行われる。"
  },
  {
    "start": 981700,
    "end": 994840,
    "text": "因果関係のあるアーキテクチャの生成プロセスはまったく同じですが、拡散モデルの場合は因果関係のあるアーキテクチャを使うことができないので、ランダムな生成ステップで各データポイントを使って学習する必要があります。"
  },
  {
    "start": 997380,
    "end": 1002980,
    "text": "私は拡散モデルを、前のステップで得られたノイズの少ない画像を予測すると説明した。"
  },
  {
    "start": 1003140,
    "end": 1008560,
    "text": "しかし、実際には、すべてのステップで完全にクリーンな元の画像を予測する方が良い。"
  },
  {
    "start": 1009030,
    "end": 1013210,
    "text": "その理由は、ニューラルネットの仕事が容易になるからだ。"
  },
  {
    "start": 1013750,
    "end": 1021650,
    "text": "ノイズの多い次のステップの画像を予測させるのであれば、ニューラルネットはあらゆるノイズレベルの画像を生成する方法を学習する必要がある。"
  },
  {
    "start": 1022110,
    "end": 1027450,
    "text": "これは、ノイズの多い画像を生成するために、モデルが学習能力の一部を浪費することを意味する。"
  },
  {
    "start": 1028070,
    "end": 1037359,
    "text": "その代わりにニューラルネットに常にきれいな画像を予測させれば、モデルはきれいな画像を生成する方法だけを学習すればよくなり、それが私たちの関心事となる。"
  },
  {
    "start": 1037819,
    "end": 1045479,
    "text": "その後、予測されたクリーンな画像を取り出し、ノイズ処理を再度適用することで、生成プロセスの次のステップを得ることができる。"
  },
  {
    "start": 1046699,
    "end": 1061999,
    "text": "ただし、きれいな画像を予測した場合、生成プロセスの初期段階では、モデルには純粋なノイズしか入力されないので、元のきれいな画像は何でもよかったことになり、またぼやけた画像になってしまう。"
  },
  {
    "start": 1063190,
    "end": 1068838,
    "text": "これを避けるために、画像に加えられたノイズを予測するようにニューラルネットを訓練することができる。"
  },
  {
    "start": 1068974,
    "end": 1075822,
    "text": "ノイズの予測値が得られたら、それをこの式に差し込むことで、元のきれいな画像の予測値を得ることができる。"
  },
  {
    "start": 1075966,
    "end": 1080770,
    "text": "私たちはまだ、遠回しにではあるが、元のクリーンなイメージを予測しているのだ。"
  },
  {
    "start": 1081230,
    "end": 1091716,
    "text": "この方法の利点は、クリーンな画像にノイズが加わっている可能性があるため、生成プロセスの後の段階でモデル出力が不確実になることだ。"
  },
  {
    "start": 1091868,
    "end": 1097520,
    "text": "このモデルは、異なるノイズサンプルの平均を出力するが、それでも有効なノイズである。"
  },
  {
    "start": 1099580,
    "end": 1108772,
    "text": "ここまでは、何もないところから画像を生成してきたが、実はほとんどの画像ジェネレーターでは、作りたい画像を説明するテキストプロンプトを入力することができる。"
  },
  {
    "start": 1108956,
    "end": 1115248,
    "text": "この仕組みはまったく同じで、各ステップでニューラルネットにテキストを追加入力として与えるだけだ。"
  },
  {
    "start": 1115444,
    "end": 1123740,
    "text": "これらのモデルは、画像とそれに対応するテキスト説明文のペアで学習され、通常はインターネット上の画像altテキストタグからスクレイピングされる。"
  },
  {
    "start": 1124240,
    "end": 1131940,
    "text": "これは、生成された画像が、プロンプトのテキストがその画像の説明としてもっともらしく与えられたものであることを保証する。"
  },
  {
    "start": 1132720,
    "end": 1139700,
    "text": "原理的には、適切な学習データさえ見つかれば、テキストに限らずどんなものでも生成モデルを条件づけることができる。"
  },
  {
    "start": 1140120,
    "end": 1144060,
    "text": "例えば、スケッチを条件とする生成モデルである。"
  },
  {
    "start": 1148550,
    "end": 1161970,
    "text": "最後に、条件付き拡散モデルをよりうまく機能させるためのテクニックとして、分類器フリーのガイダンスと呼ばれるものがある。"
  },
  {
    "start": 1162310,
    "end": 1167926,
    "text": "こうすることで、同じモデルが、入力として条件付けプロンプトがあってもなくても予測を行うことを学習する。"
  },
  {
    "start": 1168118,
    "end": 1175530,
    "text": "次に、ノイズ除去プロセスの各ステップで、モデルを2回実行する。1回はプロンプトを使用し、もう1回は予測なしで実行する。"
  },
  {
    "start": 1175570,
    "end": 1188350,
    "text": "プロンプトがない場合、プロンプトがある予測からプロンプトが差し引かれ、プロンプトなしで生成された詳細が取り除かれ、プロンプトから得られた詳細だけが残る。"
  },
  {
    "start": 1189130,
    "end": 1196554,
    "text": "結論として、生成AIは他の機械学習と同様、カーブフィッティングに過ぎない。"
  },
  {
    "start": 1196642,
    "end": 1198714,
    "text": "もし楽しんでいただけたなら、「いいね！」と購読をお願いします。"
  },
  {
    "start": 1198762,
    "end": 1203950,
    "text": "今後のビデオで取り上げてほしいトピックがあれば、以下にコメントを残してください。"
  },
  {
    "start": 1203970,
    "end": 1204110,
    "text": "流れだ。"
  }
]