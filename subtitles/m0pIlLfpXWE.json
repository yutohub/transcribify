[
  {
    "start": 10650,
    "end": 16458,
    "text": "このビデオでは、活性化関数とは何か、そしてニューラルネットワークで活性化関数をどのように使うかについて説明する。"
  },
  {
    "start": 16554,
    "end": 23178,
    "text": "また、いくつかの異なる活性化関数について説明し、kerasを使ったコードで活性化関数を指定する方法を見ていきます。"
  },
  {
    "start": 23274,
    "end": 30610,
    "text": "前のビデオでは、ニューラルネットワーク内のレイヤーについて説明し、活性化関数が通常レイヤーに従うことを簡単に述べた。"
  },
  {
    "start": 30690,
    "end": 32742,
    "text": "このアイデアをもう少し進めてみよう。"
  },
  {
    "start": 32876,
    "end": 36038,
    "text": "では、活性化関数の定義とは？"
  },
  {
    "start": 36124,
    "end": 43830,
    "text": "まず、人工ニューラルネットワークでは、ニューロンの活性化関数が、一連の入力が与えられたときのニューロンの出力を定義する。"
  },
  {
    "start": 43910,
    "end": 47258,
    "text": "これは、前回のビデオにあったイラストを考えれば納得がいく。"
  },
  {
    "start": 47344,
    "end": 54686,
    "text": "次の層の同じニューロンを指す各接続の加重和を取り、その加重和を活性化関数に渡した。"
  },
  {
    "start": 54788,
    "end": 62362,
    "text": "次に活性化関数は、ある種の演算を行い、和をある下限値と上限値の間の数値に変換する。"
  },
  {
    "start": 62426,
    "end": 64010,
    "text": "どうしたんだ、この変身は？"
  },
  {
    "start": 64090,
    "end": 66114,
    "text": "なぜそれを説明する必要があるのか？"
  },
  {
    "start": 66152,
    "end": 69278,
    "text": "まずシグモイドという活性化関数を見てみよう。"
  },
  {
    "start": 69374,
    "end": 77906,
    "text": "シグモイドは入力を受け取り、入力が非常に負の数であれば、シグモイドは入力をゼロに非常に近い数に変換する。"
  },
  {
    "start": 78008,
    "end": 83638,
    "text": "入力が非常に正の数の場合、シグモイドは入力を1に非常に近い数に変換する。"
  },
  {
    "start": 83724,
    "end": 90198,
    "text": "入力がゼロに近い場合、シグモイドは入力をゼロと1の間の数値に変換する。"
  },
  {
    "start": 90284,
    "end": 94470,
    "text": "シグモイドの場合、0が下限、1が上限となる。"
  },
  {
    "start": 94550,
    "end": 102430,
    "text": "さて、活性化関数のひとつが何をしているのか、数学的に理解できたところで、なぜこのようなことをするのかという前回の疑問に戻ろう。"
  },
  {
    "start": 102500,
    "end": 103982,
    "text": "その直感とは？"
  },
  {
    "start": 104036,
    "end": 112618,
    "text": "活性化関数は、私たちの脳の活動から生物学的に着想を得ている。"
  },
  {
    "start": 112714,
    "end": 120014,
    "text": "例えば、焼きたてのクッキーのような心地よい匂いを嗅ぐと、脳内の特定のニューロンが発火して活性化する。"
  },
  {
    "start": 120142,
    "end": 125458,
    "text": "腐った牛乳のような不快な匂いを嗅ぐと、脳の他のニューロンが発火する。"
  },
  {
    "start": 125544,
    "end": 129606,
    "text": "私たちの脳内では、特定のニューロンが発火しているかしていないかだ。"
  },
  {
    "start": 129708,
    "end": 133890,
    "text": "これは、発射しない場合は0、発射する場合は1で表すことができる。"
  },
  {
    "start": 133970,
    "end": 140406,
    "text": "人工ニューラルネットワークのシグモイド活性化関数では、ニューロンは0と1の間にあることがわかった。"
  },
  {
    "start": 140508,
    "end": 143978,
    "text": "に近いほど、そのニューロンはより活性化される。"
  },
  {
    "start": 144064,
    "end": 146858,
    "text": "ゼロに近ければ近いほど、活性化しない。"
  },
  {
    "start": 146944,
    "end": 153406,
    "text": "さて、活性化関数が入力を0と1の間に変換するとは限らない。"
  },
  {
    "start": 153508,
    "end": 159294,
    "text": "実際、現在最も広く使われている活性化関数のひとつであるreluは、このようなことはしない。"
  },
  {
    "start": 159412,
    "end": 167634,
    "text": "Reluはrectified linear unitの略で、入力をゼロまたは入力そのものの最大値に変換する。"
  },
  {
    "start": 167752,
    "end": 173474,
    "text": "入力がゼロ以下の場合、reluは入力をゼロに変換する。"
  },
  {
    "start": 173592,
    "end": 178242,
    "text": "数値が0より大きい場合、reluは与えられた入力をそのまま出力します。"
  },
  {
    "start": 178306,
    "end": 182678,
    "text": "この考え方は、ニューロンがポジティブであればあるほど、活性化されるというものだ。"
  },
  {
    "start": 182764,
    "end": 192422,
    "text": "さて、ここではシグモイドとreluという2つの活性化関数についてだけ説明したが、入力に対してさまざまな変換を行う活性化関数には多くの種類がある。"
  },
  {
    "start": 192486,
    "end": 197594,
    "text": "では、kerasの逐次モデルで活性化関数を指定する方法を見てみましょう。"
  },
  {
    "start": 197712,
    "end": 202218,
    "text": "Jupyterノートブックで、kerasの逐次モデルを作り始めました。"
  },
  {
    "start": 202304,
    "end": 206730,
    "text": "まず最初に、シーケンシャル・デントとアクティベーション・クラスをインポートした。"
  },
  {
    "start": 206810,
    "end": 212014,
    "text": "そして、このモデル変数を作成し、シーケンシャル・オブジェクトのインスタンスと等しく設定した。"
  },
  {
    "start": 212132,
    "end": 217506,
    "text": "さて、このシーケンシャル・オブジェクトは、コンストラクタに配列を取り込む。"
  },
  {
    "start": 217608,
    "end": 221214,
    "text": "ここでは、5つのニューロンを持つ1つの高密度レイヤーを通過させているだけだ。"
  },
  {
    "start": 221262,
    "end": 226098,
    "text": "入力形状を指定し、次に活性化関数を指定する。"
  },
  {
    "start": 226184,
    "end": 227870,
    "text": "今回はreluを使っている。"
  },
  {
    "start": 227950,
    "end": 232582,
    "text": "現在、kerasはサポートしているさまざまな活性化関数のリストを持っており、それは彼らのウェブサイトで入手できる。"
  },
  {
    "start": 232716,
    "end": 235238,
    "text": "これは活性化関数を指定するひとつの方法である。"
  },
  {
    "start": 235324,
    "end": 238642,
    "text": "レイヤーのパラメータとして渡すことができる。"
  },
  {
    "start": 238706,
    "end": 247830,
    "text": "もうひとつの方法は、この次のセルで、modelをシーケンシャル・オブジェクトのインスタンスと等しくなるように定義していますが、コンストラクターには何も渡していません。"
  },
  {
    "start": 247910,
    "end": 251642,
    "text": "その代わり、その後にモデルに緻密なレイヤーを追加している。"
  },
  {
    "start": 251696,
    "end": 259294,
    "text": "これは、活性化関数を指定するパラメーターを渡していないことを除けば、上で指定したのと同じ密なレイヤーだ。"
  },
  {
    "start": 259412,
    "end": 267390,
    "text": "その代わりに、アクティベーション・レイヤーを追加し、アクティベーションの種類を指定している。"
  },
  {
    "start": 267470,
    "end": 274110,
    "text": "kerasの逐次APIを使用する際のニューラルネットワーク内の活性化関数の指定は以上です。"
  },
  {
    "start": 274190,
    "end": 284578,
    "text": "これで、これらの活性化関数がニューラルネットワーク全体にどのように適合し、何を行っているのか、またkerasの逐次API内でどのように使用するのかについて、ある程度理解していただけたと思います。"
  },
  {
    "start": 284674,
    "end": 286194,
    "text": "このビデオがお役に立てば幸いです。"
  },
  {
    "start": 286242,
    "end": 290180,
    "text": "もしそうなら、このビデオに「いいね！」、「購読」、「提案」、「コメント」をお願いします。"
  }
]