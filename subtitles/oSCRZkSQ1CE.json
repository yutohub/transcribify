[
  {
    "start": 4280,
    "end": 6860,
    "text": "機械学習のエキサイティングなトレンドについてお話しします。"
  },
  {
    "start": 6930,
    "end": 8940,
    "text": "とても幅広い話になるだろう。"
  },
  {
    "start": 9010,
    "end": 23150,
    "text": "しかし、この分野で何が起きているのか、何がエキサイティングなのか、何がチャンスなのか、そしてこの技術をすべての人のために発展させるために私たちが注意すべきことは何なのかを理解することは重要だと思う。"
  },
  {
    "start": 23840,
    "end": 26212,
    "text": "私はグーグルの多くの人々の仕事を紹介する。"
  },
  {
    "start": 26306,
    "end": 29152,
    "text": "この中には、私が共同執筆者として関わった仕事もある。"
  },
  {
    "start": 29216,
    "end": 29924,
    "text": "そうでないものもある。"
  },
  {
    "start": 29962,
    "end": 31700,
    "text": "これはクールな仕事だ。"
  },
  {
    "start": 31770,
    "end": 45370,
    "text": "ということで、このトークのために質問をする方法について、Slidoの番号220-7201をもう1度お見せしましょう。"
  },
  {
    "start": 46940,
    "end": 50360,
    "text": "ということで、まずはいくつかの観察から始めよう。"
  },
  {
    "start": 52140,
    "end": 58876,
    "text": "近年、機械学習は、私たちが考えるコンピューターができることへの期待を大きく変えたと思う。"
  },
  {
    "start": 59058,
    "end": 66012,
    "text": "10年前、15年前を思い返すと、音声認識は一応機能していたが、シームレスではなかった。"
  },
  {
    "start": 66076,
    "end": 67900,
    "text": "エラーも多かった。"
  },
  {
    "start": 67980,
    "end": 72224,
    "text": "コンピュータはピクセルレベルから画像を理解することはできなかった。"
  },
  {
    "start": 72342,
    "end": 76050,
    "text": "そのイメージ言語の中にあったのは、ある種のものだった。"
  },
  {
    "start": 77800,
    "end": 86324,
    "text": "自然言語処理の研究はたくさんあったが、言語概念や多言語データを深く理解していたわけではなかった。"
  },
  {
    "start": 86442,
    "end": 97672,
    "text": "そのような状態から、コンピューターが10年前よりもはるかに優れた方法で私たちの周りの世界を見たり認識したりできるようになることを期待する状態へと、私たちは移行したと思う。"
  },
  {
    "start": 97726,
    "end": 107756,
    "text": "というのも、動物がいつ目を進化させたかを考えてみてほしい。"
  },
  {
    "start": 107938,
    "end": 109992,
    "text": "私たちはコンピューティングにおいて、そういう段階にいる。"
  },
  {
    "start": 110136,
    "end": 115280,
    "text": "私たちは今、見て感じることのできるコンピューターを持っている。"
  },
  {
    "start": 115700,
    "end": 132816,
    "text": "もうひとつは、スケールの拡大、コンピュート・リソースの大規模な使用、特殊化されたコンピュート、より大規模でより興味深く豊富なデータセット、より大規模な機械学習モデルについてお話ししますが、これらすべてをスケーリングすることで、より良い結果が得られる傾向があるということです。"
  },
  {
    "start": 132848,
    "end": 135700,
    "text": "ここ10～15年はそうだった。"
  },
  {
    "start": 135850,
    "end": 139460,
    "text": "規模を拡大するたびに、物事は良くなっていく。"
  },
  {
    "start": 139530,
    "end": 149044,
    "text": "突然、新しい能力が現れたり、ある問題の精度が閾値に達し、それまでは使い物にならなかったのに、突然使えるようになったりする。"
  },
  {
    "start": 149092,
    "end": 150970,
    "text": "新しいことを可能にする。"
  },
  {
    "start": 152060,
    "end": 167708,
    "text": "また、この新しい機械学習ベースのパラダイムのために実行したい計算の種類は、多くの基本的なcpusが効果的に実行するように設計された、従来の手書きの曲がりくねったc＋＋＋コードとはかなり異なる。"
  },
  {
    "start": 167804,
    "end": 172508,
    "text": "そのため、これらの計算をより効率的に実行するために、さまざまな種類のハードウェアが必要なのだ。"
  },
  {
    "start": 172604,
    "end": 187990,
    "text": "私たちは、ある意味で、コンピューターにやってもらいたいことを絞り込んで、それを極めてうまく、極めて効率的に行うことができる。"
  },
  {
    "start": 188680,
    "end": 195624,
    "text": "さて、このようなことをいくつか挙げたが、コンピューターにできることはこの10年で驚くほど進歩した。"
  },
  {
    "start": 195742,
    "end": 207048,
    "text": "このことを考えると、画像の生のピクセルから、おそらく10,000か1,000の異なるカテゴリのうちの1つというカテゴリカル・ラベルに行くことになる。"
  },
  {
    "start": 207224,
    "end": 210590,
    "text": "10年前はコンピューターにそんなことはできなかった。"
  },
  {
    "start": 211040,
    "end": 218540,
    "text": "音声波形は、5秒間の音声の中で何が話されていたかを示す。"
  },
  {
    "start": 218700,
    "end": 219932,
    "text": "それが音声認識だ。"
  },
  {
    "start": 219996,
    "end": 223612,
    "text": "私たちはその翻訳で大きな進歩を遂げた。"
  },
  {
    "start": 223676,
    "end": 224544,
    "text": "こんにちは、お元気ですか？"
  },
  {
    "start": 224582,
    "end": 226480,
    "text": "ボンジュール・コマ・テレビへ。"
  },
  {
    "start": 226820,
    "end": 234150,
    "text": "人間の言語を別の言語に翻訳できることは、コンピューターにとって信じられないほど便利な能力だ。"
  },
  {
    "start": 234680,
    "end": 246330,
    "text": "チーターがジープの上に乗っている素敵な休暇の写真というようなものから、そのような説明までできるようになった。"
  },
  {
    "start": 247340,
    "end": 253080,
    "text": "レオパードのようなカテゴライズされたラベルではなく、そのシーンで何が起こっているのかを説明するちょっとした短い文章だ。"
  },
  {
    "start": 253500,
    "end": 254648,
    "text": "それはとても素晴らしいことだ。"
  },
  {
    "start": 254734,
    "end": 256684,
    "text": "私たちはこの面で大きな進歩を遂げた。"
  },
  {
    "start": 256802,
    "end": 263070,
    "text": "しかし、もっと驚くべきことは、ここ数年で、こうしたミスの多くを覆すことができたということだ。"
  },
  {
    "start": 263520,
    "end": 272364,
    "text": "ヒョウのようなカテゴライズされたラベルをコンピューターに入力すると、50種類から100種類のヒョウの画像が生成される。"
  },
  {
    "start": 272492,
    "end": 277932,
    "text": "あるいは、テキストを音声に変換しているだけのオーディオ波形に対して、外はどれほど寒いのだろう。"
  },
  {
    "start": 277996,
    "end": 280564,
    "text": "それは以前からあったことだが、ずいぶん改善された。"
  },
  {
    "start": 280762,
    "end": 285124,
    "text": "翻訳の逆転はそれほど驚くことではないが、どんどん良くなっている。"
  },
  {
    "start": 285242,
    "end": 300836,
    "text": "そして、欲しいイメージの短い説明からイメージを得たり、時には欲しいイメージの短いビデオクリップを得たり、言語で音を説明するとオーディオクリップを得たりもする。"
  },
  {
    "start": 301028,
    "end": 310990,
    "text": "これらの能力は、今まさに現れ始めているもので、10年前とは対照的に、今コンピューターで何ができるのか、とてもエキサイティングなことだと思う。"
  },
  {
    "start": 312320,
    "end": 316044,
    "text": "過去10年間のレベルアップを見てみよう。"
  },
  {
    "start": 316172,
    "end": 335796,
    "text": "スタンフォード大学が開発したImagenetと呼ばれるベンチマークは、ご存知の方も多いと思いますが、基本的には、カラー画像の束とラベル、1000個のラベルのうちの1つのような形式の学習データを入手し、そのような約100万個の画像でシステムを学習させます。"
  },
  {
    "start": 335898,
    "end": 338644,
    "text": "すると、見たこともないような映像が次々と映し出される。"
  },
  {
    "start": 338682,
    "end": 344696,
    "text": "今までに見たことのない新しいイメージの実際のラベルは何なのかを予測しなければならない。"
  },
  {
    "start": 344798,
    "end": 353870,
    "text": "機械学習の仕事の多くは、データに対して行った観察から、新しい設定や見たことのない新しい画像に対してどのように一般化するか？"
  },
  {
    "start": 357680,
    "end": 364668,
    "text": "コンテストが実施された最初の年である2011年、優勝作品の精度は50.9％だった。"
  },
  {
    "start": 364844,
    "end": 385824,
    "text": "アレックス・クルシェフスキー・イリオスカヴァーとジェフリー・ヒントンによる『アレックスネット』として親しまれている、非常に有名な画期的な論文である。"
  },
  {
    "start": 385872,
    "end": 391960,
    "text": "その年の約28の応募者の中で、ニューラルネットワークを使っていたのは彼らだけだった。"
  },
  {
    "start": 393820,
    "end": 395940,
    "text": "これは大きな改善である。"
  },
  {
    "start": 396020,
    "end": 414664,
    "text": "翌年、ほぼすべての応募者がニューラルネットワークを使用したのは、これが非常に画期的な改善であり、ヒョウを示す特徴を手作業で作り出そうとするのではなく、実際の生データから学習するという実に主要なアプローチであることが明らかだったからだ。"
  },
  {
    "start": 414712,
    "end": 416992,
    "text": "それは本当に難しいことだ。"
  },
  {
    "start": 417046,
    "end": 426530,
    "text": "キリンや車ではなく、ヒョウだと判断するために、どのような機能をデザインするのか。"
  },
  {
    "start": 428020,
    "end": 430656,
    "text": "これはかなり大きな進歩だと思う。"
  },
  {
    "start": 430688,
    "end": 434868,
    "text": "しかし、それ以降に起こった改善を無視するのは簡単だ。"
  },
  {
    "start": 434954,
    "end": 441108,
    "text": "例えば、このタスクの精度は63％から91％になった。"
  },
  {
    "start": 441284,
    "end": 444120,
    "text": "これは本当にすごいことだ。"
  },
  {
    "start": 444190,
    "end": 450424,
    "text": "このタスクの人間の正確さは、実際にはかなり難しいので、そのレベルを少し下回ることが分かっている。"
  },
  {
    "start": 450462,
    "end": 453604,
    "text": "1000のカテゴリー、40種類の犬種がある。"
  },
  {
    "start": 453652,
    "end": 456376,
    "text": "人は自分が写真を見つめているかどうか、実際にはわからない。"
  },
  {
    "start": 456408,
    "end": 457532,
    "text": "それはどの犬種ですか？"
  },
  {
    "start": 457586,
    "end": 459548,
    "text": "それはとても素晴らしいことだ。"
  },
  {
    "start": 459714,
    "end": 466764,
    "text": "これは約10年のスパンで、音声認識を見れば、コンピューター・ビジョンに革命をもたらした。"
  },
  {
    "start": 466812,
    "end": 472428,
    "text": "これは、音声認識の精度を測定するための一般的なオープンソースのベンチマークです。"
  },
  {
    "start": 472524,
    "end": 479620,
    "text": "ここでは単語の誤り率、つまり間違っている単語の割合を測定している。"
  },
  {
    "start": 479770,
    "end": 484964,
    "text": "13.25%から2.5%に下がった。"
  },
  {
    "start": 485082,
    "end": 486576,
    "text": "これはもっと短いスパンだ。"
  },
  {
    "start": 486608,
    "end": 488150,
    "text": "たった5年のことだ。"
  },
  {
    "start": 488780,
    "end": 498456,
    "text": "基本的には、6、7個に1個は間違い、40個に1個は間違いという感じだ。"
  },
  {
    "start": 498558,
    "end": 502512,
    "text": "これは、これらのシステムの使い勝手に大きな違いをもたらす。"
  },
  {
    "start": 502596,
    "end": 509550,
    "text": "突然、これに頼ることができるようになり、Eメールを口述することができるようになった。"
  },
  {
    "start": 512080,
    "end": 517032,
    "text": "だから、スケールアップすることでモデルの質が向上することを申し上げた。"
  },
  {
    "start": 517096,
    "end": 521212,
    "text": "だから、より効率的にスケールアップできるハードウェアが欲しいんだ。"
  },
  {
    "start": 521276,
    "end": 528932,
    "text": "どうすれば、同じ額の計算ハードウェアや同じ額のエネルギーで、さらに高品質なモデルを得ることができるのか？"
  },
  {
    "start": 528986,
    "end": 530272,
    "text": "その方が効率的だからだ。"
  },
  {
    "start": 530416,
    "end": 537524,
    "text": "つまり、コンピューターや機械学習の設計方法を変えるということだ。"
  },
  {
    "start": 537562,
    "end": 542548,
    "text": "最適化されたハードウェアははるかに効率的で、世代を重ねるごとに大きな改善が見られる。"
  },
  {
    "start": 542644,
    "end": 547720,
    "text": "これにより、より経済的でエネルギーコストの低い、より大規模なモデルが可能になる。"
  },
  {
    "start": 548540,
    "end": 555790,
    "text": "最近誰もが使っている機械学習モデルの一種であるニューラルネットワークには、2つの優れた特性がある。"
  },
  {
    "start": 556960,
    "end": 559550,
    "text": "1つ目は、精度を落としても構わないということだ。"
  },
  {
    "start": 560080,
    "end": 568064,
    "text": "例えば、機械学習モデルの計算を小数点以下6桁ではなく、1桁か2桁の精度で行っても構わない。"
  },
  {
    "start": 568182,
    "end": 575856,
    "text": "多くの場合、これらの最適化アルゴリズムの中には、モデルをより良く学習させるために、明示的にノイズを導入するものもある。"
  },
  {
    "start": 575958,
    "end": 583590,
    "text": "だから、精度を落とすというのは、ある意味、学習プロセスにちょっとしたノイズを加えることだと考えることができる。"
  },
  {
    "start": 584840,
    "end": 598436,
    "text": "もう1つの性質は、ある意味で、すべての計算、つまり、皆さんが騒いでいるすべてのアルゴリズムは、実際には、さまざまな線形代数演算を組み立てる方法の転置にすぎないということです。"
  },
  {
    "start": 598548,
    "end": 603100,
    "text": "行列の乗算やさまざまな種類のベクトル演算などだ。"
  },
  {
    "start": 604400,
    "end": 611928,
    "text": "つまり、これらのアルゴリズムは、多くの異なる線形代数プリミティブを繰り返し適用したものなのだ。"
  },
  {
    "start": 612024,
    "end": 626690,
    "text": "だから、もし精度の低い線形代数を得意とするコンピューターを作ることができれば、計算コストやエネルギーコストを削減しながら、本当に質の高いモデルを学習することができる。"
  },
  {
    "start": 627860,
    "end": 635172,
    "text": "グーグルでは、このようなシステムを構築する必要性を感じていました。"
  },
  {
    "start": 635306,
    "end": 644372,
    "text": "テンソル・プロセッシング・ユニット（TPU）と呼ばれるものの初期バージョンは、低精度線形代数用に設計されたアーキテクチャだ。"
  },
  {
    "start": 644516,
    "end": 646772,
    "text": "最初に作ったのは推論用だった。"
  },
  {
    "start": 646836,
    "end": 664008,
    "text": "すでに訓練された機械学習モデルを持っていて、それを製品に適用しようとする場合、その画像に何が写っているかを認識するために、あるいは誰かがマイクで音声を発し、その音声が何を言っているかを認識するために、すべての計算を適用する必要がある。"
  },
  {
    "start": 664194,
    "end": 673570,
    "text": "第一世代は、TPU V 1というアクセラレーターを搭載したシングルカードシステムでした。"
  },
  {
    "start": 674100,
    "end": 685780,
    "text": "これは、エネルギー効率と計算性能の両面で、当時のCPUを使うよりも30倍から80倍ほど向上していた。"
  },
  {
    "start": 687000,
    "end": 697556,
    "text": "TPUの後の世代では、複数のチップで構成され、学習と推論の両方を行う大規模なシステムに焦点を当てた。"
  },
  {
    "start": 697668,
    "end": 701268,
    "text": "これが、このチップを4つ搭載したTPU V 2ボードだ。"
  },
  {
    "start": 701444,
    "end": 711624,
    "text": "TPU V 3ボードはこのボードに近いものだが、水を加えたので、実際にチップの表面に水が行き渡る。"
  },
  {
    "start": 711672,
    "end": 719984,
    "text": "TPU製の4枚のボードの冷却を助けるために、クールな色を追加した。"
  },
  {
    "start": 720102,
    "end": 726312,
    "text": "その3世代後のものは、ポッドと呼ばれる大きなシステムに組み立てられるように設計されている。"
  },
  {
    "start": 726396,
    "end": 729744,
    "text": "そのため、ポッドは世代を重ねるごとに規模を拡大していった。"
  },
  {
    "start": 729792,
    "end": 737904,
    "text": "最初のものは、ポッド内に非常にシンプルだが広帯域のネットワークを持っている。"
  },
  {
    "start": 737952,
    "end": 744932,
    "text": "つまり、基本的にこの第一世代の各チップは、2次元メッシュで4つの隣接チップに接続されていた。"
  },
  {
    "start": 744996,
    "end": 750280,
    "text": "これらのラックには、ある意味で16×16のチップのグリッドがある。"
  },
  {
    "start": 750780,
    "end": 753880,
    "text": "すべてのチップは基本的にワイヤーで隣のチップと接続されている。"
  },
  {
    "start": 754220,
    "end": 757180,
    "text": "つまり、ネットワークでルーティングをする必要がない。"
  },
  {
    "start": 757520,
    "end": 765570,
    "text": "そのため、非常に高速な帯域幅で、非常に低コストな接続が可能になる。"
  },
  {
    "start": 766260,
    "end": 771244,
    "text": "その次の世代では、8ラックで1024チップに拡張された。"
  },
  {
    "start": 771372,
    "end": 777270,
    "text": "その次の世代では、64個のチップをそれぞれ64ラック使っていた。"
  },
  {
    "start": 777640,
    "end": 788740,
    "text": "実際にはこれらのデータセンター列の複数であり、4096個のチップで1.1エクサフロップスの低精度浮動小数点キャビテーションを実現する。"
  },
  {
    "start": 789340,
    "end": 800388,
    "text": "そして、昨年末に公表した最新世代がV型5シリーズだ。"
  },
  {
    "start": 800484,
    "end": 802084,
    "text": "2つのバリエーションがある。"
  },
  {
    "start": 802132,
    "end": 829376,
    "text": "1つは、256チップのポッドを持つ推論用のもので、V5Pはチップあたりのメモリ量が多く、チップ間の帯域幅も広く、メモリ帯域幅も広く、16ビット浮動小数点演算性能はチップあたりペタフロップの半分近く、int型8ビット演算性能はその2倍ある。"
  },
  {
    "start": 829568,
    "end": 836180,
    "text": "つまり、これらのポッドの1つはさらに大きく、9000チップ近く、大量のコンピュート4個分ということになる。"
  },
  {
    "start": 839040,
    "end": 840936,
    "text": "では、言葉について話そう。"
  },
  {
    "start": 840968,
    "end": 852290,
    "text": "さて、画像認識や音声認識の進歩についてお話ししましたが、実は言語は、コンピューターができることの中で、人々が最も変化を感じている分野のひとつだと思います。"
  },
  {
    "start": 853060,
    "end": 858848,
    "text": "実は、ニューラルネットワーク以前から、言語モデルには注目していたんだ。"
  },
  {
    "start": 858944,
    "end": 862710,
    "text": "私はグーグル翻訳チームの何人かとパートナーを組んだ。"
  },
  {
    "start": 863240,
    "end": 877384,
    "text": "彼らは基本的に、非常に質の高い翻訳ができる有能なシステムを持っていたが、それは2週間で50センテンスとかしか翻訳できないような研究コンテスト用に設計されていた。"
  },
  {
    "start": 877502,
    "end": 879268,
    "text": "その後、エントリーを提出する。"
  },
  {
    "start": 879444,
    "end": 887256,
    "text": "そのため、翻訳する文章ごとに検索する必要がある20万ものngramをディスクシークするようなものだ。"
  },
  {
    "start": 887448,
    "end": 894364,
    "text": "だから、もし本当に質の高い翻訳があるのなら、それを実際に実践するのもいいんじゃないかと言ったんだ。"
  },
  {
    "start": 894492,
    "end": 898320,
    "text": "そこで、私たちはNgramモデルを提供するシステムを構築した。"
  },
  {
    "start": 898390,
    "end": 904428,
    "text": "基本的には、2兆個のトークンの中で、5つの単語がどれくらいの頻度で出現するかを統計していた。"
  },
  {
    "start": 904604,
    "end": 909360,
    "text": "ということは、5グラムで約3000億個ということになる。"
  },
  {
    "start": 909520,
    "end": 912832,
    "text": "そうなれば、それを何台ものマシンのメモリーに保存するだけだ。"
  },
  {
    "start": 912896,
    "end": 917700,
    "text": "文章を訳すのに必要な10万個の事柄について、並行して調べるのだ。"
  },
  {
    "start": 917860,
    "end": 939644,
    "text": "つまり、5グラムを検索してそこにデータがない場合、その前にある4グラムを検索して、もしあればそれを使うというものだ。"
  },
  {
    "start": 939682,
    "end": 942304,
    "text": "それがなければ、3グラムを調べたりする。"
  },
  {
    "start": 942422,
    "end": 951570,
    "text": "これは、よりファンシーなナイフやナイ・スムージングに比べればそれなりにうまくいった。"
  },
  {
    "start": 952500,
    "end": 957968,
    "text": "つまり、ここから得られる教訓のひとつは、大量のデータに対するシンプルなテクニックが非常に効果的だということだ。"
  },
  {
    "start": 958064,
    "end": 967210,
    "text": "これは私のキャリアを通しての教訓であり、とてもシンプルなことをすれば、データが語ってくれる。"
  },
  {
    "start": 969900,
    "end": 975844,
    "text": "その後、私の同僚であるタマシュ・ミコロフが分散表現に興味を持った。"
  },
  {
    "start": 975892,
    "end": 983688,
    "text": "単語をある種の離散的なものとして表現するのではなく、非常に高次元のベクトルとして表現したい。"
  },
  {
    "start": 983784,
    "end": 989020,
    "text": "異なる単語を異なる、例えば100次元のベクトルで表現する。"
  },
  {
    "start": 989520,
    "end": 1000400,
    "text": "訓練プロセスを通じて、似たような文脈で登場する単語同士を近づけ、異なる文脈で登場する単語を引き離そうとする。"
  },
  {
    "start": 1001300,
    "end": 1016016,
    "text": "もし、非常に大量のデータに対して、比較的単純なトレーニング目標でトレーニングするのであれば、「もし、これらのものが似たような文脈で現れるのであれば、それらを近づけ、異なるのであれば、それらを遠ざける」ということになる。"
  },
  {
    "start": 1016128,
    "end": 1035148,
    "text": "この100次元空間では、100次元空間を理解するのは難しいが、高次元空間では、非常に似ているもの同士が近くに集まっている。"
  },
  {
    "start": 1035234,
    "end": 1042290,
    "text": "山や丘や崖があれば、それらは高次元空間で互いに近接する傾向がある。"
  },
  {
    "start": 1043220,
    "end": 1055940,
    "text": "空間上の点も面白いが、おそらくもっと面白いのは、この高次元空間では方向にも意味があるということだ。"
  },
  {
    "start": 1056440,
    "end": 1065940,
    "text": "例えば、このスペースでキングがどこにいるかを見て、クイーンに行きたいと思ったら、ある方向に行くことがわかった。"
  },
  {
    "start": 1066020,
    "end": 1072010,
    "text": "を計算するには、ベクトル \"king \"を \"queen \"から引く。"
  },
  {
    "start": 1072460,
    "end": 1083660,
    "text": "キングからクイーンを引いた方向が、男から女になる方向とほぼ同じであることがわかった。"
  },
  {
    "start": 1084080,
    "end": 1088588,
    "text": "だから方向には意味があり、方向が違えば意味も違ってくる。"
  },
  {
    "start": 1088674,
    "end": 1095330,
    "text": "動詞の現在形から過去形になることは、動詞が何であるかに関係なく、方向が異なる。"
  },
  {
    "start": 1096340,
    "end": 1100540,
    "text": "つまり、分散された表現には大きな力があるということだ。"
  },
  {
    "start": 1100700,
    "end": 1106790,
    "text": "単語を表す100次元のベクトルには、さまざまな情報がエンコードされているのだ。"
  },
  {
    "start": 1111150,
    "end": 1118862,
    "text": "その後、私の同僚であるイリヤ、オリエル、クオックは、配列対配列学習と呼ばれるモデルを開発した。"
  },
  {
    "start": 1118996,
    "end": 1124714,
    "text": "つまり、基本的にはニューラルネットワークを使い、入力シーケンスがある。"
  },
  {
    "start": 1124842,
    "end": 1126698,
    "text": "翻訳の場合を考えてみよう。"
  },
  {
    "start": 1126794,
    "end": 1140402,
    "text": "英文を一単語ずつ入力すると、システムは自分の現在の状態と、今見ている新しい単語から表現を構築し、その状態を更新する。"
  },
  {
    "start": 1140456,
    "end": 1157050,
    "text": "個々の単語に対する分散表現と同じように、これまで見てきた文章に対する分散表現ができ、それを長期短期記憶と呼ばれるリカレント・ニューラル・ネットワークで更新することができる。"
  },
  {
    "start": 1157710,
    "end": 1168150,
    "text": "そして、文末マーカーにぶつかったら、その文の訳を吐き出すようにモデルを訓練する。"
  },
  {
    "start": 1168230,
    "end": 1173774,
    "text": "英語の文章とフランス語の文章が同じ意味であるような、たくさんのトレーニングデータがある。"
  },
  {
    "start": 1173892,
    "end": 1174862,
    "text": "モデルをトレーニングする。"
  },
  {
    "start": 1174916,
    "end": 1182418,
    "text": "この英文を見たら、この仏文を吐き出す。これを大量のペア学習データで繰り返すだけだ。"
  },
  {
    "start": 1182584,
    "end": 1190146,
    "text": "確かに、この入力シーケンスに対してニューラル・エンコーダーを使えば、状態を初期化することができる。"
  },
  {
    "start": 1190248,
    "end": 1198402,
    "text": "入力された文章を吸収した私は、今度は一語ずつ正しい翻訳文を解読したい。"
  },
  {
    "start": 1198546,
    "end": 1201730,
    "text": "これをニューラル・デコーダーの状態を初期化するのに使う。"
  },
  {
    "start": 1201810,
    "end": 1206890,
    "text": "これを拡大すれば、翻訳精度が大幅に向上する。"
  },
  {
    "start": 1210750,
    "end": 1221706,
    "text": "その後、オリオールとクオックは、翻訳の代わりに文脈を利用したマルチターン会話が可能であることを示すワークショップ論文を発表した。"
  },
  {
    "start": 1221898,
    "end": 1248710,
    "text": "つまり、基本的には、ある相手との一連のやり取りがあり、それにコンピューターモデルが応答し、相手やその人がまた別の応答を口にし、複数のターンがあり、それがあなたのコンテキスト、以前の複数のターンのやり取りであり、その前に起こった複数のターンの物事のコンテキストにおいて、良い返事を生成するように訓練することができるのです。"
  },
  {
    "start": 1248780,
    "end": 1249750,
    "text": "同じモデルだ。"
  },
  {
    "start": 1249820,
    "end": 1258458,
    "text": "基本的にはシーケンス対シーケンスのモデルだが、シーケンスには、これまでに起こったすべての会話のターンのコンテキストが初期化されている。"
  },
  {
    "start": 1258624,
    "end": 1265850,
    "text": "そうすれば、ニューラル言語モデルを使った効果的なマルチ・ターナー・インタラクションが可能になる。"
  },
  {
    "start": 1268370,
    "end": 1276682,
    "text": "その後、グーグルの他の研究者とインターンが集まって、トランスフォーマーと呼ばれるモデルを考え出した。"
  },
  {
    "start": 1276746,
    "end": 1280850,
    "text": "このモデルで、これはリカレント・モデルだと言ったのを覚えている。"
  },
  {
    "start": 1280920,
    "end": 1296422,
    "text": "トークンを吸収して新しい状態を更新し、その新しい状態でさらに別のトークンを吸収して状態を更新する。"
  },
  {
    "start": 1296556,
    "end": 1298614,
    "text": "それは非常に順を追ったプロセスですよね？"
  },
  {
    "start": 1298652,
    "end": 1304102,
    "text": "なぜなら、3つ目の単語を吸収するためには、2つ目の単語の処理を終えている必要があるからだ。"
  },
  {
    "start": 1304156,
    "end": 1308540,
    "text": "2つ目の単語を処理するためには、1つ目の単語を処理する必要がある。"
  },
  {
    "start": 1309070,
    "end": 1310170,
    "text": "それはあまり良くない。"
  },
  {
    "start": 1310240,
    "end": 1317018,
    "text": "コンピューターでもそうだが、私たちはできることなら順番にではなく、並行して物事を進めたい。"
  },
  {
    "start": 1317104,
    "end": 1332580,
    "text": "このモデルは、入力されたすべての単語を並列に処理することで、単語を順次更新していく単一の状態ではなく、さまざまな断片に注目するようにしたのだ。"
  },
  {
    "start": 1333030,
    "end": 1338254,
    "text": "つまり、その州を単一の分散型代表に押し込めようとするなということだ。"
  },
  {
    "start": 1338302,
    "end": 1346966,
    "text": "見たことのあるすべてのトークンや単語の表現を保存して、それを参加させるだけでいい。"
  },
  {
    "start": 1347068,
    "end": 1359770,
    "text": "文のこの部分を訳すとか、文のあの部分を訳すとか、そういうことをするときに注目すべき部分に注意を払えば、10倍から100倍少ない計算量で高い精度が得られる。"
  },
  {
    "start": 1360350,
    "end": 1377978,
    "text": "コンピュータのハードウエアが改良され、特殊なハードウエアが開発されたことで、時間の経過とともに大きな改善がもたらされた。"
  },
  {
    "start": 1378074,
    "end": 1389380,
    "text": "アルゴリズムの進歩によるトレーニング能力、それに機械学習ハードウェア、より大規模なモデル、より高性能なモデルなどだ。"
  },
  {
    "start": 1393350,
    "end": 1405686,
    "text": "そこであるグループは、リカレント・モデルの代わりにトランスフォーマー・モデルを使って、会話形式のデータをスケールアップして訓練することにした。"
  },
  {
    "start": 1405788,
    "end": 1415430,
    "text": "その結果、非常に良い結果が得られた。特に、この結果を評価する方法については、その回答が理にかなったものであった。"
  },
  {
    "start": 1415510,
    "end": 1429230,
    "text": "チャットボットが漠然としたものになりすぎないように、例えば、あなたがチャットボットとやりとりしたことに対して、あなたが実際に何か賢明なことを言いたかったのはいいことだ。"
  },
  {
    "start": 1430850,
    "end": 1439970,
    "text": "さて、これらのいくつかについて話したが、ニューラル言語モデルの進歩があり、ニューラル・チャットの研究も進歩している。"
  },
  {
    "start": 1440870,
    "end": 1454418,
    "text": "Know、ニューラル会話モデル、Mina chat、1年ほど前にGoogleでリリースしたOpenAI bardのGPT、そしてニューラル言語モデルの進歩。"
  },
  {
    "start": 1454434,
    "end": 1458982,
    "text": "シークエンスからシークエンスへの仕事では、OpenAIのGPT-2の話をした。"
  },
  {
    "start": 1459116,
    "end": 1463674,
    "text": "これらの中には、モデルの大まかなスケールの感覚として考えることができるパラメータ数を持つものもある。"
  },
  {
    "start": 1463792,
    "end": 1467174,
    "text": "2019年には5億のパラメータが必要となる。"
  },
  {
    "start": 1467302,
    "end": 1474278,
    "text": "グーグルの5つの仕事、私の同僚の110億のパラメータ、非常に有能だ。"
  },
  {
    "start": 1474384,
    "end": 1480910,
    "text": "トランスフォーマーの仕事は、このTとTのように、これらの多くを支えている。"
  },
  {
    "start": 1481060,
    "end": 1482494,
    "text": "トランスフォーマーは以上だ。"
  },
  {
    "start": 1482542,
    "end": 1496950,
    "text": "現在では、トランスフォーマーモデルとアーキテクチャーの進歩により、計算が10倍から100倍向上し、大規模な言語モデルの基盤として利用されるようになっている。"
  },
  {
    "start": 1497850,
    "end": 1518486,
    "text": "GPT-3はDeepMindの同僚たちから、PalmはGoogle Researchから、ChinchillaはDeepMindから、PalmはGoogle Researchから2つ、そしてGPT、4つはOpenAIから、そしてGeminiは私が同僚のOriel vignalsと共同でリードしているプロジェクトです。"
  },
  {
    "start": 1518678,
    "end": 1527018,
    "text": "私たちは、さまざまな研究室で、有能なマルチモーダルモデルの構築に取り組んでいる人々を大勢集めている。"
  },
  {
    "start": 1527034,
    "end": 1537134,
    "text": "私たちがやりたかったことのひとつは、単にテキストを理解する言語ベースのモデルから、すべての異なるモダリティを同時に扱えるモデルに移行することでした。"
  },
  {
    "start": 1537182,
    "end": 1553910,
    "text": "テキストと画像、あるいは音声とテキストを入力し、何かをするように指示すれば、どんな種類のモダリティであっても、流暢かつ首尾一貫して処理することができる。"
  },
  {
    "start": 1553980,
    "end": 1554502,
    "text": "与える。"
  },
  {
    "start": 1554556,
    "end": 1562300,
    "text": "ですから、1年ほど前にこのプロジェクトを始めたときの私たちの目標は、世界最高のマルチモーダルモデルをトレーニングし、Google全体で使用することでした。"
  },
  {
    "start": 1563950,
    "end": 1573950,
    "text": "ジェミニに関するブログがあり、ウェブサイトがあり、ジェミニ・チームによる技術レポートがある。"
  },
  {
    "start": 1576050,
    "end": 1579162,
    "text": "ジェミニは最初から本当にマルチモーダルだった。"
  },
  {
    "start": 1579226,
    "end": 1582942,
    "text": "私たちがしたことのひとつは、先ほども言ったように、テキストを扱うだけにはしたくなかったということです。"
  },
  {
    "start": 1582996,
    "end": 1589086,
    "text": "私たちは画像やビデオ、音声を扱いたいと考え、それを一連のトークンに変換した。"
  },
  {
    "start": 1589198,
    "end": 1592098,
    "text": "その上で、トランスフォーマーに基づくモデルをトレーニングする。"
  },
  {
    "start": 1592264,
    "end": 1595682,
    "text": "となると、2つの異なるデコード・パスがあることになる。"
  },
  {
    "start": 1595746,
    "end": 1612570,
    "text": "そしてもうひとつは、変換器が学習した状態でデコーダを初期化し、その状態から画像のピクセルの完全なセットに移行する。"
  },
  {
    "start": 1613710,
    "end": 1616234,
    "text": "私たちは、これらの一連のテキストをインターリーブすることをサポートします。"
  },
  {
    "start": 1616272,
    "end": 1619814,
    "text": "テキスト入力と画像入力を与えるようなものではない。"
  },
  {
    "start": 1619862,
    "end": 1622398,
    "text": "ビデオ用にインターリーブすることもできる。"
  },
  {
    "start": 1622484,
    "end": 1645400,
    "text": "ビデオフレームとそれを説明するテキストを入れ、さらに別のビデオフレームとテキスト、あるいはテキストの中で話されている音声のクローズドキャプションを入れるかもしれません。そして、トランスフォーマーに、トレーニング中にこれらのモダリティすべてに触れたという事実を利用させて、与えたいさまざまなモダリティに共通する表現を構築させるのです。"
  },
  {
    "start": 1647210,
    "end": 1652834,
    "text": "V、ジェミニの1世代には3種類のサイズがあるんだ。"
  },
  {
    "start": 1652882,
    "end": 1657654,
    "text": "ウルトラは、我々が持っている中で最もスケールが大きく、最も高性能なモデルだ。"
  },
  {
    "start": 1657772,
    "end": 1665270,
    "text": "プロはデータセンターで運用するのにちょうどいいサイズで、さまざまな製品の文脈で使っています。"
  },
  {
    "start": 1665430,
    "end": 1679246,
    "text": "先週発表したばかりのプロモデルやウルトラモデルで動いている。"
  },
  {
    "start": 1679428,
    "end": 1686926,
    "text": "そしてナノモデルでは、これらの機械学習モデルの多くを、小型の携帯電話やラップトップなど、デバイス上で実行できるようにしたい。"
  },
  {
    "start": 1687038,
    "end": 1692494,
    "text": "その点、ナノモデルは非常に効率的で、サイズも手頃だ。"
  },
  {
    "start": 1692542,
    "end": 1696600,
    "text": "これらをクオンタイズしてさらに小さくしたりすることもできる。"
  },
  {
    "start": 1698250,
    "end": 1717626,
    "text": "私たちのトレーニング・インフラストラクチャーは、非常にスケーラブルなファブリックが必要であり、そのファブリックは、あなたが望む計算の非常に高度な記述を指定し、その計算を利用可能なハードウェアにマッピングするシステムです。"
  },
  {
    "start": 1717728,
    "end": 1720054,
    "text": "だから、このポッドがあると言ったんだ。"
  },
  {
    "start": 1720182,
    "end": 1733454,
    "text": "だから、例えば、あなたの計算をこう表現するかもしれない。私が気にするのはこの2つの部分だ。"
  },
  {
    "start": 1733492,
    "end": 1743698,
    "text": "この部分はあるポッドに、この部分は別のポッドに置くことにして、チップの位置と、その間のトポロジーと帯域幅を把握する。"
  },
  {
    "start": 1743784,
    "end": 1750166,
    "text": "このチップが他のチップと通信する必要がある場合、このリンクを使う。"
  },
  {
    "start": 1750268,
    "end": 1761338,
    "text": "モデルのこの部分がこっちで通信する必要がある場合、データセンター・ネットワークに送られる。"
  },
  {
    "start": 1761424,
    "end": 1767260,
    "text": "機械学習の研究者や開発者はそれを気にする必要がない。"
  },
  {
    "start": 1767890,
    "end": 1772270,
    "text": "その観点からは、単に理解するだけでなく、異なるパフォーマンス特性がある。"
  },
  {
    "start": 1775650,
    "end": 1782674,
    "text": "スケールの大きなモデルをトレーニングすることのひとつは、スケールを大きくすればするほど、失敗が起こるということだ。"
  },
  {
    "start": 1782792,
    "end": 1789970,
    "text": "マシンが死んだり、TPUチップの1つがオーバーヒートしたり、何らかの形で誤作動を起こしたりする。"
  },
  {
    "start": 1790120,
    "end": 1792706,
    "text": "だから、失敗を最小限に抑えることは本当に重要だ。"
  },
  {
    "start": 1792888,
    "end": 1798614,
    "text": "あなたが最小限に抑えたいと思っている失敗の中には、ほとんど人間的なもの、自業自得のものもある。"
  },
  {
    "start": 1798652,
    "end": 1808342,
    "text": "例えば、私たちはマシンのカーネルをアップグレードする方法を一手に引き受けていた。"
  },
  {
    "start": 1808486,
    "end": 1822442,
    "text": "それらがすべて同じ1000台のマシンの計算の一部であるなら、実際には、マシンをダウンさせ、1000台すべてのカーネルを同時にアップグレードし、そしてそれらを立ち上げる方が、全体を通してローリング障害を起こすよりも望ましい。"
  },
  {
    "start": 1822506,
    "end": 1827150,
    "text": "修理とアップグレードのプロセスを最適化するんだ。"
  },
  {
    "start": 1827490,
    "end": 1839982,
    "text": "回復が早ければ早いほど、実際の前進に役立つからだ。"
  },
  {
    "start": 1840046,
    "end": 1852614,
    "text": "これは、チェックポイントからの回復やシステムの他の部分の起動待ちとは対照的に、モデルトレーニングが実際に有用な前進を遂げている時間の割合である。"
  },
  {
    "start": 1852812,
    "end": 1864470,
    "text": "チェックポイントからリカバリーするために分散ファイルシステムに行くのではなく、他のマシンにあるメモリからモデル状態の他のコピーから素早くリカバリーするのだ。"
  },
  {
    "start": 1864550,
    "end": 1872080,
    "text": "そのため、回復にかかる時間は数分ではなく、5秒から10秒程度である。"
  },
  {
    "start": 1874450,
    "end": 1890100,
    "text": "学習データに関しては、このモデルをマルチモーダルなものにしたいので、大量のウェブ文書、さまざまな種類の書籍、さまざまなプログラミング言語のコード、それに画像、音声、動画データを使って学習させたい。"
  },
  {
    "start": 1890470,
    "end": 1893806,
    "text": "私たちは、そのようなデータセットをフィルタリングするためのヒューリスティックな方法を持っている。"
  },
  {
    "start": 1893998,
    "end": 1900706,
    "text": "あるものは手書きのヒューリスティックなもので、あるものはモデルベースの分類法である。"
  },
  {
    "start": 1900738,
    "end": 1901800,
    "text": "いろいろな意味で。"
  },
  {
    "start": 1902410,
    "end": 1908966,
    "text": "トレーニングデータの最終的な混合は、より小さなモデルでのアブレーションによって決定される。"
  },
  {
    "start": 1908998,
    "end": 1912054,
    "text": "より小さなスケールのモデルを、異なるミックスで走らせるつもりだ。"
  },
  {
    "start": 1912102,
    "end": 1919174,
    "text": "32％のコードを使うべきか、それとも27％のコードを使うべきか。"
  },
  {
    "start": 1919222,
    "end": 1925934,
    "text": "それをよりよく理解するために、トレーニングの終盤にドメインに関連するデータのウェイトを増やすなどの工夫をしている。"
  },
  {
    "start": 1925972,
    "end": 1934450,
    "text": "多言語能力を向上させるために、例えば、トレーニングの終盤に多言語データをもっと充実させたい。"
  },
  {
    "start": 1935030,
    "end": 1950246,
    "text": "データの質は本当に興味深く、重要な研究分野だと思います。本当に質の高いデータを持つことで、気になるタスクでのモデルのパフォーマンスに大きな違いが出ることがわかりました。"
  },
  {
    "start": 1950348,
    "end": 1959340,
    "text": "ということは、ある意味では、実際に使っているモデル・アーキテクチャと同じか、場合によってはそれ以上に重要だということだ。"
  },
  {
    "start": 1961710,
    "end": 1964300,
    "text": "今後の研究にとってかなり重要な分野だと思う。"
  },
  {
    "start": 1964750,
    "end": 1974960,
    "text": "質の高い例と低い例を識別するなど、カリキュラムを自動的に学習する能力を持つことは重要なようだ。"
  },
  {
    "start": 1978460,
    "end": 1986748,
    "text": "モデルをトレーニングするだけでなく、モデルの最高の資質を引き出すにはどうすればいいのか？"
  },
  {
    "start": 1986834,
    "end": 1994748,
    "text": "モデルがより効果的な方法で質問に答えられるようにするには、実際にどのように質問をすればいいのだろうか？"
  },
  {
    "start": 1994914,
    "end": 2001200,
    "text": "例えば、モデルに自分の仕事を見せるよう求めることで、モデルの精度が向上し、解釈しやすくなる。"
  },
  {
    "start": 2001780,
    "end": 2006556,
    "text": "そこで私の同僚たちは、思考の連鎖を促すというテクニックを考え出した。"
  },
  {
    "start": 2006748,
    "end": 2013764,
    "text": "小学校3年生の算数の授業を思い出すと、先生はいつも自分の作品を見せるように勧めていたよね。"
  },
  {
    "start": 2013882,
    "end": 2029988,
    "text": "彼らがそうしたい理由は、答えにたどり着くまでのあなたの思考プロセスを見るためであると同時に、次のステップは何なのか、この複雑な問題をどのように小さなステップに分解していけばいいのかを考えるように促すためでもある。"
  },
  {
    "start": 2030164,
    "end": 2043212,
    "text": "だから、モデルに質問する場合、普通は答えたい質問の例を与えて、その質問に対する実際の答えを与え、それから新しい質問をして、その質問に答えてもらう。"
  },
  {
    "start": 2043346,
    "end": 2051568,
    "text": "だから、ここに質問の例がある。そして、モデルが教えられた答え方は、ただ答えを考えて、それを与えるというものだ。"
  },
  {
    "start": 2051734,
    "end": 2059510,
    "text": "モデル出力では、答えは50となっているが、これは間違いである。"
  },
  {
    "start": 2060200,
    "end": 2065910,
    "text": "その代わり、モデルに頼んで実演してもらうとしたら、どうやって自分の仕事を見せるのか？"
  },
  {
    "start": 2066760,
    "end": 2069632,
    "text": "ショーンは5つのおもちゃから始めたんだ。"
  },
  {
    "start": 2069696,
    "end": 2072292,
    "text": "おもちゃを2つずつもらったとしたら、4つ増えることになる。"
  },
  {
    "start": 2072436,
    "end": 2073064,
    "text": "4は9だ。"
  },
  {
    "start": 2073102,
    "end": 2074410,
    "text": "答えは9だ。"
  },
  {
    "start": 2074860,
    "end": 2078330,
    "text": "小学校3年生の算数の先生が誇りに思うような仕事だ。"
  },
  {
    "start": 2079420,
    "end": 2089820,
    "text": "さらに重要なのは、そうすることで、モデルは実際に答えにたどり着くための、より漸進的なステップを導き出すということだ。"
  },
  {
    "start": 2089970,
    "end": 2101010,
    "text": "なぜなら、正しい答えを導き出すためのステップを考える時間が長くなったからだ。"
  },
  {
    "start": 2102660,
    "end": 2104432,
    "text": "かなり劇的な効果だ。"
  },
  {
    "start": 2104566,
    "end": 2105250,
    "text": "そうだろう？"
  },
  {
    "start": 2106820,
    "end": 2110560,
    "text": "この2つの線は、スケールの異なる同じ基礎モデルである。"
  },
  {
    "start": 2110900,
    "end": 2115264,
    "text": "ご覧のように、これらは2つの異なる数学指向のベンチマークである。"
  },
  {
    "start": 2115392,
    "end": 2120532,
    "text": "右は8年生の数学の問題で、これは算数の問題集だ。"
  },
  {
    "start": 2120666,
    "end": 2126692,
    "text": "標準的なプロンプトを与えただけでは、回答の質はかなり悪い。"
  },
  {
    "start": 2126756,
    "end": 2135550,
    "text": "ある時点で、モデルのスケールが十分に大きくなり、思考を連鎖的に促しながら質問すると、突然、精度がかなり跳ね上がる。"
  },
  {
    "start": 2136160,
    "end": 2147330,
    "text": "このようなモデルに対して、どのように質問を投げかければ、より解釈しやすく、より正しい答えを導き出せるかという、実に興味深い科学があるということだ。"
  },
  {
    "start": 2148900,
    "end": 2153264,
    "text": "さて、それではジェミニモデルにおけるマルチモーダル推論について話そう。"
  },
  {
    "start": 2153302,
    "end": 2158800,
    "text": "このモデルで何ができるかを理解するには、いいものの例がいいと思う。"
  },
  {
    "start": 2158950,
    "end": 2160896,
    "text": "これがプロンプトだ。"
  },
  {
    "start": 2161008,
    "end": 2176088,
    "text": "これはある生徒による物理の問題の解答で、問題の写真と、その生徒が手書きで書いた答えがあります。"
  },
  {
    "start": 2176174,
    "end": 2178888,
    "text": "それがまた、思考の連鎖を促すようなスタイルなんだ。"
  },
  {
    "start": 2178974,
    "end": 2180344,
    "text": "生徒は正しい答えを得たか？"
  },
  {
    "start": 2180382,
    "end": 2183240,
    "text": "もしそれが間違っているなら、何が間違っているのかを説明し、問題を解決してください。"
  },
  {
    "start": 2183390,
    "end": 2188140,
    "text": "計算にはlatexを使用し、最終的な答えは小数点以下2桁で四捨五入してください。"
  },
  {
    "start": 2188480,
    "end": 2190008,
    "text": "これがインプットだ。"
  },
  {
    "start": 2190104,
    "end": 2195772,
    "text": "手書きの文字とか、斜面を滑るスキーヤーとか、そういう陳腐なイメージだ。"
  },
  {
    "start": 2195826,
    "end": 2198040,
    "text": "エネルギー保存とか、ばかばかしい。"
  },
  {
    "start": 2198200,
    "end": 2200080,
    "text": "これがモデルの出力である。"
  },
  {
    "start": 2200230,
    "end": 2202448,
    "text": "生徒が正解を得られなかった。"
  },
  {
    "start": 2202534,
    "end": 2206240,
    "text": "生徒がスロープのスタート地点で位置エネルギーの計算を間違えた。"
  },
  {
    "start": 2206580,
    "end": 2209500,
    "text": "スタート時の位置エネルギーはMGHで与えられる。"
  },
  {
    "start": 2209660,
    "end": 2211296,
    "text": "生徒はスロープの長さを使った。"
  },
  {
    "start": 2211328,
    "end": 2214432,
    "text": "計算上、高さではなく斜辺になるのだろう。"
  },
  {
    "start": 2214496,
    "end": 2218224,
    "text": "正しい解答は、つまり、総計を意味するんだ。"
  },
  {
    "start": 2218352,
    "end": 2227444,
    "text": "したがって、これは実際にはlatexで書かれているが、読みやすいようにレンダリングして値を代入している、と書くことができる。"
  },
  {
    "start": 2227492,
    "end": 2227944,
    "text": "あれだ。"
  },
  {
    "start": 2227982,
    "end": 2230948,
    "text": "この問題は小数点以下2桁まで計算できた。"
  },
  {
    "start": 2231124,
    "end": 2233660,
    "text": "これが何を意味するのか考えてみよう。"
  },
  {
    "start": 2233730,
    "end": 2234376,
    "text": "突然だ。"
  },
  {
    "start": 2234408,
    "end": 2246012,
    "text": "マルチモーダル入力のような、ホワイトボードの複雑な絵や問題をモデルに与えて、何かをするように指示すれば、それができる。"
  },
  {
    "start": 2246146,
    "end": 2248688,
    "text": "いつもうまくいくとは限らないが、うまくいくことはある。"
  },
  {
    "start": 2248854,
    "end": 2253232,
    "text": "これは素晴らしい教育ツールになる。"
  },
  {
    "start": 2253366,
    "end": 2264404,
    "text": "生徒が自分で物事を解決しようとして、その解決策を写真に撮り、システムが何が間違っていたのかを理解する手助けをする。"
  },
  {
    "start": 2264602,
    "end": 2277972,
    "text": "個別指導の場合、1対1の人間家庭教師による教育の方が、より広範な教室での教育の場合よりも2標準偏差高い結果が得られることがわかっている。"
  },
  {
    "start": 2278036,
    "end": 2283400,
    "text": "個別指導という点では、それに近づけるのでは？"
  },
  {
    "start": 2283560,
    "end": 2286940,
    "text": "その可能性は私たちの手の届くところにあると思う。"
  },
  {
    "start": 2289120,
    "end": 2301692,
    "text": "さて、評価はジェミニの能力を定性的に示したようなものだが、さまざまな特性について比較してみるのもいいだろう。"
  },
  {
    "start": 2301836,
    "end": 2308304,
    "text": "評価は、モデルの長所と短所を見極め、トレーニングがうまくいっているかどうかを理解するのに役立つ。"
  },
  {
    "start": 2308342,
    "end": 2311652,
    "text": "私たちは常にこれらの指標を評価しながらトレーニングを行っている。"
  },
  {
    "start": 2311706,
    "end": 2315220,
    "text": "このモデルは、何を変えるべきかの決断を下すのに役立つ。"
  },
  {
    "start": 2315290,
    "end": 2318372,
    "text": "数学の成績が期待より低いのだろうか？"
  },
  {
    "start": 2318426,
    "end": 2322484,
    "text": "だから、もっと数学に特化したデータを混ぜてトレーニングしたほうがいいかもしれない。"
  },
  {
    "start": 2322602,
    "end": 2325320,
    "text": "多言語パフォーマンスはどうなるのか？"
  },
  {
    "start": 2326460,
    "end": 2343820,
    "text": "複雑なトレードオフがたくさんあって、トレーニングの最初に決断することもあれば、オンラインでモニターしながら、原理原則に基づいた決断を下すこともある。"
  },
  {
    "start": 2345860,
    "end": 2358710,
    "text": "つまり、最高レベルのまとめとして、32のアカデミックベンチマークを調べたところ、ジェミニのウルトラモデルは32のうち30で最先端の性能を必要とした。"
  },
  {
    "start": 2359880,
    "end": 2369060,
    "text": "だから、これらのいくつかを深く掘り下げて見てみると、文章重視、一般的な推論、数学重視のベンチマークがたくさんある。"
  },
  {
    "start": 2369800,
    "end": 2382984,
    "text": "ジェミニ・ウルトラをGPT4と比較した場合、一般的にこのような問題ではGPT4が先行技術である。"
  },
  {
    "start": 2383102,
    "end": 2386092,
    "text": "だから、8つのうち7つで最先端を行っている。"
  },
  {
    "start": 2386226,
    "end": 2394628,
    "text": "MMLUの90％は、57の異なる科目から出題される非常に幅広い問題群なので興味深い。"
  },
  {
    "start": 2394824,
    "end": 2398960,
    "text": "化学、数学、国際法、哲学。"
  },
  {
    "start": 2399540,
    "end": 2410772,
    "text": "このベンチマークを作成したグループは、人間の専門家レベルのパフォーマンスを89.6％、あるいは89.8と測定した。"
  },
  {
    "start": 2410906,
    "end": 2417812,
    "text": "つまり、57のカテゴリーで人間の専門家レベルのパフォーマンスを上回っているのだ。"
  },
  {
    "start": 2417866,
    "end": 2419030,
    "text": "私たちはそれで満足している。"
  },
  {
    "start": 2420200,
    "end": 2424490,
    "text": "コーディング関連のものはこの下に、数学関連のものはこの下にたくさんある。"
  },
  {
    "start": 2425340,
    "end": 2427304,
    "text": "ああ、9割のことは言ったよ。"
  },
  {
    "start": 2427502,
    "end": 2434136,
    "text": "画像理解ベンチマークを見ると、これらは現在、マルチモーダルな側面に入ってきている。"
  },
  {
    "start": 2434318,
    "end": 2439950,
    "text": "我々は、8つのベンチマークのうち8つで最先端の結果を得た。"
  },
  {
    "start": 2440560,
    "end": 2447010,
    "text": "私たちが論文を発表する1週間前にこのベンチマークが発表され、私たちはそれを見たことがなかった。"
  },
  {
    "start": 2447700,
    "end": 2461524,
    "text": "我々のValチームはすぐにこのベンチマークを我々のValセットに追加した。"
  },
  {
    "start": 2461642,
    "end": 2471770,
    "text": "見たことのないベンチマークで好成績を残せると、いつもうれしいものだ。テストセットへのトレーニングデータの漏れなどをいつも心配しているからね。"
  },
  {
    "start": 2473980,
    "end": 2481032,
    "text": "映像の理解度を見ると、やはりこのモデルのマルチモーダルな能力は非常に優れている。"
  },
  {
    "start": 2481086,
    "end": 2493470,
    "text": "重要な英語料理、ビデオキャプションベンチマーク、ビデオ質問応答など、6つのベンチマークのうち6つで最先端を行く。"
  },
  {
    "start": 2494480,
    "end": 2513924,
    "text": "音声に注目すると、4つの異なる公的音声認識ベンチマーク、音声翻訳ベンチマーク、最先端のm505、多言語機能などでの単語エラー率は非常に優れている。"
  },
  {
    "start": 2513962,
    "end": 2515990,
    "text": "私たちは5つのうち4つで最新技術を駆使している。"
  },
  {
    "start": 2516520,
    "end": 2526264,
    "text": "というのも、これらのモデルを評価し、このレベルの詳細な能力を本当に理解することは、途方もない作業だからだ。"
  },
  {
    "start": 2526382,
    "end": 2529850,
    "text": "それはとても素晴らしいことだ。"
  },
  {
    "start": 2530460,
    "end": 2536616,
    "text": "しかし、ジェミニがかなり高性能であることは確かだ。"
  },
  {
    "start": 2536808,
    "end": 2540350,
    "text": "論文にはプロとナノの測定値もある。"
  },
  {
    "start": 2542480,
    "end": 2542988,
    "text": "オーケー。"
  },
  {
    "start": 2543074,
    "end": 2557490,
    "text": "このような大規模なトランスフォーマーモデルは、実際に驚くほど首尾一貫した会話を生成することができる。これは、ある種のニューラル会話モデルの進化であり、そのトランスフォーマーベースのバージョンである。"
  },
  {
    "start": 2557940,
    "end": 2560880,
    "text": "バードを見ると、スライドを更新しなければならないようだ。"
  },
  {
    "start": 2560960,
    "end": 2564230,
    "text": "google.comのジェミニになります。"
  },
  {
    "start": 2564920,
    "end": 2572768,
    "text": "実は数カ月前、ジェミニのモデルを使う前に、吟遊詩人ジェミニで講演を準備していたんだ。"
  },
  {
    "start": 2572944,
    "end": 2578232,
    "text": "ホットチップとテンソル・プロセッシング・ユニットの文字を逆にしてくれ、と言ったんだ。"
  },
  {
    "start": 2578366,
    "end": 2580776,
    "text": "このモデルで何ができるかを示すためにね"
  },
  {
    "start": 2580798,
    "end": 2584184,
    "text": "と書いてある。"
  },
  {
    "start": 2584222,
    "end": 2585596,
    "text": "彼らは素晴らしい。"
  },
  {
    "start": 2585778,
    "end": 2589288,
    "text": "Pythonでも可能です。"
  },
  {
    "start": 2589464,
    "end": 2590670,
    "text": "これがコードだ。"
  },
  {
    "start": 2591840,
    "end": 2593836,
    "text": "逆文字列を関数として定義する。"
  },
  {
    "start": 2593938,
    "end": 2597968,
    "text": "これがその文字列で、その逆文字列をプリントする。"
  },
  {
    "start": 2598134,
    "end": 2599340,
    "text": "コードの使用は慎重に。"
  },
  {
    "start": 2599420,
    "end": 2601090,
    "text": "私はいつもそれを勧めている。"
  },
  {
    "start": 2601860,
    "end": 2604370,
    "text": "そして、その説明も続いている。"
  },
  {
    "start": 2605460,
    "end": 2609308,
    "text": "コードではまず、reverse stringという関数を定義し、入力として文字列を受け取る。"
  },
  {
    "start": 2609324,
    "end": 2615200,
    "text": "文字列を反転させる関数は、文字列コードをループし、反転させて表示する。"
  },
  {
    "start": 2615280,
    "end": 2617270,
    "text": "他に何かお手伝いできることはありますか？"
  },
  {
    "start": 2619320,
    "end": 2620932,
    "text": "これはかなりすごいことだろう？"
  },
  {
    "start": 2620986,
    "end": 2630344,
    "text": "誰かが質問して、その通りにやってくれたんだけど、ついでにプログラミングってやつと、パイソンのコードも書いてあった。"
  },
  {
    "start": 2630542,
    "end": 2633390,
    "text": "こうするんだ。"
  },
  {
    "start": 2634640,
    "end": 2636670,
    "text": "そのためのコードを書く。"
  },
  {
    "start": 2637040,
    "end": 2638284,
    "text": "とてもクールだと思う。"
  },
  {
    "start": 2638322,
    "end": 2640910,
    "text": "またしても、本当に勉強になる機会だった。"
  },
  {
    "start": 2643360,
    "end": 2644972,
    "text": "他に何かお手伝いできることはありますか？"
  },
  {
    "start": 2645026,
    "end": 2645244,
    "text": "もちろんだ。"
  },
  {
    "start": 2645282,
    "end": 2646760,
    "text": "tpusについて詳しく教えてください。"
  },
  {
    "start": 2646920,
    "end": 2649948,
    "text": "つまり、このモデルはかなりの世界知識を持っている。"
  },
  {
    "start": 2650044,
    "end": 2653936,
    "text": "TPUが基本的にそうであることは知っている。"
  },
  {
    "start": 2654038,
    "end": 2657712,
    "text": "機械学習を加速させるためにグーグルが開発した特殊なハードウェア・プロセッサーだ。"
  },
  {
    "start": 2657846,
    "end": 2660420,
    "text": "効率とパフォーマンスの向上に役立つ。"
  },
  {
    "start": 2660760,
    "end": 2661796,
    "text": "以下はその利点の一部である。"
  },
  {
    "start": 2661898,
    "end": 2663460,
    "text": "より速いトレーニング、推論。"
  },
  {
    "start": 2664440,
    "end": 2666100,
    "text": "繰り返しになるが、これが役に立つことを願っている。"
  },
  {
    "start": 2669640,
    "end": 2674280,
    "text": "チャットボットの面白いところは、さまざまな性格を持つことができることだと思います。"
  },
  {
    "start": 2675740,
    "end": 2680890,
    "text": "バルドはあなたの助け舟のようなもので、たくさんの質問に答えてくれるだろう。"
  },
  {
    "start": 2684080,
    "end": 2700768,
    "text": "また、LMSysという公開サイトでは、さまざまなチャットエージェントを評価することができます。"
  },
  {
    "start": 2700934,
    "end": 2705836,
    "text": "その方法は、ユーザー自身にプロンプトを書かせるというものだ。"
  },
  {
    "start": 2706028,
    "end": 2718320,
    "text": "彼らは、システムに設定した2つのランダムなチャットボットを選び、その両方にクエリーとプロンプトを送信し、匿名化された出力を表示する。"
  },
  {
    "start": 2718400,
    "end": 2720950,
    "text": "右と左、どっちがいい？"
  },
  {
    "start": 2721740,
    "end": 2725124,
    "text": "そして、そこからEloスコアと呼ばれるものを計算することができる。"
  },
  {
    "start": 2725252,
    "end": 2732656,
    "text": "Eloは確かハンガリーの数学者で、チェスプレイヤーをランク付けする方法を開発しようとしていた。"
  },
  {
    "start": 2732788,
    "end": 2740344,
    "text": "だから、トーナメントがあるときは、基本的に1人の対戦相手に勝つと、より多くのEloポイントを得ることができる。"
  },
  {
    "start": 2740392,
    "end": 2744728,
    "text": "だから、トーナメントではEloスコアを計算することができる。"
  },
  {
    "start": 2744824,
    "end": 2752256,
    "text": "大雑把に言うと、Eloスコアが100高いということは、64％の確率で強い方が勝つということだ。"
  },
  {
    "start": 2752438,
    "end": 2756400,
    "text": "400点は10対1のアドバンテージを意味する。"
  },
  {
    "start": 2757880,
    "end": 2767732,
    "text": "というわけで、プロレベル・モデルは、この試合で2番目に高いEloスコアを記録している。"
  },
  {
    "start": 2767786,
    "end": 2770028,
    "text": "おそらく30種類くらいのモデルがあると思う。"
  },
  {
    "start": 2770064,
    "end": 2773720,
    "text": "私はリーダーボードのトップを表示している。"
  },
  {
    "start": 2773870,
    "end": 2779690,
    "text": "これは無料サービスのようなもので、こういったものはそうではない。"
  },
  {
    "start": 2787220,
    "end": 2793792,
    "text": "それで、このことをツイートしたら、その見たこともない人が、すごくいいって言ってくれたんだ。"
  },
  {
    "start": 2793846,
    "end": 2794768,
    "text": "この例をご覧いただきたい。"
  },
  {
    "start": 2794854,
    "end": 2801076,
    "text": "私たちは、人々が気に入り、実際に公開したいと思うバルドとの交流を共有する方法を持っています。"
  },
  {
    "start": 2801178,
    "end": 2803108,
    "text": "だから、彼はそうすることにした。"
  },
  {
    "start": 2803194,
    "end": 2810924,
    "text": "をクリックすると、次の各国の人口100万人当たりの企業数を推定することができる。"
  },
  {
    "start": 2810992,
    "end": 2813124,
    "text": "アメリカ、イギリス、韓国、台湾、シンガポール。"
  },
  {
    "start": 2813172,
    "end": 2814890,
    "text": "数字を表形式で提示する。"
  },
  {
    "start": 2815260,
    "end": 2817816,
    "text": "そう双子座は言った。"
  },
  {
    "start": 2817918,
    "end": 2819752,
    "text": "これはその数を示した表である。"
  },
  {
    "start": 2819806,
    "end": 2820852,
    "text": "ブラブラ、ブラブラ、ブラブラ。"
  },
  {
    "start": 2820996,
    "end": 2821672,
    "text": "あれだ。"
  },
  {
    "start": 2821726,
    "end": 2824312,
    "text": "彼が尋ねたように、100万人当たりの企業数である。"
  },
  {
    "start": 2824446,
    "end": 2828796,
    "text": "ご覧の通り、イングランドの数字が最も高く、その結果も一種の解釈になっている。"
  },
  {
    "start": 2828898,
    "end": 2832936,
    "text": "イギリスが最も多く、次いでアメリカ、韓国、台湾、シンガポールとなっている。"
  },
  {
    "start": 2833048,
    "end": 2835096,
    "text": "重要なのは、これらはあくまでも推定であるということだ。"
  },
  {
    "start": 2835208,
    "end": 2838080,
    "text": "実際の数字はソースや定義によって異なる場合がある。"
  },
  {
    "start": 2838500,
    "end": 2839612,
    "text": "参考になれば幸いだ。"
  },
  {
    "start": 2839676,
    "end": 2841250,
    "text": "他に質問があれば教えてください。"
  },
  {
    "start": 2843380,
    "end": 2847328,
    "text": "それで彼は、各社の数字はどこで見つけたんだ？"
  },
  {
    "start": 2847494,
    "end": 2850580,
    "text": "ああ、ソースを示さなかったことをお詫びする。"
  },
  {
    "start": 2851080,
    "end": 2853556,
    "text": "情報の出所を透明にすることは重要だ。"
  },
  {
    "start": 2853658,
    "end": 2857584,
    "text": "私が使っている会社の数字は、さまざまな情報源から得たものだ。"
  },
  {
    "start": 2857712,
    "end": 2860496,
    "text": "アメリカについては、ダン・ブラッドスキーのデータベースを使用した。"
  },
  {
    "start": 2860688,
    "end": 2864628,
    "text": "イギリスは国家統計局を使ったよ。"
  },
  {
    "start": 2864724,
    "end": 2867444,
    "text": "なお、これらの情報源は定義が多少異なっている。"
  },
  {
    "start": 2867492,
    "end": 2869156,
    "text": "その機微を理解している。"
  },
  {
    "start": 2869188,
    "end": 2869432,
    "text": "そうだね。"
  },
  {
    "start": 2869486,
    "end": 2873960,
    "text": "会社を構成するものにはさまざまな定義があるようにね。"
  },
  {
    "start": 2874110,
    "end": 2880220,
    "text": "どこに行けば、さまざまな種類のデータを入手できるかを知っていたんだ。"
  },
  {
    "start": 2880290,
    "end": 2883310,
    "text": "それを記憶していたわけではないが、活用することはできた。"
  },
  {
    "start": 2884740,
    "end": 2885840,
    "text": "かなりいい。"
  },
  {
    "start": 2886340,
    "end": 2886752,
    "text": "オーケー。"
  },
  {
    "start": 2886806,
    "end": 2897836,
    "text": "私が重要だと思うもうひとつの傾向は、こうした一般的なモデルをさらに洗練させることで、素晴らしいドメイン固有のモデルを作ることができるということだ。"
  },
  {
    "start": 2898028,
    "end": 2912808,
    "text": "私の同僚たちは、私たちが以前に研究したパーム・モデル、そしてパーム2モデルを、一般的なテキストで訓練したような汎用モデルに改良し、さらに医療データで訓練することにしました。"
  },
  {
    "start": 2912894,
    "end": 2915860,
    "text": "医学的な種類の質問と医療記事。"
  },
  {
    "start": 2916020,
    "end": 2919688,
    "text": "彼らが見つけたのはメドパームモデルだった。"
  },
  {
    "start": 2919774,
    "end": 2925320,
    "text": "1人目は、実際に医師会の合格点を超えた。"
  },
  {
    "start": 2925480,
    "end": 2926492,
    "text": "その時"
  },
  {
    "start": 2926546,
    "end": 2937724,
    "text": "そして6ヵ月後、パーム2モデルでメドパーム2を訓練したところ、実際にこの特定のタスクでメディカルボードでエキスパートレベルの成績を収めた。"
  },
  {
    "start": 2937772,
    "end": 2942092,
    "text": "さて、これは完全な汎用セッティングではない。"
  },
  {
    "start": 2942156,
    "end": 2953670,
    "text": "医学的な質問の束のようなものだが、本当に有能な一般的モデルを持ち、それを特定の問題に対してドメイン特有の方法でトレーニングすることの能力を示している。"
  },
  {
    "start": 2955320,
    "end": 2961736,
    "text": "では、ジェネレイティブ・モデルについて、画像と映像の制作について手短に説明しよう。"
  },
  {
    "start": 2961838,
    "end": 2964920,
    "text": "世界のトレンドとして目にしたことがあるだろう。"
  },
  {
    "start": 2964990,
    "end": 2967268,
    "text": "いくつかの研究プロジェクトがある。"
  },
  {
    "start": 2967364,
    "end": 2968760,
    "text": "パーティーと想像。"
  },
  {
    "start": 2969580,
    "end": 2986180,
    "text": "私が言ったクールなことのひとつに、視覚的イメージに何を求めるかを記述したプロンプトを与え、その文章を処理するエンコーディング表現に制約されたイメージを生成するモデルを持つことができる、というものがある。"
  },
  {
    "start": 2986280,
    "end": 2990508,
    "text": "そして、それを条件として、画像のピクセルを生成する。"
  },
  {
    "start": 2990604,
    "end": 2995884,
    "text": "レンブラント風の壮大な図書館の油絵の中を蒸気機関車が通り過ぎる。"
  },
  {
    "start": 2996012,
    "end": 2997030,
    "text": "そうだ。"
  },
  {
    "start": 2998440,
    "end": 3008240,
    "text": "xから作られた巨大なコブラの蛇。xはコーンパンケーキ、寿司、サラダかもしれないが、どれが好き？"
  },
  {
    "start": 3008320,
    "end": 3015050,
    "text": "私は獰猛なレタスの蛇が好きだけど、トウモロコシの蛇もなかなかいいね。"
  },
  {
    "start": 3016300,
    "end": 3018836,
    "text": "暖炉に白いソファが置かれたリビングルームの写真。"
  },
  {
    "start": 3018868,
    "end": 3021924,
    "text": "壁には抽象画が描かれ、窓からは明るい光が差し込む。"
  },
  {
    "start": 3022052,
    "end": 3029532,
    "text": "もし、私のようにプレゼンテーションか何かでそのような写真が必要になったら、そうすればいい。"
  },
  {
    "start": 3029666,
    "end": 3031288,
    "text": "かなり細かくなる。"
  },
  {
    "start": 3031384,
    "end": 3032232,
    "text": "説明"
  },
  {
    "start": 3032376,
    "end": 3035144,
    "text": "馬に乗るパンダのハイコントラスト写真。"
  },
  {
    "start": 3035272,
    "end": 3037456,
    "text": "パンダは魔法使いの帽子をかぶり、本を読んでいる。"
  },
  {
    "start": 3037558,
    "end": 3042812,
    "text": "灰色のコンクリート壁、色とりどりの花、そして平和の文字を背景に、馬が路上に立っている。"
  },
  {
    "start": 3042956,
    "end": 3044080,
    "text": "ブラブラ、ブラブラ。"
  },
  {
    "start": 3044420,
    "end": 3047620,
    "text": "一眼レフ写真、日中の照明。"
  },
  {
    "start": 3048200,
    "end": 3049510,
    "text": "これでいい。"
  },
  {
    "start": 3049960,
    "end": 3057110,
    "text": "もっともらしい解釈はいくつもあるが、少なくともあなたが求めたことの一例は得られた。"
  },
  {
    "start": 3059020,
    "end": 3061156,
    "text": "これは現在、吟遊詩人に統合されている。"
  },
  {
    "start": 3061268,
    "end": 3074620,
    "text": "イリノイ州にある幼稚園から12歳までの公立学校は、マスコットであるハリネズミのハイパーリンクの画像を作成できることにとても興奮していた。"
  },
  {
    "start": 3074960,
    "end": 3085804,
    "text": "このAIの波に乗ってハイパーリンク・サーフィンが行われているのだが、この人物は、ロンドンのコスタ・コーヒーでコーヒーを買う人間のプロンプトにとても興奮していた。"
  },
  {
    "start": 3085932,
    "end": 3102484,
    "text": "コスタ・コーヒーは非常に人気のあるコーヒー・チェーンだが、このようなモデルがしばしば苦労してきたことのひとつに、要求されたテキストを忠実に配置し、本物のフォントのように見せることなどがある。"
  },
  {
    "start": 3102522,
    "end": 3104790,
    "text": "これはかなりいい仕事をしている。"
  },
  {
    "start": 3106280,
    "end": 3137836,
    "text": "詳細についてはあまり話しませんが、基本的には、分散ベクトルベースの設定でその文章が何であるかを表現するプロンプトを入力し、それを条件として、まず小さなスケールの画像を生成するようにモデルを学習させ、次に、その低スケール、低解像度の画像とテキスト埋め込みの両方を条件として、画像の解像度を上げるように設計された別のモデルを使用します。"
  },
  {
    "start": 3137948,
    "end": 3153376,
    "text": "次に、1024×1024のフルスケールの画像を生成するために、より大きな画像とテキスト埋め込みの条件でもう一度適用すると、スケールの効果を実感できます。"
  },
  {
    "start": 3153408,
    "end": 3186140,
    "text": "4つの異なるモデルを350,000,000から200,000,000のパラメータで訓練し、同じプロンプト、つまり、オレンジ色のパーカーを着て青いサングラスをかけたカンガルーが、シドニーのオペラハウスの前の芝生の上に立っていて、胸に「ようこそ、友よ」と書かれた看板を持っているポートレート写真を与えると、カンガルーの面影は最小のスケールで表現され、オレンジ色のパーカーを着用していると思いますが、それ以外の看板はあまりありませんが、やはりテキストで苦労しました。"
  },
  {
    "start": 3186210,
    "end": 3190592,
    "text": "もう少し規模を大きくして、カンガルーが少し良くなったとしよう。"
  },
  {
    "start": 3190726,
    "end": 3197990,
    "text": "シドニー・オペラハウスがそれに似ていることは少しわかったが、ちょっとずんぐりしていて、ディテールはあまりない。"
  },
  {
    "start": 3199560,
    "end": 3204912,
    "text": "友達を迎えるには近いけど、ベグニかもしれない。"
  },
  {
    "start": 3204976,
    "end": 3205910,
    "text": "よく分からない。"
  },
  {
    "start": 3207560,
    "end": 3216136,
    "text": "そして拡大すると、シドニー・オペラハウスとカンガルー、オレンジのパーカー、そして適切なテキストが映し出される。"
  },
  {
    "start": 3216318,
    "end": 3230376,
    "text": "この10年で進歩が見られるのは、基本的にスケールと、より優れたトレーニング方法とアルゴリズムが、より質の高い結果に貢献しているからだ。"
  },
  {
    "start": 3230488,
    "end": 3235330,
    "text": "このグラフは事実上同じことを言っているが、私はカンガルーの方がよく言っていると思う。"
  },
  {
    "start": 3238100,
    "end": 3249056,
    "text": "また、目に見えない形でさまざまな形で人々を助けている機械学習がたくさんあることを認識することも重要だと思う。"
  },
  {
    "start": 3249168,
    "end": 3262504,
    "text": "最近のスマートフォンに搭載されている多くのカメラ機能は、計算写真手法と機械学習手法を組み合わせることで、数年前から格段に向上している。"
  },
  {
    "start": 3262702,
    "end": 3275016,
    "text": "ポートレートモードは、背景をぼかし、手前を派手に見せるもので、ポートレートスタイルの写真にはいいテクニックだ。"
  },
  {
    "start": 3275208,
    "end": 3291264,
    "text": "夜間撮影では、非常に暗い状況で画像を撮影しようとする場合、基本的にセンサーから多くの読み取り値を取得し、それらをソフトウェアで統合することで、実際に撮影した条件よりもはるかに高い照明条件を作り出すことができる。"
  },
  {
    "start": 3291302,
    "end": 3298370,
    "text": "また、ポートレートぼかしやカラーポップは、必要なときに必要な機能だ。"
  },
  {
    "start": 3299460,
    "end": 3300408,
    "text": "魔法の消しゴム。"
  },
  {
    "start": 3300444,
    "end": 3309992,
    "text": "もし、あなたが実際に映像を理解し、電柱のひとつを指さして、『これを消してくれ』と言えば、システムはそれができる。"
  },
  {
    "start": 3310046,
    "end": 3317930,
    "text": "滝の写真に他の観光客が写り込んでいて、それが嫌だったのかもしれない。"
  },
  {
    "start": 3318460,
    "end": 3319610,
    "text": "そうだ。"
  },
  {
    "start": 3321020,
    "end": 3327710,
    "text": "携帯電話にはたくさんの機能があり、その多くは、あるモダリティを別のモダリティに変換する方法に関するものだ。"
  },
  {
    "start": 3328560,
    "end": 3333310,
    "text": "時には、通話をスクリーンに映すこともできる。"
  },
  {
    "start": 3334080,
    "end": 3356516,
    "text": "実際に電話に出るのではなく、コンピューターが生成した音声があなたの代わりに電話に出て、相手が何について電話しているのかを尋ね、そして相手が言ったことを書き起こしてくれる。"
  },
  {
    "start": 3356538,
    "end": 3370232,
    "text": "バンク・オブ・アメリカでは、カスタマー・サポートに電話をかけると、ライブ・キャプションが携帯電話で再生されているビデオを取り込み、音声を聞いて、その内容をトランスクリプトやキャプションにしてくれます。"
  },
  {
    "start": 3370286,
    "end": 3375390,
    "text": "このように講義室でビデオを見ようとしていて、音声が人の邪魔にならないようにしたいのかもしれない。"
  },
  {
    "start": 3376800,
    "end": 3385650,
    "text": "これらの多くは、必ずしも気づかれることなく、またその下にどんなテクノロジーがあるのかを考えることなく、人々の携帯電話で実行されている。"
  },
  {
    "start": 3386740,
    "end": 3393852,
    "text": "これは、読み書きの限られた環境にいる人々のために、驚くべき進歩をもたらす。"
  },
  {
    "start": 3393996,
    "end": 3404790,
    "text": "カメラを何かに向けると、何を向けているのか読み取ってくれる。あるいは、その言語を話せなくても、理解しようとしているのであれば、読み取って翻訳してくれる。"
  },
  {
    "start": 3406760,
    "end": 3411240,
    "text": "ここは手短に、このセクションの一部を省略することにしよう。"
  },
  {
    "start": 3412460,
    "end": 3414584,
    "text": "一部省略する。"
  },
  {
    "start": 3414702,
    "end": 3418490,
    "text": "かなり素晴らしい進歩がある。"
  },
  {
    "start": 3419980,
    "end": 3421972,
    "text": "ええ、ではここから始めます。"
  },
  {
    "start": 3422126,
    "end": 3451220,
    "text": "材料科学は、基本的に機械学習が科学の多くの側面に影響を与え始めている、かなり興味深い分野だと思います。科学的仮説空間の興味深い部分を自動探索したり、従来のような大規模なHPCスタイルの計算ではなく、学習型の非常に高速なシミュレーターを作成したりすることで、科学の多くの側面に影響を与え始めています。"
  },
  {
    "start": 3451960,
    "end": 3463300,
    "text": "ある分野では、手作業でコード化されたシミュレーターと機能的に同等でありながら、10万倍速くなったシミュレーターを学ぶことができた。"
  },
  {
    "start": 3463380,
    "end": 3477388,
    "text": "つまり、1,000万種類もの化学物質や材料の可能性を検索し、通常ならもっと多くの計算量を必要とするような、興味深く有望で特定の特性を持つものを特定することができるのだ。"
  },
  {
    "start": 3477554,
    "end": 3489692,
    "text": "そこでディープマインドの同僚たちは、可能性のある材料の中から興味深い特性を持つものを探し出す興味深い方法を実際に研究していた。"
  },
  {
    "start": 3489836,
    "end": 3518196,
    "text": "潜在的な材料をグラフィカルなニューラルネットワークとして表現することができる構造パイプラインと、既知の構造をある種の興味深いもの、隣接するものに変異させることができる組成パイプラインがあり、既存の材料データベースを使用して、エネルギーモデルと安定した興味深い可能性のある化合物の束を出力することができる。"
  },
  {
    "start": 3518388,
    "end": 3532750,
    "text": "つまり、220万個の新しい結晶構造を自動発見したことで、実際にどのような特性を持つのか、研究室で実際に合成する興味深い候補がたくさん出てきたのだ。"
  },
  {
    "start": 3534160,
    "end": 3542096,
    "text": "ヘルスケアのあらゆる場面で機械学習を活用できる大きな可能性があると思う。"
  },
  {
    "start": 3542278,
    "end": 3548164,
    "text": "私たちは医療用画像処理と診断の分野で、かなり長い間、かなりの量の仕事をしてきた。"
  },
  {
    "start": 3548362,
    "end": 3570810,
    "text": "このような問題は、2D画像のものから、MRIや他の種類のスキャンによる3Dボリュームのようなもの、そしてシングルビューのものから、複数のビューや大きな画像、例えば病理用の非常に高解像度のものまで、多岐にわたる。"
  },
  {
    "start": 3571740,
    "end": 3574212,
    "text": "だから、それなりの仕事がある。"
  },
  {
    "start": 3574286,
    "end": 3577324,
    "text": "そのうちの2つについて簡単に話そう。"
  },
  {
    "start": 3577442,
    "end": 3583740,
    "text": "私たちがこの分野で最も長く取り組んでいる分野のひとつが、糖尿病性網膜症の分野です。"
  },
  {
    "start": 3584160,
    "end": 3592060,
    "text": "糖尿病性網膜症は退行性の眼病で、発見が早ければ治療が可能です。"
  },
  {
    "start": 3592140,
    "end": 3596076,
    "text": "そうしないと、視力の全部または一部が失われる可能性がある。"
  },
  {
    "start": 3596188,
    "end": 3603604,
    "text": "糖尿病や糖尿病予備軍のようなリスクのある人は、毎年検査を受けるべきです。"
  },
  {
    "start": 3603722,
    "end": 3611160,
    "text": "世界の多くの地域では、網膜画像を解釈する訓練を受けた眼科医がスクリーニングを行えるだけの眼科医がいないのだ。"
  },
  {
    "start": 3611980,
    "end": 3626190,
    "text": "というのも、訓練された眼科医が画像に注釈をつけて、これは1、これは3、これは2、これは5と言うようなモデルを実際に訓練することができるからだ。"
  },
  {
    "start": 3627280,
    "end": 3635400,
    "text": "認定眼科医をモデルにトレーニングすれば、実際に認定眼科医と同等の効果を持つモデルをトレーニングすることができる。"
  },
  {
    "start": 3635560,
    "end": 3649612,
    "text": "同じトレーニングデータを、このような症例について多くの専門知識と経験を持つ網膜専門医にアノテーションしてもらえば、実際に網膜専門医と同等のモデルをトレーニングすることができる。"
  },
  {
    "start": 3649676,
    "end": 3663480,
    "text": "しかし、ノートパソコンのGPUを使えば、網膜の専門医が行うようなスクリーニングの質を突然実現できる。"
  },
  {
    "start": 3664460,
    "end": 3674140,
    "text": "ですから、私たちはインドの眼科病院ネットワークやタイ政府、フランスやドイツの組織と提携しています。"
  },
  {
    "start": 3674480,
    "end": 3679624,
    "text": "私たちは毎年、たくさんの検診を受けている。"
  },
  {
    "start": 3679672,
    "end": 3690972,
    "text": "皮膚科学は、解釈するのに役立つデータを収集するのに特別な装置を必要としないので、興味深い分野だ。"
  },
  {
    "start": 3691116,
    "end": 3694050,
    "text": "皮膚病の有無は？"
  },
  {
    "start": 3694740,
    "end": 3706052,
    "text": "だから、ビデオで見たように、何かを写真に撮れば、それが何であるかを教えてくれるシステムを導入したんだ。"
  },
  {
    "start": 3706186,
    "end": 3717240,
    "text": "皮膚科のデータベースのようなもので、他の似たような画像があれば、これは非常に深刻なものなのか、それともかなり良性のものなのかを判断するのに役立ちます。"
  },
  {
    "start": 3719980,
    "end": 3720730,
    "text": "オーケー。"
  },
  {
    "start": 3721260,
    "end": 3730268,
    "text": "そして最後に、機械学習手法をより深く、より広く理解することは、世界のより多くの場所で機械学習手法を展開する上で、本当に本当に重要なことだと思う。"
  },
  {
    "start": 3730434,
    "end": 3748308,
    "text": "私たちは、機械学習の基礎的な研究から、すべての製品の多くの場所で機械学習を使用するようになり、機械学習を使用することの意味を考えるための一連の原則について考え始めました。"
  },
  {
    "start": 3748394,
    "end": 3754390,
    "text": "それを応用するためのさまざまな方法について、私たちはどのような配慮をすべきなのだろうか？"
  },
  {
    "start": 3754840,
    "end": 3760112,
    "text": "私たちは2018年に、私たちが考え出した一連の原則を発表した。"
  },
  {
    "start": 3760266,
    "end": 3772190,
    "text": "これらは、機械学習について社内のチームを教育するために作られたものであり、機械学習を自分の関心のある問題に適用しようと考えているときに考えるべきことなのだ。"
  },
  {
    "start": 3772720,
    "end": 3777096,
    "text": "例えば、不公平なバイアスを作り出したり、強化したりしないようにする。"
  },
  {
    "start": 3777208,
    "end": 3783692,
    "text": "多くの場合、これらのモデルを訓練するときは、現実世界のデータで訓練する。"
  },
  {
    "start": 3783826,
    "end": 3789408,
    "text": "それはしばしば、私たちが望む世界ではなく、ありのままの世界である。"
  },
  {
    "start": 3789494,
    "end": 3801780,
    "text": "機械学習モデルを導入する際に本当に重要なのは、不公平な方法で偏ったデータで訓練しないこと、そしてそれを加速させることだ。"
  },
  {
    "start": 3802280,
    "end": 3808660,
    "text": "ある種のバイアスを取り除くために、アルゴリズムベースで適用できるテクニックがたくさんある。"
  },
  {
    "start": 3809720,
    "end": 3825132,
    "text": "私たちが目指しているのは、現在最もよく知られている技術を応用することであり、また、例えば、人々に対する説明責任など、バイアスのかかる分野での技術の進歩に関する研究も行っている。"
  },
  {
    "start": 3825186,
    "end": 3838988,
    "text": "モデルを解釈しやすくすることは、その重要な側面であり、プライバシーに配慮することであり、導入する環境において意味があり、社会的に有益であることだと考えています。"
  },
  {
    "start": 3839164,
    "end": 3842770,
    "text": "だから、これらの多くはある種、活発な研究分野であることを指摘しておこう。"
  },
  {
    "start": 3843140,
    "end": 3855090,
    "text": "私たちは過去5年か6年の間に、公平性や偏見、プライバシーや安全性に関連する約200種類の論文を発表しました。"
  },
  {
    "start": 3856020,
    "end": 3856624,
    "text": "オーケー。"
  },
  {
    "start": 3856742,
    "end": 3860932,
    "text": "結論から言うと、コンピューティングにとってはかなりエキサイティングな時代だと思う。"
  },
  {
    "start": 3860996,
    "end": 3872510,
    "text": "手作業でコード化されたソフトウェアシステムから、学習され、さまざまな興味深い方法で世界と関わり、興味深い方法で人々と関わることができるものへと変化しつつあると思う。"
  },
  {
    "start": 3873440,
    "end": 3886904,
    "text": "現在、コンピューターが取り込み、理解し、生成することのできるモダリティは増え続けており、コンピューターをよりシームレスに、より自然に使うことができるようになると思う。"
  },
  {
    "start": 3887032,
    "end": 3892624,
    "text": "多くの場合、私たちはキーボードを打つこととか、そういうことに限定してしまう。"
  },
  {
    "start": 3892662,
    "end": 3898512,
    "text": "私たちは今、とても自然な方法でコンピューティング・システムと対話する能力を手に入れたと思う。"
  },
  {
    "start": 3898566,
    "end": 3900256,
    "text": "私たちの言うことを理解してくれる。"
  },
  {
    "start": 3900358,
    "end": 3905860,
    "text": "私たちが求めたものであれば、それに応えて自然な音声を出したり、素敵な映像を映し出すことができるだろう。"
  },
  {
    "start": 3906010,
    "end": 3907600,
    "text": "それはとてもエキサイティングなことだと思う。"
  },
  {
    "start": 3907680,
    "end": 3912228,
    "text": "大きなチャンスがあるのは確かだが、責任も大きい。"
  },
  {
    "start": 3912324,
    "end": 3921588,
    "text": "どうすればこの仕事を前進させ、社会的に有益なものにし、それを使って本当に世の中に良いことをすることができるのか。"
  },
  {
    "start": 3921694,
    "end": 3922588,
    "text": "手を貸してくれ。"
  },
  {
    "start": 3922674,
    "end": 3923790,
    "text": "ありがとうございました。"
  },
  {
    "start": 3928720,
    "end": 3929630,
    "text": "そうするよ。"
  },
  {
    "start": 3930480,
    "end": 3933548,
    "text": "もうひとつ、スリド・ナンバーのプラグを貼っておこう。"
  },
  {
    "start": 3933634,
    "end": 3934590,
    "text": "あれだ。"
  },
  {
    "start": 3936100,
    "end": 3938144,
    "text": "ご講演ありがとうございました。"
  },
  {
    "start": 3938342,
    "end": 3940496,
    "text": "ご講演ありがとうございました。"
  },
  {
    "start": 3940598,
    "end": 3943440,
    "text": "これ以上スリッドに質問を送らないでください。"
  },
  {
    "start": 3943940,
    "end": 3944640,
    "text": "オーケー。"
  },
  {
    "start": 3944790,
    "end": 3949350,
    "text": "とてもいいアイデアだが、現時点では圧倒されている。"
  },
  {
    "start": 3950120,
    "end": 3955030,
    "text": "これからいくつか質問をする。"
  },
  {
    "start": 3955800,
    "end": 3962360,
    "text": "スリッドで出題された質問にはいくつかの傾向があった。"
  },
  {
    "start": 3962510,
    "end": 3969400,
    "text": "では、この講堂に来られた方々のために、観客席から1つか2つの質問を受け付けます。"
  },
  {
    "start": 3969900,
    "end": 3975580,
    "text": "質問の1つ、おそらく皆さんが予想している質問から始めさせてください。"
  },
  {
    "start": 3975730,
    "end": 3976188,
    "text": "オーケー。"
  },
  {
    "start": 3976274,
    "end": 3976988,
    "text": "より多くのデータ"
  },
  {
    "start": 3977074,
    "end": 3979964,
    "text": "それはあなたのモデルをより良くすることになるのか？"
  },
  {
    "start": 3980162,
    "end": 3981260,
    "text": "2倍のデータ"
  },
  {
    "start": 3981330,
    "end": 3985820,
    "text": "倍のパフォーマンスが見られるのか？"
  },
  {
    "start": 3985980,
    "end": 3991120,
    "text": "いい質問だし、単純な答えではない。"
  },
  {
    "start": 3991190,
    "end": 3991696,
    "text": "私はそう思う。"
  },
  {
    "start": 3991798,
    "end": 4002756,
    "text": "質の高いデータが多ければ多いほど、その大量のデータで学習する能力があれば、モデルの性能は絶対に向上する。"
  },
  {
    "start": 4002858,
    "end": 4006416,
    "text": "モデルのキャパシティを考えることが重要だ。"
  },
  {
    "start": 4006608,
    "end": 4009412,
    "text": "時にはモデルのスケールも大きくする必要がある。"
  },
  {
    "start": 4009466,
    "end": 4015700,
    "text": "トレーニングデータが多ければ多いほど、かえって不利になる。"
  },
  {
    "start": 4015780,
    "end": 4024956,
    "text": "低品質なデータが多くなると、例えば、数学の問題などを効果的にこなすモデルの能力が低下する可能性がある。"
  },
  {
    "start": 4025058,
    "end": 4032620,
    "text": "微妙なところだが、一般的には、より質の高いデータとモデルのキャパシティを増やせば、モデルはより良くなる。"
  },
  {
    "start": 4032690,
    "end": 4033116,
    "text": "そうだね。"
  },
  {
    "start": 4033218,
    "end": 4044480,
    "text": "次に出てきた質問は、「質の高いトレーニングデータの大半を使い果たした今、llmsの将来はどうなるのか？"
  },
  {
    "start": 4045620,
    "end": 4046912,
    "text": "あなたならどう反応する？"
  },
  {
    "start": 4046966,
    "end": 4049270,
    "text": "その主張には少し同意しかねる。"
  },
  {
    "start": 4049880,
    "end": 4055940,
    "text": "私たちはまだ、例えばビデオでのトレーニングをそれほど始めていないと思う。"
  },
  {
    "start": 4056010,
    "end": 4059936,
    "text": "つまり、我々は少量のビデオを扱ってきたが、世界には膨大な量のビデオデータがある。"
  },
  {
    "start": 4060058,
    "end": 4070324,
    "text": "視覚的、音声的なデータを通して世界を理解することは、多くの言語を訓練することとは異なると思う。"
  },
  {
    "start": 4070372,
    "end": 4075836,
    "text": "両方やりたいだろうけど、世界中のトレーニングデータを使い果たしたとは思わない。"
  },
  {
    "start": 4075938,
    "end": 4077724,
    "text": "ああ、私もそう思う。"
  },
  {
    "start": 4077762,
    "end": 4079790,
    "text": "まだまだこれからだと思う。"
  },
  {
    "start": 4080400,
    "end": 4083996,
    "text": "マルチモーダルモデル、あなたは講演でそれを強調していた。"
  },
  {
    "start": 4084178,
    "end": 4090160,
    "text": "各ドメインごとにターゲットを絞ったモデルよりも、全ドメインで優れたパフォーマンスを達成できるのか？"
  },
  {
    "start": 4090900,
    "end": 4094688,
    "text": "あるいは、この問答版を言い換えることもできる。"
  },
  {
    "start": 4094854,
    "end": 4096480,
    "text": "そういうケースもあると思う。"
  },
  {
    "start": 4096550,
    "end": 4102528,
    "text": "問題は、モダリティを増やせば増やすほど、他のモダリティのパフォーマンスが向上するのか、ということだ。"
  },
  {
    "start": 4102704,
    "end": 4104900,
    "text": "そう願うよ"
  },
  {
    "start": 4105050,
    "end": 4107910,
    "text": "一般的には、そのような側面も見られる。"
  },
  {
    "start": 4109020,
    "end": 4128428,
    "text": "もしあなたが狭い範囲の問題を抱えていて、その問題だけに取り組むように設計された、非常に的を絞ったデータセットを収集すれば、多くの場合、その問題に関して良い結果を出すことができると思う。"
  },
  {
    "start": 4128514,
    "end": 4148064,
    "text": "複雑な問題を抱えていたり、非常に専門的なデータを収集するのが難しい場合、欲しいのは、言語や画像や音声から、世の中のさまざまな物事に関する膨大な知識を持ったモデルであり、そしてそのモデルを気になる問題に適用できるようにすることだ。"
  },
  {
    "start": 4148262,
    "end": 4160790,
    "text": "もし気になる問題のデータが少しでもあるのなら、そのベースモデルから始めて、微調整をしたり、コンテキスト学習などをしたりして、パフォーマンスをかなり良くしたいと思うだろう。"
  },
  {
    "start": 4161160,
    "end": 4165192,
    "text": "続いて、今日はちょっと関連した質問をさせてもらおうかな。"
  },
  {
    "start": 4165246,
    "end": 4169556,
    "text": "大規模なバンドル・トレーニングのコストは、小規模な新興企業がインパクトを与えることを妨げている。"
  },
  {
    "start": 4169668,
    "end": 4173788,
    "text": "リソースの少ない個人はどのようなプロジェクトに取り組むだろうか？"
  },
  {
    "start": 4173954,
    "end": 4175868,
    "text": "それについてコメントは？"
  },
  {
    "start": 4176034,
    "end": 4176748,
    "text": "ああ、もちろんだ。"
  },
  {
    "start": 4176834,
    "end": 4184332,
    "text": "つまり、機械学習の領域には本当に多くの問題があると思う。"
  },
  {
    "start": 4184396,
    "end": 4197668,
    "text": "私は、大規模なデータセンターなどにアクセスできないような広い分野で、どのような興味深い研究ができるのか、というところから話を進めようと思っている。"
  },
  {
    "start": 4197754,
    "end": 4201076,
    "text": "いろいろなことが本当に広く開かれていると思う。"
  },
  {
    "start": 4201258,
    "end": 4223240,
    "text": "データの質、データの質の自動評価、オンラインカリキュラム学習、最適化手法、こういったものの多くは、実際に机の下にある1台のGPUや数台のGPUで実証することができ、実際にかなり重要で革新的な進歩を遂げることができる。"
  },
  {
    "start": 4223400,
    "end": 4227564,
    "text": "トランスフォーマーの原型は、8つのGpusで作られたと思う。"
  },
  {
    "start": 4227762,
    "end": 4228604,
    "text": "興味深い。"
  },
  {
    "start": 4228802,
    "end": 4232600,
    "text": "あるいは、シークエンスからシークエンスへのモデルは確かに8Gpusだった。"
  },
  {
    "start": 4232760,
    "end": 4242160,
    "text": "だから、巧みなアイデア、その優れた評価、さらには小規模な実証から得られる進歩があると思う。"
  },
  {
    "start": 4242740,
    "end": 4245984,
    "text": "さて、もうひとつの質問はこうだ。"
  },
  {
    "start": 4246102,
    "end": 4247380,
    "text": "llmsがすべてですか？"
  },
  {
    "start": 4247450,
    "end": 4248884,
    "text": "トランスフォーマーがすべてか。"
  },
  {
    "start": 4249002,
    "end": 4250180,
    "text": "他に何がある？"
  },
  {
    "start": 4250250,
    "end": 4253552,
    "text": "他のモデルに取り組むべきか？"
  },
  {
    "start": 4253616,
    "end": 4259608,
    "text": "llmsの重視が機械学習の他の研究を阻害しているのだろうか？"
  },
  {
    "start": 4259774,
    "end": 4262504,
    "text": "ええ、心配ですよね？"
  },
  {
    "start": 4262542,
    "end": 4275736,
    "text": "例えば、他の革新的なアイデアに水を差すようなことはしていないだろうか？"
  },
  {
    "start": 4275768,
    "end": 4287776,
    "text": "私たちは今、何がうまく機能するのか、もしかしたらこっちにあるものが本当にうまく機能するかもしれないのに、そのあたりを穏やかに探っているようなものだ。"
  },
  {
    "start": 4287878,
    "end": 4300340,
    "text": "たとえ小規模であっても、他のアイデアが本当に興味深い方向性であることを示すことは、多くの場合、ささやかな実験的証拠で可能だと思う。"
  },
  {
    "start": 4300840,
    "end": 4303670,
    "text": "それは重要な分野だと思う。"
  },
  {
    "start": 4304680,
    "end": 4309590,
    "text": "マルチモーダルな世界に移行していると思うので、私はLLMを使わない傾向がある。"
  },
  {
    "start": 4310220,
    "end": 4323528,
    "text": "マルチモーダルとは、視覚、聴覚、言語といった人間的なモダリティだけでなく、世界で重要な他のモダリティのことだと思う。"
  },
  {
    "start": 4323614,
    "end": 4330516,
    "text": "また、ヘルスケア・アプリケーションのための興味深い心拍センサーの時系列データとかね。"
  },
  {
    "start": 4330628,
    "end": 4334610,
    "text": "おそらく、50から100のモダリティのデータを持ち運ぶことができるようにしたい。"
  },
  {
    "start": 4336820,
    "end": 4341024,
    "text": "時計を見たら、本当に時間がオーバーしていた。"
  },
  {
    "start": 4341142,
    "end": 4346400,
    "text": "最後に、ジェフ・ディーンの講演に感謝したい。"
  },
  {
    "start": 4346550,
    "end": 4346990,
    "text": "ありがとう。"
  }
]