[
  {
    "start": 170,
    "end": 8042,
    "text": "さて、ボロ負け問題で直面する可能性のある最大の問題のひとつは、レトリバーからいったい何を持ち帰るのか、ということだ。"
  },
  {
    "start": 8186,
    "end": 15486,
    "text": "あなたが望む特定の答えを見つけるために、言語モデル全体にとってどの程度役に立つのでしょうか？"
  },
  {
    "start": 15668,
    "end": 32214,
    "text": "ここでの課題は、いくつかのものを持ち帰って、そのうちのいくつかは役に立つが、いくつかは役に立たないということである。あるいは、大きな塊を持ち帰って、その中のごく少量だけが全体の答えに役に立つということもよくある。"
  },
  {
    "start": 32412,
    "end": 40058,
    "text": "これは、特定の問題が複数のチャンクからの事実を必要とし、それらを合成する必要がある場合である。"
  },
  {
    "start": 40224,
    "end": 50198,
    "text": "また、実際のクエリと一緒に、他の事実をインコンテクスト学習ウィンドウに入れたくないような質問で、明確にするためだけの場合もある。"
  },
  {
    "start": 50374,
    "end": 55050,
    "text": "ここで、コンテクスト圧縮とフィルターを導入する。"
  },
  {
    "start": 55210,
    "end": 76750,
    "text": "文脈圧縮の考え方は、ベースとなるリトリーバーがさまざまな情報を取得し、その情報を処理して、質問に答えるために有用なものだけを抽出するというものだ。"
  },
  {
    "start": 76920,
    "end": 95402,
    "text": "例えば、返されるドキュメントの途中に必要な情報がたくさんある場合、コンプレッサーはそのドキュメントの最初と最後にある情報を消去し、その情報だけを抽出することができる。"
  },
  {
    "start": 95536,
    "end": 115250,
    "text": "つまり、コンプレッサー、あるいは複数のことを行うコンプレッサーのパイプラインが、ドキュメントをクリーンアップし、特定のクエリに答えられるように、最も有用なものだけを最終的にモデルに与えるということだ。"
  },
  {
    "start": 115400,
    "end": 124722,
    "text": "これらのコンプレッサーでは、まずベースとなるリトリーバーから始め、コンプレッサーの一部としてフィルターを追加する。"
  },
  {
    "start": 124856,
    "end": 133634,
    "text": "そのひとつが、LLMチェイン・エクストラクターと呼ばれる大規模な言語モデルを呼び出すことだ。"
  },
  {
    "start": 133762,
    "end": 141114,
    "text": "このアイデアは、基本的に言語モデルを使って、渡す前にビットを抽出してクリーンアップするというものだ。"
  },
  {
    "start": 141232,
    "end": 146778,
    "text": "最終的な答えに使うのと同じ言語モデルである必要はない。"
  },
  {
    "start": 146864,
    "end": 152186,
    "text": "この特殊な作業を行うために、モデルを微調整することもできる。"
  },
  {
    "start": 152298,
    "end": 165822,
    "text": "人々がEメールから情報を抽出するモデルを微調整し、「こんにちは」「お元気ですか」といった簡単なことを無視している例を見たことがある。"
  },
  {
    "start": 165876,
    "end": 166858,
    "text": "そういうことだ。"
  },
  {
    "start": 166964,
    "end": 172594,
    "text": "メールの本文を読み、それをタグ付けする。"
  },
  {
    "start": 172712,
    "end": 180690,
    "text": "これは、ファインチューニングでできる重要な機能のひとつで、非常に特定のタスクのために言語モデルを微調整することです。"
  },
  {
    "start": 180770,
    "end": 187318,
    "text": "この種のものは、このような特定のタスクのために微調整すると、非常にうまく機能することがわかった。"
  },
  {
    "start": 187404,
    "end": 200858,
    "text": "コンプレッサーフィルターのもうひとつの例は、言語モデルに各レスポンスを見てもらい、これを入れるべきかどうかを判断してもらうことです。"
  },
  {
    "start": 201024,
    "end": 208478,
    "text": "もうひとつは、アウトプットを操作し始めたら、もう一度エンベッディングを取りたくなるかもしれないということだ。"
  },
  {
    "start": 208644,
    "end": 214370,
    "text": "あなたは、情報を引き出すためにエンベッディングを行ったオリジナルのクエリを持っている。"
  },
  {
    "start": 214520,
    "end": 230438,
    "text": "コンプレッサー・パイプラインを通した後、最後に別のエンベッディング・フィルターをかけることで、最終的なエンベッディング・フィルターのうち、クエリに近いエンベッディング・フィルターがいくつあるかを確認することができる。"
  },
  {
    "start": 230604,
    "end": 250090,
    "text": "ここで重要なことのひとつは、これによって、多くの場合、大量のドキュメントを取得し、それらを持ち帰り、フィルタリングし、クエリーと一緒に最終的な言語モデルの呼び出しに送って答えを返すことができる方法で情報を圧縮することができるということだ。"
  },
  {
    "start": 250160,
    "end": 255360,
    "text": "ここで、コードに飛び込んで、これらが実際にどのように機能するのかを見てみよう。"
  },
  {
    "start": 256370,
    "end": 260622,
    "text": "さて、ここでは標準的なラングチェーンの設定をしている。"
  },
  {
    "start": 260756,
    "end": 265262,
    "text": "BGエンベッディングの設定などを行っているところだ。"
  },
  {
    "start": 265396,
    "end": 271042,
    "text": "まずは簡単なインポートを行い、基本的にficeをセットアップするだけだ。"
  },
  {
    "start": 271096,
    "end": 272686,
    "text": "テキスト・スプリッターをセットアップする。"
  },
  {
    "start": 272718,
    "end": 277634,
    "text": "今回は、実際にBGEのエンベッディングをローカルで使ってみようと思う。"
  },
  {
    "start": 277752,
    "end": 279426,
    "text": "それはとても簡単なことだ。"
  },
  {
    "start": 279528,
    "end": 281666,
    "text": "書類を持ち込むつもりだ。"
  },
  {
    "start": 281698,
    "end": 282966,
    "text": "私は彼らを分割するつもりだ。"
  },
  {
    "start": 283068,
    "end": 289762,
    "text": "あとは基本的に、これらのドキュメントを検索したときに得られる結果を見るための、シンプルで小さなヘルパー関数を設定するだけだ。"
  },
  {
    "start": 289906,
    "end": 293718,
    "text": "ラングスミスとは何か？"
  },
  {
    "start": 293814,
    "end": 303862,
    "text": "ここに4つの異なる文脈が返ってきているのがわかると思うが、ここには確かに関連性のあるものもあるが、関連性のないものもたくさんある。"
  },
  {
    "start": 303936,
    "end": 309502,
    "text": "あるいは、もっと冗長でなく、さまざまなものを取り戻せるかもしれない。"
  },
  {
    "start": 309636,
    "end": 315578,
    "text": "まず最初に行うのは、LLMチェイン・エクストラクターによるコンテクスト圧縮の追加だ。"
  },
  {
    "start": 315754,
    "end": 324594,
    "text": "これは基本的にLLMチェーンをセットアップするだけで、そのチェーンが何をするかというと、実はプロンプトを見るだけなんだ。"
  },
  {
    "start": 324632,
    "end": 335622,
    "text": "このプロンプトは、次の質問と文脈が与えられたら、文脈の中から質問の答えに関連する部分をそのまま抜き出せ、というものであることがわかる。"
  },
  {
    "start": 335756,
    "end": 339214,
    "text": "コンテキストに関連するものがない場合は、出力を返さない。"
  },
  {
    "start": 339362,
    "end": 342026,
    "text": "コンテンツの抽出部分を編集しないでください。"
  },
  {
    "start": 342128,
    "end": 347366,
    "text": "私たちは基本的に書き換えを要求しているだけで、実際には書き換えさえしていない。"
  },
  {
    "start": 347398,
    "end": 354190,
    "text": "私たちは、無関係な部分を切り落とし、私たちにとって有用な部分だけを抽出するよう求めているのだ。"
  },
  {
    "start": 354260,
    "end": 357658,
    "text": "ラングスミスとは何か？"
  },
  {
    "start": 357754,
    "end": 362446,
    "text": "以前のものよりもはるかに短いものを手に入れているのがわかる。"
  },
  {
    "start": 362548,
    "end": 367570,
    "text": "今、私たちはデバッグ、テスト、評価のための統一されたプラットフォームをラングスミスに発表しました。"
  },
  {
    "start": 367990,
    "end": 371842,
    "text": "また、4つの文書が3つに減っていることもおわかりいただけるだろう。"
  },
  {
    "start": 371976,
    "end": 373714,
    "text": "これが最初のものだ。"
  },
  {
    "start": 373752,
    "end": 378840,
    "text": "さて、このためには、明らかに、大規模な言語モデルをもうひとつ呼び出す必要がある。"
  },
  {
    "start": 379370,
    "end": 388198,
    "text": "スピードが遅くなることもあるが、実際のアウトプットの質は格段に向上するだろう。"
  },
  {
    "start": 388364,
    "end": 390802,
    "text": "次に見たいのはフィルターだ。"
  },
  {
    "start": 390946,
    "end": 397850,
    "text": "このLLMのチェーンフィルターは、イエス・ノーのようなものだと考えるのが一番だと思う。"
  },
  {
    "start": 398000,
    "end": 404414,
    "text": "プロンプトをもう一度見てみると、これはまた大規模な言語モデルを経由している。"
  },
  {
    "start": 404532,
    "end": 414750,
    "text": "プロンプトを見ると、次の質問と文脈が与えられたら、文脈が質問に関連していれば「はい」を、関連していなければ「いいえ」を返せ、と言っていることがわかる。"
  },
  {
    "start": 414900,
    "end": 421682,
    "text": "基本的には、「よし、こいつは関連性がある。"
  },
  {
    "start": 421736,
    "end": 425010,
    "text": "これはスルーしているので関係ない。"
  },
  {
    "start": 425160,
    "end": 430370,
    "text": "これによって、基本的に、ああ、そうだ、よし、この部分は関連性がある。"
  },
  {
    "start": 430450,
    "end": 441002,
    "text": "さて、このURLとタイトルは、質問に答えるための最良の部分ではなかったので、この中で切り捨てられたことに注目してほしい。"
  },
  {
    "start": 441136,
    "end": 447398,
    "text": "確かに、デバッグテストのためのラングスミス統一プラットフォームの発表が関係している。"
  },
  {
    "start": 447494,
    "end": 447946,
    "text": "そうだね。"
  },
  {
    "start": 448048,
    "end": 457326,
    "text": "今回、私たちはそのコンテクストを完全に把握することができた。"
  },
  {
    "start": 457348,
    "end": 458714,
    "text": "これは返されたのだろうか？"
  },
  {
    "start": 458762,
    "end": 459262,
    "text": "そうだ。"
  },
  {
    "start": 459396,
    "end": 461434,
    "text": "他のものは返却されたのだろうか？"
  },
  {
    "start": 461482,
    "end": 462174,
    "text": "そうだ。"
  },
  {
    "start": 462372,
    "end": 465998,
    "text": "もうひとつのトリックは、埋め込みフィルターだ。"
  },
  {
    "start": 466174,
    "end": 471778,
    "text": "ここを見て、基本的には最初にリトリーブを行う場所だ。"
  },
  {
    "start": 471864,
    "end": 486470,
    "text": "理想を言えば、これについてはまた別のビデオでお話しすることになると思いますが、5つのコンテクストの検索を行いたい、あるいはそれ以上の検索を行いたい、場合によっては異なるソースから5つのコンテキストを検索して一緒に戻すこともあるでしょう。"
  },
  {
    "start": 486620,
    "end": 502510,
    "text": "エンベッディング・フィルターを使って、実際に採点したり、上位のものを選んでランキングしたりすることができる。"
  },
  {
    "start": 502580,
    "end": 505822,
    "text": "はい、このために異なるエンベッディングを使用することができます。"
  },
  {
    "start": 505876,
    "end": 514126,
    "text": "あることにはBGeを使い、別のことにはOpenAIを使うこともできるし、同じエンベッディングを使うこともできる。"
  },
  {
    "start": 514238,
    "end": 516958,
    "text": "これをパイプラインに入れられることがわかるだろう。"
  },
  {
    "start": 517134,
    "end": 528210,
    "text": "実際のコンテキスト検索では、埋め込みを行い、最も類似したコンテキストを検索してここに戻す。"
  },
  {
    "start": 528360,
    "end": 536342,
    "text": "パイプラインで物事を実行すると、ここで状況が変わり始める。"
  },
  {
    "start": 536476,
    "end": 557934,
    "text": "そこで、まずエクストラクタを実行し、次に新しいエクストラクタを作成して、先ほど見たように切り落とされたエクストラクタを作成する。"
  },
  {
    "start": 558052,
    "end": 561546,
    "text": "これは類似性のしきい値を設定できるものだ。"
  },
  {
    "start": 561658,
    "end": 562782,
    "text": "私たちはそれをやり遂げることができる。"
  },
  {
    "start": 562836,
    "end": 567380,
    "text": "基本的には、新しいエンベッディング・ルックアップを行うことで、何かを返すことができる。"
  },
  {
    "start": 568390,
    "end": 572290,
    "text": "さて、次はこれらすべてをつなぎ合わせるところから始めよう。"
  },
  {
    "start": 572360,
    "end": 574814,
    "text": "これはドキュメント・コンプレッサーのパイプラインである。"
  },
  {
    "start": 574942,
    "end": 584566,
    "text": "ここでのアイデアは、さまざまなことをパイプラインに組み込んで、コンテキストを取り戻すことができるということだ。"
  },
  {
    "start": 584748,
    "end": 600298,
    "text": "そのコンテキストが1000とか2000とかで、それを分割したい場合、ここに来て、これらのコンテキストを再びスプリッターで分割し、1000から300の複数のチャンクに分割することができる。"
  },
  {
    "start": 600464,
    "end": 603630,
    "text": "そこにオーバーラップを入れるのもいいだろう。"
  },
  {
    "start": 603780,
    "end": 608830,
    "text": "そうすれば、このパイプラインが基本的に分割を行うことになる。"
  },
  {
    "start": 609170,
    "end": 616450,
    "text": "それから、新しいエンベッディング・フィルターを使って、どれが冗長で、捨ててしまうべきものかを調べます。"
  },
  {
    "start": 616520,
    "end": 622750,
    "text": "その後、基本的に類似度のしきい値の範囲内で、関連するものだけを最終的に戻す。"
  },
  {
    "start": 622910,
    "end": 634790,
    "text": "そうすれば、1000文字のチャンクを5つ取り出して、それぞれを300文字に分割することができる。"
  },
  {
    "start": 634860,
    "end": 636694,
    "text": "そこにいくつか重なりがあるとしよう。"
  },
  {
    "start": 636732,
    "end": 640120,
    "text": "それぞれ4チャンクずつくらいは取れるだろう。"
  },
  {
    "start": 640430,
    "end": 646438,
    "text": "そして、そのチャンクはさらに小さくなっていく。"
  },
  {
    "start": 646534,
    "end": 652474,
    "text": "そして、そのチャンクのエンベッディングを取り出し、そのチャンクに最も関連する情報を持ち帰る。"
  },
  {
    "start": 652592,
    "end": 654542,
    "text": "それを実行すればわかるだろう。"
  },
  {
    "start": 654676,
    "end": 660030,
    "text": "さて、基本的にはこれらのものを分割して、そこにあるものから戻すことになる。"
  },
  {
    "start": 660180,
    "end": 664846,
    "text": "しかし、このようにスプリッターを使うこともできる。"
  },
  {
    "start": 664958,
    "end": 676814,
    "text": "大きな言語モデルを使って実際に圧縮するためのコンプレッサーがあり、それを埋め込むフィルターがある。"
  },
  {
    "start": 676862,
    "end": 677314,
    "text": "今すぐだ。"
  },
  {
    "start": 677432,
    "end": 687634,
    "text": "さて、この場合、おそらくこれはそれほど役に立たないだろうが、戻ってくる他のもののいくつかは、かなり小さい文脈になることがわかるだろう。"
  },
  {
    "start": 687762,
    "end": 694042,
    "text": "さて、この例では少しやりすぎかもしれないが、パイプラインでさまざまなことを行うことができる。"
  },
  {
    "start": 694096,
    "end": 696634,
    "text": "パイプラインでフィルタリングすることもできる。"
  },
  {
    "start": 696752,
    "end": 698278,
    "text": "そして書き直しをする。"
  },
  {
    "start": 698374,
    "end": 705562,
    "text": "そして、アンサンブルで複数のソースから検索できる埋め込みをチェックし、フィルターをかけ、書き換える。"
  },
  {
    "start": 705626,
    "end": 707610,
    "text": "埋め込みをチェックすることもできる。"
  },
  {
    "start": 707690,
    "end": 713370,
    "text": "それを返す、検索する、分割する、埋め込みで分割をチェックする、フィルタリングする、書き直す。"
  },
  {
    "start": 713450,
    "end": 718082,
    "text": "このパイプラインのアイデアには、さまざまなものがある。"
  },
  {
    "start": 718216,
    "end": 729478,
    "text": "これは基本的にパイプライン・コンプレッサーをセットアップするもので、以前お話したことを実際のドキュメント・リトリーバー・パイプラインで使い始めるものです。"
  },
  {
    "start": 729644,
    "end": 741074,
    "text": "つまり、コンテキストに沿った圧縮タスクとフィルターは、パイプラインそのものとともに、本当に優れた有用なラグを構築するための重要な要素のひとつなのだ。"
  },
  {
    "start": 741202,
    "end": 747354,
    "text": "リアルタイムであることが必要な場合、スピードとやっていることの数のバランスを常に考えなければならない。"
  },
  {
    "start": 747472,
    "end": 760302,
    "text": "要約のようなことをする場合、リアルタイムである必要はないかもしれないが、このようなことをかなり多く行うことができ、これらのチャンクの取得に基づいてカスタム要約を要約することができる。"
  },
  {
    "start": 760436,
    "end": 768030,
    "text": "その場合、特定の要約問題の解答に使われるチャンクを大量に作ることもできる。"
  },
  {
    "start": 768190,
    "end": 776390,
    "text": "もしリアルタイムで質疑応答をしているのであれば、基本的に、それぞれのことにどれくらいの時間がかかっているのか、タイミングをチェックしたい。"
  },
  {
    "start": 776540,
    "end": 787842,
    "text": "おそらく複数のコンプレッサーパイプラインを構築し、さまざまな種類の書き換え、さまざまな種類のフィルタリング、さまざまな種類の分割などをテストすることになるだろう。"
  },
  {
    "start": 787986,
    "end": 794470,
    "text": "もうひとつ忘れてはならないのは、これらの特別なプロンプトはすべて書き直すことができるということだ。"
  },
  {
    "start": 794550,
    "end": 801178,
    "text": "このプロンプトのように、非常に特殊なユースケースのために書き直したい場合。"
  },
  {
    "start": 801344,
    "end": 809386,
    "text": "非常に特定のユースケースのためにボロ布を作りながら、非常に一般的なプロンプトを使っている人をよく見かける。"
  },
  {
    "start": 809498,
    "end": 819582,
    "text": "特定のユースケースにプロンプトを絞り込み、言語モデルに「医療に関連することだけに興味がある」と認識させることは悪いことではない。"
  },
  {
    "start": 819636,
    "end": 824670,
    "text": "あなたが興味を持っているのは、あなたが働いている領域によって、特定の種類のものだけだ。"
  },
  {
    "start": 824740,
    "end": 829990,
    "text": "よし、これで遊んでみて、あなたの特定のタスクのためにいろいろなバージョンを試してみてほしい。"
  },
  {
    "start": 830330,
    "end": 833846,
    "text": "いつものように、質問があれば下のコメント欄に書き込んでください。"
  },
  {
    "start": 833948,
    "end": 836658,
    "text": "このビデオがお役に立ちましたら、「いいね！」と「購読」をクリックしてください。"
  },
  {
    "start": 836754,
    "end": 838374,
    "text": "また次のビデオで会おう。"
  },
  {
    "start": 838492,
    "end": 839560,
    "text": "とりあえず、さようなら。"
  },
  {
    "start": 839930,
    "end": 840290,
    "text": "さようなら。"
  }
]