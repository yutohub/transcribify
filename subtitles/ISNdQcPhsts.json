[
  {
    "start": 90,
    "end": 590,
    "text": "やあ、みんな。"
  },
  {
    "start": 660,
    "end": 3482,
    "text": "トランスフォーマーについてのエピソードへようこそ。"
  },
  {
    "start": 3626,
    "end": 8026,
    "text": "このエピソードでは、Pytorchを使ってトランスフォーマーをゼロから作ります。"
  },
  {
    "start": 8058,
    "end": 17306,
    "text": "モデルを構築し、それをトレーニングし、推論し、アテンション・スコアを視覚化するためのコードも構築する。"
  },
  {
    "start": 17498,
    "end": 29190,
    "text": "長いビデオになるのでお付き合いいただきたいが、ビデオが終わるころには、概念的な観点からだけでなく、実用的な観点からも、トランス・モデルに関する深い知識を得ることができることを保証する。"
  },
  {
    "start": 29260,
    "end": 36310,
    "text": "つまり、ある言語から別の言語への翻訳を可能にするモデルである。"
  },
  {
    "start": 36460,
    "end": 43770,
    "text": "私はopus booksと呼ばれるデータセットを選んだ。"
  },
  {
    "start": 44110,
    "end": 51594,
    "text": "私はイタリア人なので、英語からイタリア語への翻訳を選びました。"
  },
  {
    "start": 51712,
    "end": 58810,
    "text": "同じモデルをお好きな言語でテストできるよう、言語を変更できるポイントをお教えします。"
  },
  {
    "start": 58890,
    "end": 59758,
    "text": "始めよう。"
  },
  {
    "start": 59844,
    "end": 62842,
    "text": "好きなイデを開こう。"
  },
  {
    "start": 62906,
    "end": 65170,
    "text": "私の場合、ビジュアル・スタジオ・コードが大好きだ。"
  },
  {
    "start": 65240,
    "end": 70530,
    "text": "トランスフォーマーのモデルである最初のファイルを作成しよう。"
  },
  {
    "start": 71990,
    "end": 78610,
    "text": "さて、まずトランスのモデルを見て、どの部分を最初に作るかを確認しよう。"
  },
  {
    "start": 78680,
    "end": 81222,
    "text": "その後、各パートを1つずつ作っていく。"
  },
  {
    "start": 81276,
    "end": 84642,
    "text": "最初に構築するのは、入力埋め込みだ。"
  },
  {
    "start": 84706,
    "end": 89246,
    "text": "ご覧のように、入力エンベッディングは、入力を取り込んでエンベッディングに変換する。"
  },
  {
    "start": 89298,
    "end": 90790,
    "text": "入力エンベッディングとは？"
  },
  {
    "start": 90870,
    "end": 100518,
    "text": "前回のビデオで覚えているように、入力埋め込みによって、元の文章を512次元のベクトルに変換することができる。"
  },
  {
    "start": 100694,
    "end": 104222,
    "text": "例えば、この文章では、あなたの猫はかわいい猫です。"
  },
  {
    "start": 104356,
    "end": 114042,
    "text": "まず、文を入力ID、つまり語彙内の各単語の位置に対応する数字のリストに変換する。"
  },
  {
    "start": 114106,
    "end": 120402,
    "text": "とすると、この数はそれぞれ埋め込みに対応し、512サイズのベクトルである。"
  },
  {
    "start": 120536,
    "end": 122660,
    "text": "まずはこのレイヤーを作ってみよう。"
  },
  {
    "start": 123110,
    "end": 126070,
    "text": "まず、トーチをインポートする必要がある。"
  },
  {
    "start": 131850,
    "end": 140630,
    "text": "それなら、教室を作る必要がある。"
  },
  {
    "start": 144350,
    "end": 145574,
    "text": "これがコンストラクターだ。"
  },
  {
    "start": 145622,
    "end": 148522,
    "text": "モデルの寸法を伝える必要がある。"
  },
  {
    "start": 148576,
    "end": 153600,
    "text": "論文のベクトルの次元、これをDモデルと呼ぶ。"
  },
  {
    "start": 155970,
    "end": 159120,
    "text": "また、ボキャブラリーのサイズも伝える必要がある。"
  },
  {
    "start": 159730,
    "end": 162590,
    "text": "ボキャブラリーの中にいくつ単語があるか。"
  },
  {
    "start": 180730,
    "end": 183986,
    "text": "この2つの値を保存して、実際の埋め込みを作成します。"
  },
  {
    "start": 184018,
    "end": 184406,
    "text": "オーケー。"
  },
  {
    "start": 184508,
    "end": 195002,
    "text": "実は、Pytorchは、私たちがまさにやりたいことをやってくれるレイヤーをすでに提供している。"
  },
  {
    "start": 195136,
    "end": 197194,
    "text": "これこそが、エンベディングの役割なのだ。"
  },
  {
    "start": 197232,
    "end": 200542,
    "text": "これは数値と大きさのベクトルとの対応付けに過ぎない。"
  },
  {
    "start": 200596,
    "end": 202430,
    "text": "512, 512."
  },
  {
    "start": 202500,
    "end": 204800,
    "text": "ここでは、我々のケースはDモデルである。"
  },
  {
    "start": 206450,
    "end": 215300,
    "text": "これはエンベッディングレイヤー、nnエンベッディング、ボキャブラリーのサイズとDモデルによって行われる。"
  },
  {
    "start": 216310,
    "end": 220420,
    "text": "オートコンプリートが機能しない原因を調べてみます。"
  },
  {
    "start": 225590,
    "end": 226254,
    "text": "それだ。"
  },
  {
    "start": 226392,
    "end": 229830,
    "text": "さて、それではフォワード・メソッドを実装してみよう。"
  },
  {
    "start": 234730,
    "end": 242070,
    "text": "エンベッディングで行っているのは、Pytorchが提供するエンベッディング・レイヤーを使ってマッピングを行うだけだ。"
  },
  {
    "start": 242230,
    "end": 246730,
    "text": "xの自己ドット埋め込みを返す。"
  },
  {
    "start": 246800,
    "end": 249690,
    "text": "さて、実はこの紙にはちょっとした詳細が書かれている。"
  },
  {
    "start": 249840,
    "end": 251482,
    "text": "つまり、論文を見てみよう。"
  },
  {
    "start": 251536,
    "end": 252762,
    "text": "実は、ここに行こう。"
  },
  {
    "start": 252816,
    "end": 261326,
    "text": "埋込みとソフトマックスを確認すると、この文では、埋込み層で、埋込みの重みにDモデルの平方根を掛けていることがわかる。"
  },
  {
    "start": 261428,
    "end": 275878,
    "text": "この埋め込みレイヤーは、数字を毎回同じベクトルにマッピングする辞書のようなものだ。"
  },
  {
    "start": 275964,
    "end": 278470,
    "text": "このベクトルはモデルによって学習される。"
  },
  {
    "start": 278620,
    "end": 285000,
    "text": "を乗じるだけである。"
  },
  {
    "start": 287530,
    "end": 289420,
    "text": "また、マットをインポートする必要がある。"
  },
  {
    "start": 290750,
    "end": 294394,
    "text": "さて、これで入力エンベッディングの準備ができた。"
  },
  {
    "start": 294512,
    "end": 296102,
    "text": "次のモジュールに行こう。"
  },
  {
    "start": 296166,
    "end": 299686,
    "text": "次に作るモジュールは、位置エンコーディングだ。"
  },
  {
    "start": 299878,
    "end": 303262,
    "text": "また、位置エンコーディングの速さについても見てみよう。"
  },
  {
    "start": 303316,
    "end": 312282,
    "text": "先ほど、元の文が埋め込みによってベクトルのリストにマッピングされることを見た。"
  },
  {
    "start": 312426,
    "end": 314474,
    "text": "これが我々のエンベッディングだ。"
  },
  {
    "start": 314602,
    "end": 321262,
    "text": "そこで、文中の各単語の位置に関する情報をモデルに伝えたい。"
  },
  {
    "start": 321326,
    "end": 325726,
    "text": "これは、埋め込みと同じサイズの別のベクトルを追加することによって行われる。"
  },
  {
    "start": 325758,
    "end": 336630,
    "text": "サイズ512で、後で示す数式で与えられた特別な値を含んでいる。この特別な値は、この特定の単語が文中でこの位置を占めていることをモデルに伝える。"
  },
  {
    "start": 337050,
    "end": 342374,
    "text": "位置埋め込みと呼ばれるこれらのベクトルを作成し、埋め込みに追加する。"
  },
  {
    "start": 342422,
    "end": 343402,
    "text": "よし、やろう。"
  },
  {
    "start": 343456,
    "end": 354430,
    "text": "では、クラスの位置エンコーディングを定義し、コンストラクタを定義しよう。"
  },
  {
    "start": 355650,
    "end": 366222,
    "text": "というのも、これは位置エンコードされるべきベクターのサイズであり、配列の長さだからだ。"
  },
  {
    "start": 366286,
    "end": 369518,
    "text": "これが刑期の上限である。"
  },
  {
    "start": 369694,
    "end": 377010,
    "text": "なぜなら、各ポジションに1つのベクトルを作成する必要があり、ドロップアウトも与える必要があるからだ。"
  },
  {
    "start": 377170,
    "end": 380950,
    "text": "ドロップアウトとは、モデルのオーバーフィットを少なくすることである。"
  },
  {
    "start": 398970,
    "end": 401194,
    "text": "実際に位置エンコーディングを構築してみよう。"
  },
  {
    "start": 401242,
    "end": 407838,
    "text": "さて、まず位置エンコーディングだが、Dモデルに対して形状、配列長の行列を作る。"
  },
  {
    "start": 407924,
    "end": 409534,
    "text": "なぜDモデルに配列長なのか？"
  },
  {
    "start": 409652,
    "end": 420850,
    "text": "Dモデルの大きさ、つまり512のベクトルが必要だが、文の最大長は配列長なので、その数である配列長が必要だからだ。"
  },
  {
    "start": 421750,
    "end": 425640,
    "text": "そうしよう"
  },
  {
    "start": 435690,
    "end": 443686,
    "text": "さて、マトリックスを作る前に、そしてマトリックスの作り方はわかったので、ポジションエンコーディングを作るための公式を見てみよう。"
  },
  {
    "start": 443798,
    "end": 447222,
    "text": "では、ポジションエンコーディングに使われる計算式を見てみよう。"
  },
  {
    "start": 447286,
    "end": 450234,
    "text": "これは前回のビデオのスライドだ。"
  },
  {
    "start": 450272,
    "end": 452998,
    "text": "ベクターの作り方を見てみよう。"
  },
  {
    "start": 453094,
    "end": 454922,
    "text": "だから、思い出してほしい。"
  },
  {
    "start": 454986,
    "end": 456814,
    "text": "この場合、3つの単語があるとしよう。"
  },
  {
    "start": 456932,
    "end": 460446,
    "text": "論文から引用したこの2つの公式を使用する。"
  },
  {
    "start": 460628,
    "end": 466418,
    "text": "サイズ512のベクトルを作成し、各ポジションに1つずつ配置する。"
  },
  {
    "start": 466504,
    "end": 472846,
    "text": "配列の長さまでで、偶数位置では、最初の式を適用する。"
  },
  {
    "start": 472878,
    "end": 476418,
    "text": "ベクトルのOdの位置では、2番目の式を適用する。"
  },
  {
    "start": 476594,
    "end": 483126,
    "text": "この場合、ネットでも簡略化されているのを見たので、実際に計算を簡略化する。"
  },
  {
    "start": 483228,
    "end": 488358,
    "text": "ここでは、対数空間を使って少し修正した計算を行う。"
  },
  {
    "start": 488524,
    "end": 490294,
    "text": "これは数値的な安定のためだ。"
  },
  {
    "start": 490422,
    "end": 499590,
    "text": "指数を適用し、さらに指数内部で何かの対数を適用すると、結果は同じ数値になるが、より数値的に安定する。"
  },
  {
    "start": 499670,
    "end": 506430,
    "text": "まず、文中の単語の位置を表すpositionと呼ばれるベクトルを作成する。"
  },
  {
    "start": 511650,
    "end": 516260,
    "text": "このベクトルはゼロからシーケンス長マイナス1まで成長することができる。"
  },
  {
    "start": 533850,
    "end": 540540,
    "text": "実際、我々は形状のテンソルを作っている。"
  },
  {
    "start": 542430,
    "end": 550570,
    "text": "これは間違っている。"
  },
  {
    "start": 551170,
    "end": 579474,
    "text": "ここで、式の分母を作り、式の中にある2つの項を見る。"
  },
  {
    "start": 579522,
    "end": 580642,
    "text": "スライドに戻ろう。"
  },
  {
    "start": 580706,
    "end": 585926,
    "text": "最初に作ったテンソルはポジションと呼ばれ、ここでポーズをとっている。"
  },
  {
    "start": 586028,
    "end": 588774,
    "text": "私たちが作った2番目のテンソルは、ここでは分母である。"
  },
  {
    "start": 588812,
    "end": 592678,
    "text": "数値的安定のために対数空間で計算した。"
  },
  {
    "start": 592854,
    "end": 596714,
    "text": "実際の値は若干異なるが、結果は同じである。"
  },
  {
    "start": 596752,
    "end": 598934,
    "text": "モデルはこの位置エンコーディングを学習する。"
  },
  {
    "start": 599062,
    "end": 601690,
    "text": "この部分を十分に理解できなくても心配しないでほしい。"
  },
  {
    "start": 601760,
    "end": 603134,
    "text": "とても特別なんだ。"
  },
  {
    "start": 603252,
    "end": 607678,
    "text": "この位置情報をモデルに伝える関数を言ってみよう。"
  },
  {
    "start": 607844,
    "end": 611518,
    "text": "前回のビデオを見てもらえれば、その理由もわかってもらえると思う。"
  },
  {
    "start": 611604,
    "end": 621298,
    "text": "さて、これを分子と分母に当てはめて正弦と余弦を考える。覚えているように、正弦は偶数位置、余弦は奇数位置だけに使われる。"
  },
  {
    "start": 621384,
    "end": 623170,
    "text": "これを2回適用する。"
  },
  {
    "start": 623510,
    "end": 624594,
    "text": "そうしよう。"
  },
  {
    "start": 624712,
    "end": 641510,
    "text": "を適用すると、すべてのポジションが符号を持つが、偶数次元だけが符号を持つので、すべての単語が符号を持つ。"
  },
  {
    "start": 641590,
    "end": 657390,
    "text": "ゼロから始めて2つ進むということは、ゼロ、2、4、......といった具合に、ポジションにdiv termを掛けるということだ。"
  },
  {
    "start": 660050,
    "end": 662910,
    "text": "次にコサインについても同じことをする。"
  },
  {
    "start": 666630,
    "end": 670114,
    "text": "この場合、1から始めて2ずつ進む。"
  },
  {
    "start": 670152,
    "end": 672690,
    "text": "1、3、5、などという意味だ。"
  },
  {
    "start": 678730,
    "end": 685410,
    "text": "となると、このテンソルにバッチ次元を追加して、文章全体に適用できるようにする必要がある。"
  },
  {
    "start": 685490,
    "end": 691974,
    "text": "というのも、今はDモデルに配列の長さを合わせた形になっているが、文章のバッチを持つことになるからだ。"
  },
  {
    "start": 692102,
    "end": 708240,
    "text": "これは、unsquezeを使い、最初の位置で行うので、dモデルに対する長さのシーケンスに1つずつ、形状のテンソルになる。"
  },
  {
    "start": 708610,
    "end": 714094,
    "text": "最後に、このテンソルをこのモジュールのバッファに登録することができる。"
  },
  {
    "start": 714142,
    "end": 715902,
    "text": "モジュールのバッファーは何ですか？"
  },
  {
    "start": 715966,
    "end": 717266,
    "text": "まずはやってみよう。"
  },
  {
    "start": 717448,
    "end": 719250,
    "text": "レジスタバッファ。"
  },
  {
    "start": 722470,
    "end": 731506,
    "text": "基本的に、モジュール内に保存しておきたいテンソルがある場合、パラメータとしてではなく、学習したパラメータでもなく、保存しておきたい。"
  },
  {
    "start": 731538,
    "end": 735634,
    "text": "モジュールのファイルを保存する際には、バッファとして登録する必要がある。"
  },
  {
    "start": 735682,
    "end": 739694,
    "text": "こうすることで、テンソルはモジュールの状態とともにファイルに保存される。"
  },
  {
    "start": 739762,
    "end": 742730,
    "text": "それからフォワード・メソッドを行う。"
  },
  {
    "start": 747070,
    "end": 753722,
    "text": "前述したように、文中のすべての単語にこの位置エンコーディングを追加する必要がある。"
  },
  {
    "start": 753786,
    "end": 754830,
    "text": "そうしよう"
  },
  {
    "start": 754900,
    "end": 761470,
    "text": "xはxにこの文の位置エンコーディングを足したものに等しい。"
  },
  {
    "start": 772310,
    "end": 779686,
    "text": "というのも、位置エンコーディングは固定されているからだ。"
  },
  {
    "start": 779708,
    "end": 782518,
    "text": "トレーニングの過程で身につくものではない。"
  },
  {
    "start": 782604,
    "end": 786242,
    "text": "私たちはただ、折り目をつけるだけです。"
  },
  {
    "start": 786306,
    "end": 790650,
    "text": "これにより、この特定のテンソルは学習されなくなる。"
  },
  {
    "start": 790990,
    "end": 792810,
    "text": "その後、ドロップアウトを適用する。"
  },
  {
    "start": 796110,
    "end": 796906,
    "text": "それだけだ。"
  },
  {
    "start": 796928,
    "end": 798390,
    "text": "これは位置エンコーディングである。"
  },
  {
    "start": 798470,
    "end": 800134,
    "text": "次のモジュールを見てみよう。"
  },
  {
    "start": 800182,
    "end": 806318,
    "text": "よし、まずはトランスのエンコーダー部分を作ろう。"
  },
  {
    "start": 806484,
    "end": 811118,
    "text": "我々はまだ、加算とノルム、そしてフィードフォワードを構築するためのマルチヘッドアテンションを持っている。"
  },
  {
    "start": 811204,
    "end": 816138,
    "text": "実際には、このスキップコネクションをこれらすべてのサブレイヤーに接続する別のレイヤーがある。"
  },
  {
    "start": 816234,
    "end": 817874,
    "text": "一番簡単なものから始めよう。"
  },
  {
    "start": 817912,
    "end": 823298,
    "text": "レイヤーの正規化から始めよう。前回のビデオを覚えているだろうか？"
  },
  {
    "start": 823384,
    "end": 825422,
    "text": "レイヤーの正規化を見てみよう。"
  },
  {
    "start": 825486,
    "end": 826638,
    "text": "ブリーフィングを少し。"
  },
  {
    "start": 826734,
    "end": 834690,
    "text": "つまり、レイヤーの正規化とは、基本的に、n個のアイテムのバッチ（この場合は3個だけ）がある場合、各アイテムがいくつかの特徴を持つことを意味する。"
  },
  {
    "start": 834770,
    "end": 841018,
    "text": "これらは実際には文であり、それぞれの文は数字と多くの単語で構成されているとしよう。"
  },
  {
    "start": 841184,
    "end": 843606,
    "text": "これが3つの項目だ。"
  },
  {
    "start": 843718,
    "end": 852750,
    "text": "層正規化とは、バッチ内の各項目について、バッチの他の項目とは独立に平均と分散を計算することである。"
  },
  {
    "start": 853090,
    "end": 860202,
    "text": "そして、レイヤーの正規化において、それぞれの平均と分散を用いて、それぞれの新しい値を計算する。"
  },
  {
    "start": 860266,
    "end": 865418,
    "text": "通常、ガンマとベータと呼ばれるパラメータも導入する。"
  },
  {
    "start": 865514,
    "end": 867486,
    "text": "それをアルファとベータと呼ぶ人もいる。"
  },
  {
    "start": 867518,
    "end": 869262,
    "text": "それをアルファとバイアスと呼ぶ人もいる。"
  },
  {
    "start": 869326,
    "end": 870498,
    "text": "オーケー、それは問題じゃない。"
  },
  {
    "start": 870584,
    "end": 875150,
    "text": "1つは乗法的で、このxのそれぞれと乗算され、1つは加法的である。"
  },
  {
    "start": 875230,
    "end": 886390,
    "text": "というのも、この値を増幅する必要があるときに、モデルがこの値を増幅できるようにしたいからだ。"
  },
  {
    "start": 886810,
    "end": 894550,
    "text": "モデルは、増幅させたい値を増幅させるように、このガンマをこれらの値に乗算することを学習する。"
  },
  {
    "start": 894630,
    "end": 895402,
    "text": "よし、行こう。"
  },
  {
    "start": 895456,
    "end": 909710,
    "text": "このレイヤーのコードを構築するために、通常通りレイヤーの正規化とコンストラクタを定義しよう。"
  },
  {
    "start": 911250,
    "end": 924050,
    "text": "この場合、これからお見せするイプシロン以外のパラメータは必要ありません。通常、EPSはイプシロンの略で、モデルに与える必要のある非常に小さな数値です。"
  },
  {
    "start": 924120,
    "end": 927014,
    "text": "また、なぜこの数字が必要なのかも紹介しよう。"
  },
  {
    "start": 927212,
    "end": 930680,
    "text": "この場合、10のマイナス6乗を使う。"
  },
  {
    "start": 931290,
    "end": 932600,
    "text": "保存しよう。"
  },
  {
    "start": 933770,
    "end": 942074,
    "text": "スライドを見ると、この式の分母にこのイプシロンがある。"
  },
  {
    "start": 942112,
    "end": 950086,
    "text": "キャップ付きxは、x、jからmuを引いたものをシグマの平方根で割ったものにイプシロンを足したものに等しい。"
  },
  {
    "start": 950198,
    "end": 951514,
    "text": "なぜこのイプシロンが必要なのか？"
  },
  {
    "start": 951562,
    "end": 953818,
    "text": "この分母を想像してみてほしい。"
  },
  {
    "start": 953914,
    "end": 968430,
    "text": "シグマがゼロかゼロに非常に近い場合、このx nuは非常に大きくなり、CPUやGPUはある位置とスケールまでの数値しか表現できないことがわかっているので、これは望ましくない。"
  },
  {
    "start": 968510,
    "end": 971234,
    "text": "大きな数字も小さな数字もいらない。"
  },
  {
    "start": 971352,
    "end": 976018,
    "text": "通常、数値的安定性のために、ゼロによる除算を避けるためにこのイプシロンも使用する。"
  },
  {
    "start": 976104,
    "end": 977346,
    "text": "前へ進もう。"
  },
  {
    "start": 977448,
    "end": 981170,
    "text": "では、レイヤーの正規化に使う2つのパラメーターを紹介しよう。"
  },
  {
    "start": 981250,
    "end": 984642,
    "text": "ひとつはアルファと呼ばれるもので、これは乗算され、もうひとつはバイアスである。"
  },
  {
    "start": 984706,
    "end": 985810,
    "text": "どちらが追加されるのか。"
  },
  {
    "start": 985890,
    "end": 988422,
    "text": "通常、加法はバイアスと呼ばれる。"
  },
  {
    "start": 988486,
    "end": 992010,
    "text": "常に加算され、アルファは乗算されるものだ。"
  },
  {
    "start": 994510,
    "end": 997126,
    "text": "この場合、nnパラメータを使用する。"
  },
  {
    "start": 997238,
    "end": 1006270,
    "text": "これにより、パラメータは学習可能になり、バイアスも定義される。"
  },
  {
    "start": 1010930,
    "end": 1017090,
    "text": "これは掛け算で、これは足し算だ。"
  },
  {
    "start": 1018230,
    "end": 1019860,
    "text": "フォワードを定義しよう。"
  },
  {
    "start": 1022310,
    "end": 1027394,
    "text": "さて、覚えているように、平均と標準偏差または分散を計算する必要がある。"
  },
  {
    "start": 1027442,
    "end": 1037282,
    "text": "いずれも、最後の次元の標準偏差を計算する。"
  },
  {
    "start": 1037346,
    "end": 1042730,
    "text": "バッチの後、我々は寸法を維持する。"
  },
  {
    "start": 1044430,
    "end": 1063620,
    "text": "このパラメータkeep dimensionは、通常は平均が適用された次元をキャンセルするが、我々はそれを維持したいことを意味する。"
  },
  {
    "start": 1064310,
    "end": 1067294,
    "text": "そうしたら、スライドで見た公式を適用するだけです。"
  },
  {
    "start": 1067422,
    "end": 1084150,
    "text": "alphaにxからその平均を標準偏差で割ったものを掛け、さらに自己のドットepsを加え、すべてをバイアスに加える。"
  },
  {
    "start": 1087770,
    "end": 1089698,
    "text": "これがレイヤーの正規化だ。"
  },
  {
    "start": 1089874,
    "end": 1093098,
    "text": "では、次に作るレイヤーを見てみよう。"
  },
  {
    "start": 1093184,
    "end": 1096762,
    "text": "次のレイヤーはフィードフォワードだ。"
  },
  {
    "start": 1096896,
    "end": 1106314,
    "text": "フィードフォワードは基本的に完全連結層で、エンコーダーとデコーダーの両方で使われる。"
  },
  {
    "start": 1106442,
    "end": 1112334,
    "text": "まず、このフィードフォワード層の詳細を論文で見てみよう。"
  },
  {
    "start": 1112452,
    "end": 1123438,
    "text": "フィードフォワード層は基本的に2つのマトリックスで構成され、1つはW1、もう1つはW2である。"
  },
  {
    "start": 1123614,
    "end": 1138902,
    "text": "Pytorchでは線形レイヤーを使ってこれを行うことができ、最初のレイヤーはw1とb1の行列、2番目のレイヤーはw2とb2の行列と定義し、その間にrluを適用する。"
  },
  {
    "start": 1138956,
    "end": 1142614,
    "text": "これらの行列の次元も見ることができる。"
  },
  {
    "start": 1142742,
    "end": 1148986,
    "text": "1つ目は基本的にDモデルからDFFへ、2つ目はDFFからDモデルへ。"
  },
  {
    "start": 1149088,
    "end": 1153166,
    "text": "DFFは2048、Dモデルは512。"
  },
  {
    "start": 1153268,
    "end": 1154654,
    "text": "さあ、作ろう。"
  },
  {
    "start": 1154852,
    "end": 1164350,
    "text": "クラス・フィードフォワード・ブロックは、この場合はコンストラクターも構築する。"
  },
  {
    "start": 1167650,
    "end": 1171262,
    "text": "コンストラクタでは、論文で見た2つの値を定義する必要がある。"
  },
  {
    "start": 1171316,
    "end": 1175640,
    "text": "Dモデルはdffで、この場合もドロップアウトする。"
  },
  {
    "start": 1186890,
    "end": 1198090,
    "text": "最初の行列、つまりw1とb1を線形行列と定義し、Dモデルからdffまでとする。"
  },
  {
    "start": 1198830,
    "end": 1200830,
    "text": "その後、ドロップアウトを適用する。"
  },
  {
    "start": 1201250,
    "end": 1211694,
    "text": "実際には、ドロップアウトを定義し、次に2番目の行列、w 2とb 2を定義する。"
  },
  {
    "start": 1211732,
    "end": 1213074,
    "text": "コメントをここに書かせてください。"
  },
  {
    "start": 1213112,
    "end": 1228246,
    "text": "DfF2Dモデルのw1とb1であり、これはw2とb2である。"
  },
  {
    "start": 1228428,
    "end": 1229702,
    "text": "なぜ2つあるのか？"
  },
  {
    "start": 1229756,
    "end": 1234390,
    "text": "実際、ここにあるように、バイアスはデフォルトで真実なのだから。"
  },
  {
    "start": 1234460,
    "end": 1237400,
    "text": "それはすでに私たちのためにバイアスマトリックスを定義している。"
  },
  {
    "start": 1240750,
    "end": 1243210,
    "text": "では、フォワード・メソッドを定義しよう。"
  },
  {
    "start": 1245950,
    "end": 1251530,
    "text": "この場合、私たちがやろうとしているのは、バッチという入力文があるということだ。"
  },
  {
    "start": 1251610,
    "end": 1257360,
    "text": "次元バッチシーケンス長とDモデルを持つテンソルである。"
  },
  {
    "start": 1257890,
    "end": 1267934,
    "text": "まず、リニアを使って、DfFのシーケンス長をバッチテンソルに変換する。"
  },
  {
    "start": 1268062,
    "end": 1290300,
    "text": "というのも、このリニアを適用すると、DモデルがDFFに変換され、次にリニアを適用すると、その間にDモデルに変換されるからだ。"
  },
  {
    "start": 1298110,
    "end": 1300358,
    "text": "これがフィードフォワード・ブロックだ。"
  },
  {
    "start": 1300534,
    "end": 1302762,
    "text": "次のブロックを見てみよう。"
  },
  {
    "start": 1302906,
    "end": 1308030,
    "text": "次のブロックは、最も重要で最も興味深いもので、マルチヘッド・アテンションだ。"
  },
  {
    "start": 1309090,
    "end": 1314814,
    "text": "マルチヘッドアテンションがどのように機能するかは、前回のビデオで簡単に、いや、実際に詳しく見た。"
  },
  {
    "start": 1314852,
    "end": 1320482,
    "text": "スライドをもう一度開いて、実際にどのように機能するのかリハーサルしてみよう。"
  },
  {
    "start": 1320536,
    "end": 1323262,
    "text": "それなら、コーディングで実践的にやろう。"
  },
  {
    "start": 1323326,
    "end": 1331190,
    "text": "覚えているように、エンコーダーには、エンコーダーの入力を3回使用するマルチヘッドアテンションがある。"
  },
  {
    "start": 1331340,
    "end": 1336498,
    "text": "ある時はクエリーと呼ばれ、ある時はキーと呼ばれ、ある時はバリューと呼ばれる。"
  },
  {
    "start": 1336594,
    "end": 1343418,
    "text": "入力が3回重複していると考えることもできるし、同じ入力を3回適用していると言うこともできる。"
  },
  {
    "start": 1343584,
    "end": 1346042,
    "text": "マルチハイドの注意は基本的にこうだ。"
  },
  {
    "start": 1346096,
    "end": 1350314,
    "text": "Dモデルによる配列長の入力配列がある。"
  },
  {
    "start": 1350512,
    "end": 1362458,
    "text": "q、k、vという3つの行列に変換する。この行列はこの場合、入力とまったく同じであるが、ここではエンコーダーの話をしているので、デコーダーでは少し異なることがわかるだろう。"
  },
  {
    "start": 1362564,
    "end": 1374340,
    "text": "そして、これにWQWKとWvと呼ばれる行列を掛けると、Dモデルによる次元数列の新しい行列ができる。"
  },
  {
    "start": 1374870,
    "end": 1379634,
    "text": "次に、これらの行列をH行列とモル行列に分割する。"
  },
  {
    "start": 1379682,
    "end": 1380262,
    "text": "なぜHなのか？"
  },
  {
    "start": 1380316,
    "end": 1383586,
    "text": "なぜなら、このマルチヘッドに必要なヘッドの数だからだ。"
  },
  {
    "start": 1383698,
    "end": 1396794,
    "text": "つまり、各ヘッドは完全な文にアクセスできるが、各単語の埋め込みの異なる部分にアクセスできることになる。"
  },
  {
    "start": 1396992,
    "end": 1405070,
    "text": "この式を使って、それぞれのモル行列に注意を払うと、結果として行列が小さくなる。"
  },
  {
    "start": 1405220,
    "end": 1406926,
    "text": "そして、また合体させる。"
  },
  {
    "start": 1407028,
    "end": 1410862,
    "text": "新聞に書いてあるように、我々はそれらを連結して戻す。"
  },
  {
    "start": 1410916,
    "end": 1423774,
    "text": "ヘッド1からヘッドhまでを連結し、最後にそれをwoと掛け合わせ、再び入力行列と同じ次元の行列である多ヘッド注目出力を得る。"
  },
  {
    "start": 1423822,
    "end": 1429234,
    "text": "ご覧のように、このスライドではマルチヘッドアテンションの出力もDモデルによってシーケンスされている。"
  },
  {
    "start": 1429282,
    "end": 1433554,
    "text": "実は、1つの文章について話しているので、バッチ次元は表示していない。"
  },
  {
    "start": 1433602,
    "end": 1438850,
    "text": "トランスフォーマーをコーディングするとき、私たちは1つのセンテンスだけを扱うのではなく、複数のセンテンスを扱う。"
  },
  {
    "start": 1438930,
    "end": 1443290,
    "text": "ここにはバッチという別の次元があると考える必要がある。"
  },
  {
    "start": 1444350,
    "end": 1448102,
    "text": "では、このマルチヘッドに注目するコードを書いてみよう。"
  },
  {
    "start": 1448166,
    "end": 1453662,
    "text": "もう少しゆっくりやって、どのように行われるかをすべて詳しく見ることができるようにするつもりだ。"
  },
  {
    "start": 1453796,
    "end": 1459598,
    "text": "その仕組みと、なぜ私たちがこのようなことをしているのかについて、あらためて概要を知っていただきたかったのです。"
  },
  {
    "start": 1459684,
    "end": 1461440,
    "text": "さあ、コーディングしよう。"
  },
  {
    "start": 1462050,
    "end": 1466750,
    "text": "クラシックだ。"
  },
  {
    "start": 1469970,
    "end": 1477454,
    "text": "また、この場合、コンストラクタを定義し、このマルチヘッド・アテンションに何をパラメータとして与える必要があるかを定義する。"
  },
  {
    "start": 1477502,
    "end": 1486294,
    "text": "確かに、dモデルは我々の場合512であり、論文と同じようにhと呼ぶヘッドの数である。"
  },
  {
    "start": 1486492,
    "end": 1490700,
    "text": "hは必要なヘッド数、そしてドロップアウト値を示す。"
  },
  {
    "start": 1492750,
    "end": 1494410,
    "text": "これらの値は保存しておく。"
  },
  {
    "start": 1500430,
    "end": 1508174,
    "text": "おわかりのように、この埋め込みベクトルをh個の頭に分割する必要がある。"
  },
  {
    "start": 1508212,
    "end": 1517394,
    "text": "そうでなければ、埋め込みを表す同じベクトルを、各ヘッドごとに等しい行列に分割することはできない。"
  },
  {
    "start": 1517512,
    "end": 1520980,
    "text": "モデルは基本的にhで割り切れることを確認する。"
  },
  {
    "start": 1533290,
    "end": 1541958,
    "text": "私のスライドをもう一度見ると、Dモデルをhで割った値が減衰と呼ばれることがわかります。"
  },
  {
    "start": 1542054,
    "end": 1543340,
    "text": "ここにあるように。"
  },
  {
    "start": 1543710,
    "end": 1550802,
    "text": "Dモデルをh個のヘッドで割ると、減衰と呼ばれる新しい値が得られる。"
  },
  {
    "start": 1550886,
    "end": 1556154,
    "text": "論文で使用されている命名法に合わせるため、ここではdkと呼ぶことにする。"
  },
  {
    "start": 1556202,
    "end": 1559280,
    "text": "dkはDモデルをhで割ったもの。"
  },
  {
    "start": 1569270,
    "end": 1576600,
    "text": "また、クエリー、キー、値を掛け合わせる行列と、出力行列woも定義しておこう。"
  },
  {
    "start": 1581530,
    "end": 1582930,
    "text": "これもまたリニアだ。"
  },
  {
    "start": 1583010,
    "end": 1585430,
    "text": "DモデルからDモデルへ。"
  },
  {
    "start": 1585500,
    "end": 1587030,
    "text": "なぜD型からD型なのか？"
  },
  {
    "start": 1587100,
    "end": 1596440,
    "text": "なぜなら、私のスライドを見てわかるように、これはDモデルによるDモデルなので、出力はDモデルによって順番に行われるからだ。"
  },
  {
    "start": 1599290,
    "end": 1621758,
    "text": "これがWQで、これがWBだ。"
  },
  {
    "start": 1621854,
    "end": 1626566,
    "text": "最後に、woと呼ばれる出力行列がある。"
  },
  {
    "start": 1626748,
    "end": 1630998,
    "text": "この \"Wo \"は \"h by dv by D \"モデルである。"
  },
  {
    "start": 1631164,
    "end": 1632722,
    "text": "hはdvで。"
  },
  {
    "start": 1632866,
    "end": 1638714,
    "text": "Dvは、DモデルをHで割ったものなので、実際にはdkに等しい。"
  },
  {
    "start": 1638832,
    "end": 1645418,
    "text": "なぜここでdv、ここでdkと呼ばれるかというと、このヘッドは実際に結果だからだ。"
  },
  {
    "start": 1645584,
    "end": 1650090,
    "text": "このヘッドはこの掛け算から生まれ、最後の掛け算はvによるものだ。"
  },
  {
    "start": 1650240,
    "end": 1656458,
    "text": "論文ではこの値をdvと呼んでいるが、実用レベルではdkに等しい。"
  },
  {
    "start": 1656634,
    "end": 1664180,
    "text": "h×dvはDモデルに等しいので、我々のwoもDモデル×Dモデルの行列である。"
  },
  {
    "start": 1672630,
    "end": 1674020,
    "text": "これがそうだ。"
  },
  {
    "start": 1674470,
    "end": 1676390,
    "text": "最後に、ドロップアウトを作る。"
  },
  {
    "start": 1682410,
    "end": 1689260,
    "text": "フォワード・メソッドを実装し、マルチヘッド・アテンションがどのように機能するかを詳しく見てみよう。"
  },
  {
    "start": 1689870,
    "end": 1697062,
    "text": "コーディングの過程で、クエリー、キー、値を定義する。"
  },
  {
    "start": 1697126,
    "end": 1698422,
    "text": "このマスクがある。"
  },
  {
    "start": 1698486,
    "end": 1700330,
    "text": "このマスクは何ですか？"
  },
  {
    "start": 1700990,
    "end": 1707854,
    "text": "マスクは基本的に、ある単語が他の単語と相互作用しないようにしたい場合、その単語をマスクする。"
  },
  {
    "start": 1707972,
    "end": 1709630,
    "text": "前回のビデオで見たとおりだ。"
  },
  {
    "start": 1709700,
    "end": 1713486,
    "text": "では、マスクが何をしているのか、そのライトに戻って見てみよう。"
  },
  {
    "start": 1713588,
    "end": 1726230,
    "text": "この式を使ってアテンションを計算するとき、qのソフトマックスにktを掛け、dkの平方根で割ったものをvで割ると、このようなヘッドマトリックスができることを思い出してほしい。"
  },
  {
    "start": 1726570,
    "end": 1738054,
    "text": "つまり、qとkの掛け算だけで、各単語と各単語が結合した行列ができる。"
  },
  {
    "start": 1738172,
    "end": 1740358,
    "text": "シーケンスごとのマトリックスだ。"
  },
  {
    "start": 1740454,
    "end": 1752070,
    "text": "ある単語を他の単語と相互作用させたくない場合は、ソフトマックスを適用する前に、基本的にその単語のアテンション・スコアの値を非常に小さいものに置き換える。"
  },
  {
    "start": 1752150,
    "end": 1755630,
    "text": "ソフトマックスを適用すると、これらの値はゼロになる。"
  },
  {
    "start": 1755700,
    "end": 1760126,
    "text": "覚えているように、分子のソフトマックスはeのx乗だからだ。"
  },
  {
    "start": 1760228,
    "end": 1768740,
    "text": "xがマイナス無限大になり非常に小さくなれば、eのマイナス無限大乗は非常に小さくなり、ゼロに非常に近くなる。"
  },
  {
    "start": 1769190,
    "end": 1774162,
    "text": "基本的に、私たちはこの2つの言葉のために注意を隠す。"
  },
  {
    "start": 1774296,
    "end": 1778306,
    "text": "これがマスクの仕事だ。"
  },
  {
    "start": 1778418,
    "end": 1781462,
    "text": "私のスライドに従って、掛け算を1つずつやっていきます。"
  },
  {
    "start": 1781516,
    "end": 1786930,
    "text": "覚えているように、まずクエリにWqを掛けて計算する。"
  },
  {
    "start": 1787090,
    "end": 1794374,
    "text": "自己のドットWQとクエリを掛け合わせると、新しい行列ができる。"
  },
  {
    "start": 1794422,
    "end": 1795382,
    "text": "私はクエリーと呼んでいるだけだ。"
  },
  {
    "start": 1795446,
    "end": 1803310,
    "text": "ここでは、キーも値も同じにする。"
  },
  {
    "start": 1807570,
    "end": 1809338,
    "text": "寸法も書いておこう。"
  },
  {
    "start": 1809434,
    "end": 1815780,
    "text": "バッチシーケンス長からDモデルへ。"
  },
  {
    "start": 1816150,
    "end": 1823282,
    "text": "この掛け算で、バッチシーケンス長とDモデルである別の行列を作ることになる。"
  },
  {
    "start": 1823416,
    "end": 1825118,
    "text": "スライドを見ればわかるだろう。"
  },
  {
    "start": 1825214,
    "end": 1833586,
    "text": "Dモデル×Dモデル×Dモデルでシーケンスを行うと、初期行列と同じ次元を持つ新しい行列が得られる。"
  },
  {
    "start": 1833618,
    "end": 1839420,
    "text": "Dモデルによるシーケンスで、3つとも同じだ。"
  },
  {
    "start": 1843150,
    "end": 1854110,
    "text": "さて、ここでやりたいことは、このクエリーのキーと値を小さな行列に分割し、それぞれの小さな行列を異なるヘッドに渡すことだ。"
  },
  {
    "start": 1854260,
    "end": 1855600,
    "text": "そうしよう"
  },
  {
    "start": 1856690,
    "end": 1870930,
    "text": "Pytorchのビューメソッドを使って、バッチ次元を維持したまま、文章を分割するのではなく、埋め込みをh個の部分に分割する。"
  },
  {
    "start": 1872390,
    "end": 1877414,
    "text": "また、2つ目の次元であるシーケンスは分割したくないので残しておきたい。"
  },
  {
    "start": 1877612,
    "end": 1885442,
    "text": "Dモデルは3番目の次元なので、それを2つのより小さな次元に分割したい。"
  },
  {
    "start": 1885506,
    "end": 1889450,
    "text": "セルフ・ドット、hセルフ・ドット、dk."
  },
  {
    "start": 1890670,
    "end": 1894730,
    "text": "覚えているように、Dkは基本的にDモデルをhで割ったものである。"
  },
  {
    "start": 1894800,
    "end": 1899100,
    "text": "これを掛け合わせると、Dモデルになる。"
  },
  {
    "start": 1900770,
    "end": 1906782,
    "text": "で、1、2を転置する。"
  },
  {
    "start": 1906916,
    "end": 1908042,
    "text": "なぜ移籍するのか？"
  },
  {
    "start": 1908106,
    "end": 1912538,
    "text": "なぜなら、我々はエッジの寸法を持つことを好むからだ。"
  },
  {
    "start": 1912634,
    "end": 1916450,
    "text": "三次元ではなく、二次元であってほしい。"
  },
  {
    "start": 1917190,
    "end": 1922654,
    "text": "こうすることで、各ヘッドがすべての文章を見ることができる。"
  },
  {
    "start": 1922702,
    "end": 1923934,
    "text": "この次元を見ることになるだろう。"
  },
  {
    "start": 1923982,
    "end": 1926230,
    "text": "減衰による配列の長さ。"
  },
  {
    "start": 1928010,
    "end": 1930040,
    "text": "ここにもコメントを書かせてください。"
  },
  {
    "start": 1931690,
    "end": 1944182,
    "text": "バッチシーケンス長Dモデルからバッチシーケンス長hdkモデルへ。"
  },
  {
    "start": 1944246,
    "end": 1952910,
    "text": "ということは、転置を使うことで、h個のシーケンスの長さと減衰を一括することになる。"
  },
  {
    "start": 1953730,
    "end": 1963038,
    "text": "これは本当に重要なことだ。"
  },
  {
    "start": 1963124,
    "end": 1967882,
    "text": "つまり、各ヘッドの全文を見ることになる。"
  },
  {
    "start": 1968026,
    "end": 2026120,
    "text": "文中の各単語は、埋め込みのごく一部だが、キーとその値については同じことをする。"
  },
  {
    "start": 2028170,
    "end": 2034198,
    "text": "さて、小さいマトリックスができたので、スライドに戻り、現在地をお見せしましょう。"
  },
  {
    "start": 2034364,
    "end": 2038594,
    "text": "この乗算を行うと、クエリーのキーと値が得られる。"
  },
  {
    "start": 2038642,
    "end": 2040870,
    "text": "より小さなマトリックスに分割した。"
  },
  {
    "start": 2040950,
    "end": 2044394,
    "text": "ここで、この式を使って注目度を計算する必要がある。"
  },
  {
    "start": 2044592,
    "end": 2048822,
    "text": "注目度を計算する前に、注目度を計算する関数を作ってみよう。"
  },
  {
    "start": 2048886,
    "end": 2053694,
    "text": "もし、後で使える新しい関数を作ったら。"
  },
  {
    "start": 2053812,
    "end": 2059870,
    "text": "というわけで、静的メソッドとして定義してみよう。"
  },
  {
    "start": 2063970,
    "end": 2070226,
    "text": "staticメソッドとは、基本的に、このクラスのインスタンスを持っていなくてもこの関数を呼び出せることを意味する。"
  },
  {
    "start": 2070328,
    "end": 2073262,
    "text": "マルチヘッドアテンション、ブロックドットアテンションと言えばいい。"
  },
  {
    "start": 2073326,
    "end": 2084790,
    "text": "このクラスのインスタンスを持つ代わりに、ドロップアウト・レイヤーも与える。"
  },
  {
    "start": 2085770,
    "end": 2093340,
    "text": "ディケイとは、クエリのキーと値の最後のディメンジョンです。"
  },
  {
    "start": 2098270,
    "end": 2104366,
    "text": "この関数の使い方を理解していただくために、まずこの関数を呼び出します。"
  },
  {
    "start": 2104388,
    "end": 2105694,
    "text": "そして、それを定義する。"
  },
  {
    "start": 2105732,
    "end": 2112314,
    "text": "私たちがこの関数に求めるものは2つ、出力と注目点である。"
  },
  {
    "start": 2112362,
    "end": 2117250,
    "text": "ソフトマックスのテンションスコアの出力。"
  },
  {
    "start": 2117590,
    "end": 2121250,
    "text": "このように呼ぶことにする。"
  },
  {
    "start": 2121320,
    "end": 2128658,
    "text": "クエリ、キー、値、マスク、ドロップアウト・レイヤーを与える。"
  },
  {
    "start": 2128834,
    "end": 2130680,
    "text": "さて、ここに戻ろう。"
  },
  {
    "start": 2131770,
    "end": 2133042,
    "text": "私たちには崩壊がある。"
  },
  {
    "start": 2133106,
    "end": 2136642,
    "text": "では、まず公式の最初の部分を適用する。"
  },
  {
    "start": 2136706,
    "end": 2143130,
    "text": "つまり、キーの移調にディケイの平方根を掛けたものである。"
  },
  {
    "start": 2143790,
    "end": 2146330,
    "text": "これが注目のスコアだ。"
  },
  {
    "start": 2149710,
    "end": 2152234,
    "text": "行列の乗算を問い合わせる。"
  },
  {
    "start": 2152282,
    "end": 2154842,
    "text": "この加算記号は行列の乗算を意味する。"
  },
  {
    "start": 2154906,
    "end": 2161386,
    "text": "ピトーチでは、最後の2つの次元を転置する。"
  },
  {
    "start": 2161498,
    "end": 2164414,
    "text": "マイナス2、マイナス1とは、最後の2つの次元を入れ替えることを意味する。"
  },
  {
    "start": 2164462,
    "end": 2169758,
    "text": "となり、最後の次元は減衰によるシーケンス長である。"
  },
  {
    "start": 2169774,
    "end": 2171730,
    "text": "シークエンスの長さによって減衰する。"
  },
  {
    "start": 2172710,
    "end": 2178210,
    "text": "そして、これをマット・ディケイで割る。"
  },
  {
    "start": 2180650,
    "end": 2184914,
    "text": "ソフトマックスを適用する前に見たように、マスクを適用する必要がある。"
  },
  {
    "start": 2184962,
    "end": 2187510,
    "text": "単語間の相互作用を隠したい。"
  },
  {
    "start": 2187580,
    "end": 2190626,
    "text": "マスクを適用し、ソフトマックスを適用する。"
  },
  {
    "start": 2190658,
    "end": 2194214,
    "text": "ソフトマックスは、置き換えた値を処理する。"
  },
  {
    "start": 2194342,
    "end": 2195798,
    "text": "どのようにマスクをするのですか？"
  },
  {
    "start": 2195894,
    "end": 2203600,
    "text": "マスクしたい値をすべて、非常に小さな値に置き換え、ソフトマックスがそれらをゼロに置き換えるようにする。"
  },
  {
    "start": 2204610,
    "end": 2213140,
    "text": "マスクが定義されていれば、それを適用する。"
  },
  {
    "start": 2222710,
    "end": 2230630,
    "text": "これは基本的に、このステートメントが真であるすべての値をこの値に置き換えることを意味する。"
  },
  {
    "start": 2230780,
    "end": 2238710,
    "text": "マスクは、この値、この式が真である場合、この値に置き換えるように定義する。"
  },
  {
    "start": 2238780,
    "end": 2241798,
    "text": "マスクの作り方も後で見てみよう。"
  },
  {
    "start": 2241894,
    "end": 2248422,
    "text": "とりあえず、これらはすべて注目されたくない価値観であることを当然のこととして受け止めておいてほしい。"
  },
  {
    "start": 2248486,
    "end": 2255226,
    "text": "例えば、ある単語が将来の単語、例えばデコーダーを作るときの単語を監視するようなことは避けたい。"
  },
  {
    "start": 2255338,
    "end": 2261022,
    "text": "あるいは、パディング値は単なるフィラーなので、他の値と相互作用させたくない。"
  },
  {
    "start": 2261076,
    "end": 2277874,
    "text": "数列の長さに達するには、マイナス1のマイナス10の9乗に置き換える。これは負の範囲の非常に大きな数で、基本的にマイナス無限大を表す。"
  },
  {
    "start": 2278002,
    "end": 2292230,
    "text": "ということは、今ソフトマックスを適用すると、この次元はゼロに置き換えられることになる。"
  },
  {
    "start": 2292390,
    "end": 2294886,
    "text": "では、いくつかコメントを書かせてもらおう。"
  },
  {
    "start": 2294998,
    "end": 2305950,
    "text": "この場合、バッチはhずつなので、各ヘッドは、次にシーケンス長とシーケンス長になる。"
  },
  {
    "start": 2307570,
    "end": 2309562,
    "text": "よし、もし脱落者が出たとしてもだ。"
  },
  {
    "start": 2309626,
    "end": 2313730,
    "text": "ドロップアウトが不明な場合は、ドロップアウトも適用する。"
  },
  {
    "start": 2321190,
    "end": 2331442,
    "text": "最後に、元のスライドで見たように、ソフトマックスの出力にv行列を掛け合わせる。"
  },
  {
    "start": 2331506,
    "end": 2338438,
    "text": "アテンション・スコアに値を掛けたものと、アテンション・スコアそのものを返す。"
  },
  {
    "start": 2338524,
    "end": 2340878,
    "text": "なぜタプルを返すのか？"
  },
  {
    "start": 2340994,
    "end": 2349254,
    "text": "もちろん、次のレイヤーに渡す必要があるため、モデルには必要だが、これは視覚化に使用する。"
  },
  {
    "start": 2349382,
    "end": 2353882,
    "text": "自己注意のアウトプット。"
  },
  {
    "start": 2353946,
    "end": 2358494,
    "text": "この場合のマルチヘッドの注目は、実はここにある。"
  },
  {
    "start": 2358532,
    "end": 2360282,
    "text": "私たちはそれを視覚化するために使う。"
  },
  {
    "start": 2360346,
    "end": 2365710,
    "text": "視覚化するために、その特定の相互作用についてモデルが与えたスコアは何ですか？"
  },
  {
    "start": 2367490,
    "end": 2369680,
    "text": "私からもコメントを書かせてください。"
  },
  {
    "start": 2370450,
    "end": 2387910,
    "text": "このバッチをやっているところだ。"
  },
  {
    "start": 2387980,
    "end": 2390614,
    "text": "今、我々はマルチヘッドに注目している。"
  },
  {
    "start": 2390662,
    "end": 2403050,
    "text": "マルチヘッドアテンションの出力で、最終的に何をするかというと、まずスライドに戻って、ここで小さい行列を計算するんだ。"
  },
  {
    "start": 2403120,
    "end": 2410590,
    "text": "は、ソフトマックスqをk、tをdvの平方根で割り、さらにvを掛けたものである。"
  },
  {
    "start": 2410660,
    "end": 2417698,
    "text": "ヘッド1、ヘッド2、ヘッド3、そしてスレッド4。"
  },
  {
    "start": 2417784,
    "end": 2424910,
    "text": "あとは、論文に書いてある計算式と同じように、それらを組み合わせて連結し、最後にwoを掛ける必要がある。"
  },
  {
    "start": 2425080,
    "end": 2426520,
    "text": "そうしよう"
  },
  {
    "start": 2434090,
    "end": 2450560,
    "text": "行列をシーケンス長に変換する前に、シーケンス長を3番目の次元として持っていたので、それらを結合するために最初に戻したのである。"
  },
  {
    "start": 2451010,
    "end": 2452542,
    "text": "書かせてください。"
  },
  {
    "start": 2452596,
    "end": 2460510,
    "text": "まず、私たちがしたいこと、バッチ、私たちはこの1から始めた、配列の長さ。"
  },
  {
    "start": 2462470,
    "end": 2472500,
    "text": "まず、移調を行う。"
  },
  {
    "start": 2477530,
    "end": 2487646,
    "text": "この転置でここにたどり着き、ビューを行うのだが、これはできない。"
  },
  {
    "start": 2487698,
    "end": 2522500,
    "text": "これは基本的に、テンソルの形状を変換するためにpytorchはメモリを連続させる必要があることを意味する。"
  },
  {
    "start": 2523830,
    "end": 2524580,
    "text": "オーケー。"
  },
  {
    "start": 2525290,
    "end": 2535400,
    "text": "最後に、このxにWoを掛け合わせ、これがxの出力行列となる。"
  },
  {
    "start": 2535770,
    "end": 2553286,
    "text": "これで、バッチからマルチヘッド・アテンション・ブロックになる。"
  },
  {
    "start": 2553478,
    "end": 2555322,
    "text": "材料はすべて揃っていると思う。"
  },
  {
    "start": 2555386,
    "end": 2559658,
    "text": "さて、これらすべてを組み合わせるには、小さなレイヤーをひとつ欠くだけだ。"
  },
  {
    "start": 2559754,
    "end": 2560926,
    "text": "見に行こう。"
  },
  {
    "start": 2560948,
    "end": 2565730,
    "text": "まず、最後のレイヤーを構築する必要がある。"
  },
  {
    "start": 2565800,
    "end": 2568686,
    "text": "例えば、ここにこのレイヤーの出力がある。"
  },
  {
    "start": 2568718,
    "end": 2574722,
    "text": "このコネクションでここにノルムを追加し、この1部をここに送る。"
  },
  {
    "start": 2574856,
    "end": 2579442,
    "text": "そして、その出力は加算とノルムに送られ、この層で合成される。"
  },
  {
    "start": 2579506,
    "end": 2583362,
    "text": "このスキップ接続を管理するレイヤーを作成する必要がある。"
  },
  {
    "start": 2583426,
    "end": 2591766,
    "text": "入力を受け取り、それを1層飛ばし、前の層の出力を受け取る。"
  },
  {
    "start": 2591798,
    "end": 2597578,
    "text": "この場合、マルチヘッドに注目し、このレイヤーにそれを与えるが、この部分とも組み合わせる。"
  },
  {
    "start": 2597664,
    "end": 2599610,
    "text": "このレイヤーを作ってみよう。"
  },
  {
    "start": 2600210,
    "end": 2605178,
    "text": "基本的にスキップ接続なので、残留接続と呼ぶことにする。"
  },
  {
    "start": 2605274,
    "end": 2607550,
    "text": "よし、この残留コネクションを構築しよう。"
  },
  {
    "start": 2615590,
    "end": 2620210,
    "text": "いつものようにコンストラクタを定義し、今回はドロップアウトが必要なだけだ。"
  },
  {
    "start": 2632170,
    "end": 2637726,
    "text": "覚えているように、スキップのコネクションは、アドとノルムと前のレイヤーの間にある。"
  },
  {
    "start": 2637778,
    "end": 2644074,
    "text": "また、ノルムが必要である。これは、前に定義したレイヤーの正規化である。"
  },
  {
    "start": 2644272,
    "end": 2652190,
    "text": "そして、フォワード・メソッドとその前のレイヤーであるサブレイヤーを定義する。"
  },
  {
    "start": 2654530,
    "end": 2667010,
    "text": "xを次のレイヤー（この場合はサブレイヤー）の出力と組み合わせ、ドロップアウトを適用する。"
  },
  {
    "start": 2671510,
    "end": 2674034,
    "text": "これがアドとノルムの定義である。"
  },
  {
    "start": 2674152,
    "end": 2679962,
    "text": "実際には、まず正規化を適用し、それからサブレイヤーを適用するという若干の違いがある。"
  },
  {
    "start": 2680126,
    "end": 2685110,
    "text": "論文の場合、まずサブレイヤーを適用し、次に正規化を行う。"
  },
  {
    "start": 2685530,
    "end": 2689226,
    "text": "私は多くの実施例を見たが、そのほとんどは実際にこのようにやっていた。"
  },
  {
    "start": 2689328,
    "end": 2691580,
    "text": "我々もこの特別なものにこだわるつもりだ。"
  },
  {
    "start": 2691950,
    "end": 2701082,
    "text": "覚えているように、これらのブロックはこの大きなブロックによって組み合わされ、n個のブロックがある。"
  },
  {
    "start": 2701216,
    "end": 2704730,
    "text": "この大きなブロックをエンコーダー・ブロックと呼ぶことにする。"
  },
  {
    "start": 2704810,
    "end": 2714030,
    "text": "このエンコーダー・ブロックはそれぞれn回繰り返され、前のブロックの出力は次のブロックに送られ、最後のブロックの出力はデコーダーに送られる。"
  },
  {
    "start": 2714190,
    "end": 2722370,
    "text": "このブロックには、1つのマルチヘッドアテンション、2つの加算とノルム、1つのフィードフォワードが含まれる。"
  },
  {
    "start": 2722520,
    "end": 2726120,
    "text": "そうしよう"
  },
  {
    "start": 2728730,
    "end": 2731330,
    "text": "このブロックをエンコーダー・ブロックと呼ぶことにする。"
  },
  {
    "start": 2731490,
    "end": 2736120,
    "text": "デコーダーには3つのブロックがあるが、エンコーダーには2つしかない。"
  },
  {
    "start": 2746730,
    "end": 2748038,
    "text": "私のように。"
  },
  {
    "start": 2748204,
    "end": 2752830,
    "text": "このブロックは、マルチヘッド・アテンションである。"
  },
  {
    "start": 2753250,
    "end": 2762374,
    "text": "エンコーダーの場合、同じ入力に対して3つの異なる役割が適用されるため、私たちはこれを自己注意と呼んでいる。"
  },
  {
    "start": 2762522,
    "end": 2772754,
    "text": "キーと値のクエリーの役割は、我々のフィードフォワードである。"
  },
  {
    "start": 2772872,
    "end": 2777414,
    "text": "となると、浮動小数点であるドロップアウトがある。"
  },
  {
    "start": 2777612,
    "end": 2796410,
    "text": "次に、2つの残留コネクションを定義する。"
  },
  {
    "start": 2802290,
    "end": 2807210,
    "text": "モジュールのリストを整理する方法であるモデルリストを使う。"
  },
  {
    "start": 2807290,
    "end": 2809280,
    "text": "この場合は2本必要だ。"
  },
  {
    "start": 2825370,
    "end": 2830630,
    "text": "よし、フォワード・メソッドを定義しよう。"
  },
  {
    "start": 2835610,
    "end": 2837874,
    "text": "私はソースマスクを定義する。"
  },
  {
    "start": 2837922,
    "end": 2839234,
    "text": "ソースマスクとは？"
  },
  {
    "start": 2839282,
    "end": 2842518,
    "text": "エンコーダーの入力に適用したいマスクだ。"
  },
  {
    "start": 2842614,
    "end": 2845494,
    "text": "なぜエンコーダーの入力にマスクが必要なのか？"
  },
  {
    "start": 2845542,
    "end": 2850382,
    "text": "パディングされた単語と他の単語との相互作用を隠したいからだ。"
  },
  {
    "start": 2850436,
    "end": 2853280,
    "text": "パディングワードが他の単語と相互作用することは避けたい。"
  },
  {
    "start": 2853650,
    "end": 2863194,
    "text": "マスクを適用し、最初の残留接続を行おう。"
  },
  {
    "start": 2863242,
    "end": 2868500,
    "text": "ビデオに戻ってスライドを確認し、今やっていることを理解しよう。"
  },
  {
    "start": 2869030,
    "end": 2875714,
    "text": "最初のスキップコネクションは、この×がここに行くというものだ。"
  },
  {
    "start": 2875832,
    "end": 2882194,
    "text": "ノルムが追加される前に、まずマルチヘッドアテンションを適用する必要がある。"
  },
  {
    "start": 2882242,
    "end": 2889240,
    "text": "このXをマルチヘッドアテンションに送り、同時にここにも送り、その2つを組み合わせる。"
  },
  {
    "start": 2893610,
    "end": 2899270,
    "text": "最初のスキップコネクションはxとxの間にあり、もう一つのxは自己の注意から来る。"
  },
  {
    "start": 2899350,
    "end": 2902842,
    "text": "これがその機能である。"
  },
  {
    "start": 2902976,
    "end": 2906602,
    "text": "ラムダを使ってサブレイヤーを定義する。"
  },
  {
    "start": 2906666,
    "end": 2915198,
    "text": "これは基本的に、まず自己注意を適用することを意味する。自己注意とは、クエリーキーを与え、その値がx以上であることである。"
  },
  {
    "start": 2915284,
    "end": 2916282,
    "text": "私たちの意見だ。"
  },
  {
    "start": 2916346,
    "end": 2921650,
    "text": "これは、クエリーのキーと値の役割がxそのものであることから、自己注意と呼ばれる所以である。"
  },
  {
    "start": 2921720,
    "end": 2922610,
    "text": "入力そのもの。"
  },
  {
    "start": 2922680,
    "end": 2926706,
    "text": "それは、自分自身を見ている文章なのだ。"
  },
  {
    "start": 2926808,
    "end": 2932386,
    "text": "ある文の各単語は、同じ文の他の単語と相互作用している。"
  },
  {
    "start": 2932498,
    "end": 2936370,
    "text": "デコーダーでは、クロスアテンションがあるため、異なることがわかるだろう。"
  },
  {
    "start": 2936450,
    "end": 2947290,
    "text": "デコーダーから送られてくるキーは、エンコーダーから送られてくるキーと値を見ている。"
  },
  {
    "start": 2948350,
    "end": 2951002,
    "text": "ソースマスクを与える。"
  },
  {
    "start": 2951066,
    "end": 2952126,
    "text": "これは何だ？"
  },
  {
    "start": 2952228,
    "end": 2958026,
    "text": "基本的には、この関数をマルチヘッドアテンションブロックのフォワード関数と呼んでいる。"
  },
  {
    "start": 2958058,
    "end": 2961390,
    "text": "クエリのキーとマスクを与える。"
  },
  {
    "start": 2961810,
    "end": 2967330,
    "text": "これは、残留コネクションを使うことでこれに組み合わされる。"
  },
  {
    "start": 2968950,
    "end": 2970898,
    "text": "そしてまた2つ目をやる。"
  },
  {
    "start": 2970984,
    "end": 2981480,
    "text": "もうひとつは、フィードフォワードのラムダだ。"
  },
  {
    "start": 2985210,
    "end": 2987046,
    "text": "であれば、xを返す。"
  },
  {
    "start": 2987148,
    "end": 2994250,
    "text": "これは、フィードフォワードとXそのものを組み合わせることを意味する。"
  },
  {
    "start": 2994400,
    "end": 3000822,
    "text": "前のレイヤーの出力、つまりこのレイヤーの出力に、残差接続を適用する。"
  },
  {
    "start": 3000966,
    "end": 3003698,
    "text": "これがエンコーダー・ブロックの定義だ。"
  },
  {
    "start": 3003894,
    "end": 3006318,
    "text": "これでエンコーダー・オブジェクトを定義できる。"
  },
  {
    "start": 3006404,
    "end": 3012794,
    "text": "エンコーダーは多数のエンコーダー・ブロックで構成されるため、論文によれば最大n個のエンコーダー・ブロックを持つことができる。"
  },
  {
    "start": 3012932,
    "end": 3024994,
    "text": "エンコーダーを定義しよう。"
  },
  {
    "start": 3025032,
    "end": 3025990,
    "text": "我々はNを持つ。"
  },
  {
    "start": 3026060,
    "end": 3030678,
    "text": "我々は多くのレイヤーを持ち、次々と適用していく。"
  },
  {
    "start": 3030764,
    "end": 3051120,
    "text": "これはモデル・リストであり、最後にレイヤーの正規化を適用する。"
  },
  {
    "start": 3051490,
    "end": 3053760,
    "text": "次から次へとレイヤーを重ねていく。"
  },
  {
    "start": 3060370,
    "end": 3063834,
    "text": "前の層の出力が次の層の入力となる。"
  },
  {
    "start": 3063882,
    "end": 3066420,
    "text": "忘れ物をしたらしい。"
  },
  {
    "start": 3068070,
    "end": 3070130,
    "text": "最後に正規化を適用する。"
  },
  {
    "start": 3071750,
    "end": 3075406,
    "text": "これでエンコーダーを巡る旅は終わりである。"
  },
  {
    "start": 3075518,
    "end": 3079030,
    "text": "私たちがやってきたことを簡単に説明しよう。"
  },
  {
    "start": 3079100,
    "end": 3081880,
    "text": "私たちは、インプットを取り、それを各チームに送りました。"
  },
  {
    "start": 3082890,
    "end": 3085366,
    "text": "今のところ、すべてのブロックを一緒にすることはしていない。"
  },
  {
    "start": 3085388,
    "end": 3094534,
    "text": "エンコーダーと呼ばれるコントロールという大きなブロックを作り、その中に2つの小さなブロックが含まれている。"
  },
  {
    "start": 3094582,
    "end": 3095590,
    "text": "スキップ接続。"
  },
  {
    "start": 3095670,
    "end": 3099786,
    "text": "最初のものは、マルチヘッドアテンションとここに送られるこのXの間である。"
  },
  {
    "start": 3099888,
    "end": 3104030,
    "text": "もうひとつは、このフィードフォワードと、ここに送られるXの間だ。"
  },
  {
    "start": 3104180,
    "end": 3106106,
    "text": "我々はこのブロックをn個持っている。"
  },
  {
    "start": 3106138,
    "end": 3107230,
    "text": "次から次へと。"
  },
  {
    "start": 3107380,
    "end": 3110830,
    "text": "最後の出力はデコーダーに送られる。"
  },
  {
    "start": 3111490,
    "end": 3118610,
    "text": "正規化を適用する前に、今度はデコーダー部分を構築する。"
  },
  {
    "start": 3118760,
    "end": 3123694,
    "text": "デコーダでは、出力エンベッディングは入力エンベッディングと同じになる。"
  },
  {
    "start": 3123742,
    "end": 3130194,
    "text": "つまり、定義するクラスは同じなので、2回初期化するだけだ。"
  },
  {
    "start": 3130322,
    "end": 3132594,
    "text": "位置エンコーディングも同様である。"
  },
  {
    "start": 3132642,
    "end": 3136354,
    "text": "エンコーダーに使ったのと同じ値を使うことができる。"
  },
  {
    "start": 3136402,
    "end": 3143990,
    "text": "デコーダーに関しても、マスクされたマルチヘッド・アテンションで構成されるこの大きなブロックを定義する必要がある。"
  },
  {
    "start": 3144070,
    "end": 3144810,
    "text": "規範を加える。"
  },
  {
    "start": 3144880,
    "end": 3152250,
    "text": "ここにスキップコネクションを1つ、もう1つのマルチヘッドアテンションをもう1つのスキップコネクションで、そしてフィードフォワードをここにスキップコネクションで接続する。"
  },
  {
    "start": 3152320,
    "end": 3158186,
    "text": "マルチヘッドアテンションクラスを定義する方法は、実はすでにマスクを考慮している。"
  },
  {
    "start": 3158218,
    "end": 3159962,
    "text": "車輪を再発明する必要はない。"
  },
  {
    "start": 3160026,
    "end": 3167454,
    "text": "デコーダーについても、デコーダー・ブロックを定義すればいい。この大きなブロックは3つのサブレイヤーで構成されている。"
  },
  {
    "start": 3167582,
    "end": 3174730,
    "text": "そして、このn個のデコーダー・ブロックを使ってデコーダーを構築する。"
  },
  {
    "start": 3174910,
    "end": 3176360,
    "text": "そうしよう"
  },
  {
    "start": 3178330,
    "end": 3181110,
    "text": "まず、デコーダー・ブロックを定義しよう。"
  },
  {
    "start": 3192190,
    "end": 3196218,
    "text": "デコーダーには、自己の注意がある。"
  },
  {
    "start": 3196304,
    "end": 3197418,
    "text": "戻ろう。"
  },
  {
    "start": 3197584,
    "end": 3204050,
    "text": "マスケット・マルチヘッドのアテンションで3回使われるこのインプットがあるからだ。"
  },
  {
    "start": 3204150,
    "end": 3211790,
    "text": "これは、同じ入力がクエリー、キー、バリューの役割を果たすため、自己注意と呼ばれる。"
  },
  {
    "start": 3211940,
    "end": 3216382,
    "text": "文中の各単語は、同じ文中の他の単語と照合される。"
  },
  {
    "start": 3216526,
    "end": 3229090,
    "text": "この部分では、デコーダーからのクエリーを使用してアテンションを計算し、キーと値はエンコーダーから来る。"
  },
  {
    "start": 3229250,
    "end": 3231890,
    "text": "これは自己注意ではない。"
  },
  {
    "start": 3231970,
    "end": 3242154,
    "text": "これは、2種類の異なる物体を交差させ、何らかの方法でマッチングさせ、両者の関係を計算することから、クロスアテンションと呼ばれている。"
  },
  {
    "start": 3242272,
    "end": 3243770,
    "text": "よし、定義しよう。"
  },
  {
    "start": 3254290,
    "end": 3258314,
    "text": "これはクロスアテンションブロックで、基本的にはマルチヘッドアテンションである。"
  },
  {
    "start": 3258362,
    "end": 3296466,
    "text": "フィードフォワードでさまざまなパラメーターを与え、ドロップアウトを発生させ、残留コネクションも見つける。"
  },
  {
    "start": 3296498,
    "end": 3298520,
    "text": "今回は3人だ。"
  },
  {
    "start": 3299610,
    "end": 3318046,
    "text": "あなたは素晴らしい。"
  },
  {
    "start": 3318238,
    "end": 3324290,
    "text": "それでは、エンコーダーとよく似たフォワード・メソッドを構築してみよう。"
  },
  {
    "start": 3328090,
    "end": 3329190,
    "text": "Xが必要だ。"
  },
  {
    "start": 3329260,
    "end": 3329942,
    "text": "xとは何か？"
  },
  {
    "start": 3329996,
    "end": 3335346,
    "text": "デコーダーの入力だが、エンコーダーの出力も必要だ。"
  },
  {
    "start": 3335538,
    "end": 3343254,
    "text": "エンコーダーに適用されるマスクであるソースマスクと、デコーダーに適用されるマスクであるターゲットマスクが必要だ。"
  },
  {
    "start": 3343382,
    "end": 3346230,
    "text": "なぜソースマスク、ターゲットマスクと呼ばれるのですか？"
  },
  {
    "start": 3346310,
    "end": 3349654,
    "text": "というのも、この特別なケースでは翻訳作業を扱っているからだ。"
  },
  {
    "start": 3349702,
    "end": 3351094,
    "text": "我々はソース言語を持っている。"
  },
  {
    "start": 3351142,
    "end": 3352486,
    "text": "この場合は英語だ。"
  },
  {
    "start": 3352598,
    "end": 3356170,
    "text": "私たちの場合はイタリア語である。"
  },
  {
    "start": 3356330,
    "end": 3360426,
    "text": "エンコーダー・マスクでもデコーダー・マスクでもいい。"
  },
  {
    "start": 3360458,
    "end": 3361834,
    "text": "基本的には2つのマスクがある。"
  },
  {
    "start": 3361882,
    "end": 3363594,
    "text": "ひとつはエンコーダーからのもの。"
  },
  {
    "start": 3363642,
    "end": 3365514,
    "text": "ひとつはデコーダーからのもの。"
  },
  {
    "start": 3365562,
    "end": 3368238,
    "text": "ここではソースと呼ぶことにする。"
  },
  {
    "start": 3368334,
    "end": 3370974,
    "text": "ソースマスクはエンコーダーからのものである。"
  },
  {
    "start": 3371022,
    "end": 3374954,
    "text": "はソース言語、ターゲットマスクはデコーダーからのものである。"
  },
  {
    "start": 3375022,
    "end": 3376950,
    "text": "ターゲット言語。"
  },
  {
    "start": 3383370,
    "end": 3402410,
    "text": "これはデコーダーの自己注目ブロックであるため、クエリー、キー、値が同じ入力でありながら、デコーダーのマスクがあるデコーダー・ブロックの最初の部分である。"
  },
  {
    "start": 3404830,
    "end": 3412030,
    "text": "そして、2つ目の残留コネクションであるクロスアテンションを計算する必要がある。"
  },
  {
    "start": 3423830,
    "end": 3427154,
    "text": "この場合は、デコーダーからのクエリーを与えている。"
  },
  {
    "start": 3427202,
    "end": 3437750,
    "text": "x、キー、エンコーダーからの値、エンコーダーのマスク。"
  },
  {
    "start": 3447790,
    "end": 3450860,
    "text": "最後に、先ほどと同じようにフィードフォワード・ブロックを作る。"
  },
  {
    "start": 3452910,
    "end": 3454046,
    "text": "それだけだ。"
  },
  {
    "start": 3454148,
    "end": 3463230,
    "text": "エンコーダーの時と同じように、このブロックを次々にn回繰り返すだけだ。"
  },
  {
    "start": 3473250,
    "end": 3482840,
    "text": "また、この場合、多くのレイヤーを提供することになるので、レイヤー、単なるモデル・リスト、そして最後に正規化も行うことになる。"
  },
  {
    "start": 3506690,
    "end": 3516574,
    "text": "先ほどと同じように、入力を1つのレイヤーに適用し、前のレイヤーの出力を次のレイヤーの入力として使用する。"
  },
  {
    "start": 3516622,
    "end": 3527634,
    "text": "各レイヤーはデコーダー・ブロックである。"
  },
  {
    "start": 3527682,
    "end": 3532530,
    "text": "エンコーダーの出力を与える必要がある。"
  },
  {
    "start": 3532690,
    "end": 3535938,
    "text": "次にソースマスクとターゲットマスク。"
  },
  {
    "start": 3536034,
    "end": 3537962,
    "text": "それぞれがこうだ。"
  },
  {
    "start": 3538016,
    "end": 3539754,
    "text": "ここではフォワード・メソッドを呼び出している。"
  },
  {
    "start": 3539792,
    "end": 3541500,
    "text": "何も変わらない。"
  },
  {
    "start": 3544910,
    "end": 3550990,
    "text": "最後に正規化を施せば、これがデコーダーの完成だ。"
  },
  {
    "start": 3551490,
    "end": 3558154,
    "text": "完全なトランスフォーマーになるためには、最後にもうひとつ必要なものがある。"
  },
  {
    "start": 3558202,
    "end": 3559760,
    "text": "見てみよう。"
  },
  {
    "start": 3560850,
    "end": 3564686,
    "text": "最後に必要なのは、このレイヤー、リニアレイヤーだ。"
  },
  {
    "start": 3564798,
    "end": 3573300,
    "text": "私のスライドを思い出してほしいのだが、マルチヘッドアテンションの出力はDモデルによってシーケンスされるものだ。"
  },
  {
    "start": 3573670,
    "end": 3579030,
    "text": "ここでは、Dモデルによって配列される出力が期待される。"
  },
  {
    "start": 3579100,
    "end": 3585666,
    "text": "しかし、バッチ次元を考慮しないのであれば、これらの単語をボキャブラリーにマッピングし直したい。"
  },
  {
    "start": 3585778,
    "end": 3592010,
    "text": "だから、埋め込みを語彙の位置に変換する線形レイヤーが必要なのだ。"
  },
  {
    "start": 3592910,
    "end": 3598902,
    "text": "このレイヤーは、埋め込みをボキャブラリーに投影するので、投影レイヤーと呼ぶことにする。"
  },
  {
    "start": 3598966,
    "end": 3600640,
    "text": "さあ、作ろう。"
  },
  {
    "start": 3609970,
    "end": 3612398,
    "text": "このレイヤーに必要なのはDモデルだ。"
  },
  {
    "start": 3612564,
    "end": 3617440,
    "text": "Dモデル（整数）と語彙のサイズ。"
  },
  {
    "start": 3620690,
    "end": 3624734,
    "text": "これは基本的に、Dモデルから語彙サイズに変換するリニアレイヤーである。"
  },
  {
    "start": 3624772,
    "end": 3627560,
    "text": "ドットプロジェクションレイヤーである。"
  },
  {
    "start": 3638270,
    "end": 3640250,
    "text": "フォワード・メソッドを定義してみよう。"
  },
  {
    "start": 3642270,
    "end": 3645126,
    "text": "さて、私たちがやりたいこと、ちょっとコメントを書かせてください。"
  },
  {
    "start": 3645238,
    "end": 3661770,
    "text": "この場合、すでにソフトマックスが適用されている。"
  },
  {
    "start": 3661850,
    "end": 3679590,
    "text": "実際には、前に示したように、数値的安定性のためにlog soft maxを最後の次元に適用する。"
  },
  {
    "start": 3681770,
    "end": 3682710,
    "text": "それだけだ。"
  },
  {
    "start": 3682780,
    "end": 3684514,
    "text": "これが投影レイヤーだ。"
  },
  {
    "start": 3684642,
    "end": 3688406,
    "text": "これで変圧器に必要な材料はすべて揃った。"
  },
  {
    "start": 3688438,
    "end": 3705058,
    "text": "トランスフォーマー・ブロッカーを定義しよう。"
  },
  {
    "start": 3705094,
    "end": 3710634,
    "text": "私たちにはエンコーダーがある。"
  },
  {
    "start": 3710682,
    "end": 3713834,
    "text": "私たちにはデコーダーがある。"
  },
  {
    "start": 3713962,
    "end": 3715674,
    "text": "我々はソースを埋め込んでいる。"
  },
  {
    "start": 3715802,
    "end": 3720126,
    "text": "なぜソースエンベッディングがターゲットエンベッディングとして必要なのかというと、多言語を扱っているからです。"
  },
  {
    "start": 3720238,
    "end": 3726950,
    "text": "ソース言語用の入力埋め込みとターゲット言語用の入力埋め込みが1つずつある。"
  },
  {
    "start": 3733370,
    "end": 3735670,
    "text": "ターゲット・エンベッディングがある。"
  },
  {
    "start": 3739470,
    "end": 3751854,
    "text": "そして、ソースポジションとターゲットポジションがある。"
  },
  {
    "start": 3751972,
    "end": 3754030,
    "text": "そしてプロジェクション・レイヤー。"
  },
  {
    "start": 3755570,
    "end": 3803614,
    "text": "プロジェクションでは、エンコード、デコード、プロジェクションの3つのメソッドを定義する。"
  },
  {
    "start": 3803812,
    "end": 3805950,
    "text": "順次、適用していく。"
  },
  {
    "start": 3806930,
    "end": 3809274,
    "text": "なぜフォワード・メソッドを1つしか作らないのか？"
  },
  {
    "start": 3809322,
    "end": 3814686,
    "text": "後述するように、推論中にエンコーダーの出力を再利用できるからだ。"
  },
  {
    "start": 3814718,
    "end": 3817042,
    "text": "毎回計算する必要はない。"
  },
  {
    "start": 3817176,
    "end": 3824770,
    "text": "また、注目度を可視化するためにも、これらのアウトプットを分けておくことを好む。"
  },
  {
    "start": 3830010,
    "end": 3836200,
    "text": "エンコーダーにとっては、ソース言語とソース質量があるのだから。"
  },
  {
    "start": 3838110,
    "end": 3849370,
    "text": "まずエンベッディングを適用し、次にポジションエンコーディングを適用する。"
  },
  {
    "start": 3852690,
    "end": 3854830,
    "text": "最後にエンコーダーをかける。"
  },
  {
    "start": 3860450,
    "end": 3876630,
    "text": "デコードメソッドは、テンソルであるエンコーダー出力、テンソルであるソースマスク、ターゲット、ターゲットマスクを受け取る。"
  },
  {
    "start": 3881530,
    "end": 3882470,
    "text": "おっと。"
  },
  {
    "start": 3885360,
    "end": 3887496,
    "text": "私たちがしていることは目標だ。"
  },
  {
    "start": 3887688,
    "end": 3891500,
    "text": "まず、ターゲット埋め込みをターゲット文に適用する。"
  },
  {
    "start": 3895360,
    "end": 3910420,
    "text": "次に、位置エンコーディングを対象文に適用し、それを、最後にデコードする。"
  },
  {
    "start": 3916140,
    "end": 3921556,
    "text": "これは基本的に、このデコーダーの順方向方式である。"
  },
  {
    "start": 3921668,
    "end": 3924920,
    "text": "パラメータは同じ順番である。"
  },
  {
    "start": 3925900,
    "end": 3926650,
    "text": "そうだ。"
  },
  {
    "start": 3927040,
    "end": 3934136,
    "text": "最後にプロジェクト・メソッドを定義する。"
  },
  {
    "start": 3934168,
    "end": 3943660,
    "text": "エンベッディングからボキャブラリーのサイズを取る。"
  },
  {
    "start": 3945380,
    "end": 3955732,
    "text": "さて、これが最後のブロックだが、これらのブロックを組み合わせる方法は作っていない。"
  },
  {
    "start": 3955786,
    "end": 3957120,
    "text": "たくさんのブロックを作った。"
  },
  {
    "start": 3957200,
    "end": 3968180,
    "text": "トランスフォーマーのハイパーパラメーターが与えられれば、エンコーダー・デコーダー、エンベッディングなどすべてを初期化する単一のトランスフォーマーを構築してくれるものが必要だ。"
  },
  {
    "start": 3968260,
    "end": 3981420,
    "text": "すべてのハイパーパラメーターが与えられたら、トランスフォーマーを構築し、いくつかの初期値でパラメーターを初期化する。"
  },
  {
    "start": 3984400,
    "end": 3987052,
    "text": "トランスフォーマーを定義する必要があるのは確かだ。"
  },
  {
    "start": 3987106,
    "end": 3988872,
    "text": "この場合は翻訳の話だ。"
  },
  {
    "start": 3988936,
    "end": 3994540,
    "text": "さて、これから作るこのモデルは翻訳に使うが、どんな仕事にも使える。"
  },
  {
    "start": 3994620,
    "end": 3999580,
    "text": "私が使っているネーミングは、基本的に翻訳タスクで使われているものだ。"
  },
  {
    "start": 3999660,
    "end": 4002544,
    "text": "後で名前を変えることはできるが、構造は同じだ。"
  },
  {
    "start": 4002582,
    "end": 4007380,
    "text": "トランスフォーマーが適用可能な他のタスクに使用することができます。"
  },
  {
    "start": 4008040,
    "end": 4016200,
    "text": "まず最初に必要なのは、埋め込みを構築するために必要な、ソースとターゲットの語彙サイズである。"
  },
  {
    "start": 4016780,
    "end": 4024568,
    "text": "埋め込みは、語彙のトークンからサイズ512のベクトルに変換する必要があるからである。"
  },
  {
    "start": 4024654,
    "end": 4030830,
    "text": "そのためには、語彙の大きさ、つまりいくつのベクトルを作る必要があるかを知る必要がある。"
  },
  {
    "start": 4034400,
    "end": 4039564,
    "text": "次にターゲット。これも整数である。"
  },
  {
    "start": 4039692,
    "end": 4044240,
    "text": "そして、ソース配列の長さとターゲット配列の長さを伝える必要がある。"
  },
  {
    "start": 4051940,
    "end": 4053260,
    "text": "これはとても重要なことだ。"
  },
  {
    "start": 4053430,
    "end": 4055190,
    "text": "同じ可能性もある。"
  },
  {
    "start": 4055560,
    "end": 4059732,
    "text": "我々の場合は同じだが、異なる場合もある。"
  },
  {
    "start": 4059866,
    "end": 4073784,
    "text": "たとえば、2つのまったく異なる言語を扱うトランスフォーマーを翻訳に使用する場合、ソース言語に必要なトークンが、もう一方の言語よりもはるかに多いか、少ないことがあります。"
  },
  {
    "start": 4073822,
    "end": 4075492,
    "text": "同じ長さを保つ必要はない。"
  },
  {
    "start": 4075556,
    "end": 4077160,
    "text": "長さを変えて使うこともできる。"
  },
  {
    "start": 4077820,
    "end": 4087436,
    "text": "次のハイパーパラメータはDモデルで、論文と同じ値を保ちたいので512で初期化する。"
  },
  {
    "start": 4087538,
    "end": 4091156,
    "text": "次にハイパーパラメータnを定義する。"
  },
  {
    "start": 4091208,
    "end": 4098752,
    "text": "エンコーダー・ブロックの数とデコーダー・ブロックの数は、論文によれば6個である。"
  },
  {
    "start": 4098886,
    "end": 4105590,
    "text": "次にハイパーパラメータhを定義する。"
  },
  {
    "start": 4106440,
    "end": 4110870,
    "text": "ドロップアウトは0.1。"
  },
  {
    "start": 4113160,
    "end": 4121850,
    "text": "最後に、フィードフォワード層の隠れ層のDFFを求めるが、これは2048である。"
  },
  {
    "start": 4123900,
    "end": 4127000,
    "text": "これは変圧器を作る。"
  },
  {
    "start": 4128400,
    "end": 4148640,
    "text": "まず、埋め込みレイヤーを作成します。ソース埋め込み、そしてターゲット埋め込みです。"
  },
  {
    "start": 4157720,
    "end": 4160180,
    "text": "次に、位置エンコーディングレイヤーを作成する。"
  },
  {
    "start": 4171420,
    "end": 4188360,
    "text": "2つのポジション・エンコーディング・レイヤーを作成する必要はありません。なぜなら、これらのレイヤーは同じ仕事をし、パラメータを追加することもないからです。"
  },
  {
    "start": 4188440,
    "end": 4192184,
    "text": "これは教育目的なので、実際には問題ないと思う。"
  },
  {
    "start": 4192232,
    "end": 4197212,
    "text": "コードを最適化するのではなく、できるだけ理解しやすくしたいんだ。"
  },
  {
    "start": 4197346,
    "end": 4214520,
    "text": "必要な部分はすべてやるし、近道はしない。"
  },
  {
    "start": 4214590,
    "end": 4216724,
    "text": "次に、エンコーダー・ブロックを作成した。"
  },
  {
    "start": 4216852,
    "end": 4231372,
    "text": "n個の配列があるので、空の配列を定義しよう。"
  },
  {
    "start": 4231426,
    "end": 4242428,
    "text": "各エンコーダーブロックは、マルチヘッドアテンションブロックであるセルフアテンションを持っている。"
  },
  {
    "start": 4242524,
    "end": 4248850,
    "text": "マルチヘッドアテンションは、Dモデル、エッジ、ドロップアウト値を必要とする。"
  },
  {
    "start": 4250580,
    "end": 4263076,
    "text": "次に、ご覧のようにフィードフォワード・ブロックがある。"
  },
  {
    "start": 4263098,
    "end": 4269290,
    "text": "また、私が使っている名前はかなり長いのだが、それは主に、できるだけ誰にでも理解できるようにしたいからだ。"
  },
  {
    "start": 4273420,
    "end": 4280270,
    "text": "各エンコーダー・ブロックは、セルフ・アテンションとフィードフォワードで構成されている。"
  },
  {
    "start": 4282880,
    "end": 4285660,
    "text": "最後に、私たちは彼に『ドロップアウト』はいくらだと言った。"
  },
  {
    "start": 4289120,
    "end": 4300060,
    "text": "最後にこのエンコーダー・ブロックを追加し、デコーダー・ブロックを作成する。"
  },
  {
    "start": 4300800,
    "end": 4323252,
    "text": "我々はまた、クロスに注目している。"
  },
  {
    "start": 4323316,
    "end": 4352310,
    "text": "デコーダー・ブロックにも、エンコーダーと同様にフィードフォワードがある。"
  },
  {
    "start": 4353880,
    "end": 4373080,
    "text": "次に、デコーダー・ブロックそのもの（デコーダー・ブロック・アテンション）を定義し、最後にフィードフォワードとドロップアウトを定義する。"
  },
  {
    "start": 4375660,
    "end": 4378540,
    "text": "最後にそれを配列に保存する。"
  },
  {
    "start": 4386560,
    "end": 4402310,
    "text": "これでエンコーダーとデコーダーを作ることができる。"
  },
  {
    "start": 4404520,
    "end": 4429732,
    "text": "私たちは、n個のブロックをすべてデコーダーに渡し、Dモデルを語彙サイズに変換する投影レイヤーを作成する。"
  },
  {
    "start": 4429806,
    "end": 4430744,
    "text": "どの語彙？"
  },
  {
    "start": 4430792,
    "end": 4435416,
    "text": "もちろん、ソース言語からターゲット言語へ移したいのだから、ターゲットだ。"
  },
  {
    "start": 4435448,
    "end": 4438860,
    "text": "私たちの出力をターゲット語彙に投影したい。"
  },
  {
    "start": 4442420,
    "end": 4444560,
    "text": "それからトランスを作る。"
  },
  {
    "start": 4452280,
    "end": 4453156,
    "text": "何が必要なのか？"
  },
  {
    "start": 4453178,
    "end": 4473800,
    "text": "エンコーダー、デコーダー、ソースエンベッディング、ターゲットエンベッディング、ソース位置エンコーディング、ターゲット位置エンコーディング、そして最後にプロジェクションレイヤーが必要だ。"
  },
  {
    "start": 4478320,
    "end": 4479436,
    "text": "それだけだ。"
  },
  {
    "start": 4479538,
    "end": 4484860,
    "text": "あとはザビエルユニフォームを使ってパラメーターを初期化するだけだ。"
  },
  {
    "start": 4485360,
    "end": 4492000,
    "text": "これはパラメーターを初期化する方法で、ランダムな値でスタートしないように、トレーニングを高速化する。"
  },
  {
    "start": 4494020,
    "end": 4496370,
    "text": "そのためのアルゴリズムはたくさんある。"
  },
  {
    "start": 4496820,
    "end": 4522276,
    "text": "Xavierを使った多くの実装を見たので、このモデルから学び、最終的に我々の愛するトランスフォーマーを返すには、かなり良いスタートだと思う。"
  },
  {
    "start": 4522468,
    "end": 4523560,
    "text": "これだ。"
  },
  {
    "start": 4523630,
    "end": 4525610,
    "text": "これがモデルを作る方法だ。"
  },
  {
    "start": 4526060,
    "end": 4530012,
    "text": "さて、モデルを作ったところで、さらにそれを使ってみよう。"
  },
  {
    "start": 4530066,
    "end": 4537256,
    "text": "まずデータセットを見てから、トレーニング・ループを構築する。"
  },
  {
    "start": 4537448,
    "end": 4545520,
    "text": "トレーニング・ループの後、推論部分と注意を視覚化するコードも構築する。"
  },
  {
    "start": 4546020,
    "end": 4554628,
    "text": "ちょっと長くなるけど、それだけの価値はある。"
  },
  {
    "start": 4554794,
    "end": 4560868,
    "text": "さて、モデルのコードを構築したので、次のステップはトレーニング・コードを構築することだ。"
  },
  {
    "start": 4560954,
    "end": 4567444,
    "text": "その前に、いくつかタイプミスがあるかもしれないので、コードを再チェックしよう。"
  },
  {
    "start": 4567492,
    "end": 4573064,
    "text": "実はこのチェックはすでに行ったのだが、コードにはほとんど間違いがない。"
  },
  {
    "start": 4573182,
    "end": 4575624,
    "text": "私は古いものと新しいものを比較する。"
  },
  {
    "start": 4575822,
    "end": 4578092,
    "text": "とても小さな問題だ。"
  },
  {
    "start": 4578226,
    "end": 4583356,
    "text": "ここではフィードフォワードではなくフィードフォワードと書いた。"
  },
  {
    "start": 4583538,
    "end": 4593900,
    "text": "フィード・フォワードを参照するときにも、デコーダー・ブロックを構築するときにも、同じ問題がある。"
  },
  {
    "start": 4594060,
    "end": 4599872,
    "text": "もうひとつの問題は、ここでデコーダー・ブロックを作るときに、Nnモジュールを代わりに書いてしまったことだ。"
  },
  {
    "start": 4599926,
    "end": 4608420,
    "text": "Nn個のモジュール・リストとし、フィードフォワードもトランスフォーマーの構築メソッドのこことここに固定する。"
  },
  {
    "start": 4608920,
    "end": 4613836,
    "text": "これで古いものを削除できるので、もう必要ない。"
  },
  {
    "start": 4613968,
    "end": 4615272,
    "text": "モデルを確認させてください。"
  },
  {
    "start": 4615406,
    "end": 4618970,
    "text": "フィードフォワードで正しいものだ。"
  },
  {
    "start": 4620140,
    "end": 4620840,
    "text": "そうだ。"
  },
  {
    "start": 4620990,
    "end": 4621690,
    "text": "オーケー。"
  },
  {
    "start": 4622220,
    "end": 4624616,
    "text": "次のステップはトレーニング・コードの構築だ。"
  },
  {
    "start": 4624718,
    "end": 4628120,
    "text": "トレーニングコードを作る前に、データを見なければならない。"
  },
  {
    "start": 4628190,
    "end": 4630524,
    "text": "どのようなデータを扱うのか？"
  },
  {
    "start": 4630642,
    "end": 4639388,
    "text": "そこで、前にも言ったように、私たちは翻訳タスクを扱っており、Hugging Faceで見つけることができるopus booksというデータセットを選んだ。"
  },
  {
    "start": 4639474,
    "end": 4643920,
    "text": "また、このデータセットをダウンロードするために、huggingfaceのライブラリを使用する。"
  },
  {
    "start": 4644070,
    "end": 4652032,
    "text": "Pytorchの他に使うライブラリーはこれだけだ。"
  },
  {
    "start": 4652096,
    "end": 4661540,
    "text": "このデータセットを使い、huggingfixトークナイザー・ライブラリを使ってテキストを語彙に変換する。"
  },
  {
    "start": 4661880,
    "end": 4667928,
    "text": "というのも、私たちの目標は変圧器を作ることであり、すべてを台無しにすることではないからだ。"
  },
  {
    "start": 4668014,
    "end": 4672404,
    "text": "私たちはトランスフォーマーを作り、トレーニングすることだけに集中する。"
  },
  {
    "start": 4672532,
    "end": 4676772,
    "text": "私の場合は、英語からイタリア語へのサブセットを使用する。"
  },
  {
    "start": 4676836,
    "end": 4683900,
    "text": "私たちは、あなたが言語を選ぶことができ、コードがそれに応じて動作するようにコードを構築します。"
  },
  {
    "start": 4684240,
    "end": 4692268,
    "text": "データを見ると、各データは英語とイタリア語の文のペアであることがわかる。"
  },
  {
    "start": 4692364,
    "end": 4699596,
    "text": "例えば、その日は散歩をする可能性がなかった。イタリア語ではinquil journal impossible passageを意味する。"
  },
  {
    "start": 4699788,
    "end": 4708752,
    "text": "ソース言語である英語からターゲット言語であるイタリア語に翻訳するよう、変換器を訓練する。"
  },
  {
    "start": 4708896,
    "end": 4710228,
    "text": "そうしよう"
  },
  {
    "start": 4710314,
    "end": 4711924,
    "text": "ステップ・バイ・ステップでやっていく。"
  },
  {
    "start": 4712042,
    "end": 4717876,
    "text": "まず、このデータセットをダウンロードし、トークナイザーを作成するコードを作成する。"
  },
  {
    "start": 4717908,
    "end": 4719620,
    "text": "トークナイザーとは何ですか？"
  },
  {
    "start": 4719780,
    "end": 4725288,
    "text": "スライドに戻って、このデータで何をするのか、簡単に概要を説明しよう。"
  },
  {
    "start": 4725374,
    "end": 4729108,
    "text": "トークナイザーは、入力エンベッディングの前に来るものである。"
  },
  {
    "start": 4729204,
    "end": 4731272,
    "text": "英文がある。"
  },
  {
    "start": 4731336,
    "end": 4736108,
    "text": "例えば、「あなたの猫はかわいい猫です。"
  },
  {
    "start": 4736194,
    "end": 4739592,
    "text": "トークナイザーの目的は、このトークンを作成することです。"
  },
  {
    "start": 4739656,
    "end": 4744236,
    "text": "この文章を1つの単語に分割する。"
  },
  {
    "start": 4744348,
    "end": 4756180,
    "text": "ここでわかるように、あなたの猫はかわいい猫ですという文があり、トークナイザーの目標はこの文を1つの単語に分割することです。"
  },
  {
    "start": 4756250,
    "end": 4760064,
    "text": "BPEトークナイザーもあれば、単語レベルのトークナイザーもある。"
  },
  {
    "start": 4760112,
    "end": 4762768,
    "text": "サブワードレベルの単語部分トークナイザーがある。"
  },
  {
    "start": 4762784,
    "end": 4764048,
    "text": "多くのトークナイザーがある。"
  },
  {
    "start": 4764144,
    "end": 4767812,
    "text": "今回使用するのは、最も単純なもので、単語レベルのトークナイザーと呼ばれるものだ。"
  },
  {
    "start": 4767876,
    "end": 4772152,
    "text": "単語レベルのトークナイザーは、基本的にこの文をスペースで分割する。"
  },
  {
    "start": 4772286,
    "end": 4781260,
    "text": "各スペースは単語の境界を定義するため、1つの単語に分割され、各単語は1つの数字にマッピングされる。"
  },
  {
    "start": 4781330,
    "end": 4789230,
    "text": "これらの数字の語彙を構築し、各単語を数字に対応付けるのがトークナイザーの仕事である。"
  },
  {
    "start": 4790800,
    "end": 4796284,
    "text": "トークナイザーを構築するとき、トランスフォーマーに使用する特別なトークンを作成することもできます。"
  },
  {
    "start": 4796332,
    "end": 4805504,
    "text": "例えば、パディングと呼ばれるトークン、文頭、文末と呼ばれるトークンなど、変換器の学習に必要なトークンである。"
  },
  {
    "start": 4805552,
    "end": 4807300,
    "text": "ステップ・バイ・ステップでやっていこう。"
  },
  {
    "start": 4807450,
    "end": 4813696,
    "text": "まず、トークナイザーを構築し、データセットをダウンロードするコードをビルドしよう。"
  },
  {
    "start": 4813818,
    "end": 4814964,
    "text": "新しいファイルを作成しよう。"
  },
  {
    "start": 4815012,
    "end": 4817560,
    "text": "それをトレインパイと呼ぼう。"
  },
  {
    "start": 4817900,
    "end": 4822132,
    "text": "さて、いつものライブラリをインポートしよう。"
  },
  {
    "start": 4822196,
    "end": 4823316,
    "text": "トーチ"
  },
  {
    "start": 4823508,
    "end": 4834860,
    "text": "また、torch nnもインポートし、hugging phaseのライブラリも使うので、これら2つのライブラリもインポートする必要がある。"
  },
  {
    "start": 4836720,
    "end": 4840984,
    "text": "Pipを使ってインストールできるデータセット・ライブラリを使用する。"
  },
  {
    "start": 4841112,
    "end": 4842940,
    "text": "データセット。"
  },
  {
    "start": 4843780,
    "end": 4857220,
    "text": "実際には、ロード・データ・セットを使用し、PipでインストールできるHugging Faceのトークナイザー・ライブラリも使用します。"
  },
  {
    "start": 4862360,
    "end": 4866212,
    "text": "どのトークナイザーが必要かも必要だ。"
  },
  {
    "start": 4866266,
    "end": 4881368,
    "text": "ここでは、単語レベルのトークナイザーを使用する。"
  },
  {
    "start": 4881464,
    "end": 4903670,
    "text": "このクラスはトークナイザーを訓練するクラスで、文のリストが与えられると語彙を作成し、空白に従って単語を分割します。"
  },
  {
    "start": 4904680,
    "end": 4907380,
    "text": "1つずつ方法を構築していく。"
  },
  {
    "start": 4907450,
    "end": 4914180,
    "text": "まず、トークナイザーを作成するメソッドを構築し、各パラメーターについて説明します。"
  },
  {
    "start": 4915000,
    "end": 4921524,
    "text": "今はまだ全体像が見えないが、後でこれらの方法をすべて組み合わせれば、全体像が見えてくる。"
  },
  {
    "start": 4921652,
    "end": 4925476,
    "text": "まず、トークナイザーを構築するメソッドを作ってみよう。"
  },
  {
    "start": 4925508,
    "end": 4930780,
    "text": "ここでは、これをgetまたはbuild tokenizerと呼ぶことにする。"
  },
  {
    "start": 4932960,
    "end": 4936860,
    "text": "このメソッドは、私たちのモデルのコンフィギュレーションであるコンフィギュレーションを取る。"
  },
  {
    "start": 4936930,
    "end": 4938408,
    "text": "後で定義する。"
  },
  {
    "start": 4938594,
    "end": 4943360,
    "text": "トークナイザーを構築するデータセットと言語。"
  },
  {
    "start": 4945700,
    "end": 4952900,
    "text": "トークナイザーのパスを定義し、このトークナイザーを保存するファイルを指定します。"
  },
  {
    "start": 4952970,
    "end": 4977984,
    "text": "まずコンフィグのパスですが、このパスはPatlibのパスライブラリから来ています。Patlibは相対パスを指定して絶対パスを作成できるライブラリです。"
  },
  {
    "start": 4978132,
    "end": 4984984,
    "text": "トークナイザー・ファイルというコンフィギュレーションがあることにします。"
  },
  {
    "start": 4985112,
    "end": 4988184,
    "text": "このパスは言語を使ってフォーマットすることができる。"
  },
  {
    "start": 4988232,
    "end": 5002932,
    "text": "例えば、こんな感じだ。"
  },
  {
    "start": 5003066,
    "end": 5011910,
    "text": "には、例えばトークナイザー英語、トークナイザーイタリア語といったように、作成される言語が指定される。"
  },
  {
    "start": 5015740,
    "end": 5018810,
    "text": "トークナイザーが存在しない場合は、それを作成します。"
  },
  {
    "start": 5025020,
    "end": 5027864,
    "text": "このコードはすべて、実はハグする段階から持ってきたものなんだ。"
  },
  {
    "start": 5027992,
    "end": 5029592,
    "text": "複雑なことではない。"
  },
  {
    "start": 5029656,
    "end": 5042960,
    "text": "トークナイザー・ライブラリのクイック・ツアーに参加したところ、とても使いやすく、トークン作成にかかる時間を大幅に節約することができました。"
  },
  {
    "start": 5050740,
    "end": 5055312,
    "text": "未知の単語unknownも紹介する。"
  },
  {
    "start": 5055376,
    "end": 5056516,
    "text": "どういう意味か？"
  },
  {
    "start": 5056618,
    "end": 5063772,
    "text": "トークナイザーは、語彙の中に認識できない単語があると、その単語を未知の単語に置き換えます。"
  },
  {
    "start": 5063936,
    "end": 5068120,
    "text": "この未知の単語に対応する番号にマッピングされる。"
  },
  {
    "start": 5071340,
    "end": 5081180,
    "text": "プレ・トークナイザーとは、基本的に空白で分割し、トークナイザーを訓練するためのトレーナーを構築することを意味する。"
  },
  {
    "start": 5118780,
    "end": 5120692,
    "text": "よし、これはトレーナーだ。"
  },
  {
    "start": 5120756,
    "end": 5121512,
    "text": "どういう意味ですか？"
  },
  {
    "start": 5121566,
    "end": 5124276,
    "text": "つまり、単語レベルのトレーナーになるということだ。"
  },
  {
    "start": 5124308,
    "end": 5128636,
    "text": "は、空白を使用して単語を分割し、単一の単語を使用します。"
  },
  {
    "start": 5128738,
    "end": 5131256,
    "text": "また、4つの特別なトークンがある。"
  },
  {
    "start": 5131288,
    "end": 5139448,
    "text": "つまり、ボキャブラリーの中にその単語が見つからない場合は、unknownに置き換えてください。"
  },
  {
    "start": 5139544,
    "end": 5146764,
    "text": "また、変換器の学習に使用するパディング、文頭と文末も含まれる。"
  },
  {
    "start": 5146812,
    "end": 5155590,
    "text": "特別なトークンとは頻度を意味し、ある単語が語彙に登場するためには、少なくとも2つの頻度が必要であることを意味する。"
  },
  {
    "start": 5156120,
    "end": 5159220,
    "text": "これでトークナイザーを訓練できる。"
  },
  {
    "start": 5163800,
    "end": 5174550,
    "text": "私たちはこの方法を使う。つまり、データセットからすべてのセンテンスを与える方法をまず構築し、それを後で構築する。"
  },
  {
    "start": 5175800,
    "end": 5177310,
    "text": "そうなのか？"
  },
  {
    "start": 5212920,
    "end": 5226360,
    "text": "トークン・サイザーを作成する特定の言語に対応するすべての文を取得するために、データ・セットを繰り返し処理できるようにするためです。"
  },
  {
    "start": 5236960,
    "end": 5242720,
    "text": "覚えているように、データセットの各項目は、英語とイタリア語の文章のペアである。"
  },
  {
    "start": 5243140,
    "end": 5246480,
    "text": "ある特定の言語を抽出したいだけなのだ。"
  },
  {
    "start": 5251640,
    "end": 5263200,
    "text": "これがペアを表す項目で、このペアから必要な1つの言語だけを抽出します。これがトークナイザーを構築するコードです。"
  },
  {
    "start": 5263360,
    "end": 5269188,
    "text": "では、データセットをロードし、トークナイザーを構築するコードを書いてみよう。"
  },
  {
    "start": 5269284,
    "end": 5277390,
    "text": "このメソッドはget datasetと呼ばれ、後で定義するモデルのコンフィギュレーションも受け取る。"
  },
  {
    "start": 5279120,
    "end": 5280764,
    "text": "データセットをロードしよう。"
  },
  {
    "start": 5280802,
    "end": 5283500,
    "text": "これをDS列と呼ぶことにする。"
  },
  {
    "start": 5287040,
    "end": 5292604,
    "text": "なるほど、ハグフェイスはデータセットを簡単にダウンロードできる。"
  },
  {
    "start": 5292652,
    "end": 5300832,
    "text": "データセットの名前を伝え、欲しいサブセットを伝えるだけでいい。"
  },
  {
    "start": 5300886,
    "end": 5307092,
    "text": "私たちは、英語からイタリア語へのサブセットを望んでいますが、みなさんが非常に速く言語を変更できるように設定できるようにしたいのです。"
  },
  {
    "start": 5307146,
    "end": 5324084,
    "text": "このサブセットを動的に構築するには、コンフィギュレーションに2つのパラメーターを設定しよう。"
  },
  {
    "start": 5324132,
    "end": 5328620,
    "text": "ひとつは言語ソースと呼ばれ、もうひとつは言語ターゲットと呼ばれる。"
  },
  {
    "start": 5337040,
    "end": 5340912,
    "text": "また、このデータセットをどのように分割するかも定義できる。"
  },
  {
    "start": 5340966,
    "end": 5352310,
    "text": "我々の場合、元のデータセットにはハギング段階からのトレーニング分割しかないが、検証データとトレーニングデータに自分で分割する。"
  },
  {
    "start": 5353160,
    "end": 5377020,
    "text": "トークナイザー・セット・ターゲットを作りましょう。"
  },
  {
    "start": 5387440,
    "end": 5395384,
    "text": "今、私たちはハグ顔から分割されたトレーニングしか持っていないので、私たち自身でトレーニングと検証に分割することができる。"
  },
  {
    "start": 5395432,
    "end": 5399420,
    "text": "90％のデータを訓練用に、10％のデータを検証用に保管する。"
  },
  {
    "start": 5400800,
    "end": 5454384,
    "text": "ランダムな分割が可能な方法である。"
  },
  {
    "start": 5454432,
    "end": 5462288,
    "text": "これはPytorchのメソッドで、入力として与えたサイズを使ってデータセットを分割することができる。"
  },
  {
    "start": 5462384,
    "end": 5467720,
    "text": "この場合、このデータセットを2つの小さなデータセットに分割することを意味する。"
  },
  {
    "start": 5467790,
    "end": 5469992,
    "text": "このサイズとこのサイズ。"
  },
  {
    "start": 5470126,
    "end": 5493360,
    "text": "後で必要になる、トータルオーダーとランダム分割のメソッドをトーチからインポートしよう。"
  },
  {
    "start": 5496420,
    "end": 5512148,
    "text": "トークン・サイザーを作成し、データをロードしたところで、モデルが使用するテンソルを作成する必要があります。"
  },
  {
    "start": 5512234,
    "end": 5513944,
    "text": "データセットを作成しよう。"
  },
  {
    "start": 5513982,
    "end": 5555190,
    "text": "これをバイリンガルデータセットと呼ぼう。"
  },
  {
    "start": 5562600,
    "end": 5587390,
    "text": "いつものようにコンストラクタを定義し、このコンストラクタで、抱擁フェーズからダウンロードしたデータセット、ソース言語のトークナイザー、ターゲット言語のトークナイザー、ソース言語、ソース言語の名前、ターゲット言語の名前、そして使用するシーケンス長を与える必要がある。"
  },
  {
    "start": 5594240,
    "end": 5626472,
    "text": "これらの値をすべて保存し、トークン（モデルのテンソルを作成するために使用する特定のトークン）を保存することもできる。"
  },
  {
    "start": 5626606,
    "end": 5630312,
    "text": "文頭、文末、パディングトークンが必要です。"
  },
  {
    "start": 5630456,
    "end": 5637948,
    "text": "文頭のトークンを数字に変換して入力IDに入力するにはどうすればよいですか？"
  },
  {
    "start": 5638034,
    "end": 5640464,
    "text": "そのためのトークナイザーの特別なメソッドがある。"
  },
  {
    "start": 5640502,
    "end": 5641650,
    "text": "そうしよう"
  },
  {
    "start": 5642660,
    "end": 5645100,
    "text": "これは文頭トークンである。"
  },
  {
    "start": 5645260,
    "end": 5647600,
    "text": "それをテンソルに組み込みたい。"
  },
  {
    "start": 5650340,
    "end": 5661940,
    "text": "このテンソルは、ソースまたはターゲットからこのトークナイザーを使うことができ、どちらもこれらの特定のトークンを含むので問題ではない。"
  },
  {
    "start": 5664060,
    "end": 5668650,
    "text": "トークンを数値に変換するメソッドです。"
  },
  {
    "start": 5669900,
    "end": 5690732,
    "text": "文頭のトークン、そしてこのテンソルのトークンの型は、語彙が32ビット以上の長さになる可能性があるため、長さが必要である。"
  },
  {
    "start": 5690786,
    "end": 5698860,
    "text": "通常、64ビットのロングビットを使用し、文末とパディングトークンも同様に使用する。"
  },
  {
    "start": 5700800,
    "end": 5734268,
    "text": "このデータセットのlengthメソッドも定義する必要がある。"
  },
  {
    "start": 5734354,
    "end": 5739724,
    "text": "基本的には、ハグする段階からのデータセットの長さだけである。"
  },
  {
    "start": 5739852,
    "end": 5742480,
    "text": "では、getitemメソッドを定義する必要がある。"
  },
  {
    "start": 5755240,
    "end": 5759750,
    "text": "まず、抱きつき相のデータセットから元のペアを抽出する。"
  },
  {
    "start": 5769240,
    "end": 5806020,
    "text": "次に、ソーステキストとターゲットテキストを抽出し、最後に各テキストをトークンに変換し、入力IDに変換する。"
  },
  {
    "start": 5807000,
    "end": 5808310,
    "text": "どういう意味ですか？"
  },
  {
    "start": 5809080,
    "end": 5819850,
    "text": "トークナイザーは、まず文章を1つの単語に分割し、次に各単語を語彙の対応する番号に対応付けます。"
  },
  {
    "start": 5827920,
    "end": 5835240,
    "text": "これはエンコードメソッドIdsによって行われる。"
  },
  {
    "start": 5835400,
    "end": 5843600,
    "text": "これで入力IDが得られるので、元の文の各単語に対応する数字が配列として与えられる。"
  },
  {
    "start": 5856120,
    "end": 5863040,
    "text": "覚えているように、配列の長さに到達するためには、文章をパディングする必要がある。"
  },
  {
    "start": 5863200,
    "end": 5868232,
    "text": "これは、我々のモデルが常に機能することを望んでいるので、本当に重要なことだ。"
  },
  {
    "start": 5868286,
    "end": 5874788,
    "text": "つまり、モデルは常に一定の長さのシーケンスで機能するが、すべての文に十分な単語があるわけではない。"
  },
  {
    "start": 5874884,
    "end": 5876772,
    "text": "パディング・トークンを使用する。"
  },
  {
    "start": 5876836,
    "end": 5883704,
    "text": "このパッドをパディングトークンとして、シーケンス長に達するまで文を埋める。"
  },
  {
    "start": 5883832,
    "end": 5897200,
    "text": "エンコーダー側とデコーダー側で何個のパディングトークンを追加する必要があるかを計算する。"
  },
  {
    "start": 5901700,
    "end": 5902560,
    "text": "マイナス2だ。"
  },
  {
    "start": 5902630,
    "end": 5904028,
    "text": "なぜマイナス2なのか？"
  },
  {
    "start": 5904134,
    "end": 5906496,
    "text": "我々はすでにこれだけのトークンを持っている。"
  },
  {
    "start": 5906528,
    "end": 5907796,
    "text": "この1点に到達する必要がある。"
  },
  {
    "start": 5907898,
    "end": 5914888,
    "text": "エンコーダー側には、文頭トークンと文末トークンを追加する。"
  },
  {
    "start": 5914974,
    "end": 5930700,
    "text": "ここにもマイナス2とマイナス1がある。"
  },
  {
    "start": 5930770,
    "end": 5932428,
    "text": "前回のビデオを覚えているかな？"
  },
  {
    "start": 5932514,
    "end": 5940364,
    "text": "学習時には、文頭トークンだけをデコーダ側に追加する。"
  },
  {
    "start": 5940482,
    "end": 5944396,
    "text": "であれば、ラベルには文末トークンだけを追加する。"
  },
  {
    "start": 5944508,
    "end": 5948560,
    "text": "この場合、特別なトークンを1つ追加するだけでよい。"
  },
  {
    "start": 5948980,
    "end": 5959092,
    "text": "また、選んだ配列の長さが、データセットのすべての文章を表現するのに十分であることを確認する。"
  },
  {
    "start": 5959146,
    "end": 5964340,
    "text": "もし小さすぎるものを選んだ場合は、例外を発生させたい。"
  },
  {
    "start": 5965560,
    "end": 5969220,
    "text": "基本的に、この水増し毒素の数がマイナスになることはないはずだ。"
  },
  {
    "start": 5989060,
    "end": 6002668,
    "text": "それでは、エンコーダー入力用とデコーダー入力用の2つのテンソルを構築しよう。"
  },
  {
    "start": 6002764,
    "end": 6006320,
    "text": "のセンテンスがエンコーダーの入力に送られる。"
  },
  {
    "start": 6006400,
    "end": 6015908,
    "text": "1文はデコーダーの入力に送られ、1文はデコーダーの出力として期待されるものである。"
  },
  {
    "start": 6016004,
    "end": 6018836,
    "text": "その出力をラベルと呼ぶことにする。"
  },
  {
    "start": 6019028,
    "end": 6021108,
    "text": "通常はターゲットやラベルと呼ばれる。"
  },
  {
    "start": 6021204,
    "end": 6028064,
    "text": "私はそれをラベリングと呼んでいる。"
  },
  {
    "start": 6028212,
    "end": 6031390,
    "text": "スタートのテンソルを連結する。"
  },
  {
    "start": 6033120,
    "end": 6035192,
    "text": "よし、3つのテンソルを連結しよう。"
  },
  {
    "start": 6035256,
    "end": 6065152,
    "text": "最初に文頭トークン、次にソース・テキスト・トークンのトークン、そしてシーケンス長に達するのに十分なパディング・トークンが置かれる。"
  },
  {
    "start": 6065216,
    "end": 6071190,
    "text": "この文に何個の埋め込みトークンを追加する必要があるかは、すでに計算済みだ。"
  },
  {
    "start": 6095900,
    "end": 6097764,
    "text": "これはエンコーダー入力である。"
  },
  {
    "start": 6097892,
    "end": 6099928,
    "text": "ここにコメントを書かせてください。"
  },
  {
    "start": 6100094,
    "end": 6108590,
    "text": "これは、ソース・テキストにsosとaosを追加するものである。"
  },
  {
    "start": 6110480,
    "end": 6121308,
    "text": "次にデコーダーの入力を作るが、これもトークンの連結である。"
  },
  {
    "start": 6121484,
    "end": 6128496,
    "text": "この場合、文頭も文末もない。"
  },
  {
    "start": 6128528,
    "end": 6130740,
    "text": "文頭の部分だけだ。"
  },
  {
    "start": 6146360,
    "end": 6152440,
    "text": "最後に、シーケンス長に達するのに十分なパディングトークンを追加した。"
  },
  {
    "start": 6153280,
    "end": 6155470,
    "text": "何人必要かはすでに計算済みだ。"
  },
  {
    "start": 6155920,
    "end": 6158620,
    "text": "今すぐこの値を使えばいい。"
  },
  {
    "start": 6158770,
    "end": 6178470,
    "text": "それからラベルを作る。"
  },
  {
    "start": 6179880,
    "end": 6182980,
    "text": "ラベルには文末トークンだけを追加する。"
  },
  {
    "start": 6195660,
    "end": 6200200,
    "text": "デコーダーの入力と同じ数のパディング・トークンが必要だからだ。"
  },
  {
    "start": 6201580,
    "end": 6210860,
    "text": "デバッグのために、実際にシーケンス長に達しているかどうかダブルチェックしてみよう。"
  },
  {
    "start": 6235800,
    "end": 6241032,
    "text": "さて、このチェックが終わったところで、私からもコメントを書いておこう。"
  },
  {
    "start": 6241086,
    "end": 6248920,
    "text": "ここでは、デコーダーの入力にeos、いや、ここではsosを加えるだけだ。"
  },
  {
    "start": 6249340,
    "end": 6257660,
    "text": "ここでラベルにeosを追加する。"
  },
  {
    "start": 6258800,
    "end": 6264300,
    "text": "デコーダーからの出力として期待されるもの。"
  },
  {
    "start": 6265060,
    "end": 6270210,
    "text": "これで、これらのテンソルをトレーニングで使えるように返すことができる。"
  },
  {
    "start": 6272100,
    "end": 6277280,
    "text": "エンコーダーの入力からなる辞書を返す。"
  },
  {
    "start": 6281640,
    "end": 6282896,
    "text": "エンコーダー入力とは何ですか？"
  },
  {
    "start": 6282928,
    "end": 6285620,
    "text": "シークエンスの長さは基本的にオフサイズだ。"
  },
  {
    "start": 6286600,
    "end": 6298680,
    "text": "次にデコーダーの入力があるが、これも単なるトークンのシーケンス長である。"
  },
  {
    "start": 6301900,
    "end": 6303950,
    "text": "コンマを忘れていた。"
  },
  {
    "start": 6306160,
    "end": 6308664,
    "text": "エンコーダー・マスク"
  },
  {
    "start": 6308712,
    "end": 6310856,
    "text": "エンコーダー・マスクとは何ですか？"
  },
  {
    "start": 6311048,
    "end": 6320028,
    "text": "覚えているように、パディングトークンを追加することで、エンコーダーの入力文のサイズを大きくしている。"
  },
  {
    "start": 6320124,
    "end": 6324492,
    "text": "このような水増しされたトークンには、自己注目には参加してほしくない。"
  },
  {
    "start": 6324636,
    "end": 6332256,
    "text": "必要なのは、これらのトークンを自己注意メカニズムに見られたくないというマスクを作ることだ。"
  },
  {
    "start": 6332448,
    "end": 6336260,
    "text": "そこで、エンコーダー用のマスクを作る。"
  },
  {
    "start": 6337160,
    "end": 6338416,
    "text": "どうやってこのマスクを作るのか？"
  },
  {
    "start": 6338448,
    "end": 6343928,
    "text": "水増しされていないトークンはすべてOKということだ。"
  },
  {
    "start": 6344014,
    "end": 6347050,
    "text": "水増ししているトークンはすべてダメ。"
  },
  {
    "start": 6350540,
    "end": 6358110,
    "text": "また、ネジを外してシーケンス寸法を追加したり、後でバッチ寸法を追加したりもする。"
  },
  {
    "start": 6360800,
    "end": 6363080,
    "text": "を整数に変換する。"
  },
  {
    "start": 6363160,
    "end": 6371520,
    "text": "これは、自己注意メカニズムで使用されるためである。"
  },
  {
    "start": 6372980,
    "end": 6387556,
    "text": "つまり、各単語は前の単語しか見ることができず、各単語はパディングされていない単語しか見ることができない。"
  },
  {
    "start": 6387658,
    "end": 6392388,
    "text": "繰り返しになるが、パディングトークンを自己注目の場に参加させたくないのだ。"
  },
  {
    "start": 6392484,
    "end": 6395368,
    "text": "私たちは本物の言葉だけを求めている。"
  },
  {
    "start": 6395454,
    "end": 6404840,
    "text": "また、各単語がその後に来る単語を見るのではなく、その前に来る単語だけを見るようにしたい。"
  },
  {
    "start": 6404990,
    "end": 6409612,
    "text": "ここでは、後で構築する因果マスクと呼ばれる方法を使う。"
  },
  {
    "start": 6409666,
    "end": 6410524,
    "text": "私たちもそれを作る。"
  },
  {
    "start": 6410562,
    "end": 6420784,
    "text": "今は、その使い方をお見せするために呼んでいるだけです。"
  },
  {
    "start": 6420822,
    "end": 6428420,
    "text": "この場合、パディング・トークンは不要なので、必要な寸法を追加する。"
  },
  {
    "start": 6429240,
    "end": 6480820,
    "text": "また、我々は今すぐ構築する方法であり、このcavsalマスクは、サイズ、シーケンス長とシーケンス長の行列を構築する必要があるカプセルマスクでブーリアンの終わりを行うシーケンス長とは、基本的に私たちのデコーダーの入力のサイズであり、これはあなたのためにコメントを書いてみましょうので、これは1つのシーケンスlenシーケンスと組み合わせて1つの2つのシーケンス長であり、これは1つのシーケンスlenシーケンスで終了し、これが放送することができますこのメソッド因果マスクを定義して行きましょう因果マスクとは何ですか？"
  },
  {
    "start": 6482040,
    "end": 6558488,
    "text": "因果マスクというのは、実際にはスライドに戻りましょう。スライドから覚えているように、デコーダー内の各単語がその前に来る単語のみを見ることを望んでいます。つまり、この行列を表す対角線よりも上のすべての値を隠したいので、この対角線よりも上のすべての値がマスクされるようにしたいのです。これは、自己注意機構におけるクエリとキーの乗算を表しています。したがって、例えばこの「かわいい」という単語は、それ自体までのすべての単語を見ることができますが、その後に来る「猫」という単語を見ることはできません。したがって、我々がしたいのは、ここにあるすべての値をマスクアウトすることです。これはまた、対角線よりも上のすべての値をマスクアウトしたいことを意味します。Pytorchにはそれを行うための非常に実用的な方法がありますので、それを行いましょう。つまり、マスクは基本的に私に対角線よりも上にあるすべての値を与えるという意味です。では、どの行列が欲しいですか？"
  },
  {
    "start": 6558584,
    "end": 6664300,
    "text": "すべてが1で構成された行列を作成し、この方法は対角線上のすべての値を返し、それ以外のすべてがゼロになります。したがって、我々は対角線の1の型を望んでいる。それを整数にしたいので、マスクを0に返します。これにより、対角線上のすべての値が返され、対角線以下のすべてがゼロになりますが、実際にはその逆を望んでいます。したがって、すべてが0になるものは真になり、それ以外のものは偽になるという式で表されます。この式を適用して、このマスクを構築します。このマスクは、シーケンスの長さ×シーケンスの長さになります。これがまさに我々が望んでいるものです。よし、ラベルも追加しましょう。ラベルもありました。コンマを忘れていました。シーケンスの長さがあります。そして、可視化のために、ソーステキストとターゲットテキストを送信することができます。これが私たちのデータセットです。さて、トレーニングループの作成を続けるために、トレーニングメソッドに戻りましょう。今、データセットがあるので、それを作成し、トレーニング用と検証用の2つのデータセットを作成できます。そして、それをデータローダーに送り、最終的にはトレーニングループに送ります。"
  },
  {
    "start": 6670740,
    "end": 6675344,
    "text": "データセットをインポートするのを忘れていたので、インポートしよう。"
  },
  {
    "start": 6675382,
    "end": 6685510,
    "text": "ここで、後で必要となる因果関係のあるマスクをインポートする。"
  },
  {
    "start": 6702720,
    "end": 6704936,
    "text": "我々の原語は何なのか？"
  },
  {
    "start": 6705048,
    "end": 6706620,
    "text": "それはコンフィギュレーションにある。"
  },
  {
    "start": 6709760,
    "end": 6719420,
    "text": "ターゲット言語を何にするか、配列の長さを何にするかも設定に含まれる。"
  },
  {
    "start": 6721520,
    "end": 6734230,
    "text": "バリデーションもそうだが、唯一違うのは、今はこれを使っていて、あとは同じだということだ。"
  },
  {
    "start": 6737240,
    "end": 6772444,
    "text": "最大配列長を選択するために、ソース言語とターゲット言語における各文の最大長も見ておきたい。"
  },
  {
    "start": 6772492,
    "end": 6776108,
    "text": "トークナイザーを使ってIDに変換し、長さをチェックする。"
  },
  {
    "start": 6776204,
    "end": 6786116,
    "text": "長さが例えば180だとすると、200を配列の長さとして選ぶことができる。"
  },
  {
    "start": 6786218,
    "end": 6796020,
    "text": "文頭と文末のトークンを追加する必要があるからだ。"
  },
  {
    "start": 6817040,
    "end": 6821128,
    "text": "これがソースIDである。"
  },
  {
    "start": 6821304,
    "end": 6828860,
    "text": "次に、ターゲットとなるIDを作成しよう。"
  },
  {
    "start": 6829540,
    "end": 6845916,
    "text": "であるならば、ソースの最大長は、現在の文の長さとの最大値であると言うだけである。"
  },
  {
    "start": 6846108,
    "end": 6850960,
    "text": "対象はターゲットとターゲットのIDである。"
  },
  {
    "start": 6851460,
    "end": 6853680,
    "text": "そして、これら2つの値を表示する。"
  },
  {
    "start": 6854060,
    "end": 6870220,
    "text": "また、ターゲットのためにやる、それだけだ。"
  },
  {
    "start": 6870290,
    "end": 6872940,
    "text": "これでデータ・ローダーの作成に進むことができる。"
  },
  {
    "start": 6882420,
    "end": 6893300,
    "text": "まだ定義していないが、どのような値かは想像がつくだろう。"
  },
  {
    "start": 6895160,
    "end": 6896980,
    "text": "シャッフルしてほしい。"
  },
  {
    "start": 6907020,
    "end": 6914170,
    "text": "では、検証のためにバッチ・サイズを1つにしてみよう。"
  },
  {
    "start": 6917280,
    "end": 6929260,
    "text": "このメソッドは、トレーニングのデータ・ローダー、検証のデータ・ローダー、ソース言語のトークナイザー、ターゲット言語のトークナイザーを返します。"
  },
  {
    "start": 6930740,
    "end": 6933650,
    "text": "これで、モデルの構築を始めることができる。"
  },
  {
    "start": 6934740,
    "end": 6952212,
    "text": "getモデルという新しいメソッドを定義しましょう。このメソッドは、コンフィギュレーションやボキャブラリーに従って、トランスフォーマ・モデルを構築します。"
  },
  {
    "start": 6952266,
    "end": 6958090,
    "text": "モデルをインポートしていないので、インポートしよう。"
  },
  {
    "start": 6965260,
    "end": 6978270,
    "text": "ビルド変換は、最初の、ソース語彙のサイズとターゲット語彙のサイズです。"
  },
  {
    "start": 6979920,
    "end": 6991760,
    "text": "とすれば、配列の長さがわかり、ソース言語の配列の長さとターゲット言語の配列の長さがわかる。"
  },
  {
    "start": 6992580,
    "end": 6995990,
    "text": "どちらも同じものを使う。"
  },
  {
    "start": 6996760,
    "end": 7003504,
    "text": "ということは、dモデルということになる。"
  },
  {
    "start": 7003632,
    "end": 7016548,
    "text": "もしモデルが大きすぎてgpuに学習させることができない場合は、ヘッド数やレイヤー数を減らしてみることができる。"
  },
  {
    "start": 7016644,
    "end": 7020344,
    "text": "もちろん、モデルのパフォーマンスには影響するだろう。"
  },
  {
    "start": 7020462,
    "end": 7030030,
    "text": "データセットがそれほど大きくなく、複雑でもないことを考えれば、大きな問題にはならないはずだ。"
  },
  {
    "start": 7030880,
    "end": 7035548,
    "text": "さて、モデルができたので、トレーニング・ループを作り始めよう。"
  },
  {
    "start": 7035644,
    "end": 7040848,
    "text": "トレーニングループを構築する前に、このコンフィギュレーションを定義しておこう。"
  },
  {
    "start": 7040934,
    "end": 7046292,
    "text": "今のうちに構造を明確にしておいた方がいいと思う。"
  },
  {
    "start": 7046346,
    "end": 7052576,
    "text": "config py という新しいファイルを作り、その中に2つのメソッドを定義します。"
  },
  {
    "start": 7052608,
    "end": 7061690,
    "text": "ひとつはget configと呼ばれるもので、もうひとつはモデルの重みを保存するパスを取得するmapである。"
  },
  {
    "start": 7068320,
    "end": 7071150,
    "text": "では、バッチサイズを定義しよう。"
  },
  {
    "start": 7074080,
    "end": 7075052,
    "text": "私は8つを選ぶ。"
  },
  {
    "start": 7075106,
    "end": 7078172,
    "text": "コンピュータが許すなら、もっと大きなものを選んでもいい。"
  },
  {
    "start": 7078306,
    "end": 7083010,
    "text": "トレーニングのエポック数は20で十分だと思う。"
  },
  {
    "start": 7083540,
    "end": 7088512,
    "text": "私が使っている学習率は10のマイナス4乗だ。"
  },
  {
    "start": 7088646,
    "end": 7090960,
    "text": "他の値を使うこともできる。"
  },
  {
    "start": 7092180,
    "end": 7095060,
    "text": "この学習率は妥当だと思った。"
  },
  {
    "start": 7096600,
    "end": 7099830,
    "text": "トレーニング中に学習率を変更することも可能だ。"
  },
  {
    "start": 7100920,
    "end": 7107152,
    "text": "実際には、非常に高い学習率を与え、エポックごとに徐々に下げていくのが一般的だ。"
  },
  {
    "start": 7107216,
    "end": 7110744,
    "text": "コードが少し複雑になるだけなので、使用はしない。"
  },
  {
    "start": 7110782,
    "end": 7113752,
    "text": "これはこのビデオの目的ではない。"
  },
  {
    "start": 7113806,
    "end": 7117370,
    "text": "このビデオの目的は、変圧器がどのように機能するかを教えることである。"
  },
  {
    "start": 7121040,
    "end": 7129950,
    "text": "英語からイタリア語まで、このデータセットに必要な配列の長さはすでにチェック済みだ。"
  },
  {
    "start": 7130400,
    "end": 7134530,
    "text": "今回使用するDモデルはデフォルトの512である。"
  },
  {
    "start": 7135540,
    "end": 7138972,
    "text": "言語ソースは英語。"
  },
  {
    "start": 7139036,
    "end": 7140720,
    "text": "我々は英語から出発する。"
  },
  {
    "start": 7141380,
    "end": 7144208,
    "text": "使用言語はイタリア語。"
  },
  {
    "start": 7144304,
    "end": 7146900,
    "text": "これからイタリア語に翻訳する。"
  },
  {
    "start": 7147480,
    "end": 7160200,
    "text": "モデルをweightsというフォルダに保存し、そのファイル名をT modelとする。"
  },
  {
    "start": 7160270,
    "end": 7161770,
    "text": "トランスフォームモデル。"
  },
  {
    "start": 7165340,
    "end": 7173580,
    "text": "クラッシュした後にトレーニングを再開するために、モデルをプリロードするコードも作った。"
  },
  {
    "start": 7183380,
    "end": 7187504,
    "text": "これはトークナイザー・ファイルなので、このように保存される。"
  },
  {
    "start": 7187542,
    "end": 7191520,
    "text": "トークナイザーNを使用し、言語に応じてトークン化します。"
  },
  {
    "start": 7192340,
    "end": 7204470,
    "text": "これはtensorboardの実験名で、トレーニング中の損失を保存する。"
  },
  {
    "start": 7205420,
    "end": 7207144,
    "text": "ここにコンマがあると思う。"
  },
  {
    "start": 7207262,
    "end": 7214360,
    "text": "では、重みを保存するパスを見つけることができる別のメソッドを定義しよう。"
  },
  {
    "start": 7219280,
    "end": 7229480,
    "text": "なぜこのような複雑な構成にしているかというと、このトレーニングをGoogle Colabで行うためのノートブックも提供するからだ。"
  },
  {
    "start": 7229640,
    "end": 7236464,
    "text": "Google Colabで動作するようにこれらのパラメータを変更し、Google Driveに直接ウェイトを保存するだけです。"
  },
  {
    "start": 7236582,
    "end": 7242572,
    "text": "このコードはすでに作成済みで、GitHubで提供する予定だ。"
  },
  {
    "start": 7242636,
    "end": 7283584,
    "text": "また、モデル・ビジネス名に応じたリンクをビデオの中で提供します。"
  },
  {
    "start": 7283782,
    "end": 7288080,
    "text": "そしてエポック白金。"
  },
  {
    "start": 7302760,
    "end": 7304820,
    "text": "パスライブラリーもここにある。"
  },
  {
    "start": 7309980,
    "end": 7313012,
    "text": "さて、トレーニングループに戻ろう。"
  },
  {
    "start": 7313076,
    "end": 7319944,
    "text": "さて、これでようやくトレーニング・ループを構築できる。"
  },
  {
    "start": 7320072,
    "end": 7325384,
    "text": "さて、まずはすべてのテンソルを置くデバイスを定義する必要がある。"
  },
  {
    "start": 7325512,
    "end": 7327980,
    "text": "デバイスを定義する。"
  },
  {
    "start": 7332720,
    "end": 7334576,
    "text": "私のコンピューターにCuDaがあればね。"
  },
  {
    "start": 7334678,
    "end": 7388130,
    "text": "weightフォルダが作成されていることを確認し、データセットをロードする。"
  },
  {
    "start": 7389220,
    "end": 7398100,
    "text": "ここでこれらの値を取って、コンフィグのdsと等しいと言えばいい。"
  },
  {
    "start": 7402760,
    "end": 7409112,
    "text": "また、語彙のサイズを求めるモデルも作成する。"
  },
  {
    "start": 7409166,
    "end": 7420060,
    "text": "getpocab sizedというメソッドがあり、他にパラメータはないと思う。"
  },
  {
    "start": 7420800,
    "end": 7423820,
    "text": "最後に、モデルをデバイスに転送する。"
  },
  {
    "start": 7427280,
    "end": 7429896,
    "text": "テンソルボードも始める。"
  },
  {
    "start": 7430088,
    "end": 7435040,
    "text": "Tensorboardは、損失、グラフィックス、チャートを視覚化することができます。"
  },
  {
    "start": 7468620,
    "end": 7469832,
    "text": "戻ろう。"
  },
  {
    "start": 7469966,
    "end": 7472760,
    "text": "オプティマイザーも作ってみよう。"
  },
  {
    "start": 7473100,
    "end": 7494070,
    "text": "アダム・オプティマイザーを使うつもりだ。"
  },
  {
    "start": 7495160,
    "end": 7505220,
    "text": "モデルがクラッシュしたり、何かがクラッシュした場合にトレーニングを再開する設定もあるので、それを実装しよう。"
  },
  {
    "start": 7505290,
    "end": 7511800,
    "text": "これにより、モデルの状態とオプティマイザの状態を復元することができる。"
  },
  {
    "start": 7530820,
    "end": 7534912,
    "text": "データで定義したこのメソッドをインポートしてみよう。"
  },
  {
    "start": 7534966,
    "end": 7617650,
    "text": "ここにセットしてください。"
  },
  {
    "start": 7617810,
    "end": 7621530,
    "text": "さて、最後に使う関数はクロスエントロピー損失だ。"
  },
  {
    "start": 7627630,
    "end": 7630070,
    "text": "無視指数とは何か、彼に伝える必要がある。"
  },
  {
    "start": 7630150,
    "end": 7633114,
    "text": "パディング・トークンを無視させたい。"
  },
  {
    "start": 7633162,
    "end": 7638590,
    "text": "基本的に、パディングトークンへの損失が損失の一因になることは避けたい。"
  },
  {
    "start": 7654150,
    "end": 7658354,
    "text": "また、ラベルを平滑化するラベルも使用する。"
  },
  {
    "start": 7658402,
    "end": 7664706,
    "text": "ムーティングは基本的に、私たち、私たちのモデルがその決断に自信を持てないようにするものだ。"
  },
  {
    "start": 7664898,
    "end": 7673398,
    "text": "というのは、私たちのモデルが、非常に高い確率で3という単語を選ぶように指示しているとしよう。"
  },
  {
    "start": 7673494,
    "end": 7683550,
    "text": "私たちがラベルのブートで行うことは、その確率のわずかな割合を他のトークンに分配することである。"
  },
  {
    "start": 7684130,
    "end": 7686154,
    "text": "過剰な給餌は控えた方がいい。"
  },
  {
    "start": 7686202,
    "end": 7688960,
    "text": "これはモデルの精度を向上させる。"
  },
  {
    "start": 7691730,
    "end": 7702980,
    "text": "つまり、最も高い確率のトークンから0.1％の得点を取り出して、他のトークンに与えるということである。"
  },
  {
    "start": 7707930,
    "end": 7724300,
    "text": "では、いよいよトレーニング・ループを構築しよう。"
  },
  {
    "start": 7727070,
    "end": 7736320,
    "text": "私はTkODMを使ってデータローダー用のバッチ・イテレーターを作り、とても素敵なプログレスバーを表示する。"
  },
  {
    "start": 7758090,
    "end": 7783360,
    "text": "エンコーダーが入力するTQDmをインポートする必要がある。"
  },
  {
    "start": 7788770,
    "end": 7791194,
    "text": "このテンソルのサイズは？"
  },
  {
    "start": 7791242,
    "end": 7793550,
    "text": "シークエンスの長さに比例する。"
  },
  {
    "start": 7794630,
    "end": 7804130,
    "text": "デコーダー入力は一括して、私たちのデバイスに移される。"
  },
  {
    "start": 7805430,
    "end": 7807730,
    "text": "バッチからシーケンスの長さ。"
  },
  {
    "start": 7808470,
    "end": 7810434,
    "text": "2枚のマスクを手に入れた。"
  },
  {
    "start": 7810482,
    "end": 7828330,
    "text": "また、これはサイズであり、次にデコーダー・マスクである。"
  },
  {
    "start": 7842210,
    "end": 7843966,
    "text": "なぜこの2つのマスクは違うのか？"
  },
  {
    "start": 7844068,
    "end": 7851134,
    "text": "というのも、1つのケースでは、パディングトークンのみを隠すように指示しているだけだからだ。"
  },
  {
    "start": 7851182,
    "end": 7860600,
    "text": "もう一方のケースでは、それぞれの単語に対して、後続の単語をすべて隠してマスクするように指示している。"
  },
  {
    "start": 7862170,
    "end": 7870398,
    "text": "では、テンソルをトランスフォーマーに通してみよう。"
  },
  {
    "start": 7870594,
    "end": 7882650,
    "text": "まず、エンコーダーの出力を計算し、エンコーダーの入力とマスクを使ってエンコードを行う。"
  },
  {
    "start": 7883970,
    "end": 7903090,
    "text": "次に、エンコーダー出力とエンコーダーのマスクを用いてデコーダー出力を計算し、次にデコーダー入力とデコーダーのマスクを用いる。"
  },
  {
    "start": 7906550,
    "end": 7917880,
    "text": "さて、この結果はわかっているので、モデル符号化の出力はバッチシーケンス長dのモデルになる。"
  },
  {
    "start": 7919630,
    "end": 7926620,
    "text": "また、デコーダーの出力はバッチシーケンス長dモデルになる。"
  },
  {
    "start": 7927870,
    "end": 7930134,
    "text": "それをボキャブラリーにマッピングしたい。"
  },
  {
    "start": 7930182,
    "end": 7931510,
    "text": "私たちには投影が必要だ。"
  },
  {
    "start": 7931590,
    "end": 7941646,
    "text": "投影出力を得よう。"
  },
  {
    "start": 7941748,
    "end": 7946580,
    "text": "バッチ配列の長さとターゲット語彙のサイズ。"
  },
  {
    "start": 7949110,
    "end": 7954334,
    "text": "さて、モデルの出力が得られたので、ラベルと比較したい。"
  },
  {
    "start": 7954382,
    "end": 7964882,
    "text": "まず、バッチからラベルを抽出し、それをデバイスに貼り付けよう。"
  },
  {
    "start": 7965026,
    "end": 7966386,
    "text": "ラベルは何ですか？"
  },
  {
    "start": 7966418,
    "end": 7967558,
    "text": "Bだ。"
  },
  {
    "start": 7967644,
    "end": 7972298,
    "text": "バッチは、各ポジションが伝える配列の長さに比例する。"
  },
  {
    "start": 7972384,
    "end": 7977910,
    "text": "ラベルは各bと配列の長さに対して既にある。"
  },
  {
    "start": 7977990,
    "end": 7983840,
    "text": "各次元は、その単語の語彙における位置を示している。"
  },
  {
    "start": 7984290,
    "end": 7988554,
    "text": "この2つを比較できるようにしたい。"
  },
  {
    "start": 7988682,
    "end": 8008218,
    "text": "まず、損失を計算する必要がある。"
  },
  {
    "start": 8008414,
    "end": 8010630,
    "text": "よし、これは何をするんだ？"
  },
  {
    "start": 8010700,
    "end": 8028666,
    "text": "これは基本的に、このサイズをこのサイズに変換し、bにシーケンスlenを掛け合わせ、ターゲット語彙のサイズ、語彙のサイズに変換する。"
  },
  {
    "start": 8028848,
    "end": 8031900,
    "text": "オーケー、これと比較したいからね。"
  },
  {
    "start": 8032370,
    "end": 8041550,
    "text": "これがクロスエントロピーが求めるテンソルのあり方であり、ラベルでもある。"
  },
  {
    "start": 8044370,
    "end": 8048714,
    "text": "さて、これで損失を計算した。"
  },
  {
    "start": 8048762,
    "end": 8083006,
    "text": "プログレス・バーを更新し、計算した損失額をプログレス・バーに表示します。"
  },
  {
    "start": 8083188,
    "end": 8086350,
    "text": "tensorboardに記録することもできる。"
  },
  {
    "start": 8107610,
    "end": 8114230,
    "text": "これでロスを逆伝播することができる。"
  },
  {
    "start": 8114730,
    "end": 8118600,
    "text": "最後に、モデルの重みを更新する。"
  },
  {
    "start": 8119290,
    "end": 8121718,
    "text": "それがオプティマイザの仕事だ。"
  },
  {
    "start": 8121814,
    "end": 8129514,
    "text": "最後に、グリッドをゼロにし、グローバル・ステップを1つずつ削除することができる。"
  },
  {
    "start": 8129552,
    "end": 8134826,
    "text": "グローバル・ステップは、主にテンソルボードに使用されている。"
  },
  {
    "start": 8135018,
    "end": 8147410,
    "text": "エポックごとにモデルを保存することができる。"
  },
  {
    "start": 8147830,
    "end": 8165880,
    "text": "このファイル名には、エポックの前にゼロをつけたものである。"
  },
  {
    "start": 8166650,
    "end": 8177206,
    "text": "トレーニングを再開する際には、モデルの状態だけでなく、オプティマイザの状態も保存しておくとよいだろう。"
  },
  {
    "start": 8177238,
    "end": 8187550,
    "text": "なぜなら、オプティマイザは各ウェイトの統計情報も記録しているからだ。"
  },
  {
    "start": 8187620,
    "end": 8194574,
    "text": "実際、オプティマイザーの辞書はかなり大きい。"
  },
  {
    "start": 8194692,
    "end": 8200162,
    "text": "たとえ大きくても、トレーニングを再開できるようにしたいなら、保存しておく必要がある。"
  },
  {
    "start": 8200216,
    "end": 8209270,
    "text": "そうしないと、オプティマイザは常にゼロからスタートすることになり、たとえ前のエポックからスタートしたとしても、各ウェイトをどのように動かすかをゼロから考えなければならなくなる。"
  },
  {
    "start": 8210010,
    "end": 8226360,
    "text": "スナップショットを保存するたびに、モデルの状態、これはモデルのすべての重みである。"
  },
  {
    "start": 8226730,
    "end": 8248770,
    "text": "また、オプティマイザーを保存し、グローバル・ステップも実行し、これらすべてをファイル名に保存したい。"
  },
  {
    "start": 8248840,
    "end": 8254658,
    "text": "モデル・ファイル名、以上。"
  },
  {
    "start": 8254824,
    "end": 8257910,
    "text": "では、これを実行するコードをビルドしてみよう。"
  },
  {
    "start": 8257980,
    "end": 8278778,
    "text": "というのも、多くのライブラリ（特にCuda）を持っていて、すでに内容が分かっているので、毎回警告を視覚化したくないのです。"
  },
  {
    "start": 8278944,
    "end": 8285070,
    "text": "何か大きな問題があるかどうかを理解するために、少なくとも一度は見ることをお勧めする。"
  },
  {
    "start": 8285140,
    "end": 8287630,
    "text": "そうでなければ、クダから文句を言われるだけだ。"
  },
  {
    "start": 8303190,
    "end": 8308580,
    "text": "このコードを実行し、すべてがうまく機能しているかどうか確認してみよう。"
  },
  {
    "start": 8309530,
    "end": 8318354,
    "text": "私たちが期待しているのは、コードが最初にデータセットをダウンロードし、次にトークナイザーを作成してファイルに保存することです。"
  },
  {
    "start": 8318482,
    "end": 8324806,
    "text": "も30エポックのモデル学習を開始する。"
  },
  {
    "start": 8324838,
    "end": 8327738,
    "text": "もちろん、完成することはないだろうが、やろうじゃないか。"
  },
  {
    "start": 8327824,
    "end": 8333050,
    "text": "コンフィギュレーション・トークナイザーをもう一度確認してみよう。"
  },
  {
    "start": 8333650,
    "end": 8335360,
    "text": "よし、やってみよう。"
  },
  {
    "start": 8353310,
    "end": 8357494,
    "text": "さて、トークナイザーを構築しているところですが、ここで問題が発生しました。"
  },
  {
    "start": 8357632,
    "end": 8361278,
    "text": "シーケンスの長さはOKで、いよいよモデルのトレーニングだ。"
  },
  {
    "start": 8361444,
    "end": 8365322,
    "text": "私が何を勘違いしていたのか、君たちに再確認してもらおう。"
  },
  {
    "start": 8365466,
    "end": 8368874,
    "text": "まず、配列の長さが間違っていた。"
  },
  {
    "start": 8368922,
    "end": 8373122,
    "text": "ここにも大文字のlがあったし、データセットにもあった。"
  },
  {
    "start": 8373176,
    "end": 8380690,
    "text": "ここに保存するのを忘れていて、ここでも大文字で書いていたので、lは大文字だった。"
  },
  {
    "start": 8381030,
    "end": 8396150,
    "text": "少なくとも私のコンピューターでは、それほど速くはないのだが、バッチサイズを8にしているので、それを増やしてみることもできる。"
  },
  {
    "start": 8396220,
    "end": 8398490,
    "text": "クーダで起きていることだ。"
  },
  {
    "start": 8398990,
    "end": 8403082,
    "text": "ロスは減っており、ウエイトはここでセーブされる。"
  },
  {
    "start": 8403136,
    "end": 8407114,
    "text": "エポックの終わりに到達すれば、ここで最初のウェイトが作られる。"
  },
  {
    "start": 8407152,
    "end": 8415086,
    "text": "エポックが終了するまで待ち、モデルのトレーニングが終了する前にウェイトが実際に作成されるかどうかを確認しよう。"
  },
  {
    "start": 8415268,
    "end": 8416880,
    "text": "もうひとつやろう。"
  },
  {
    "start": 8417250,
    "end": 8421738,
    "text": "また、トレーニング中のモデルの出力を可視化したい。"
  },
  {
    "start": 8421844,
    "end": 8423358,
    "text": "これをバリデーションと呼ぶ。"
  },
  {
    "start": 8423454,
    "end": 8429182,
    "text": "モデルが学習される間にどのように進化していくかをチェックしたい。"
  },
  {
    "start": 8429326,
    "end": 8443314,
    "text": "つまり、このモデルから推論を行い、いくつかのサンプル文をチェックして、どのように翻訳されるかを確認するのだ。"
  },
  {
    "start": 8443442,
    "end": 8446022,
    "text": "検証ループを作り始めよう。"
  },
  {
    "start": 8446166,
    "end": 8450410,
    "text": "最初にすることは、実行検証という新しいメソッドを作ることだ。"
  },
  {
    "start": 8456990,
    "end": 8461658,
    "text": "このメソッドは、これから使ういくつかのパラメーターを受け付ける。"
  },
  {
    "start": 8461744,
    "end": 8465900,
    "text": "今のところ、私はそれらをすべて書くだけで、後でそれらがどのように使われるかを説明する。"
  },
  {
    "start": 8469870,
    "end": 8499562,
    "text": "大丈夫だ。"
  },
  {
    "start": 8499696,
    "end": 8506070,
    "text": "検証を実行するために最初にすることは、モデルを評価モードにすることだ。"
  },
  {
    "start": 8506150,
    "end": 8508394,
    "text": "我々はモデル評価を行っている。"
  },
  {
    "start": 8508522,
    "end": 8513120,
    "text": "これは、Pytorchにモデルを評価することを伝えることを意味する。"
  },
  {
    "start": 8513490,
    "end": 8558800,
    "text": "では、どうするかというと、2つの文章を推論し、そのモデルの出力を見てみる。"
  },
  {
    "start": 8561410,
    "end": 8570106,
    "text": "torch not gradの場合、このブロックの中で実行されるすべてのテンソルの勾配計算を無効にしている。"
  },
  {
    "start": 8570218,
    "end": 8571714,
    "text": "これこそ私たちが望んでいることだ。"
  },
  {
    "start": 8571752,
    "end": 8573570,
    "text": "我々はモデルから推論したいだけなのだ。"
  },
  {
    "start": 8573640,
    "end": 8576050,
    "text": "このループの中でトレーニングはしたくない。"
  },
  {
    "start": 8577910,
    "end": 8584534,
    "text": "検証データセットからバッチを取得してみよう。"
  },
  {
    "start": 8584572,
    "end": 8592790,
    "text": "すでに処理した数を記録し、現在のバッチから入力を得る。"
  },
  {
    "start": 8593210,
    "end": 8598380,
    "text": "バリデーションDSでは、バッチサイズが1つしかないことを忘れないでほしい。"
  },
  {
    "start": 8607890,
    "end": 8609274,
    "text": "これはエンコーダー入力である。"
  },
  {
    "start": 8609322,
    "end": 8627700,
    "text": "また、エンコーダー・マスクに、バッチのサイズが実際に1であることを確認させることもできる。"
  },
  {
    "start": 8640710,
    "end": 8643922,
    "text": "さて、興味深い部分に行こう。"
  },
  {
    "start": 8644056,
    "end": 8659414,
    "text": "覚えているように、モデルを推論する場合、エンコーダーの出力を一度だけ計算し、モデルがデコーダーから出力するトークンごとに再利用する必要がある。"
  },
  {
    "start": 8659542,
    "end": 8668714,
    "text": "モデルに対して貪欲なデコーディングを実行する別の関数を作ってみよう。"
  },
  {
    "start": 8668912,
    "end": 8671570,
    "text": "この関数をgriddy decodeで呼び出してみよう。"
  },
  {
    "start": 8695150,
    "end": 8705526,
    "text": "文頭のSOSトークンは、どちらのトークナイザーからも取得できる。"
  },
  {
    "start": 8705558,
    "end": 8708620,
    "text": "ターゲットであろうとソースであろうと関係ない。"
  },
  {
    "start": 8726790,
    "end": 8727678,
    "text": "EOS。"
  },
  {
    "start": 8727854,
    "end": 8758250,
    "text": "次に、エンコーダー出力を事前に計算し、デコーダーとソース・マスク（エンコーダー入力とエンコーダー・マスク）から得られるトークンごとに再利用する。"
  },
  {
    "start": 8759470,
    "end": 8763150,
    "text": "エンコーダー入力、エンコーダー・マスクと呼ぶこともできる。"
  },
  {
    "start": 8763970,
    "end": 8768330,
    "text": "それから、推論をどうするか？"
  },
  {
    "start": 8768410,
    "end": 8779534,
    "text": "まず、デコーダーに文頭トークンを与えて、デコーダーが翻訳文の文頭トークンを出力するようにする。"
  },
  {
    "start": 8779662,
    "end": 8792530,
    "text": "そして、スライドで見たように、反復ごとに前のトークンをデコーダーの入力に加え、デコーダーが次のトークンを出力できるようにする。"
  },
  {
    "start": 8792610,
    "end": 8799878,
    "text": "そして次のトークンを取り出し、デコーダーの入力の前に再び置くと、連続したトークンが得られる。"
  },
  {
    "start": 8800054,
    "end": 8830050,
    "text": "最初の反復のために、文頭トークンだけのデコーダー入力を作ってみよう。"
  },
  {
    "start": 8838330,
    "end": 8840470,
    "text": "エンコーダ入力としてタイプする。"
  },
  {
    "start": 8842170,
    "end": 8853900,
    "text": "では、文末トークンか、ここで定義した最大lenに達するまで、デコーダーに次のトークンを出力するように要求し続けよう。"
  },
  {
    "start": 8855150,
    "end": 8857478,
    "text": "暫くは本当だ。"
  },
  {
    "start": 8857664,
    "end": 8878242,
    "text": "最初の停止条件は、次のステップの入力となるデコーダ出力がmax lenより大きくなるか、ここでmax lenに達した場合である。"
  },
  {
    "start": 8878296,
    "end": 8879742,
    "text": "なぜ2次元なのか？"
  },
  {
    "start": 8879806,
    "end": 8885190,
    "text": "ひとつはバッチ用、もうひとつはデコーダー入力のトークン用だ。"
  },
  {
    "start": 8889530,
    "end": 8891314,
    "text": "次にマスクを作成する必要がある。"
  },
  {
    "start": 8891362,
    "end": 8930420,
    "text": "この場合、入力に未来の単語を監視させないようにするために、関数causal maskを使用することができます。また、ここではパディングトークンがないので、他のマスクは必要ありません。"
  },
  {
    "start": 8932730,
    "end": 8952170,
    "text": "ここで、ループの反復ごとにエンコーダーの出力を計算する。"
  },
  {
    "start": 8952590,
    "end": 8958794,
    "text": "ソース・マスクを再利用するので、入力はエンコーダーのマスクとなる。"
  },
  {
    "start": 8958922,
    "end": 8967950,
    "text": "次にデコーダに入力を与え、そのマスクとともにデコーダのマスクを与え、次のトークンを得る。"
  },
  {
    "start": 8971670,
    "end": 8976610,
    "text": "射影層を使って次のトークンの確率を求める。"
  },
  {
    "start": 8979670,
    "end": 8984306,
    "text": "最後のトークンの投影だけが欲しい。"
  },
  {
    "start": 8984418,
    "end": 8989190,
    "text": "エンコーダーに渡した最後のトークンの次のトークン。"
  },
  {
    "start": 8991770,
    "end": 9001926,
    "text": "これで、最大確率でトークンが得られるように、最大値を使うことができる。"
  },
  {
    "start": 9002118,
    "end": 9003900,
    "text": "これが欲張りな検索だ。"
  },
  {
    "start": 9018370,
    "end": 9031330,
    "text": "次の反復の入力になるからだ。"
  },
  {
    "start": 9033430,
    "end": 9038526,
    "text": "デコーダーの入力を受け取り、次のトークンを追加する。"
  },
  {
    "start": 9038718,
    "end": 9079506,
    "text": "そのために別のテンソルを作ればいい。"
  },
  {
    "start": 9079688,
    "end": 9093286,
    "text": "次のトークンが、文末のトークンと等しければ、ループを止め、これが貪欲な検索です。"
  },
  {
    "start": 9093388,
    "end": 9095750,
    "text": "あとは出力を返すだけだ。"
  },
  {
    "start": 9096270,
    "end": 9103734,
    "text": "なぜなら、毎回次のトークンを追加し、バッチ次元を削除しているからだ。"
  },
  {
    "start": 9103782,
    "end": 9109434,
    "text": "私たちはそれを絞り、それが私たちの貪欲な解読なのだ。"
  },
  {
    "start": 9109562,
    "end": 9123890,
    "text": "この関数を検証関数で使うことで、最終的にモデル出力は貪欲なデコードに等しくなる。"
  },
  {
    "start": 9139370,
    "end": 9144866,
    "text": "そして、このモデル出力を予想したものと比較したい。"
  },
  {
    "start": 9144898,
    "end": 9146230,
    "text": "というラベルが貼られている。"
  },
  {
    "start": 9146650,
    "end": 9148794,
    "text": "これらをすべて追加しよう。"
  },
  {
    "start": 9148912,
    "end": 9166170,
    "text": "入力に与えたもの、モデルに与えたもの、モデルが出力したもの、モデルの出力、予測されたもの、出力として期待されたもの、これらをすべてリストに保存し、ループの最後にコンソールに表示する。"
  },
  {
    "start": 9169790,
    "end": 9201180,
    "text": "モデルの出力のテキストを得るには、トークナイザーをもう一度使ってトークンをテキストに変換する必要がある。"
  },
  {
    "start": 9201950,
    "end": 9206890,
    "text": "もちろん、ターゲット・トークナイザーを使います。"
  },
  {
    "start": 9220390,
    "end": 9249610,
    "text": "よし、ではこれらのリストをそれぞれのリストに保存し、コンソールに表示しよう。"
  },
  {
    "start": 9254430,
    "end": 9260682,
    "text": "なぜprint messageという関数を使うのか、なぜパイソンのprintを使わないのか？"
  },
  {
    "start": 9260826,
    "end": 9270234,
    "text": "メイン・ループ、トレーニング・ループでは、tkodmを使っている。"
  },
  {
    "start": 9270372,
    "end": 9277378,
    "text": "このプログレス・パートの実行中に、コンソールに直接印刷することは推奨されない。"
  },
  {
    "start": 9277544,
    "end": 9306410,
    "text": "そこで、コンソールに出力するために、TQDMが提供するprintというメソッドがある。このメソッドをこの関数に与えて、出力が進行部分を邪魔しないようにし、いくつかのバーを出力し、それからすべてのメッセージを出力する。"
  },
  {
    "start": 9339440,
    "end": 9345790,
    "text": "もし、すでに処理済みの例があれば、そのまま中断する。"
  },
  {
    "start": 9347460,
    "end": 9350160,
    "text": "なぜこのようなリストを作成したのか。"
  },
  {
    "start": 9350660,
    "end": 9356800,
    "text": "実は、このすべてをtensorboardに送ることもできる。"
  },
  {
    "start": 9358580,
    "end": 9364880,
    "text": "例えば、tensorboardを有効にしていれば、これをすべてtensorboardに送ることができる。"
  },
  {
    "start": 9365040,
    "end": 9370500,
    "text": "そのためには、いくつかのメトリクスを計算できる別のライブラリが必要だ。"
  },
  {
    "start": 9370920,
    "end": 9394636,
    "text": "この部分は省略できると思うが、GitHubで公開したコードに本当に興味があるのであれば、トーチ・メトリクスというライブラリを使っていることがわかるだろう。"
  },
  {
    "start": 9394818,
    "end": 9399420,
    "text": "もし本当に興味があれば、GitHubでコードを見つけることができる。"
  },
  {
    "start": 9399500,
    "end": 9402880,
    "text": "私たちのデモンストレーションには必要ないと思う。"
  },
  {
    "start": 9404900,
    "end": 9411030,
    "text": "実際、この部分はやらないのだから、取り除くこともできる。"
  },
  {
    "start": 9412440,
    "end": 9418052,
    "text": "さて、これで実行検証メソッドができたので、あとはそれを呼び出すだけだ。"
  },
  {
    "start": 9418186,
    "end": 9425000,
    "text": "さて、私が普段やっているのは、数ステップごとにバリデーションを実行することだ。"
  },
  {
    "start": 9425420,
    "end": 9446472,
    "text": "検証を実行した後、モデルがトレーニング・モードに戻るように、このループの中にトレーニング・モデルを配置します。"
  },
  {
    "start": 9446616,
    "end": 9453852,
    "text": "バリデーションを実行するために必要なすべてのパラメータを与えることができる。"
  },
  {
    "start": 9453916,
    "end": 9473210,
    "text": "モグラのモデルになる"
  },
  {
    "start": 9476860,
    "end": 9481290,
    "text": "では、メッセージの印刷ですが、何かメッセージを印刷していますか？"
  },
  {
    "start": 9482780,
    "end": 9483480,
    "text": "我々はそうだ。"
  },
  {
    "start": 9483550,
    "end": 9489710,
    "text": "ラムダを作って、それを実行しよう。"
  },
  {
    "start": 9495760,
    "end": 9507904,
    "text": "これはtQodmで書き込むメッセージであり、グローバル・ステップとライターを指定する必要がある。"
  },
  {
    "start": 9507942,
    "end": 9508240,
    "text": "でもね。"
  },
  {
    "start": 9508310,
    "end": 9538468,
    "text": "さて、もう一度トレーニングを行って、検証ワークショップができるかどうか見てみよう。"
  },
  {
    "start": 9538564,
    "end": 9540830,
    "text": "よし、うまくいっているようだ。"
  },
  {
    "start": 9541280,
    "end": 9544252,
    "text": "モデルは大丈夫だ。"
  },
  {
    "start": 9544306,
    "end": 9548590,
    "text": "すべてのステップでバリデーションが実行されるが、これはまったく望ましくない。"
  },
  {
    "start": 9549040,
    "end": 9553264,
    "text": "少なくとも、貪欲な検索が機能しているかどうかはわかる。"
  },
  {
    "start": 9553302,
    "end": 9555344,
    "text": "少なくとも機能しているように見える。"
  },
  {
    "start": 9555462,
    "end": 9564832,
    "text": "このモデルは何も有益なことを予測していない。実際には、まったく訓練されていないため、コンマの束を予測しているだけなのだ。"
  },
  {
    "start": 9564966,
    "end": 9572790,
    "text": "しばらくしてモデルを訓練すれば、数エポック後にモデルがどんどん良くなっていくのがわかるはずだ。"
  },
  {
    "start": 9573880,
    "end": 9579396,
    "text": "このトレーニングをやめて、このトレーニングをあるべき場所に戻そう。"
  },
  {
    "start": 9579428,
    "end": 9585530,
    "text": "ここでも、そしてここでも、どの時代の終わりでも、このままここに置いておけば問題ない。"
  },
  {
    "start": 9587500,
    "end": 9588250,
    "text": "そうだね。"
  },
  {
    "start": 9588940,
    "end": 9594104,
    "text": "さて、ここからは早送りして、事前に訓練されたモデルについて説明しよう。"
  },
  {
    "start": 9594232,
    "end": 9600168,
    "text": "それを推論し、注意を視覚化できるように、数時間前トレーニングした。"
  },
  {
    "start": 9600264,
    "end": 9612220,
    "text": "事前に計算した学習済み重みをコピーし、trainファイルで定義した関数を再利用して、このノートブックも作成しました。"
  },
  {
    "start": 9612380,
    "end": 9613856,
    "text": "コードはとてもシンプルだ。"
  },
  {
    "start": 9613878,
    "end": 9616700,
    "text": "列車ファイルからコードをコピー＆ペーストしただけだ。"
  },
  {
    "start": 9616780,
    "end": 9624336,
    "text": "モデルをロードして検証を実行するだけです。先ほど書いたのと同じ方法で、事前に訓練したモデルに対して検証を実行しました。"
  },
  {
    "start": 9624368,
    "end": 9625990,
    "text": "例えば、もう一度実行してみよう。"
  },
  {
    "start": 9627400,
    "end": 9634344,
    "text": "ご覧のように、このモデルは10個の例文、文章を推論しており、結果は悪くない。"
  },
  {
    "start": 9634382,
    "end": 9635956,
    "text": "レビンの笑顔が目に浮かぶようだ。"
  },
  {
    "start": 9635988,
    "end": 9636788,
    "text": "レヴィン・ソレサ"
  },
  {
    "start": 9636804,
    "end": 9637508,
    "text": "レヴィン・ソレサ"
  },
  {
    "start": 9637524,
    "end": 9640184,
    "text": "お揃いで、ほとんどがお揃いだ。"
  },
  {
    "start": 9640232,
    "end": 9646428,
    "text": "実際、この特定のデータに対しては、ほぼオーバーフィットしているとも言える。"
  },
  {
    "start": 9646594,
    "end": 9649016,
    "text": "これがトランスのパワーである。"
  },
  {
    "start": 9649048,
    "end": 9651004,
    "text": "何日もトレーニングしなかった。"
  },
  {
    "start": 9651042,
    "end": 9656928,
    "text": "私の記憶が正しければ、数時間トレーニングしただけだが、結果は本当に良かった。"
  },
  {
    "start": 9657094,
    "end": 9667824,
    "text": "では、この学習済みモデルの注目度を視覚化するために使うノートブックを、先ほど作ったファイルを使って作ってみよう。"
  },
  {
    "start": 9667862,
    "end": 9668784,
    "text": "PIを養成する。"
  },
  {
    "start": 9668832,
    "end": 9681672,
    "text": "また、好きな言語を選んで自分のモデルをトレーニングすることもできます。言語を変えてみて、モデルのパフォーマンスを確認し、モデルのパフォーマンスがなぜ悪いのかを診断してみることを強くお勧めします。"
  },
  {
    "start": 9681726,
    "end": 9687720,
    "text": "もしそれが悪いパフォーマンスなら、あるいは良いパフォーマンスなら、どうすればさらに改善できるかを理解しようとする。"
  },
  {
    "start": 9688080,
    "end": 9690264,
    "text": "その注意を視覚化してみよう。"
  },
  {
    "start": 9690312,
    "end": 9692540,
    "text": "新しいノートブックを作りましょう。"
  },
  {
    "start": 9693120,
    "end": 9698700,
    "text": "それを、注意の可視化とでも言おうか。"
  },
  {
    "start": 9703440,
    "end": 9709230,
    "text": "よし、ではまず最初に、必要なライブラリをすべてインポートしよう。"
  },
  {
    "start": 9712800,
    "end": 9741660,
    "text": "Altairというライブラリも使うつもりだ。"
  },
  {
    "start": 9742000,
    "end": 9744872,
    "text": "チャートの視覚化ライブラリだ。"
  },
  {
    "start": 9745016,
    "end": 9747612,
    "text": "実はディープラーニングとは何の関係もない。"
  },
  {
    "start": 9747666,
    "end": 9749724,
    "text": "単なる視覚化機能だ。"
  },
  {
    "start": 9749842,
    "end": 9751932,
    "text": "特に視覚化機能。"
  },
  {
    "start": 9751986,
    "end": 9753180,
    "text": "実はネットで見つけたんだ。"
  },
  {
    "start": 9753250,
    "end": 9761756,
    "text": "チャートを作ったり、ヒストグラムを作ったりしようと思えば、インターネットで簡単に見つけることができる可視化関数のほとんどがそうであるように、これは私が書いたものではない。"
  },
  {
    "start": 9761868,
    "end": 9769510,
    "text": "このライブラリーを使用しているのは、主にインターネットからコードをコピーして視覚化したためで、それ以外はすべて私自身のコードである。"
  },
  {
    "start": 9769960,
    "end": 9771830,
    "text": "輸入しよう"
  },
  {
    "start": 9788560,
    "end": 9789310,
    "text": "それだ。"
  },
  {
    "start": 9791200,
    "end": 9793630,
    "text": "よし、これを全部インポートしよう。"
  },
  {
    "start": 9795440,
    "end": 9801116,
    "text": "もちろん、あなたのコンピューターでコードを実行する際には、この特定のライブラリをインストールする必要がある。"
  },
  {
    "start": 9801298,
    "end": 9802984,
    "text": "ディフィーの定義も説明しよう。"
  },
  {
    "start": 9803032,
    "end": 9828830,
    "text": "デバイスは、ここからコードをコピーして、モデルをロードすればいい。"
  },
  {
    "start": 9829520,
    "end": 9831676,
    "text": "よし、ここに貼り付けよう。"
  },
  {
    "start": 9831778,
    "end": 9840820,
    "text": "こちらは語彙のソースであり、語彙のターゲットとなる。"
  },
  {
    "start": 9859110,
    "end": 9863010,
    "text": "では、バッチをロードする関数を作ってみよう。"
  },
  {
    "start": 9897270,
    "end": 9928246,
    "text": "バッチをトークンに変換する。"
  },
  {
    "start": 9928278,
    "end": 9972070,
    "text": "さて、トークナイザーを使い、もちろんデコーダーにもターゲット語彙を使う。"
  },
  {
    "start": 9973470,
    "end": 9995930,
    "text": "ターゲット・トークナイザーは、グリッド・デコード・アルゴリズムを使用します。"
  },
  {
    "start": 9996670,
    "end": 10026860,
    "text": "私たちのモデルでは、これらの情報をすべて返します。"
  },
  {
    "start": 10035250,
    "end": 10043210,
    "text": "さて、それでは注目度を可視化するために必要な機能を構築していこう。"
  },
  {
    "start": 10043370,
    "end": 10051186,
    "text": "これから作ろうとしているものは、学習という観点からは何の面白みもないものだからだ。"
  },
  {
    "start": 10051368,
    "end": 10056066,
    "text": "ディープラーニングに関しては、データを視覚化する機能がほとんどだ。"
  },
  {
    "start": 10056168,
    "end": 10058914,
    "text": "書くとかなり長くなるのでコピーします。"
  },
  {
    "start": 10059032,
    "end": 10062050,
    "text": "もちろん、重要な部分は私が説明する。"
  },
  {
    "start": 10062200,
    "end": 10063894,
    "text": "これがその機能である。"
  },
  {
    "start": 10064092,
    "end": 10066582,
    "text": "さて、この関数は何をするのだろう？"
  },
  {
    "start": 10066636,
    "end": 10070514,
    "text": "基本的に、エンコーダーから得られる注目はある。"
  },
  {
    "start": 10070562,
    "end": 10072786,
    "text": "エンコーダーの注意を引くには？"
  },
  {
    "start": 10072978,
    "end": 10075810,
    "text": "例えば、3つのポジションに注目する。"
  },
  {
    "start": 10075890,
    "end": 10077174,
    "text": "まずはエンコーダーだ。"
  },
  {
    "start": 10077222,
    "end": 10082342,
    "text": "もうひとつはデコーダーの中にあり、デコーダーの最初にあるため、デコーダーの自己注意である。"
  },
  {
    "start": 10082406,
    "end": 10086166,
    "text": "エンコーダーとデコーダーの間のクロスアテンションだ。"
  },
  {
    "start": 10086278,
    "end": 10088810,
    "text": "私たちは、3種類の注意を視覚化することができる。"
  },
  {
    "start": 10088970,
    "end": 10091562,
    "text": "注目の情報を得るには"
  },
  {
    "start": 10091626,
    "end": 10098258,
    "text": "さて、モデルをロードし、エンコーダーを用意し、どのレイヤーから注目を集めたいかを選択する。"
  },
  {
    "start": 10098344,
    "end": 10103810,
    "text": "そして、各レイヤーから自己のアテンション・ブロックとそのアテンション・スコアを得ることができる。"
  },
  {
    "start": 10104790,
    "end": 10107730,
    "text": "この変数はどこから来るのか？"
  },
  {
    "start": 10107880,
    "end": 10125130,
    "text": "ここでアテンション計算を定義したときを思い出してほしいのだが、アテンションを計算するとき、次のレイヤーに出力を返すだけでなく、このアテンションのスコア、つまりソフトマックスの出力も与える。"
  },
  {
    "start": 10127550,
    "end": 10131158,
    "text": "それをこの変数、self dot attention scoresに保存する。"
  },
  {
    "start": 10131254,
    "end": 10135614,
    "text": "あとはそれを取り出して視覚化するだけだ。"
  },
  {
    "start": 10135732,
    "end": 10146218,
    "text": "この関数は、どのレイヤーから、どのヘッドから、どのアテンションを得たいかに基づいて、正しいマトリックスを選択する。"
  },
  {
    "start": 10146394,
    "end": 10151250,
    "text": "この関数は、情報を視覚化するためのデータフレームを構築する。"
  },
  {
    "start": 10151400,
    "end": 10156578,
    "text": "この行列から抽出されたトークンとスコア。"
  },
  {
    "start": 10156664,
    "end": 10163938,
    "text": "この行列から行と列を抽出し、チャートを作成する。"
  },
  {
    "start": 10164034,
    "end": 10167410,
    "text": "チャートはAltairで作られている。"
  },
  {
    "start": 10167570,
    "end": 10183654,
    "text": "このメソッドは、入力としてこの関数に渡したすべてのヘッドとすべてのレイヤーのアテンションを取得するために作った。"
  },
  {
    "start": 10183782,
    "end": 10186240,
    "text": "このセルを動かしてみよう。"
  },
  {
    "start": 10187330,
    "end": 10191374,
    "text": "では、新しいセルを作って、実行してみましょう。"
  },
  {
    "start": 10191412,
    "end": 10191614,
    "text": "オーケー。"
  },
  {
    "start": 10191652,
    "end": 10195326,
    "text": "まず、扱っている文章を視覚化したい。"
  },
  {
    "start": 10195428,
    "end": 10204530,
    "text": "バッチオーダーの入力トークン。"
  },
  {
    "start": 10208310,
    "end": 10248050,
    "text": "バッチをロードし、ソースとターゲットを可視化する。"
  },
  {
    "start": 10255270,
    "end": 10268050,
    "text": "最後に、長さも計算する。"
  },
  {
    "start": 10268130,
    "end": 10272466,
    "text": "つまり、パディング・キャラクターの前に登場するすべてのキャラクターを指します。"
  },
  {
    "start": 10272498,
    "end": 10279578,
    "text": "なぜなら、これはデータセットから取り出されたバッチであり、すでに訓練用に構築されたテンソルだからである。"
  },
  {
    "start": 10279664,
    "end": 10281318,
    "text": "すでにパディングが含まれている。"
  },
  {
    "start": 10281414,
    "end": 10286922,
    "text": "今回のケースでは、文中の実際の文字数を取得したいだけである。"
  },
  {
    "start": 10286986,
    "end": 10294270,
    "text": "こちらは、文中の実際の単語の数なので、パディングの前に来る単語の数をチェックできる。"
  },
  {
    "start": 10295170,
    "end": 10296720,
    "text": "これを実行しよう。"
  },
  {
    "start": 10297090,
    "end": 10307382,
    "text": "ここに問題がある。"
  },
  {
    "start": 10307436,
    "end": 10308760,
    "text": "忘れてた。"
  },
  {
    "start": 10310650,
    "end": 10314026,
    "text": "この関数は間違っていた。"
  },
  {
    "start": 10314128,
    "end": 10316282,
    "text": "さて、この文章は小さすぎる。"
  },
  {
    "start": 10316336,
    "end": 10317610,
    "text": "もっと長いのを買おう。"
  },
  {
    "start": 10317680,
    "end": 10320300,
    "text": "よし、品質をチェックしよう。"
  },
  {
    "start": 10320670,
    "end": 10322026,
    "text": "今のままではいられない。"
  },
  {
    "start": 10322048,
    "end": 10323020,
    "text": "特に君はね。"
  },
  {
    "start": 10326130,
    "end": 10326494,
    "text": "オーケー。"
  },
  {
    "start": 10326532,
    "end": 10327840,
    "text": "見た目は悪くない。"
  },
  {
    "start": 10328690,
    "end": 10331674,
    "text": "では、レイヤーの注意を印刷しよう。"
  },
  {
    "start": 10331802,
    "end": 10335902,
    "text": "6人いるから、ゼロ、1、2としよう。"
  },
  {
    "start": 10335956,
    "end": 10339250,
    "text": "覚えているだろうか、パラメータnは6に等しい。"
  },
  {
    "start": 10339400,
    "end": 10344670,
    "text": "3つのレイヤーを視覚化し、すべてのヘッドを視覚化する。"
  },
  {
    "start": 10344750,
    "end": 10346878,
    "text": "各レイヤーに8本ずつある。"
  },
  {
    "start": 10346974,
    "end": 10351960,
    "text": "電話番号は0123-4567と7。"
  },
  {
    "start": 10353050,
    "end": 10357590,
    "text": "さて、まずはエンコーダーの自己注意を視覚化してみよう。"
  },
  {
    "start": 10358570,
    "end": 10362362,
    "text": "私たちはどれが欲しいか、すべてのアテンション・マップを手に入れる。"
  },
  {
    "start": 10362416,
    "end": 10367926,
    "text": "エンコーダーのほうは、これらのレイヤーとヘッドが欲しい。"
  },
  {
    "start": 10368038,
    "end": 10372246,
    "text": "行トークンとは、エンコーダーの入力トークンである。"
  },
  {
    "start": 10372438,
    "end": 10375462,
    "text": "コラムに何を求めるか？"
  },
  {
    "start": 10375526,
    "end": 10377290,
    "text": "なぜなら、我々はグリッドを建設しようとしているからだ。"
  },
  {
    "start": 10377370,
    "end": 10383866,
    "text": "ご存知のように、アテンションは行と列を関連付けるグリッドである。"
  },
  {
    "start": 10383978,
    "end": 10387114,
    "text": "私たちの場合、エンコーダーの自己注意について話している。"
  },
  {
    "start": 10387162,
    "end": 10391026,
    "text": "同じ文章を読んでいるのだから。"
  },
  {
    "start": 10391128,
    "end": 10397086,
    "text": "エンコーダーの入力文を行と列の両方に提供する必要がある。"
  },
  {
    "start": 10397198,
    "end": 10400818,
    "text": "可視化したい長さの最大数は？"
  },
  {
    "start": 10400994,
    "end": 10407350,
    "text": "では、仮に20個以下を可視化するとして、最低20個と文の長さ。"
  },
  {
    "start": 10410810,
    "end": 10414394,
    "text": "さて、これが私たちが見ることのできる視覚化だ。"
  },
  {
    "start": 10414432,
    "end": 10425420,
    "text": "私たちが予想したように、実際に注意を視覚化すると、対角線に沿った値が高くなることが予想される。"
  },
  {
    "start": 10425870,
    "end": 10430062,
    "text": "他にも興味深い関係があることがわかる。"
  },
  {
    "start": 10430196,
    "end": 10447390,
    "text": "例えば、文頭トークンと文末トークンは、少なくとも頭部ゼロとレイヤーゼロについては、私が期待するような他の単語との関連はないが、他の頭部については、非常に小さなマッピングを学習する。"
  },
  {
    "start": 10447550,
    "end": 10454162,
    "text": "各グリッドセルにカーソルを合わせると、自己アテンションの実際の値を見ることができる。"
  },
  {
    "start": 10454226,
    "end": 10459414,
    "text": "例えば、自己の注目度のスコアを見ると、ここでは注目度が非常に高いことがわかる。"
  },
  {
    "start": 10459452,
    "end": 10463030,
    "text": "especiallyとespeciallyは関連している。"
  },
  {
    "start": 10463110,
    "end": 10468140,
    "text": "それ自体もそうだが、特に、そして今も同じ言葉なのだ。"
  },
  {
    "start": 10469390,
    "end": 10472534,
    "text": "私たちは、すべてのレイヤーに対するこのような注意を視覚化することができる。"
  },
  {
    "start": 10472582,
    "end": 10487258,
    "text": "というのも、我々は単語の埋め込みを各ヘッドに均等に分配しているため、各ヘッドは単語の埋め込みの異なる部分を見ることになるからである。"
  },
  {
    "start": 10487364,
    "end": 10492130,
    "text": "また、単語と単語の間のさまざまなマッピングを学んでほしい。"
  },
  {
    "start": 10492200,
    "end": 10497362,
    "text": "これは実際にそうであり、あるレイヤーと次のレイヤーの間にある。"
  },
  {
    "start": 10497416,
    "end": 10506070,
    "text": "また、WQWキーとWVメトリックスも異なるので、彼らも異なる関係を学ぶ必要がある。"
  },
  {
    "start": 10506490,
    "end": 10512070,
    "text": "ここで、デコーダーの注意を視覚化することもできるだろう。"
  },
  {
    "start": 10512230,
    "end": 10514140,
    "text": "そうしよう"
  },
  {
    "start": 10520030,
    "end": 10525150,
    "text": "コードをコピーして、パラメーターを変えてみよう。"
  },
  {
    "start": 10531390,
    "end": 10536086,
    "text": "よし、ここでデコーダーが欲しい、同じレイヤーが欲しい、等々。"
  },
  {
    "start": 10536118,
    "end": 10542874,
    "text": "行と列のトークンはデコーダートークンである。"
  },
  {
    "start": 10543002,
    "end": 10547978,
    "text": "デコーダーの入力トークンとデコーダーの入力トークンを視覚化してみよう。"
  },
  {
    "start": 10548074,
    "end": 10553010,
    "text": "また、デコーダーの自己注意を使用しているため、イタリア語が表示されるはずだ。"
  },
  {
    "start": 10553350,
    "end": 10554994,
    "text": "そうだ。"
  },
  {
    "start": 10555112,
    "end": 10559220,
    "text": "ここでは、デコーダー側で異なる種類の注意が見られる。"
  },
  {
    "start": 10559590,
    "end": 10567800,
    "text": "また、ここでは、異なるマッピングを学習すべき複数のヘッドがあり、異なるレイヤーは単語間の異なるマッピングを学習すべきである。"
  },
  {
    "start": 10568810,
    "end": 10571794,
    "text": "私が最も興味深いと思うのは、クロス・アテンションだ。"
  },
  {
    "start": 10571842,
    "end": 10573480,
    "text": "それを見てみよう。"
  },
  {
    "start": 10577150,
    "end": 10581260,
    "text": "よし、コードをコピーしてもう一度実行してみよう。"
  },
  {
    "start": 10586030,
    "end": 10592458,
    "text": "つまり、エンコーダー、デコーダー、同じレイヤーということだ。"
  },
  {
    "start": 10592554,
    "end": 10596922,
    "text": "ここでは、エンコーダー入力を示す。"
  },
  {
    "start": 10596986,
    "end": 10603570,
    "text": "列にはデコーダーの入力トークンを表示する。これはエンコーダーとデコーダーの間のクロスアテンションだからだ。"
  },
  {
    "start": 10605830,
    "end": 10616694,
    "text": "エンコーダーとデコーダーの相互作用は、多かれ少なかれ、こうなっている。"
  },
  {
    "start": 10616892,
    "end": 10629510,
    "text": "ここでは、エンコーダーからのキーと値を用いて計算されたクロスアテンションと、デコーダーからのクエリーを見つける。"
  },
  {
    "start": 10629590,
    "end": 10634234,
    "text": "実はここで翻訳作業が行われる。"
  },
  {
    "start": 10634432,
    "end": 10644350,
    "text": "このようにして、モデルは2つの文の関連付けを学習し、実際に翻訳を計算する。"
  },
  {
    "start": 10644850,
    "end": 10649278,
    "text": "ぜひ自分でコードを実行してみてほしい。"
  },
  {
    "start": 10649444,
    "end": 10654394,
    "text": "最初の提案は、私と一緒にコードを書くことだ。"
  },
  {
    "start": 10654452,
    "end": 10659602,
    "text": "ビデオは一時停止もできるし、自分でコードを書くこともできる。"
  },
  {
    "start": 10659736,
    "end": 10662414,
    "text": "では、実際の例をいくつか挙げてみよう。"
  },
  {
    "start": 10662462,
    "end": 10672502,
    "text": "例えば、私がモデルのコードを書いているとき、ある特定のレイヤーのコードを書いているところを見て、ビデオを止めることをお勧めします。"
  },
  {
    "start": 10672636,
    "end": 10673766,
    "text": "自分で書くんだ。"
  },
  {
    "start": 10673868,
    "end": 10674902,
    "text": "時間をかけて。"
  },
  {
    "start": 10675036,
    "end": 10677462,
    "text": "すぐに解決策を見るな。"
  },
  {
    "start": 10677516,
    "end": 10679702,
    "text": "何が間違っているのかを突き止めよう。"
  },
  {
    "start": 10679836,
    "end": 10684474,
    "text": "もし本当にできないのであれば、2分後に何が問題なのかを理解することはできない。"
  },
  {
    "start": 10684512,
    "end": 10687946,
    "text": "ビデオでちらっと見ることはできるが、自分でやってみてほしい。"
  },
  {
    "start": 10688128,
    "end": 10691018,
    "text": "もちろん、自分ひとりでは思いつかないこともある。"
  },
  {
    "start": 10691104,
    "end": 10697738,
    "text": "例えば、位置エンコーディングやすべての計算は、基本的に数式の応用に過ぎない。"
  },
  {
    "start": 10697914,
    "end": 10702282,
    "text": "重要なのは、少なくとも自分で構成を考えることができるということだ。"
  },
  {
    "start": 10702356,
    "end": 10706066,
    "text": "すべてのレイヤーがどのように相互作用しているか。"
  },
  {
    "start": 10706248,
    "end": 10708094,
    "text": "これが私の最初の推薦だ。"
  },
  {
    "start": 10708222,
    "end": 10710530,
    "text": "トレーニングループについて"
  },
  {
    "start": 10711110,
    "end": 10713714,
    "text": "トレーニングの部分は実際、ごく普通のことだ。"
  },
  {
    "start": 10713832,
    "end": 10718726,
    "text": "他のトレーニングループとよく似ている。"
  },
  {
    "start": 10718828,
    "end": 10725974,
    "text": "興味深いのは、損失の計算方法と変圧器モデルの使い方だ。"
  },
  {
    "start": 10726092,
    "end": 10732550,
    "text": "最後に本当に重要なのは、どのようにモデルを推論するかである。"
  },
  {
    "start": 10732710,
    "end": 10737242,
    "text": "ビデオを見てくれて、そして長い間付き合ってくれてありがとう。"
  },
  {
    "start": 10737376,
    "end": 10749114,
    "text": "その甲斐あって、次回のビデオでは、トランスフォーマーや私がよく知っている他のモデルの例をもっと作りたいと思います。"
  },
  {
    "start": 10749152,
    "end": 10751370,
    "text": "また、君たちと一緒に探検したい。"
  },
  {
    "start": 10751520,
    "end": 10756722,
    "text": "何かわからないことがあったり、もっとうまく説明してほしいことがあれば言ってほしい。"
  },
  {
    "start": 10756856,
    "end": 10761698,
    "text": "コメント欄も必ずフォローしますので、書き込みをお願いします。"
  },
  {
    "start": 10761784,
    "end": 10763554,
    "text": "ありがとう。"
  },
  {
    "start": 10763592,
    "end": 10763710,
    "text": "さようなら。"
  }
]