[
  {
    "start": 330,
    "end": 11040,
    "text": "翻訳システムの構築に真剣に取り組む企業は、おそらく汎用言語モデルを採用し、それを本当に優れた翻訳モデルになるように微調整する方向に進むだろう。"
  },
  {
    "start": 15250,
    "end": 17790,
    "text": "スレーターポッドへようこそ"
  },
  {
    "start": 17860,
    "end": 20330,
    "text": "今日はグラハム・ニュービッグをポッドキャストに迎えることができた。"
  },
  {
    "start": 20410,
    "end": 28470,
    "text": "グラハムはカーネギーメロン大学のコンピューターサイエンス准教授で、言語技術研究所の新しいラボを運営している。"
  },
  {
    "start": 28890,
    "end": 37602,
    "text": "グラハムは、自然言語処理機械学習、特に機械翻訳、多言語LMP、自然言語理解の研究を行っている。"
  },
  {
    "start": 37666,
    "end": 47418,
    "text": "最近、LLMと特殊用途の機械翻訳モデルの比較という超面白い比較をしていましたね。"
  },
  {
    "start": 47504,
    "end": 51366,
    "text": "語学業界では誰もが気になる質問だ。"
  },
  {
    "start": 51478,
    "end": 53730,
    "text": "こんにちは、グラハム。"
  },
  {
    "start": 53830,
    "end": 55694,
    "text": "ああ、呼んでくれてありがとう。"
  },
  {
    "start": 55812,
    "end": 63374,
    "text": "過去に機械翻訳について疑問があったとき、何度もあなたに問い合わせをしたことがあります。"
  },
  {
    "start": 63412,
    "end": 64910,
    "text": "本当にありがとう。"
  },
  {
    "start": 65060,
    "end": 69246,
    "text": "カーネギーメロン大学言語技術研究所。"
  },
  {
    "start": 69438,
    "end": 74194,
    "text": "富士山研究の世界的な拠点のひとつだ。"
  },
  {
    "start": 74312,
    "end": 76182,
    "text": "その裏話は？"
  },
  {
    "start": 76236,
    "end": 78418,
    "text": "なぜこの大学なのか？"
  },
  {
    "start": 78594,
    "end": 84646,
    "text": "だから実は、私が所属する前からのもっと長い裏話があるんだ。"
  },
  {
    "start": 84748,
    "end": 91866,
    "text": "ランゲージ・テクノロジーズ・インスティテュートは、1980年代に機械翻訳のセンターとしてスタートした。"
  },
  {
    "start": 92048,
    "end": 98870,
    "text": "それ以来、機械翻訳の研究は常に強い伝統を持っている。"
  },
  {
    "start": 98950,
    "end": 106074,
    "text": "その後、言語技術のさまざまな分野に手を広げ、ランゲージ・テクノロジーズ・インスティテュートに改名した。"
  },
  {
    "start": 106122,
    "end": 114434,
    "text": "今、機械翻訳に取り組んでいる教員は1人か数人で、もちろん学生もかなりいる。"
  },
  {
    "start": 114552,
    "end": 121090,
    "text": "もちろん、機械翻訳の方でも、この業界へのスピンオフや雇用がいくつかあると思う。"
  },
  {
    "start": 121240,
    "end": 126466,
    "text": "さて、あなたが言語技術機械翻訳の世界に入ったきっかけは何ですか？"
  },
  {
    "start": 126488,
    "end": 129298,
    "text": "日本で多くの時間、あるいはいくつかの時間を過ごされたようですね。"
  },
  {
    "start": 129394,
    "end": 131970,
    "text": "それが機械翻訳に興味を持つきっかけになりましたか？"
  },
  {
    "start": 132130,
    "end": 141882,
    "text": "自然言語処理に興味を持ったのは、学部時代に日本に留学していたことがきっかけです。"
  },
  {
    "start": 142016,
    "end": 148506,
    "text": "その前は音楽加工をやりたかったんだけど、ある言語を勉強し始めて、その魅力に取りつかれたんだ。"
  },
  {
    "start": 148528,
    "end": 154926,
    "text": "もちろん、他の言語を勉強していたのだから、翻訳をするのは当然の方向に思えた。"
  },
  {
    "start": 155028,
    "end": 156746,
    "text": "日本語は堪能ですか？"
  },
  {
    "start": 156938,
    "end": 160106,
    "text": "そう、僕は基本的に日本語が堪能なんだ。"
  },
  {
    "start": 160218,
    "end": 161120,
    "text": "とても興味深い。"
  },
  {
    "start": 162210,
    "end": 164254,
    "text": "音楽処理は、ちょっと寄り道するようなものだ。"
  },
  {
    "start": 164302,
    "end": 167486,
    "text": "技術コンセプトにおける音楽処理はどのようなものですか？"
  },
  {
    "start": 167598,
    "end": 169202,
    "text": "まあ、いろんなことがある。"
  },
  {
    "start": 169256,
    "end": 182342,
    "text": "エレクトロニック・ミュージックが好きだったから、エレクトロニック・ミュージックを生み出す方法とか、既存の楽器を加工していろいろな面白い音にする方法とか、そういうものが好きだったんだ。"
  },
  {
    "start": 182396,
    "end": 188278,
    "text": "技術的な詳細については聞かないでほしい。"
  },
  {
    "start": 188364,
    "end": 194806,
    "text": "というのも、最近、AIが生成した音楽についてあまり耳にしないからだ。"
  },
  {
    "start": 194838,
    "end": 200134,
    "text": "それは確かだが、チャチュブトのような誇大広告はない。"
  },
  {
    "start": 200262,
    "end": 207342,
    "text": "そうですね、AIが生成した小説とかあまり聞かないのは、同じような理由かもしれませんね。"
  },
  {
    "start": 207396,
    "end": 216590,
    "text": "クリエイティブな空間では、クリエイティブなものを作ることができるのは間違いないと思う。"
  },
  {
    "start": 216660,
    "end": 219506,
    "text": "人々はまだそれを好んでいるかもしれないが、私にはわからない。"
  },
  {
    "start": 219528,
    "end": 220386,
    "text": "いい質問だ。"
  },
  {
    "start": 220488,
    "end": 222594,
    "text": "つまり、ビデオは相変わらず残酷だ。"
  },
  {
    "start": 222632,
    "end": 228674,
    "text": "AIプラットフォームを使って、テキストをビデオに変換するようなことをしているんだけど、今のところ意味がないんだ。"
  },
  {
    "start": 228712,
    "end": 234950,
    "text": "つまり、私がツイッターで目にするものはすべて、有益なものを得るために2、3日催促したようなものでしょう。"
  },
  {
    "start": 236010,
    "end": 239314,
    "text": "とにかく、マシーン、あるいはNLPの話に戻ろう。"
  },
  {
    "start": 239362,
    "end": 245226,
    "text": "ニュー・ラボの皆さんがこの1、2年の間に探求してきた主なテーマは何ですか？"
  },
  {
    "start": 245328,
    "end": 248854,
    "text": "発表された論文の中で、特に興味深いものは何だと思いますか？"
  },
  {
    "start": 248982,
    "end": 252480,
    "text": "そう、だからいろいろなことに取り組んでいるんだ。"
  },
  {
    "start": 252930,
    "end": 255294,
    "text": "もちろん、機械翻訳にも取り組んでいる。"
  },
  {
    "start": 255412,
    "end": 266478,
    "text": "私たちはまた、自然言語処理に広範な知識ベースを組み込むモデルにも取り組んでおり、通常はさまざまなソースから知識を検索する。"
  },
  {
    "start": 266654,
    "end": 270318,
    "text": "コード生成にも力を入れている。"
  },
  {
    "start": 270494,
    "end": 274862,
    "text": "これらは、実際の方法論の観点からのものだ。"
  },
  {
    "start": 274926,
    "end": 279774,
    "text": "また、ここ2～3年は評価方法にも力を入れてきた。"
  },
  {
    "start": 279822,
    "end": 288214,
    "text": "なぜかというと、私は根っからのシステム・ビルダーだが、以前はシステムの問題点がはっきりしていたような気がするからだ。"
  },
  {
    "start": 288332,
    "end": 294726,
    "text": "今、私たちのシステムの何が問題なのか、どこで失敗しているのか、どこで失敗が予想されるのか、だんだんわからなくなってきている。"
  },
  {
    "start": 294918,
    "end": 304970,
    "text": "そのため、評価は自分で初期システムを構築するのと同じくらい難しくなっているような気がして、最近研究しているんだ。"
  },
  {
    "start": 305130,
    "end": 309242,
    "text": "さて、Chat GPTの立ち上げはどれほどのものだったのだろうか？"
  },
  {
    "start": 309386,
    "end": 313994,
    "text": "たしか10月か11月だったと思うけど、今は他のLLMもいる。"
  },
  {
    "start": 314042,
    "end": 320050,
    "text": "僕はヨーロッパにいるから、リスクを回避するのに数週間かかったよ。"
  },
  {
    "start": 320550,
    "end": 325394,
    "text": "それはNLPの世界にとって、どれほど大きな出来事だったのでしょうか？"
  },
  {
    "start": 325512,
    "end": 338858,
    "text": "それとも、あなたのような専門家であれば、このような事態が起こることを予見していたのでしょうか？"
  },
  {
    "start": 339024,
    "end": 345722,
    "text": "私たちが取り組むべきことに関して、間違いなく清算があったと思う。"
  },
  {
    "start": 345776,
    "end": 357758,
    "text": "実際、今年の3月か4月だったと思うが、カーネギーメロン大学で大規模言語モデルに関するサミットが開かれた。"
  },
  {
    "start": 357924,
    "end": 363600,
    "text": "その理由のひとつは、私たちが取り組むべきことは何だろう？"
  },
  {
    "start": 364290,
    "end": 372740,
    "text": "自分の研究室で、今取り組むべき重要なことと、今取り組むべきでないことは何かについて世論調査を行った。"
  },
  {
    "start": 373350,
    "end": 376818,
    "text": "私はポジティブでありたいし、悲観的になりたくない。"
  },
  {
    "start": 376914,
    "end": 379990,
    "text": "やるべきことはまだたくさんある。"
  },
  {
    "start": 380060,
    "end": 389820,
    "text": "NLPの専門家の多くは、大規模な言語モデルがどんどん良くなっていくのを見ていたと思う。"
  },
  {
    "start": 390750,
    "end": 396362,
    "text": "チャットGPTが起こった後、あれほど大きな反響が起こるとは誰も予想していなかったと思う。"
  },
  {
    "start": 396416,
    "end": 402038,
    "text": "今、私はいつもあちこちの人と話している。"
  },
  {
    "start": 402134,
    "end": 407230,
    "text": "アイクリアでルワンダに行ったとき、タクシーの運転手がチャットGPTを使っていた。"
  },
  {
    "start": 408930,
    "end": 411258,
    "text": "それは予想外のことだった。"
  },
  {
    "start": 411354,
    "end": 423902,
    "text": "1年前にも行ったと思うけど、GPT2020について報告した。"
  },
  {
    "start": 423956,
    "end": 430120,
    "text": "その背後にあるものを人々に理解してもらうためには、あのインターフェイスが本当に必要だったらしい。"
  },
  {
    "start": 431770,
    "end": 432754,
    "text": "役に立つ。"
  },
  {
    "start": 432802,
    "end": 434690,
    "text": "毎日使っているよ。"
  },
  {
    "start": 434770,
    "end": 440438,
    "text": "1時間ごとではなく、特定の仕事については毎日だろう。"
  },
  {
    "start": 440614,
    "end": 444490,
    "text": "さて、あなたは知識システムとコンテクストについて言及した。"
  },
  {
    "start": 445470,
    "end": 446522,
    "text": "ナレッジシステムについて言及したね。"
  },
  {
    "start": 446576,
    "end": 450566,
    "text": "文脈、機械翻訳と文脈に話を移したい。"
  },
  {
    "start": 450678,
    "end": 460650,
    "text": "人間の翻訳では、人生で学んだことのほとんどすべてを、可能な限り幅広い文脈として翻訳作業に持ち込むのでしょう。"
  },
  {
    "start": 460730,
    "end": 466802,
    "text": "機械翻訳はどのようにこれを処理し、LLMはどのようにこれを変えるのだろうか？"
  },
  {
    "start": 466856,
    "end": 468206,
    "text": "ちょっとした余談だ。"
  },
  {
    "start": 468398,
    "end": 478230,
    "text": "Data River Multilingual ExplorationでWindows Translation Require Contextという論文を共同執筆し、ACL2023で最優秀論文賞を受賞しましたね。"
  },
  {
    "start": 478380,
    "end": 482034,
    "text": "あなたはその特別な話題について、ひとつやふたつは知っているはずだ。"
  },
  {
    "start": 482082,
    "end": 486130,
    "text": "そう、文脈、LLM、そして機械翻訳だ。"
  },
  {
    "start": 486290,
    "end": 491306,
    "text": "あなたは、私たちが人生で学んできたことすべての、より広い文脈について話してくれた。"
  },
  {
    "start": 491408,
    "end": 496490,
    "text": "その論文は、文書から見た過去の文脈に焦点を当てたものだった。"
  },
  {
    "start": 498110,
    "end": 508458,
    "text": "文脈を扱うことの興味深い難しさのひとつは、実は、ほとんどの個々の単語を翻訳するのに、現在の文以上の文脈は必要ないということだと思います。"
  },
  {
    "start": 508554,
    "end": 511886,
    "text": "多くの単語では、現在の単語以外の文脈は必要ない。"
  },
  {
    "start": 511988,
    "end": 519330,
    "text": "それは、一般名詞の名前に1つしか妥当な訳語がないような、曖昧さのない訳語だ。"
  },
  {
    "start": 520950,
    "end": 534914,
    "text": "というのも、長期的な文脈を利用することで、出力される単語の1%にしか利益をもたらさないような、より優れたモデルを思いついたとします。"
  },
  {
    "start": 534962,
    "end": 544086,
    "text": "自動測定基準や人間による測定基準を使用している場合、コンテキストを使用するのにはるかに優れたモデルとの違いにほとんど気づかないかもしれない。"
  },
  {
    "start": 544278,
    "end": 551070,
    "text": "その論文で私たちが試みたのは、文脈が必要な場所を分類することだった。"
  },
  {
    "start": 551490,
    "end": 564340,
    "text": "というのも、文書の残りの部分の見当を見れば、それに頼ることができるからだ。"
  },
  {
    "start": 565270,
    "end": 568366,
    "text": "他には代名詞がある。"
  },
  {
    "start": 568478,
    "end": 572686,
    "text": "代名詞の使い方は言語によって異なる。"
  },
  {
    "start": 572798,
    "end": 582390,
    "text": "例えば、英語ではyouとかitとかを使うかもしれない。"
  },
  {
    "start": 583130,
    "end": 591270,
    "text": "もうひとつはエリプシス（省略）で、英語では何かを落としてしまうが、文法的に正しいかどうかを確認するためにもう一方の言語で直す必要がある、あるいはその逆である。"
  },
  {
    "start": 591350,
    "end": 607306,
    "text": "論文にはこのようなカテゴリーがもっとあるが、基本的に我々がやったことは、これらのカテゴリーを自動的に発見し、研究者として、コンテキストが実際に役に立つ場所についてより良いアイデアを与えてくれる場所を発見しようとしたことだ。"
  },
  {
    "start": 607338,
    "end": 609982,
    "text": "そこには驚くべき発見もあった。"
  },
  {
    "start": 610116,
    "end": 621614,
    "text": "というのは、現在でも特別な目的のために使用されるモデルは、ほとんどその文書に限定されているのか、それとも拡大することができるのか？"
  },
  {
    "start": 621662,
    "end": 629300,
    "text": "年前、3年前、4年前、文書レベルの機械翻訳が大流行したのを覚えています。"
  },
  {
    "start": 630090,
    "end": 631346,
    "text": "ほとんどが書類ですか？"
  },
  {
    "start": 631378,
    "end": 635778,
    "text": "LLMは、もっともっと大きな文脈を取り込むことができるので、この状況を変えることができるのでしょうか？"
  },
  {
    "start": 635874,
    "end": 639446,
    "text": "これは実に興味深い質問で、2、3回に分けて答えることができる。"
  },
  {
    "start": 639638,
    "end": 649050,
    "text": "Google翻訳のオンライン・インターフェースとAPIは、少なくとも私たちが使ったときには、実は文の先の文脈すら使っていなかった。"
  },
  {
    "start": 649470,
    "end": 659838,
    "text": "これにはとても驚きましたが、文書全体として文章を翻訳し、個々の文章として再度送信することで検証してみたのですが、結果はまったく変わりませんでした。"
  },
  {
    "start": 660004,
    "end": 668980,
    "text": "文脈が重要であることは誰もが知っているはずなのに、なぜそれを使わないのだろう？"
  },
  {
    "start": 669430,
    "end": 675058,
    "text": "グーグルを使うたびに、あらゆる方法でこのようなことが起こるとは保証できないが、少なくとも我々が発見したのはこのようなことだ。"
  },
  {
    "start": 675224,
    "end": 680406,
    "text": "対照的に、ディペルのような選手はコンテクストをうまく使っていた。"
  },
  {
    "start": 680588,
    "end": 687622,
    "text": "実際、グーグルの利用が大きく伸びなかったときに、それが大きな後押しになったと思う。"
  },
  {
    "start": 687676,
    "end": 695290,
    "text": "コンテクストを使う場合、さらに追加できるエンジンもあると思う。"
  },
  {
    "start": 695360,
    "end": 698940,
    "text": "例えば、私たちが期待するアウトプットの形式はどのようなものだろうか？"
  },
  {
    "start": 701230,
    "end": 707646,
    "text": "頭から知らない選手も多いから、また戻って探してみるよ。"
  },
  {
    "start": 707748,
    "end": 716722,
    "text": "大規模な言語モデルについてエキサイティングなことのひとつは、もしそれがあなたにとって重要なことであれば、実際にあなたが望むことをそのまま伝えることができるということだと思う。"
  },
  {
    "start": 716856,
    "end": 721650,
    "text": "これを正式に訳してください、これを非公式に訳してください、と言ってもいい。"
  },
  {
    "start": 722230,
    "end": 730502,
    "text": "この用語をこの用語に訳してください。そうすれば、翻訳してくれるはずです。"
  },
  {
    "start": 730556,
    "end": 733206,
    "text": "そうなるかどうかは誰にもわからない。"
  },
  {
    "start": 733308,
    "end": 734758,
    "text": "それは別の問題だ。"
  },
  {
    "start": 734844,
    "end": 743370,
    "text": "理論的には、テキストだけでどんな翻訳が必要かを指示すれば、それに従ってくれるはずだ。"
  },
  {
    "start": 743520,
    "end": 750794,
    "text": "個人的には、たぶんちょっとばかげた実験をしたんだけど、11歳の子供のように、これを訳してくれ、とか言い続けたんだ。"
  },
  {
    "start": 750832,
    "end": 751658,
    "text": "大丈夫だった。"
  },
  {
    "start": 751744,
    "end": 755054,
    "text": "それは5歳児に単純化したようなものだ。"
  },
  {
    "start": 755092,
    "end": 756640,
    "text": "本当にシンプルになった。"
  },
  {
    "start": 757090,
    "end": 758638,
    "text": "だから、そうだね。"
  },
  {
    "start": 758804,
    "end": 761870,
    "text": "基本的に、プロンプトはコンテクストを設定するものだ。"
  },
  {
    "start": 763170,
    "end": 770418,
    "text": "あなたは最近、私が冒頭で言ったような、ゼノGptmtレポートと呼ばれる非常に興味深いレポートを発表した。"
  },
  {
    "start": 770504,
    "end": 772190,
    "text": "GitHubで公開されていると思う。"
  },
  {
    "start": 772350,
    "end": 783026,
    "text": "GPTモデルを使って翻訳タスクを処理できるのか、それとも特別な翻訳モデルを使うべきなのか。"
  },
  {
    "start": 783058,
    "end": 790550,
    "text": "さて、繰り返しになるが、これは250億を超える言語サービス業界における10億ドルの問題である。"
  },
  {
    "start": 790710,
    "end": 795674,
    "text": "その結果、どのようなことが明らかになりましたか？"
  },
  {
    "start": 795792,
    "end": 807658,
    "text": "そう、だから僕らがパフォーマンスを評価する方法は、実はXenoというツールを作っているんだ。"
  },
  {
    "start": 807674,
    "end": 821330,
    "text": "これはオープンソースのツールで、非常に簡単に結果を視覚化して探索し、さまざまな軸に沿ってサブセグメント化し、モデルの精度の興味深い傾向を明らかにすることができる。"
  },
  {
    "start": 821670,
    "end": 841254,
    "text": "しかし、基本的には、最先端の機械翻訳評価指標のようなものを用いて、どのような種類のデータにおいて、あるモデルがより優れており、どのような種類のデータにおいて、あるモデルがより劣っているかを見つけ出そうとしている。"
  },
  {
    "start": 841382,
    "end": 842998,
    "text": "全体的なパフォーマンスは？"
  },
  {
    "start": 843094,
    "end": 845260,
    "text": "そこにはもっとニュアンスの違うストーリーがあるのだろうか？"
  },
  {
    "start": 846590,
    "end": 862110,
    "text": "そこで、さまざまなGPTモデルからの出力と、Microsoft TranslateとGoogle Translateという特殊な翻訳モデルからの出力を調べてアップロードした。"
  },
  {
    "start": 863570,
    "end": 872370,
    "text": "Deeplからの出力もいくつか持っているが、Deeplは分析に使ったすべての言語をサポートしているわけではないので、あまり注意深く見ていない。"
  },
  {
    "start": 874230,
    "end": 883234,
    "text": "その後、データをさまざまな軸で細分化したところ、いくつかの発見があった。"
  },
  {
    "start": 883282,
    "end": 890730,
    "text": "つまり、1つ1つ見ていくこともできるが、基本的には要点を英訳することだ。"
  },
  {
    "start": 891390,
    "end": 896694,
    "text": "GPT4は特別目的モデルとの競争力が非常に高かった。"
  },
  {
    "start": 896742,
    "end": 904626,
    "text": "英語から他の言語への翻訳を測定した指標によれば、多くの場合、その方が優れていた。"
  },
  {
    "start": 904758,
    "end": 914180,
    "text": "GPT4は、多くの場合もう少し悪かったが、フランス語やドイツ語のような非常にリソースの多い言語では、かなり競争力があった。"
  },
  {
    "start": 915030,
    "end": 941370,
    "text": "また、GPTモデルは文脈を必要とする多くのこと、たとえば前に話した代名詞の解決などは比較的得意なようですが、たとえば非常に長い文章を扱うことは比較的苦手なようです。"
  },
  {
    "start": 942990,
    "end": 949462,
    "text": "それをもう少し注意深く見てみると、彼らは特別な目的のために、あちこちにちょっとしたコンテンツを投下するようなことをしていた。"
  },
  {
    "start": 949526,
    "end": 956250,
    "text": "富士山のモデルは、少なくともそれなりに忠実で、そして直訳でないようだった。"
  },
  {
    "start": 956330,
    "end": 958350,
    "text": "GPTのモデルの方が良かった。"
  },
  {
    "start": 958420,
    "end": 963978,
    "text": "具体的にGPTモデルで言うと、GPT4は他のGPTモデルよりもはるかに優れている。"
  },
  {
    "start": 964074,
    "end": 965134,
    "text": "それを聞こうと思ったんだ。"
  },
  {
    "start": 965172,
    "end": 965566,
    "text": "そうだね。"
  },
  {
    "start": 965668,
    "end": 969170,
    "text": "ここでもっと詳細を掘り下げることもできる。"
  },
  {
    "start": 969240,
    "end": 973314,
    "text": "かなり長いレポートなので、時間があるものはたくさんある。"
  },
  {
    "start": 973352,
    "end": 974210,
    "text": "これは超面白い。"
  },
  {
    "start": 974280,
    "end": 981958,
    "text": "つまり、長い文章だと、業界のあちこちで少しずつ下がり始めると、みんな、いや、何も下がらないよ、と言うんだ。"
  },
  {
    "start": 982124,
    "end": 983106,
    "text": "これは非常に重要だ。"
  },
  {
    "start": 983218,
    "end": 983494,
    "text": "そうだね。"
  },
  {
    "start": 983532,
    "end": 988310,
    "text": "難しいのは、とても自然な形で落とすので、捕まらないことだと思う。"
  },
  {
    "start": 988380,
    "end": 988710,
    "text": "そうだね。"
  },
  {
    "start": 988780,
    "end": 994602,
    "text": "ポスト編集でも、これが入っていなかったという事実を見逃す危険性がある。"
  },
  {
    "start": 994656,
    "end": 997558,
    "text": "それは慎重に考えるべきことだと思う。"
  },
  {
    "start": 997654,
    "end": 1003710,
    "text": "投稿編集者を助けるツールが必要なのかもしれない。"
  },
  {
    "start": 1003780,
    "end": 1013150,
    "text": "正直なところ、翻訳業界の人々がどのように対処しているのか、その現状を私は知らないが、それは間違いなく危険だと思う。"
  },
  {
    "start": 1014470,
    "end": 1024754,
    "text": "その他に気づいたことは、GPTモデルは少しロバストでない傾向があり、たまに奇妙なことをする傾向があるということだ。"
  },
  {
    "start": 1024792,
    "end": 1027080,
    "text": "あまり頻繁ではないが、たまにある。"
  },
  {
    "start": 1027610,
    "end": 1051150,
    "text": "いくつか例を挙げると、これはとても面白い例で、英語から日本語への翻訳で、1,000回に1回とか、こんな感じで、日本語だけでなく、日本語の後に音訳された日本語も出力される。"
  },
  {
    "start": 1051970,
    "end": 1064778,
    "text": "なぜこのようなことをしたかというと、GPTはインターネット上に現れたすべてのデータを、自然な翻訳ペアのようなものに頼っているからだ。"
  },
  {
    "start": 1064874,
    "end": 1072450,
    "text": "もちろん、自然な翻訳ペアの中には、英語を話す人たちが日本語を学ぼうとしている言語学習の教科書に載っているものもある。"
  },
  {
    "start": 1072790,
    "end": 1078562,
    "text": "そこでは、英語、日本語、そしてローマ字や翻訳された日本語があるのが一般的だ。"
  },
  {
    "start": 1078626,
    "end": 1081686,
    "text": "だから、データセットの中で何度か見たんだ。"
  },
  {
    "start": 1081788,
    "end": 1083602,
    "text": "中国人の意見に似ている。"
  },
  {
    "start": 1083666,
    "end": 1083990,
    "text": "そうだね。"
  },
  {
    "start": 1084060,
    "end": 1090342,
    "text": "この意味するところは、ポスト編集であれば、おそらく大きな問題にはならないということだ。"
  },
  {
    "start": 1090396,
    "end": 1094874,
    "text": "翻訳者が、おかしなところを切り落としたり、中に入って修正したりするんだ。"
  },
  {
    "start": 1094912,
    "end": 1105414,
    "text": "もし、編集後のチェックを行わずに実際にデプロイするのであれば、そのような潜在的に非常に悪いアウトプットをどのようにキャッチするか、少し真剣に考えるべきだ。"
  },
  {
    "start": 1105462,
    "end": 1108830,
    "text": "それもまた、あなたが考えるべきことだと思う。"
  },
  {
    "start": 1108900,
    "end": 1111246,
    "text": "この上にレイヤーを置こうと考えている人はいる？"
  },
  {
    "start": 1111268,
    "end": 1130134,
    "text": "つまり、特に英語でのセットで、成績が上回っているにもかかわらず、時折、本当に奇妙なことが忍び寄るのであれば、その上にレイヤーを置く必要があるかもしれない。"
  },
  {
    "start": 1130252,
    "end": 1144182,
    "text": "私たちが開発中で、今回の分析に使用した評価指標のいくつかは、品質評価指標である。"
  },
  {
    "start": 1144326,
    "end": 1152998,
    "text": "品質評価メトリクスは、基本的に品質、つまりアウトプットがどの程度優れているかを推定するもので、この特定のケースでは、彼らはそのアウトプットを非常に悪いと判断すると思う。"
  },
  {
    "start": 1153094,
    "end": 1156382,
    "text": "今、あなたが計測していたのはコストで、これにはちょっと驚かされたよ。"
  },
  {
    "start": 1156436,
    "end": 1170034,
    "text": "というのも、基本的に、私が今日チェックした最新のレポートによると、GPT-3ターボはグーグル翻訳よりも12倍安く、ディープLよりも25倍安いと言っていたからです。"
  },
  {
    "start": 1170232,
    "end": 1171586,
    "text": "こんなことが可能なのか？"
  },
  {
    "start": 1171768,
    "end": 1178466,
    "text": "注意点があり、GPT4はグーグル翻訳やマイクロソフトの翻訳機よりはるかに高価だということだ。"
  },
  {
    "start": 1178498,
    "end": 1182520,
    "text": "そこでは、両方の言い分を伝えたい。"
  },
  {
    "start": 1183290,
    "end": 1200502,
    "text": "チャットGPT、GPT 3.5ターボがチャットGPTの背後にあるモデルだと思う理由はいくつかあると思いますが、ご存知のようにチャットGPTは基本的にOpenAIチャットのように世界を席巻しています。"
  },
  {
    "start": 1200566,
    "end": 1208554,
    "text": "Openai.comは現在、世界でトップ20に入るウェブサイトで、たくさんのチャットを提供している。"
  },
  {
    "start": 1208682,
    "end": 1219938,
    "text": "基本的に規模の経済というものがあって、多くのスループットを供給しているから、いろいろなことをする余裕があるのだと思う。"
  },
  {
    "start": 1220104,
    "end": 1231398,
    "text": "少し専門的な話になるが、例えば、同時にたくさんの入力があった場合、それらを同時に処理することができる。"
  },
  {
    "start": 1231484,
    "end": 1237190,
    "text": "より速くするためのインフラを持っている可能性はある。"
  },
  {
    "start": 1239610,
    "end": 1253610,
    "text": "もうひとつは、みんなが使っているモデルのサイズやモデルの複雑さを私は知らないが、チャットGPTはおそらく、安くできるように小さくて効率的なモデルを使ってサービスを提供しているのだと思う。"
  },
  {
    "start": 1254110,
    "end": 1264830,
    "text": "一方、GPT Fourは巨大なモデルで、グーグル翻訳やマイクロソフト翻訳で使われているモデルよりも確実に大きい。"
  },
  {
    "start": 1264990,
    "end": 1268846,
    "text": "というのも、一方では、その方が高くつくからだ。"
  },
  {
    "start": 1268958,
    "end": 1275714,
    "text": "これらのモデルにプロンプトを与え、何をすべきかを指示するさまざまな方法がある。"
  },
  {
    "start": 1275832,
    "end": 1281714,
    "text": "一つの方法は、英語から日本語に訳してくださいと言うだけで、何の例も示さないことだ。"
  },
  {
    "start": 1281762,
    "end": 1284790,
    "text": "その場合、それはゼロ・ショット・トランスレーションと呼ばれる。"
  },
  {
    "start": 1285610,
    "end": 1299702,
    "text": "ゼロショット翻訳なら、チャットGPTの方が安く、GPT3.5ターボなら、チャットGPTの後ろのモデルの方が安く、GPT4はGoogle翻訳の4倍と高い。"
  },
  {
    "start": 1299846,
    "end": 1302646,
    "text": "もうひとつの方法は、例を挙げることだ。"
  },
  {
    "start": 1302678,
    "end": 1309402,
    "text": "日本語の一文と英語の一文を提供するようなもので、一発翻訳と呼ばれるものです。"
  },
  {
    "start": 1309466,
    "end": 1315818,
    "text": "あるいは、5つの文のペアを提供することもできる。"
  },
  {
    "start": 1315994,
    "end": 1324370,
    "text": "もし、5ショット翻訳まで始めると、Chat GPTはGoogle翻訳とほぼ同じ値段になり、GPT 4は20倍高くなる。"
  },
  {
    "start": 1329210,
    "end": 1336498,
    "text": "また、GPT4が特別目的翻訳モデルに対して非常に競争力があることを指摘することも重要だと思う。"
  },
  {
    "start": 1336514,
    "end": 1340326,
    "text": "チャットGPT3.5ターボは、それほど競争力がないことがわかった。"
  },
  {
    "start": 1340438,
    "end": 1348422,
    "text": "全体的な傾向としては、GPTモデルの方がスペシャル・パーパス・モデルよりもまだ高価だということだろう。"
  },
  {
    "start": 1348566,
    "end": 1354014,
    "text": "GPT3.5ターボがチャットGPTに搭載されているというのは、無料版に搭載されているものですよね？"
  },
  {
    "start": 1354052,
    "end": 1357918,
    "text": "なぜなら、私は購読者だし、4つを手に入れたと思うからだ。"
  },
  {
    "start": 1358084,
    "end": 1364254,
    "text": "ええ、ごめんなさい。3.5ターボは無料版で、加入すると4ターボになります。"
  },
  {
    "start": 1364372,
    "end": 1364942,
    "text": "その通りだ。"
  },
  {
    "start": 1364996,
    "end": 1366514,
    "text": "わかったよ。"
  },
  {
    "start": 1366712,
    "end": 1367410,
    "text": "とても興味深い。"
  },
  {
    "start": 1367480,
    "end": 1378094,
    "text": "そして、もちろん、すべての統合やそのようなもの、何百万語もの単語を打ち込み始めると、クラッシュしてしまうかもしれないし、他にもいろいろな困難がある。"
  },
  {
    "start": 1378142,
    "end": 1384390,
    "text": "ああ、興味深いのは、異なるパラメーターを総合的に判断すれば、同じような範囲にあるということだ。"
  },
  {
    "start": 1387450,
    "end": 1402346,
    "text": "さて、ちょっと水晶玉のような質問ですが、このような汎用LLMが進化を続ける中で、おそらく今後2年以内に、スペシャル・パーパス・モデルやモデルに勝てるようになると思いますか？"
  },
  {
    "start": 1402378,
    "end": 1417250,
    "text": "それとも、特別な目的のモデルをより良くする方法は常にあるのだろうか、それとも、手を加えれば、鍛えれば、もっと良くなるのだろうか、それとも、ある時点で、他のモデルがあまりにも巨大で強力になっただけなのだろうか。"
  },
  {
    "start": 1417830,
    "end": 1425346,
    "text": "もうひとつは、スペシャル・パーパス・モデルが今後どのように進化していくかということだと思う。"
  },
  {
    "start": 1425448,
    "end": 1431826,
    "text": "翻訳ペアを主にトレーニングするという伝統的な手法を使い続けるのだろうか？"
  },
  {
    "start": 1432018,
    "end": 1439610,
    "text": "それとも、まず言語モデルをトレーニングし、それを微調整して翻訳を行うようなパラダイムに移行するのでしょうか？"
  },
  {
    "start": 1440430,
    "end": 1444010,
    "text": "私は後者になると予想している。"
  },
  {
    "start": 1445070,
    "end": 1459118,
    "text": "翻訳システムの構築に真剣に取り組んでいる企業は、おそらく汎用的な言語モデルを採用し、それを本当に優れた翻訳モデルになるように微調整する方向に進むでしょう。"
  },
  {
    "start": 1459204,
    "end": 1469890,
    "text": "そうすれば、言語モデルの勝利とも言えるが、まだ特別目的モデルがある。"
  },
  {
    "start": 1471430,
    "end": 1473550,
    "text": "コントロールしやすいという大きなメリットもある。"
  },
  {
    "start": 1473630,
    "end": 1477830,
    "text": "例えば、一番最初に話したように、これを正式に訳してください、というようなことだ。"
  },
  {
    "start": 1478490,
    "end": 1487766,
    "text": "以前は、個々のモデルを1つの公式モデルと1つの非公式モデル、あるいは少なくともそのような特別なものに訓練しなければならなかった。"
  },
  {
    "start": 1487788,
    "end": 1490666,
    "text": "大規模な言語モデルがあれば、それは無料で手に入る。"
  },
  {
    "start": 1490768,
    "end": 1496860,
    "text": "何か特別なことをするよりも、その方がいい。"
  },
  {
    "start": 1497230,
    "end": 1509738,
    "text": "つまり、LLMの普及は明らかで、あなたがおっしゃったように、私たちは特殊目的の上に一般目的のようなものを積み重ねていくのかもしれません。"
  },
  {
    "start": 1509834,
    "end": 1514702,
    "text": "現在、音声から音声への機械翻訳の分野でも、さまざまなことが起こっている。"
  },
  {
    "start": 1514756,
    "end": 1518350,
    "text": "この4週間でメタのボイスボックスを見た。"
  },
  {
    "start": 1518430,
    "end": 1526820,
    "text": "Googleのこのオーディオパーム、BytanceのPolyvoice、そして同じくGoogleのMood to Slamのような発音すらできないものを読むことができた。"
  },
  {
    "start": 1527510,
    "end": 1529140,
    "text": "何がそうさせるのか？"
  },
  {
    "start": 1529510,
    "end": 1537586,
    "text": "今後もこのようなペースでのリリースが続くのでしょうか？それとも、誰もが今まさにゲートから出てきていて、少しペースダウンするのでしょうか？"
  },
  {
    "start": 1537708,
    "end": 1538826,
    "text": "そこで何が起こっているのか？"
  },
  {
    "start": 1538928,
    "end": 1548620,
    "text": "ここ2、3年、音声翻訳に非常に力を入れていると思う。"
  },
  {
    "start": 1550290,
    "end": 1563086,
    "text": "最近のリリースラッシュは、その継続であると同時に、すべてのスピーチでもあるような気がする。"
  },
  {
    "start": 1563118,
    "end": 1583026,
    "text": "Chat GPTやすべての言語モデルで起こったことを見て、私たちもこの一部になりたい、あるいはもっとポジティブに考えて、この可能性を解き放ちたいと言う人たちがいる。"
  },
  {
    "start": 1583218,
    "end": 1605326,
    "text": "例えば、オーディオポエムの背後にあるアイデアが好きだ。彼らは基本的に言語モデルを取り入れていて、純粋に言語訓練された言語モデルを、かなり賢い方法で音声認識もできるように応用している。"
  },
  {
    "start": 1605428,
    "end": 1611630,
    "text": "テキストデータの方が音声翻訳データよりも多いのですから。"
  },
  {
    "start": 1611700,
    "end": 1615406,
    "text": "音声対音声の翻訳データを作るのはとても難しい。"
  },
  {
    "start": 1615588,
    "end": 1620818,
    "text": "利用可能なすべての資源を活用する賢い方法は、間違いなく大歓迎だ。"
  },
  {
    "start": 1620904,
    "end": 1624206,
    "text": "オープンソースだからといって、彼らが何を達成しようとしていると思う？"
  },
  {
    "start": 1624318,
    "end": 1625302,
    "text": "大半はそうだろう？"
  },
  {
    "start": 1625356,
    "end": 1628360,
    "text": "そうでない部分もあるかもしれないが、ほとんどはそうだ。"
  },
  {
    "start": 1632970,
    "end": 1639346,
    "text": "彼らは潜在的なユーザー層のある部分を取り込もうとしている。"
  },
  {
    "start": 1639378,
    "end": 1639622,
    "text": "問題だ。"
  },
  {
    "start": 1639676,
    "end": 1645478,
    "text": "その上に企業の利害関係があるのか、それともなぜオープンソースなのか。"
  },
  {
    "start": 1645654,
    "end": 1647210,
    "text": "ああ、これはいい質問だね。"
  },
  {
    "start": 1647280,
    "end": 1657680,
    "text": "つまり、1年前なら、おそらくこのような質問はしなかっただろう。業界の研究者たちは、オープンソースにもっとオープンだったからだ。"
  },
  {
    "start": 1658850,
    "end": 1671986,
    "text": "当時、オープンソースが正当化されたのは、基本的に研究者が自分の研究を一般に公開することを望んだからだと思う。"
  },
  {
    "start": 1672088,
    "end": 1679570,
    "text": "そして、オープンソースにすることで、より一般大衆にインパクトを与えることができる。"
  },
  {
    "start": 1679730,
    "end": 1692010,
    "text": "そのため、研究者を満足させ、会社に留まらせるために、企業はオープンソースに関しても比較的寛容だった。"
  },
  {
    "start": 1692160,
    "end": 1715698,
    "text": "というのも、ここ数年、多くの企業がOpenAIに注目し、OpenAIが達成している驚くべきことを見て、彼らは誰にも何も語ろうとしないからです。"
  },
  {
    "start": 1715864,
    "end": 1717298,
    "text": "私たちは研究を公表している。"
  },
  {
    "start": 1717384,
    "end": 1723102,
    "text": "しかし、それを認めたり、クローズドなAIに話したりしている。"
  },
  {
    "start": 1723246,
    "end": 1738522,
    "text": "だから、今のグーグルは、オープンAIと競合するという観点に立てば、競合他社が何をやっているか教えてくれないのに、なぜ自分たちが何をやっているかを教えなければならないのか、ということだと思う。"
  },
  {
    "start": 1738576,
    "end": 1741450,
    "text": "より競争的な環境になっている。"
  },
  {
    "start": 1742110,
    "end": 1751934,
    "text": "以前のオープンソースのようなムーブメントの名残はまだ残っていると思う。"
  },
  {
    "start": 1751972,
    "end": 1758030,
    "text": "実際、OpenAIはWhisperモデルをリリースした。"
  },
  {
    "start": 1758100,
    "end": 1766786,
    "text": "スピーチの構成要素が公開されることを、人々はそれほど心配していないのかもしれない。"
  },
  {
    "start": 1766888,
    "end": 1778134,
    "text": "Whisperがこの特定のポッドキャストを書き起こすかどうかは分かりませんが、私たちが使っている書き起こしソリューションHappy Scribeの一部だからです。"
  },
  {
    "start": 1778172,
    "end": 1782034,
    "text": "発売後すぐに統合されたんだ。"
  },
  {
    "start": 1782082,
    "end": 1783190,
    "text": "幸せだ。"
  },
  {
    "start": 1783260,
    "end": 1784630,
    "text": "囁きを書き写す。"
  },
  {
    "start": 1785290,
    "end": 1793862,
    "text": "最近、主に中国からだと思いますが、低リソース言語の機械翻訳を法学修士にやらせようという動きがあります。"
  },
  {
    "start": 1794006,
    "end": 1795850,
    "text": "少なくとも、私たちはそのうちのいくつかを拾った。"
  },
  {
    "start": 1795920,
    "end": 1801590,
    "text": "また、LLMが低リソースに対してどのようなパフォーマンスを発揮するか、一般的に調べたことがありますか？"
  },
  {
    "start": 1801750,
    "end": 1807834,
    "text": "少し調べてみたが、ゼノ・レポートにもある程度含まれている。"
  },
  {
    "start": 1807882,
    "end": 1817650,
    "text": "アイスランド語やハウサ語のような言語がそこにあるが、私の一般的な印象では、リソースの少ない言語ではかなり悪化している。"
  },
  {
    "start": 1817990,
    "end": 1824350,
    "text": "低リソース言語から低リソース言語への移行は悲惨だ。"
  },
  {
    "start": 1824430,
    "end": 1828626,
    "text": "競争力はあるが、市販のソリューションより悪い。"
  },
  {
    "start": 1828738,
    "end": 1835670,
    "text": "とはいえ、商用ソリューションは非常に優れたデータパイプライン、データフライホイールを持っているので、かなり優れている。"
  },
  {
    "start": 1836570,
    "end": 1847142,
    "text": "通常のオープンソースのモデルを使った場合、ゼノ・レポートにはその評価は載っていない。"
  },
  {
    "start": 1847196,
    "end": 1861230,
    "text": "そうすべきかもしれないが、オープンソースで最高のモデルの一つであるNllbのようなものを使った場合、おそらくGPTの4つのモデルと似たり寄ったりだと思う。"
  },
  {
    "start": 1861730,
    "end": 1869870,
    "text": "ええ、GPTが低リソースで苦労するのは理解できます。"
  },
  {
    "start": 1870030,
    "end": 1874898,
    "text": "非常に入手しにくいデータを、誰かが手作業でたくさん取り込まなければならないだろうね。"
  },
  {
    "start": 1874984,
    "end": 1880294,
    "text": "それが、多言語機械翻訳モデルを構築するエンジニアの仕事の一部なのですね。"
  },
  {
    "start": 1880332,
    "end": 1884360,
    "text": "彼らは可能な限りあらゆるデータソースを探してくる。"
  },
  {
    "start": 1884890,
    "end": 1890302,
    "text": "低リソースのデータを合成的に生成するのはどうか？"
  },
  {
    "start": 1890386,
    "end": 1896906,
    "text": "というのも、今日文字通り読んだんだけど、何人かの学生がそれに関する論文を発表していて、彼らはそれを人工的に作り出そうとしているんだ。"
  },
  {
    "start": 1896928,
    "end": 1902170,
    "text": "それが有望な方向性なのか、そうでないのか、あるいはある種の崩壊が始まるのか。"
  },
  {
    "start": 1902240,
    "end": 1907162,
    "text": "特に、他のリソースの使い方を工夫すれば、どこかにたどり着くことができると思う。"
  },
  {
    "start": 1907226,
    "end": 1916850,
    "text": "例えば、辞書を使った合成データの生成について少し考えてみました。辞書は、インターネット上で見つけることができるどのようなデータよりも、はるかに優れた語彙カバレッジを持っているからです。"
  },
  {
    "start": 1917910,
    "end": 1919442,
    "text": "それはあなたをここまで導くだけだ。"
  },
  {
    "start": 1919496,
    "end": 1926094,
    "text": "これでは、自然で構造化されたアウトプットは得られない。"
  },
  {
    "start": 1926142,
    "end": 1933110,
    "text": "ターゲット言語では、モデルがすでにできることを超えている。"
  },
  {
    "start": 1934890,
    "end": 1937794,
    "text": "何かを得ることはできると思うが、そこまでの道のりを得ることはできない。"
  },
  {
    "start": 1937932,
    "end": 1950278,
    "text": "2021年、あなたはInspire Cognitionを立ち上げました。Inspire Cognitionは、開発チームがテキスト生成、質問応答、要約、コード生成、チャットの出力を試作、評価、理解、改善するのを支援する新興企業です。"
  },
  {
    "start": 1950374,
    "end": 1952974,
    "text": "それについて、あなたの立ち位置をもう少し教えていただけますか？"
  },
  {
    "start": 1953092,
    "end": 1961070,
    "text": "基本的な考え方は、AIシステムの構築を容易にするツールを提供したいということだ。"
  },
  {
    "start": 1961730,
    "end": 1969346,
    "text": "僕がゼノでやっている仕事は、実はゼノで開発したプラットフォームをベースにしているんだ。"
  },
  {
    "start": 1969368,
    "end": 1975810,
    "text": "プラットフォームは、さまざまなタスクの評価指標を計算している。"
  },
  {
    "start": 1976330,
    "end": 1980534,
    "text": "ゼノは、実はフロントエンドで、僕はちょっと仕事をしているんだ。"
  },
  {
    "start": 1980732,
    "end": 1990220,
    "text": "これはオープンソースのプロジェクトで、私はCMUでの仕事の一環として一緒に仕事をしているが、会社を通じてもサポートしている。"
  },
  {
    "start": 1993230,
    "end": 2009758,
    "text": "基本的には、AIシステムのエラーをできるだけ簡単に見つけて修正できるようにしたいということで、Xenoはそのために人々が使えるフロントエンドのインターフェースのようなものです。"
  },
  {
    "start": 2009924,
    "end": 2020866,
    "text": "基本的には、ゼノ・レポートで行ったことと同じように、モデルが失敗しているデータのサブセグメントを特定し、その中に入っていくのです。"
  },
  {
    "start": 2020968,
    "end": 2024882,
    "text": "そこがゼノの取材で立ち寄った場所だ。"
  },
  {
    "start": 2024936,
    "end": 2034918,
    "text": "例えば、モデルが音訳されたテキストを出力するとか、そういう特定の問題があることがわかったとしよう。"
  },
  {
    "start": 2035084,
    "end": 2042618,
    "text": "GPTモデルを使っているのであれば、プロンプトに「翻訳だけを出力し、他は何も出力しないようにしてください」などと書いて、その問題を解決することができる。"
  },
  {
    "start": 2042704,
    "end": 2048522,
    "text": "あるいは、モデルがうまく機能していないことを事後的に検出したい場合だ。"
  },
  {
    "start": 2048576,
    "end": 2054202,
    "text": "その他の問題点として、アウトプットが短すぎたり長すぎたりする傾向があることを指摘した。"
  },
  {
    "start": 2054256,
    "end": 2062080,
    "text": "入力に対して出力が非常に短かったり長かったりした場合、その問題を解決するためにモデルから再サンプリングする何かを追加することができる。"
  },
  {
    "start": 2064310,
    "end": 2079878,
    "text": "ポッドキャストを聴いている人がそれを試してみたいなら、喜んでサポートするよ。"
  },
  {
    "start": 2079964,
    "end": 2083938,
    "text": "現段階でのターゲットユーザーは？"
  },
  {
    "start": 2084034,
    "end": 2091770,
    "text": "XenoのターゲットユーザーはシステムでAIを使用している全ての開発者です。"
  },
  {
    "start": 2091840,
    "end": 2105722,
    "text": "必ずしも機械学習の専門家である必要はないが、システムのアウトプットの質を重視し、実際にかなり多様なタスクに使用できる人である必要がある。"
  },
  {
    "start": 2105786,
    "end": 2114586,
    "text": "具体的には、テキスト生成タスクやコード生成タスクに注目しており、機械翻訳は明らかにテキスト生成タスクである。"
  },
  {
    "start": 2114618,
    "end": 2120658,
    "text": "私たちがこのツールでサポートし、助けたいと考えている人々のターゲットに非常に近い。"
  },
  {
    "start": 2120744,
    "end": 2124574,
    "text": "ああ、機械翻訳者の何人かはこのポッドキャストを聴くべきだね。"
  },
  {
    "start": 2124622,
    "end": 2127250,
    "text": "グラハムと連絡を取る"
  },
  {
    "start": 2128870,
    "end": 2135702,
    "text": "もし新卒の学生がいたら、新卒の学生は機械翻訳についてどう考えているのでしょうか？"
  },
  {
    "start": 2135756,
    "end": 2141270,
    "text": "NLPを始めたばかりの頃のように、ニッチな問題を解決する。"
  },
  {
    "start": 2141350,
    "end": 2142634,
    "text": "彼らはどう考えているのか？"
  },
  {
    "start": 2142752,
    "end": 2151310,
    "text": "そうですね、機械翻訳の場合、リソースが非常に少ない言語については、明らかに解決されていないと思います。"
  },
  {
    "start": 2153410,
    "end": 2160814,
    "text": "高等リソース言語にも非常に難しいトピックがある。"
  },
  {
    "start": 2160852,
    "end": 2165650,
    "text": "最近取り組んでいることのひとつに、比喩的な言葉の翻訳がある。"
  },
  {
    "start": 2166630,
    "end": 2170338,
    "text": "比喩とか、そういうことだ。"
  },
  {
    "start": 2170504,
    "end": 2190066,
    "text": "少なくとも博士号を取得した当初は、すぐに翻訳でチャットGPTを打ち負かそうとするのはお勧めできない。"
  },
  {
    "start": 2190098,
    "end": 2200102,
    "text": "実は、古代史の話をするわけではないが、博士課程の学生だった頃、指導教官に「おい、最初の段階で」と言われて本当に感謝していた。"
  },
  {
    "start": 2200166,
    "end": 2201214,
    "text": "何かから始めたらどうだ？"
  },
  {
    "start": 2201252,
    "end": 2210430,
    "text": "もう少しニッチな場所でスキルを積み、スペースをよく理解してから、メインの城の攻撃に移るんだ。"
  },
  {
    "start": 2211010,
    "end": 2214994,
    "text": "基本的には、今と同じようなことだと思う。"
  },
  {
    "start": 2215032,
    "end": 2227934,
    "text": "もし翻訳に興味があるのであれば、既存の問題に目を向け、私がゼノのレポートで行ったような分析をここで行い、GPTがどこで失敗しているのかを正確に理解するべきだ。"
  },
  {
    "start": 2227982,
    "end": 2231506,
    "text": "そして、その一切れを切り落とし、さらに一切れを切り落とす。"
  },
  {
    "start": 2231538,
    "end": 2235270,
    "text": "そうすれば、いつの間にかその分野の第一人者になっていることだろう。"
  },
  {
    "start": 2235340,
    "end": 2238502,
    "text": "では、後半戦に向けて取り組んでいることは？"
  },
  {
    "start": 2238556,
    "end": 2238886,
    "text": "2023."
  },
  {
    "start": 2238908,
    "end": 2240170,
    "text": "2024."
  },
  {
    "start": 2240240,
    "end": 2244538,
    "text": "ゼノのレポートを続けるつもりですか、それとも一回限りですか？"
  },
  {
    "start": 2244704,
    "end": 2247580,
    "text": "ええ、私たちは間違いなくこれを続けるつもりです。"
  },
  {
    "start": 2248190,
    "end": 2252762,
    "text": "ゼノのレポートに対する私の興味は、翻訳だけに集中しているわけではないと思います。"
  },
  {
    "start": 2252826,
    "end": 2260400,
    "text": "NLPや一般的な生成AIの分野における、最新で最も興味深い開発に焦点を当てたい。"
  },
  {
    "start": 2261250,
    "end": 2268642,
    "text": "私は、あなたがただ、かなり興味深いと思われる音声翻訳に言及しただけのような気がする。"
  },
  {
    "start": 2268696,
    "end": 2274178,
    "text": "たぶん、それは次に考えるべきことだと思う。"
  },
  {
    "start": 2274264,
    "end": 2284170,
    "text": "私は、一般委員会で最も興味深いアプリケーションについて考えるつもりだ。"
  },
  {
    "start": 2284190,
    "end": 2286822,
    "text": "これだけたくさんあるのだから、聖杯であることに変わりはない。"
  },
  {
    "start": 2286876,
    "end": 2299754,
    "text": "つまり、翻訳の問題、音声の問題、待ち時間の問題、そして文章が完全に形成されるまで待たないと正しい翻訳ができないという哲学的な不可能性があるんだ。"
  },
  {
    "start": 2299792,
    "end": 2308746,
    "text": "つまり、特にドイツ語では、動詞の終わりまで待たないと、その人が特定のことをしたのかしていないのかわからないことがあることを私たちは知っている。"
  },
  {
    "start": 2308858,
    "end": 2314190,
    "text": "だから、その分野でもまだ博士号が必要なんだ。"
  },
  {
    "start": 2314260,
    "end": 2315118,
    "text": "ああ、確かにそうだ。"
  },
  {
    "start": 2315204,
    "end": 2317726,
    "text": "グレアム、とても興味深かったよ。"
  },
  {
    "start": 2317828,
    "end": 2319994,
    "text": "スピードアップしてくれて本当にありがとう。"
  },
  {
    "start": 2320042,
    "end": 2325478,
    "text": "今は、30分前よりずっと良い情報が得られたと感じています。"
  },
  {
    "start": 2325564,
    "end": 2326020,
    "text": "ありがとう。"
  }
]