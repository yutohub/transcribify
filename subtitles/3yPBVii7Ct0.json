[
  {
    "start": 170,
    "end": 7002,
    "text": "さて、このビデオでは複数のドキュメントとChroma Dbを使ったlangchainの使い方を見ていこう。"
  },
  {
    "start": 7146,
    "end": 17834,
    "text": "前作では1つのpdfファイルを見ただけで、データベースは使っていなかった。"
  },
  {
    "start": 17962,
    "end": 22378,
    "text": "今回は、実際にデータベースをディスクに書き込む。"
  },
  {
    "start": 22474,
    "end": 23962,
    "text": "これがクロマDbになる。"
  },
  {
    "start": 24026,
    "end": 27186,
    "text": "複数の全ファイル（今回はテキストファイル）を使用する。"
  },
  {
    "start": 27298,
    "end": 34098,
    "text": "私たちは、人々が問い合わせをしたときに引用情報を返すことができるように、いくつかのソース情報を取得するつもりです。"
  },
  {
    "start": 34274,
    "end": 39610,
    "text": "最後に新しいGPTファイブ・ターボAPIも投入するつもりだ。"
  },
  {
    "start": 39950,
    "end": 44342,
    "text": "まず、基本的には通常通りにラングチェンジをセットアップするだけだ。"
  },
  {
    "start": 44406,
    "end": 46938,
    "text": "ここで必要なのはOpenAIのキーだけだ。"
  },
  {
    "start": 47104,
    "end": 53210,
    "text": "今回は、言語モデルと埋め込みにOpenAIを使うつもりだ。"
  },
  {
    "start": 53570,
    "end": 60846,
    "text": "次のビデオでは、ハグする顔を埋め込んだバージョンを作るので、どんな仕上がりになるか見てほしい。"
  },
  {
    "start": 60868,
    "end": 61562,
    "text": "エンベッディングで。"
  },
  {
    "start": 61626,
    "end": 62766,
    "text": "大差ないよ。"
  },
  {
    "start": 62868,
    "end": 69140,
    "text": "ただ、このノートを複雑にしすぎたくなかったので、これから何を持ち込むかを見ていただきたい。"
  },
  {
    "start": 69590,
    "end": 73358,
    "text": "最初の部分は、複数のドキュメントをロードしているだけです。"
  },
  {
    "start": 73454,
    "end": 75070,
    "text": "これはとても簡単なことだ。"
  },
  {
    "start": 75240,
    "end": 77954,
    "text": "これは基本的にフォルダを渡すだけだ。"
  },
  {
    "start": 78002,
    "end": 82310,
    "text": "新しい記事一式をここにダウンロードした。"
  },
  {
    "start": 82650,
    "end": 90882,
    "text": "これらは基本的にテッククランチの記事で、今日の午後にさっとスクラップした最近の記事の束だ。"
  },
  {
    "start": 91026,
    "end": 93146,
    "text": "そこにはどんなテキストファイルでも入れることができる。"
  },
  {
    "start": 93248,
    "end": 96826,
    "text": "1012本以上は持っていると思う。"
  },
  {
    "start": 96848,
    "end": 98058,
    "text": "見てみよう。"
  },
  {
    "start": 98224,
    "end": 104540,
    "text": "ここを見てみると、実際に情報を取得しているものがかなりあることがわかる。"
  },
  {
    "start": 105890,
    "end": 111882,
    "text": "まず最初に、基本的にディレクトリを取得する場所に設定し、ファイルをグロブするだけだ。"
  },
  {
    "start": 111946,
    "end": 113710,
    "text": "スターテキストをやっているだけだ。"
  },
  {
    "start": 113860,
    "end": 117810,
    "text": "長いテキストファイルを1つ作るだけなら、こうすればいい。"
  },
  {
    "start": 117960,
    "end": 122334,
    "text": "PDFファイルなら、テキスト・ローダーを使うより、pdfローダーを使うだろう。"
  },
  {
    "start": 122382,
    "end": 123826,
    "text": "ここを変えるんだ。"
  },
  {
    "start": 123928,
    "end": 126126,
    "text": "どのファイルでも簡単だ。"
  },
  {
    "start": 126158,
    "end": 130198,
    "text": "マークダウン・ファイルを使用している場合は、ここをMDに変更するだけです。"
  },
  {
    "start": 130364,
    "end": 134642,
    "text": "それでは、これらのデータを取り込んで、データを塊に分割します。"
  },
  {
    "start": 134706,
    "end": 136070,
    "text": "以前にも取り上げたことがある。"
  },
  {
    "start": 136220,
    "end": 145226,
    "text": "ほら、確かにここにドキュメントがあり、基本的にはそこにある特定の記事にあった情報のかたまりを提供してくれている。"
  },
  {
    "start": 145408,
    "end": 148870,
    "text": "よし、次はデータベースを作成しよう。"
  },
  {
    "start": 149030,
    "end": 155306,
    "text": "ここでベクターストアを作成し、DBというフォルダに格納する。"
  },
  {
    "start": 155498,
    "end": 158782,
    "text": "基本的には、まず埋め込みを初期化する必要がある。"
  },
  {
    "start": 158916,
    "end": 161210,
    "text": "前にも言ったように、我々はOpenAIを使っている。"
  },
  {
    "start": 161290,
    "end": 174914,
    "text": "近い将来、これらをローカルな埋め込みに置き換える予定だ。それから、基本的にドキュメントからクロマに行くだけだ。テキストを渡し、埋め込みを渡し、これを永続化したいディレクトリを渡すだけだ。"
  },
  {
    "start": 175112,
    "end": 181334,
    "text": "そうすれば、実際にDBに保存され、そこに表示される。"
  },
  {
    "start": 181452,
    "end": 185446,
    "text": "索引もあるし、いろいろなものが入っている。"
  },
  {
    "start": 185548,
    "end": 197402,
    "text": "そのため、基本的にこのドキュメントを削除することができます。"
  },
  {
    "start": 197536,
    "end": 202474,
    "text": "最後に、実際にすべてを削除してもう一度ロードしているところもお見せしよう。"
  },
  {
    "start": 202512,
    "end": 212810,
    "text": "ここでのアイデアは、一度ディスクに保存してしまえば、それをどこかに保存さえすれば、再利用することができ、すべてのドキュメントを埋め込む必要はない、ということをお見せしたいだけなのです。"
  },
  {
    "start": 212890,
    "end": 225282,
    "text": "1,020個のテキストファイルを使っているときには大した問題ではないかもしれないが、1,000個のファイルがかなり長かったとしたら、アプリを起動するたびにそんなことをするのは嫌だろう。"
  },
  {
    "start": 225336,
    "end": 228822,
    "text": "それをどこかに保存しておいて、後で使えばいい。"
  },
  {
    "start": 228956,
    "end": 233350,
    "text": "さて、このベクターDBを手に入れたら、レトリバーにしよう。"
  },
  {
    "start": 233690,
    "end": 240278,
    "text": "レトリーバーであれば、関連文書を取得することができます。"
  },
  {
    "start": 240444,
    "end": 257598,
    "text": "私が持っているクエリ、それを思いつく方法は、ここを見て、タイトルを見て、データブリックについて、CMAのジェネレーティブAIについて、ハギング・フェイスについて、そしてそのうちの1つはパンドか何かについて言及している。"
  },
  {
    "start": 257764,
    "end": 263360,
    "text": "私は基本的にそこから質問を考えている。"
  },
  {
    "start": 263730,
    "end": 269790,
    "text": "これで、デフォルトでは4つのドキュメントが生成される。"
  },
  {
    "start": 269950,
    "end": 272402,
    "text": "今回は2つだけ使う。"
  },
  {
    "start": 272536,
    "end": 275682,
    "text": "この数値は自由に設定できる。"
  },
  {
    "start": 275816,
    "end": 284214,
    "text": "多くの情報を照会する場合、上位5位までを取得するのが良いと思われます。"
  },
  {
    "start": 284412,
    "end": 290854,
    "text": "将来的には、複数のインデックスから異なるインデックスを持ってくるようなことも考えています。"
  },
  {
    "start": 290972,
    "end": 293994,
    "text": "ここでは基本的に2本に戻す。"
  },
  {
    "start": 294112,
    "end": 299834,
    "text": "必要なのは、基本的にレトリーバーで \"k \"を\"2 \"に設定することだけなんだ。"
  },
  {
    "start": 300032,
    "end": 302860,
    "text": "私が使っている検索タイプは類似検索です。"
  },
  {
    "start": 303310,
    "end": 308720,
    "text": "検索引数を見ると、kが2に等しいことがわかる。"
  },
  {
    "start": 309090,
    "end": 314978,
    "text": "現段階では、私のベクターDBとレトリーバー、そしてそれがすべてセットアップされている。"
  },
  {
    "start": 315064,
    "end": 318420,
    "text": "あとは、実際の言語モデルチェーンの部分をやってみたい。"
  },
  {
    "start": 318950,
    "end": 344650,
    "text": "ここでは、基本的に検索QAチェーンを作成し、OpenAIに渡すつもりです。この場合、2つのコンテキストはそれぞれ1000文字なので、長さなどは問題ないでしょう。"
  },
  {
    "start": 344800,
    "end": 351162,
    "text": "次に、リトリーバーに渡して、documents equals trueを返します。"
  },
  {
    "start": 351216,
    "end": 356718,
    "text": "バックグランドで何が起こっているかを見たければ、verboseをtrueに設定すればいい。"
  },
  {
    "start": 356804,
    "end": 362842,
    "text": "今回はそうしていないが、他の多くのビデオで私がそうしているのを見ただろう。"
  },
  {
    "start": 362906,
    "end": 381062,
    "text": "チェーン中やエージェント中に何が起こっているかをもっと見たい場合は、クエリから戻ってきた結果とソース・ドキュメントを見ることができるように、これらの出力を取って基本的にきれいにプリントアウトする関数を作成します。"
  },
  {
    "start": 381196,
    "end": 386470,
    "text": "パンドはいくら集めたのか？"
  },
  {
    "start": 386970,
    "end": 395302,
    "text": "すぐにわかるのは、2つのソース文書で、1つはパワード・サプライチェーンの新興企業パンドが3,000万ドルの投資を獲得したというものだ。"
  },
  {
    "start": 395446,
    "end": 396970,
    "text": "だからこんなことを訊いたんだ。"
  },
  {
    "start": 397040,
    "end": 398570,
    "text": "チェックするのは簡単だからね。"
  },
  {
    "start": 398640,
    "end": 404766,
    "text": "案の定、パンダはシリーズBラウンドで3000万ドルを調達し、調達総額は4500万ドルに達したという。"
  },
  {
    "start": 404948,
    "end": 406366,
    "text": "あれは明らかにやっている。"
  },
  {
    "start": 406388,
    "end": 408430,
    "text": "こちらにもソースがある。"
  },
  {
    "start": 408580,
    "end": 412814,
    "text": "これらも元々は単なるHTMLファイルだった。"
  },
  {
    "start": 412852,
    "end": 417566,
    "text": "私たちは、基本的にドキュメントに戻るリンクを持つために、これを処理することができます。"
  },
  {
    "start": 417598,
    "end": 423314,
    "text": "もし1万件の記事があり、人々が元のソースHTMLページを見に行けるようにしたかったとする。"
  },
  {
    "start": 423352,
    "end": 427894,
    "text": "これを少し調べれば、簡単に入れることができるだろう。"
  },
  {
    "start": 428012,
    "end": 431250,
    "text": "パンドのニュースは？"
  },
  {
    "start": 431410,
    "end": 438902,
    "text": "私はそれを整理するための関数に通していない。"
  },
  {
    "start": 439036,
    "end": 442546,
    "text": "パンダがシリーズBで3,000万ドルを調達したというニュースだ。"
  },
  {
    "start": 442668,
    "end": 447786,
    "text": "この資金は世界的な販売拡大のために使われるという。"
  },
  {
    "start": 447968,
    "end": 462814,
    "text": "また、実際のソース・ドキュメントがここに戻ってきて、これがこの場合の一番上のドキュメントで、これがこの場合の二番目の一番上のドキュメントであることがわかります。"
  },
  {
    "start": 462852,
    "end": 470782,
    "text": "今度のは3,000万ドルの部分があるようで、誰がラウンドをリードしたか、そういうことも書いてある。"
  },
  {
    "start": 470916,
    "end": 480166,
    "text": "そのラウンドをリードしたのは誰か、と尋ねると、案の定、他のラウンドを選びながら、いとも簡単にそれをやってのける。"
  },
  {
    "start": 480268,
    "end": 482178,
    "text": "データブリックは何を獲得したのか？"
  },
  {
    "start": 482354,
    "end": 489290,
    "text": "AIに焦点を当てたデータガバナンス・プラットフォームであるOkeraを買収したことを伝えている。"
  },
  {
    "start": 489790,
    "end": 491750,
    "text": "ジェネレーティブAIとは何か？"
  },
  {
    "start": 491910,
    "end": 498938,
    "text": "このケースでは、2つの異なる記事から答えが返ってきている。"
  },
  {
    "start": 499104,
    "end": 506302,
    "text": "そう思いついたのは、CMAがジェネレーティブAIのレビューであるという記事があったからだ。"
  },
  {
    "start": 506436,
    "end": 509578,
    "text": "私はそれが戻ってくるかどうか知りたかったが、戻ってこなかった。"
  },
  {
    "start": 509674,
    "end": 511674,
    "text": "CMAとは誰ですか？"
  },
  {
    "start": 511802,
    "end": 522146,
    "text": "案の定、CMAは競争市場庁の略で、CMAの記事を返してくれた。"
  },
  {
    "start": 522328,
    "end": 527878,
    "text": "このチェーンを見ると、チェーンリトリーバーのタイプが似ていることがわかる。"
  },
  {
    "start": 527964,
    "end": 531880,
    "text": "ただ、私たちが以前に準備したものすべてがこの製品に注ぎ込まれていることをお見せしたい。"
  },
  {
    "start": 533450,
    "end": 537158,
    "text": "クロマDBがベクターストアであることがわかる。"
  },
  {
    "start": 537324,
    "end": 542018,
    "text": "実際にテンプレートを見てみると、ここにテンプレートがあることがわかる。"
  },
  {
    "start": 542114,
    "end": 544182,
    "text": "次のような文脈がある。"
  },
  {
    "start": 544246,
    "end": 550442,
    "text": "コンテキストには2つのものが渡される。"
  },
  {
    "start": 550576,
    "end": 553238,
    "text": "次に、クエリーである実際の質問。"
  },
  {
    "start": 553414,
    "end": 557502,
    "text": "最後の質問に答えるために、以下の文脈を利用する。"
  },
  {
    "start": 557636,
    "end": 559406,
    "text": "答えがわからなければ、そう言えばいい。"
  },
  {
    "start": 559428,
    "end": 562160,
    "text": "答えを知らないのだから、作ろうとするな。"
  },
  {
    "start": 562930,
    "end": 581234,
    "text": "ランタイムを再起動し、zipを解凍してみるとわかります。"
  },
  {
    "start": 581282,
    "end": 584390,
    "text": "まずはOpenAIのキーを入れ直す必要がある。"
  },
  {
    "start": 584540,
    "end": 590042,
    "text": "しかし今回は、言語モデルの部分をターボAPIにした。"
  },
  {
    "start": 590096,
    "end": 598086,
    "text": "DBという名前のパーシスト・フォルダーを指すだけでDBをセットアップした。"
  },
  {
    "start": 598278,
    "end": 601180,
    "text": "ここでレトリバーをセットする必要がある。"
  },
  {
    "start": 602270,
    "end": 609374,
    "text": "実際には、もっと簡単にするために最後にそれを付けることもできるんだけど、とにかく、これはそこで何をしているかを示しているだけなんだ。"
  },
  {
    "start": 609492,
    "end": 614498,
    "text": "そこで、ターボLmをセットアップする。"
  },
  {
    "start": 614664,
    "end": 618574,
    "text": "ターボLmで再びチェーンを組む。"
  },
  {
    "start": 618702,
    "end": 622274,
    "text": "ここではGPT 3.5のターボAPIを使っている。"
  },
  {
    "start": 622392,
    "end": 627010,
    "text": "他はすべてまったく同じで、走りながら同じ質問をしている。"
  },
  {
    "start": 627160,
    "end": 629398,
    "text": "案の定、答えが返ってきた。"
  },
  {
    "start": 629484,
    "end": 639142,
    "text": "ここで、ターボAPIを使用しているときのバージョンのプロンプトを見てみると、以前と同じプロンプトを出力するだけではうまくいかないことがわかるだろう。"
  },
  {
    "start": 639196,
    "end": 640586,
    "text": "問題にぶつかるだろう。"
  },
  {
    "start": 640768,
    "end": 645814,
    "text": "ここでは基本的に、システムプロンプトと人間プロンプトを見なければならない。"
  },
  {
    "start": 645942,
    "end": 648922,
    "text": "これはシステム・プロンプトだね？"
  },
  {
    "start": 648976,
    "end": 654266,
    "text": "これは基本的にスルーされ、最初のメッセージはその中のシステムメッセージである。"
  },
  {
    "start": 654368,
    "end": 658574,
    "text": "これは、ユーザーの質問に答えるために、次のようなコンテキストを使用します。"
  },
  {
    "start": 658772,
    "end": 665778,
    "text": "そして文脈を理解し、人間的な部分で質問を理解する。"
  },
  {
    "start": 665944,
    "end": 670402,
    "text": "ターボLLMも使っていますね。"
  },
  {
    "start": 670536,
    "end": 680546,
    "text": "さて、これでベクター・データベースの使い方を少し理解できたと思う。"
  },
  {
    "start": 680658,
    "end": 684466,
    "text": "今後のビデオでは、パインコーンの使い方を紹介する予定だ。"
  },
  {
    "start": 684498,
    "end": 688166,
    "text": "もしAPIとしてどこかに置きたいなら、そのようにpingを送ることができる。"
  },
  {
    "start": 688268,
    "end": 695686,
    "text": "OpenAIのエンベッディングを使用するのではなく、独自のエンベッディングを使用することを検討します。"
  },
  {
    "start": 695788,
    "end": 700014,
    "text": "とにかく、いつも通り、質問があれば下のコメントに書いてください。"
  },
  {
    "start": 700172,
    "end": 702890,
    "text": "この記事がお役に立ちましたら、ぜひクリックしてご購読ください。"
  },
  {
    "start": 703050,
    "end": 704878,
    "text": "また次のビデオで会おう。"
  },
  {
    "start": 705044,
    "end": 705740,
    "text": "とりあえず、さようなら。"
  }
]