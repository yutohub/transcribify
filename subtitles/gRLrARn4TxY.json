[
  {
    "start": 410,
    "end": 7534,
    "text": "さて、GTC2024の時間だ。このビデオで私が選んだGTC2024を紹介しよう。"
  },
  {
    "start": 7572,
    "end": 14094,
    "text": "その前に、とてもとてもエキサイティングなプレゼントについてお話ししましょう。"
  },
  {
    "start": 14292,
    "end": 21680,
    "text": "これはNvidia RTX GeForce 40 80 superです。"
  },
  {
    "start": 22130,
    "end": 25782,
    "text": "これはハイエンドのカードだ。"
  },
  {
    "start": 25836,
    "end": 28646,
    "text": "スペックはこちらで確認できる。"
  },
  {
    "start": 28828,
    "end": 30962,
    "text": "ゲームやAIに最適だ。"
  },
  {
    "start": 31026,
    "end": 35000,
    "text": "いずれにせよ、このチャンネルではAIを使うことが多いだろうね。"
  },
  {
    "start": 35370,
    "end": 43926,
    "text": "GTC2024の会見に入ったところで、その詳細をお伝えするつもりだ。"
  },
  {
    "start": 44038,
    "end": 49782,
    "text": "GTCが進むにつれて、私は完全なビデオのスケジュールを用意している。"
  },
  {
    "start": 49846,
    "end": 52318,
    "text": "ここでもそれを見ることができる。"
  },
  {
    "start": 52484,
    "end": 61194,
    "text": "このセッションを通して、私のお気に入りのビデオをいくつか取り上げ、そしてプレゼントについてもお話しします。"
  },
  {
    "start": 61242,
    "end": 79366,
    "text": "というのも、課税区域を越えなければならず、一旦これを全額で申告してしまうと、受け取るときに本当に割に合わなくなってしまうからだ。"
  },
  {
    "start": 79468,
    "end": 87750,
    "text": "さて、それではNvidiaが開催するこの素晴らしいカンファレンスで私が選ぶのは何だろう？"
  },
  {
    "start": 87820,
    "end": 92966,
    "text": "COVIDの時代から脱却し、願わくば直接手に入れることもできる。"
  },
  {
    "start": 93158,
    "end": 98042,
    "text": "いつかこの会議を実際に見に行きたい。"
  },
  {
    "start": 98176,
    "end": 104366,
    "text": "私は年に2、3回会議を見るが、この会議は間違いなく私のリストに入っている。"
  },
  {
    "start": 104468,
    "end": 115106,
    "text": "説明文に登録用のリンクを貼っておくから、私の登録用リンクを使ってね。"
  },
  {
    "start": 115128,
    "end": 125560,
    "text": "そうすれば、あなたがここから来たことがNvidiaに伝わり、Nvidiaとのパートナーシップがうまくいっていることがわかります。"
  },
  {
    "start": 126650,
    "end": 135074,
    "text": "ログインして登録すると、カタログにアクセスできるようになります。"
  },
  {
    "start": 135122,
    "end": 145866,
    "text": "カタログを見ると、すべての日付が表示され、さまざまな項目で絞り込むことができる。"
  },
  {
    "start": 145968,
    "end": 149162,
    "text": "さて、私が本当に気に入ったものを一握り選んだ。"
  },
  {
    "start": 149216,
    "end": 159006,
    "text": "どの作品に興味があるのか、私も知りたいんだ。たいてい、コメントで何人かの方から、ああ、私はこれにとても興味があるんだ、と言ってもらえるからね。"
  },
  {
    "start": 159028,
    "end": 160894,
    "text": "どうして見逃したんだろう？"
  },
  {
    "start": 161012,
    "end": 168898,
    "text": "そうすれば、もっと深く掘り下げたビデオを撮れる可能性が増えるから。"
  },
  {
    "start": 168984,
    "end": 173470,
    "text": "これらのプレゼンテーションのいくつかを私が総括することについて話す。"
  },
  {
    "start": 173550,
    "end": 174946,
    "text": "これはすべて無料だ。"
  },
  {
    "start": 175128,
    "end": 178166,
    "text": "直接見るのは無料ではないが、ストリーミングで見るのは無料だ。"
  },
  {
    "start": 178268,
    "end": 183602,
    "text": "私の背景を説明するだけで、今ならどれでも見ることができる。"
  },
  {
    "start": 183746,
    "end": 191482,
    "text": "私はYouTuberですが、主にフォーチュン300に入る保険会社でAIリーダーとして働いています。"
  },
  {
    "start": 191536,
    "end": 194154,
    "text": "それが僕の主な仕事だ。"
  },
  {
    "start": 194192,
    "end": 195834,
    "text": "それは確かにこの一部を左右するだろう。"
  },
  {
    "start": 195872,
    "end": 201998,
    "text": "私のチームは現在、生成AIのプロトタイプに非常に力を入れている。"
  },
  {
    "start": 202164,
    "end": 207806,
    "text": "ジェフ・ヒートンが何を決めたか見てみよう。"
  },
  {
    "start": 207908,
    "end": 228022,
    "text": "まず第一に、2時間であることは当たり前だが、ジェンセン・ウォンが発表する基調講演は、1分1秒を争う価値があり、NvidiaとAIの世界から何が新しく生まれるかという点で、彼はいつも私の世界を揺さぶってくれる。"
  },
  {
    "start": 228076,
    "end": 231478,
    "text": "この時点では、それらはほとんど同じものだ。"
  },
  {
    "start": 231644,
    "end": 235314,
    "text": "そして、ラグ・ベーシックの先を選んだ。"
  },
  {
    "start": 235442,
    "end": 239306,
    "text": "ラグは本当に重要な技術で、私もたくさん活用している。"
  },
  {
    "start": 239408,
    "end": 248534,
    "text": "事前トレーニングや微調整に多大な手間をかけずに済むようにするためだ。"
  },
  {
    "start": 248582,
    "end": 251934,
    "text": "事前に訓練された基礎モデルと言うべきだろう。"
  },
  {
    "start": 252132,
    "end": 255502,
    "text": "これについては、ここに説明がある。"
  },
  {
    "start": 255556,
    "end": 264366,
    "text": "それは確かに楽しみにしているいくつかのNvidiaの開発者によって提示される。"
  },
  {
    "start": 264548,
    "end": 266306,
    "text": "小さなアイコンも見える。"
  },
  {
    "start": 266328,
    "end": 268834,
    "text": "彼らは、それが直接のものであるかどうかをよく知らせてくれる。"
  },
  {
    "start": 268872,
    "end": 272142,
    "text": "少なくとも私の理解では、これらはすべてストリーム配信される。"
  },
  {
    "start": 272286,
    "end": 284520,
    "text": "QDFを使ったパンダの高速化には常に興味があるので、Nvidiaがセキュリティとして発表したQDFのプレゼンは必ず取り上げるつもりだ。"
  },
  {
    "start": 284890,
    "end": 286680,
    "text": "非常に重要だ。"
  },
  {
    "start": 288910,
    "end": 290614,
    "text": "私のモデルはハッキングされますか？"
  },
  {
    "start": 290742,
    "end": 298278,
    "text": "LLMSにはあらゆる種類のセキュリティ上の問題があり、その多くは大規模な言語モデルについてはまだわかっていない。"
  },
  {
    "start": 298454,
    "end": 304254,
    "text": "そのため、これから学んでいくことになる。"
  },
  {
    "start": 304292,
    "end": 313122,
    "text": "この一冊を見て、何が私を夜更かしさせるのか確かめようと思う。"
  },
  {
    "start": 313256,
    "end": 314222,
    "text": "小型モデル。"
  },
  {
    "start": 314286,
    "end": 315614,
    "text": "私は小さなモデルが大好きだ。"
  },
  {
    "start": 315662,
    "end": 317186,
    "text": "特にミストラル。"
  },
  {
    "start": 317288,
    "end": 322578,
    "text": "これらは、さまざまな手段によって削減されたモデルである。"
  },
  {
    "start": 322664,
    "end": 335110,
    "text": "複数のGPUを必要とする巨大なモデルに比べ、この70億ほどのパラメータ・モデルは、実際にローカル・システムで実行することができる。"
  },
  {
    "start": 335180,
    "end": 336806,
    "text": "これにはとても興味がある。"
  },
  {
    "start": 336908,
    "end": 358014,
    "text": "私は、アプリケーションで様々なモデルをミックスして使うのが好きなんだ。例えば、タイトルを要約するだけなら、クロードのような大きなモデルを使う必要はない。"
  },
  {
    "start": 358052,
    "end": 363502,
    "text": "ミストラルを使って、あまり強くないものを処理できるのであればね。"
  },
  {
    "start": 363566,
    "end": 366820,
    "text": "ミストラルは素晴らしいことをやっている。"
  },
  {
    "start": 368070,
    "end": 372020,
    "text": "これは本当に興味がある。"
  },
  {
    "start": 373910,
    "end": 380406,
    "text": "いつもKaggleのマスターの洞察があるので、いつもチェックしている。"
  },
  {
    "start": 380428,
    "end": 381640,
    "text": "いつも素晴らしいよ。"
  },
  {
    "start": 382650,
    "end": 393786,
    "text": "確かに、Kaggleのマスターやグランドマスターは、こうした牙をむくトップテクノロジー企業の多くが採用する入り口になっているようだ。"
  },
  {
    "start": 393888,
    "end": 397674,
    "text": "Nvidiaも同様である。"
  },
  {
    "start": 397712,
    "end": 410842,
    "text": "特に、彼らはLLMについて話していて、私は大学で教えている新しいジェネレーティブAIのクラスがあるので、LLMがKagglesにどのように組み込まれるのか、とても興味があります。"
  },
  {
    "start": 410986,
    "end": 419338,
    "text": "この素晴らしいGPUのプレゼントキャンペーンもお見逃しなく。"
  },
  {
    "start": 419434,
    "end": 422814,
    "text": "Nvidia、本当にありがとう。"
  },
  {
    "start": 422932,
    "end": 424800,
    "text": "いつもチャンネルを合わせている。"
  },
  {
    "start": 425290,
    "end": 428760,
    "text": "2024年のGTCを楽しみにしている。"
  },
  {
    "start": 429210,
    "end": 436440,
    "text": "正直なところ、このチャンネルで今後数カ月に何を取り上げるか、いつもその方向性を示してくれる。"
  },
  {
    "start": 436810,
    "end": 442982,
    "text": "ご視聴ありがとうございました。見逃さないように購読してください。"
  },
  {
    "start": 443036,
    "end": 443620,
    "text": "本当にありがとう。"
  }
]