[
  {
    "start": 0,
    "end": 17320,
    "text": "AI研究者であり、OpenAIの創設メンバーでもあるAndrej Karpathy氏をお迎えください。"
  },
  {
    "start": 17320,
    "end": 23600,
    "text": "皆さん、こんにちは。"
  },
  {
    "start": 23600,
    "end": 32159,
    "text": "今回、GPTの状況や、大規模言語モデルのエコシステムが急速に発展していることをお伝えできることを嬉しく思います。"
  },
  {
    "start": 32159,
    "end": 35400,
    "text": "講演は2つに分けて行いたいと思います。"
  },
  {
    "start": 35400,
    "end": 39600,
    "text": "前編では、GPTアシスタントの育成方法についてお伝えしたいと思います。"
  },
  {
    "start": 39600,
    "end": 46780,
    "text": "後編では、これらのアシスタントをお客様の用途に合わせて効果的に活用する方法をご紹介します。"
  },
  {
    "start": 46780,
    "end": 50519,
    "text": "まず、このアシスタントの育成方法について、新興のレシピを見てみましょう。"
  },
  {
    "start": 50519,
    "end": 53220,
    "text": "これはすべて非常に新しく、まだ急速に進化していることを念頭に置いてください。"
  },
  {
    "start": 53220,
    "end": 56000,
    "text": "今のところ、レシピはこのような感じです。"
  },
  {
    "start": 56000,
    "end": 60240,
    "text": "このスライドはちょっと複雑なので、ひとつひとつ見ていきたいと思います。"
  },
  {
    "start": 60240,
    "end": 63360,
    "text": "大きく分けて4つのステージがあります。"
  },
  {
    "start": 63360,
    "end": 70120,
    "text": "事前学習、教師ありの微調整、報酬モデリング、強化学習、それらが順次続いていく。"
  },
  {
    "start": 70120,
    "end": 74980,
    "text": "今、各ステージでは、そのステージをパワーアップさせるデータセットを持っています。"
  },
  {
    "start": 74980,
    "end": 82480,
    "text": "私たちの目的では、ニューラルネットワークを訓練するための目的となるアルゴリズムがあります。"
  },
  {
    "start": 82480,
    "end": 84120,
    "text": "結果的にモデルが出来上がる。"
  },
  {
    "start": 84120,
    "end": 86040,
    "text": "底にはいくつかのメモがあります。"
  },
  {
    "start": 86040,
    "end": 88880,
    "text": "まず、最初の段階として、プリトレーニングの段階から始めます。"
  },
  {
    "start": 88880,
    "end": 91760,
    "text": "このステージはこの図の中ではちょっと特殊です。"
  },
  {
    "start": 91760,
    "end": 93700,
    "text": "この図は、縮尺が合っていません。"
  },
  {
    "start": 93700,
    "end": 96520,
    "text": "この段階で、基本的にすべての演算処理が行われるからです。"
  },
  {
    "start": 96520,
    "end": 100600,
    "text": "これはトレーニングの計算時間の99％を占めています。"
  },
  {
    "start": 100600,
    "end": 102080,
    "text": "もフロップします。"
  },
  {
    "start": 102080,
    "end": 111480,
    "text": "スーパーコンピュータに搭載された何千ものGPUを駆使して、インターネット規模のデータセットを扱い、さらに何カ月ものトレーニングを行う可能性があるわけです。"
  },
  {
    "start": 111480,
    "end": 119440,
    "text": "他の3つのステージは微調整のステージで、GPUの数が少なかったり、数時間から数日かかったりするものです。"
  },
  {
    "start": 119440,
    "end": 124200,
    "text": "ベースモデルを実現するためのプレトレーニングの段階から見ていきましょう。"
  },
  {
    "start": 124200,
    "end": 127880,
    "text": "まずは大量のデータを集めます。"
  },
  {
    "start": 127880,
    "end": 136360,
    "text": "ここでは、Meta社が発表したこの論文に由来する、データミックスと呼ばれる例を示しますが、このラマベースモデルを発表したのはMeta社です。"
  },
  {
    "start": 136360,
    "end": 140580,
    "text": "これらのコレクションに入るデータセットの種類は大体お分かりいただけたと思います。"
  },
  {
    "start": 140580,
    "end": 143020,
    "text": "共通クロールがあり、これは単なるウェブスクレイプです。"
  },
  {
    "start": 143020,
    "end": 145540,
    "text": "C4、これも共通クロールです。"
  },
  {
    "start": 145540,
    "end": 147380,
    "text": "いくつかの高品質なデータセットも。"
  },
  {
    "start": 147380,
    "end": 151620,
    "text": "例えば、GitHub、Wikipedia、書籍、アーカイブ、スタックエクスチェンジ、などなど。"
  },
  {
    "start": 151620,
    "end": 153140,
    "text": "これらが混在している。"
  },
  {
    "start": 153140,
    "end": 156700,
    "text": "ある与えられた比率に従ってサンプリングされる。"
  },
  {
    "start": 156700,
    "end": 161140,
    "text": "GPTのニューラルネットの学習セットを形成するものである。"
  },
  {
    "start": 161140,
    "end": 166940,
    "text": "このデータで実際に学習する前に、もう1つ前処理を行う必要があります。それがトークン化です。"
  },
  {
    "start": 166980,
    "end": 173660,
    "text": "これは基本的に、インターネットからかき集めた生のテキストを、整数の列に変換するものです。"
  },
  {
    "start": 173660,
    "end": 177620,
    "text": "なぜなら、それがGPTが機能する上でのネイティブな表現だからです。"
  },
  {
    "start": 177620,
    "end": 183900,
    "text": "これは、テキストの断片、トークン、整数の間の可逆的な翻訳である。"
  },
  {
    "start": 183900,
    "end": 186180,
    "text": "このステージのためのアルゴリズムが数多く存在します。"
  },
  {
    "start": 186180,
    "end": 194000,
    "text": "典型的な例としては、バイトエンコーディングのようなものを使って、小さなテキストチャンクを反復的にマージしてトークンにグループ化することができます。"
  },
  {
    "start": 194000,
    "end": 197000,
    "text": "ここではこれらのトークンのチャンクをいくつか例示しています。"
  },
  {
    "start": 197000,
    "end": 202160,
    "text": "これが実際にトランスに供給される生の整数列となる。"
  },
  {
    "start": 202160,
    "end": 208280,
    "text": "このステージを支配するハイパーパラメータの例を2つ紹介します。"
  },
  {
    "start": 208280,
    "end": 212280,
    "text": "GPT-4は、どのようにトレーニングしたのかなど、あまり情報を公開しませんでした。"
  },
  {
    "start": 212280,
    "end": 214040,
    "text": "GPT-3の数値を使っています。"
  },
  {
    "start": 214040,
    "end": 217940,
    "text": "GPT-3はもちろん今頃、3年前くらいから少しづつですが。"
  },
  {
    "start": 217940,
    "end": 220840,
    "text": "LamaはMetaのかなり最近のモデルです。"
  },
  {
    "start": 220840,
    "end": 225280,
    "text": "プレトレーニングの時に扱う桁がだいたい決まっているんです。"
  },
  {
    "start": 225280,
    "end": 228440,
    "text": "語彙の大きさは通常、数万トークンです。"
  },
  {
    "start": 228440,
    "end": 233640,
    "text": "コンテキストの長さは、通常2,000、4,000、最近では100,000といったところでしょうか。"
  },
  {
    "start": 233640,
    "end": 237458,
    "text": "これは、GPTが見る整数の最大数を規定するものです。"
  },
  {
    "start": 237458,
    "end": 242300,
    "text": "次の整数を予測しようとするとき。"
  },
  {
    "start": 242300,
    "end": 246480,
    "text": "大体パラメーターの数がラマで650億と言うのがわかると思います。"
  },
  {
    "start": 246480,
    "end": 254280,
    "text": "GPT-3の1750億のパラメータに対して、Lamaは65Bのパラメータしか持っていないにもかかわらず、Lamaの方が圧倒的にパワフルなモデルになっています。"
  },
  {
    "start": 254280,
    "end": 258040,
    "text": "直感的には、モデルの学習時間が大幅に長くなったからだと思います。"
  },
  {
    "start": 258040,
    "end": 261860,
    "text": "この場合、3000億トークンではなく、1兆4000億トークンになります。"
  },
  {
    "start": 261860,
    "end": 267120,
    "text": "パラメータの数だけで、モデルのパワーを判断してはいけないのです。"
  },
  {
    "start": 267120,
    "end": 274200,
    "text": "以下に、トランスフォーマーニューラルネットワークを指定するための、大まかなハイパーパラメータの表をいくつか示します。"
  },
  {
    "start": 274200,
    "end": 277960,
    "text": "ヘッド数、寸法、層数、など。"
  },
  {
    "start": 277960,
    "end": 281680,
    "text": "下には、トレーニング用のハイパーパラメータを表示しています。"
  },
  {
    "start": 281680,
    "end": 292640,
    "text": "例えば、65Bのモデルをトレーニングするために、Metaは2,000GPUを使い、およそ21日間のトレーニングを行い、およそ数百万ドルを費やしました。"
  },
  {
    "start": 292640,
    "end": 299159,
    "text": "プレトレーニングの段階で、大まかな桁を決めておくとよいでしょう。"
  },
  {
    "start": 299159,
    "end": 301400,
    "text": "実際にプレトレーニングを行うとどうなるのでしょうか。"
  },
  {
    "start": 301400,
    "end": 306200,
    "text": "一般的には、トークンをデータバッチにレイアウトすることになります。"
  },
  {
    "start": 306200,
    "end": 309560,
    "text": "このようなアレイがあり、トランスに供給されます。"
  },
  {
    "start": 309560,
    "end": 315200,
    "text": "これらの配列は、バッチサイズであるBであり、これらはすべて独立した例が列をなして積み重ねられている。"
  },
  {
    "start": 315200,
    "end": 318160,
    "text": "BをTで割ったもので、Tは最大文脈長である。"
  },
  {
    "start": 318160,
    "end": 323200,
    "text": "私の写真では文脈の長さである10しかないので、これは2,000や4,000などにもなり得ます。"
  },
  {
    "start": 323200,
    "end": 325160,
    "text": "非常に長い列です。"
  },
  {
    "start": 325160,
    "end": 335300,
    "text": "これは、基本的に、新しい文書がどこから始まるかを変換器に伝えるためのものです。"
  },
  {
    "start": 335300,
    "end": 342120,
    "text": "ここではドキュメントの例をいくつか挙げて、それをこの入力に引き伸ばしてみました。"
  },
  {
    "start": 342120,
    "end": 346400,
    "text": "これらの数字をすべてトランスに送り込みます。"
  },
  {
    "start": 346400,
    "end": 352719,
    "text": "この図では、特定の1つのセルに焦点を当てていますが、同じことがこの図のすべてのセルで起こります。"
  },
  {
    "start": 352719,
    "end": 354760,
    "text": "緑のセルを見てみましょう。"
  },
  {
    "start": 354760,
    "end": 358880,
    "text": "緑のセルは、その前にあるすべてのトークンを見ていくことになります。"
  },
  {
    "start": 358880,
    "end": 360640,
    "text": "トークンをすべて黄色にします。"
  },
  {
    "start": 360640,
    "end": 365719,
    "text": "その文脈全体をトランスフォーマーニューラルネットワークに送り込むのです。"
  },
  {
    "start": 365719,
    "end": 370680,
    "text": "この場合、変換器は次のトークンを予測しようとします（この場合は赤）。"
  },
  {
    "start": 370680,
    "end": 375864,
    "text": "トランスフォーマーですが、残念ながらあまり時間がないので、このニューラルネットワークのアーキテクチャの全容を説明することはできません、"
  },
  {
    "start": 375864,
    "end": 382640,
    "text": "私たちの目的のためのニューラルネットの大きな塊で、典型的には数百億のパラメータを持っている、そのようなものです。"
  },
  {
    "start": 382640,
    "end": 389300,
    "text": "もちろん、これらのパラメータを調整することで、これらの細胞の一つ一つについて、少しずつ異なる予測分布が得られます。"
  },
  {
    "start": 389300,
    "end": 400640,
    "text": "例えば語彙のサイズが50,257トークンだとすると、次に来るものの確率分布を指定する必要があるため、それだけ多くの数値を用意することになるのです。"
  },
  {
    "start": 400640,
    "end": 403200,
    "text": "この後、何が起こるかわからないからこそ、私たちは確率を高めているのです。"
  },
  {
    "start": 403200,
    "end": 407440,
    "text": "この具体的な例では、この特定のセルでは、次に513が登場します。"
  },
  {
    "start": 407440,
    "end": 411760,
    "text": "変換器の重みを更新するための監視のソースとして利用することができます。"
  },
  {
    "start": 411880,
    "end": 416381,
    "text": "基本的にはすべての細胞に並行して適用し、バッチを入れ替えることを繰り返しています。"
  },
  {
    "start": 416381,
    "end": 422480,
    "text": "トランスフォーマーが、シーケンスの中で次に来るトークンを正しく予測するようにするためです。"
  },
  {
    "start": 422480,
    "end": 425840,
    "text": "このようなモデルをトレーニングすると、どのようになるのか、もう少し具体的に説明しましょう。"
  },
  {
    "start": 425840,
    "end": 431200,
    "text": "これはニューヨークタイムズからの情報ですが、彼らはシェイクスピアに関する小さなGPTを訓練しました。"
  },
  {
    "start": 431200,
    "end": 434760,
    "text": "シェイクスピアの小ネタを紹介したところ、GPTを獲得してくれました。"
  },
  {
    "start": 434760,
    "end": 439400,
    "text": "冒頭の初期化では、GPTは完全にランダムな重みでスタートします。"
  },
  {
    "start": 439400,
    "end": 442600,
    "text": "も、完全にランダムな出力が得られるだけです。"
  },
  {
    "start": 442600,
    "end": 451720,
    "text": "GPTを長く訓練していくと、モデルからより一貫性のあるサンプルが得られるようになります。"
  },
  {
    "start": 451720,
    "end": 459823,
    "text": "もちろん、そこからサンプリングする方法は、次に来るものを予測し、その分布からサンプリングし、それをプロセスにフィードバックし続けることです。"
  },
  {
    "start": 459823,
    "end": 461960,
    "text": "基本的に大きなシーケンスをサンプリングすることができます。"
  },
  {
    "start": 461960,
    "end": 468420,
    "text": "最後には、トランスフォーマーが言葉について、どこにスペースを入れるか、どこにカンマを入れるか、などを学んだことがわかりますね。"
  },
  {
    "start": 468440,
    "end": 471860,
    "text": "時間の経過とともに、より一貫した予測をしています。"
  },
  {
    "start": 471860,
    "end": 474740,
    "text": "このようなプロットは、モデルのプリトレーニングを行う際に見ることができます。"
  },
  {
    "start": 474740,
    "end": 478900,
    "text": "実質的には、トレーニングしながら損失関数を経時的に見ていくことになります。"
  },
  {
    "start": 478900,
    "end": 487180,
    "text": "損失が少ないということは、このトランスフォーマーが、次の整数をより高い確率で正しく予測できていることを意味します。"
  },
  {
    "start": 487180,
    "end": 491180,
    "text": "1ヶ月後にトレーニングした後、このモデルをどうするのか。"
  },
  {
    "start": 491180,
    "end": 500945,
    "text": "まず、私たちが現場で気づいたことは、これらのモデルは基本的に言語モデリングの過程で、非常に強力な一般的表現を学習するということです。"
  },
  {
    "start": 500945,
    "end": 506940,
    "text": "使えば、任意の下流タスクに対して非常に効率的にファインチューニングすることが可能です。"
  },
  {
    "start": 506940,
    "end": 517260,
    "text": "例えば、感情分類に興味がある場合、以前はポジティブとネガティブを集めて、それに対して何らかのNLPモデルを学習させるというアプローチがとられていました。"
  },
  {
    "start": 517260,
    "end": 531380,
    "text": "新しいアプローチは、感情分類を無視して、大規模な言語モデルの事前学習を行い、大規模な変換器を訓練することです。"
  },
  {
    "start": 531380,
    "end": 533780,
    "text": "これは実際にとてもよく機能します。"
  },
  {
    "start": 533780,
    "end": 540980,
    "text": "その理由は、基本的に言語モデリングタスクの中で、トランスフォーマーは膨大な量のタスクをマルチタスクで処理することを余儀なくされるからである。"
  },
  {
    "start": 540980,
    "end": 550340,
    "text": "なぜなら、次のトークンを予測するという点だけで、テキストの構造やそこにあるさまざまな概念について、多くの理解を強いられるからです。"
  },
  {
    "start": 550340,
    "end": 551340,
    "text": "GPT-1であった。"
  },
  {
    "start": 551380,
    "end": 557940,
    "text": "GPT-2の頃、微調整よりも、実はこのモデルを非常に効果的に促せることに気づいた人がいました。"
  },
  {
    "start": 557940,
    "end": 560620,
    "text": "言語モデルであり、ドキュメントを完成させたいと考えています。"
  },
  {
    "start": 560620,
    "end": 565860,
    "text": "このような偽の書類を用意するだけで、実際に相手を騙して仕事をさせることができます。"
  },
  {
    "start": 565860,
    "end": 571700,
    "text": "この例では、例えば、ある通路があり、その後、QA、QA、QAを行うような感じです。"
  },
  {
    "start": 571700,
    "end": 572700,
    "text": "これを数撃ちゃ当たるプロンプトといいます。"
  },
  {
    "start": 572700,
    "end": 573700,
    "text": "Qを行う。"
  },
  {
    "start": 573700,
    "end": 578140,
    "text": "トランスフォーマーがドキュメントを完成させようとしているとき、実は私たちの質問に答えているのです。"
  },
  {
    "start": 578140,
    "end": 585939,
    "text": "これは、ベースモデルをプロンプトエンジニアリングして、ドキュメントを模倣したかのように思わせて、タスクを実行させる例です。"
  },
  {
    "start": 585939,
    "end": 593256,
    "text": "これは、微調整を促し、実際に多くの問題に対して非常にうまく機能することを確認する時代と言えると思います、"
  },
  {
    "start": 593256,
    "end": 597620,
    "text": "ニューラルネットワークのトレーニングやファインチューニングなどを一切行わずとも"
  },
  {
    "start": 597620,
    "end": 603300,
    "text": "それ以来、誰もがトレーニングしたベースモデルの進化系ツリー全体が見られるようになったのです。"
  },
  {
    "start": 603300,
    "end": 605540,
    "text": "すべての機種に対応しているわけではありません。"
  },
  {
    "start": 605540,
    "end": 608420,
    "text": "例えば、ベースモデルのGPT-4は発売されませんでした。"
  },
  {
    "start": 608420,
    "end": 612300,
    "text": "APIでやりとりするようなGPT-4モデルは、ベースモデルではない。"
  },
  {
    "start": 612300,
    "end": 613300,
    "text": "アシスタントモデルなんです。"
  },
  {
    "start": 613300,
    "end": 616180,
    "text": "その入手方法については、これから少しずつ説明していきます。"
  },
  {
    "start": 616180,
    "end": 620780,
    "text": "GPT-3のベースモデルは、DaVinciの名称でAPIから利用できます。"
  },
  {
    "start": 620780,
    "end": 624980,
    "text": "GPT-2ベースモデルは、GitHubのレポでweightsでも利用可能です。"
  },
  {
    "start": 624980,
    "end": 634020,
    "text": "現在、ベースモデルとして最適なのは、商用ライセンスはないものの、Meta社のllamaシリーズでしょう。"
  },
  {
    "start": 634020,
    "end": 636900,
    "text": "今ひとつ、ベースモデルはアシストではないことを指摘しておきたい。"
  },
  {
    "start": 636900,
    "end": 641420,
    "text": "彼らはあなたの質問に対して答えを作ろうとしない。"
  },
  {
    "start": 641420,
    "end": 643340,
    "text": "書類を完成させたいだけなのです。"
  },
  {
    "start": 643340,
    "end": 649460,
    "text": "パンとチーズの詩を書け」と言えば、質問にさらに質問で答えてくれる。"
  },
  {
    "start": 649460,
    "end": 651460,
    "text": "ドキュメントと思われるものを完成させているところです。"
  },
  {
    "start": 651460,
    "end": 658380,
    "text": "ベースモデルの場合は具体的な方法で催促することができるので、うまくいく可能性が高くなります。"
  },
  {
    "start": 658380,
    "end": 660020,
    "text": "例に、パンとチーズに関する詩を紹介します。"
  },
  {
    "start": 660020,
    "end": 663060,
    "text": "正しくオートコンプリートされます。"
  },
  {
    "start": 663100,
    "end": 666460,
    "text": "ベースモデルを騙してアシスタントにすることも可能です。"
  },
  {
    "start": 666460,
    "end": 676580,
    "text": "そのためには、人間とアシスタントの間に何らかの文書があり、情報を交換しているように見える、特定の数ショットのプロンプトを作成することです。"
  },
  {
    "start": 676580,
    "end": 687020,
    "text": "そうすると、ベースモデルは、親切なアシスタントになり、答えてくれるようになるのです。"
  },
  {
    "start": 687020,
    "end": 691300,
    "text": "できることではありますが、あまり信頼性が高くなく、実際には超効果的ではありません。"
  },
  {
    "start": 691300,
    "end": 697380,
    "text": "その代わり、ベースモデルのドキュメント完成者だけでなく、実際のGPTアシスタントを作るための別の道も用意しています。"
  },
  {
    "start": 697380,
    "end": 699920,
    "text": "微調整の監修に入ることになりました。"
  },
  {
    "start": 699920,
    "end": 705860,
    "text": "教師ありの微調整の段階では、小さくても質の高いデータセットを集めようと思っています。"
  },
  {
    "start": 705860,
    "end": 712940,
    "text": "今回は、フォームプロンプトと理想的なレスポンスのデータを収集するために、人間のコントラクターに依頼します。"
  },
  {
    "start": 712940,
    "end": 717000,
    "text": "これを大量に、それも数万個とか集めていくわけです。"
  },
  {
    "start": 717000,
    "end": 719660,
    "text": "やはりこのデータで言語モデリングを行うことになります。"
  },
  {
    "start": 719660,
    "end": 721220,
    "text": "アルゴリズム的には何も変わっていません。"
  },
  {
    "start": 721220,
    "end": 723020,
    "text": "トレーニングセットを入れ替えただけです。"
  },
  {
    "start": 723020,
    "end": 731720,
    "text": "以前はインターネット上の文書で、基本的にQA即応型のデータとして、高容量のローカルなものでした。"
  },
  {
    "start": 731720,
    "end": 734380,
    "text": "少量多品種、高品質で提供します。"
  },
  {
    "start": 734380,
    "end": 735700,
    "text": "言語モデリングは今でもやっています。"
  },
  {
    "start": 735700,
    "end": 738620,
    "text": "トレーニング後、SFTモデルを得る。"
  },
  {
    "start": 738620,
    "end": 740420,
    "text": "これらのモデルを実際に展開することができます。"
  },
  {
    "start": 740420,
    "end": 743180,
    "text": "実際にアシスタントをやっていて、ある程度は機能しています。"
  },
  {
    "start": 743180,
    "end": 745980,
    "text": "デモの例として、どのようなものがあるのか紹介しましょう。"
  },
  {
    "start": 745980,
    "end": 748500,
    "text": "人間のコントラクターが思いつきそうなことです。"
  },
  {
    "start": 748500,
    "end": 749500,
    "text": "ランダムにプロンプトを表示します。"
  },
  {
    "start": 749820,
    "end": 754700,
    "text": "モノソニーという言葉の関連性について、簡単な紹介文を書いてもらえますか？"
  },
  {
    "start": 754700,
    "end": 757660,
    "text": "コントラクターも理想的な回答を書き出す。"
  },
  {
    "start": 757660,
    "end": 761700,
    "text": "このような回答は、ラベルに記載された膨大な資料をもとに作成されています。"
  },
  {
    "start": 761700,
    "end": 765800,
    "text": "求められているのです。"
  },
  {
    "start": 765800,
    "end": 768600,
    "text": "これは、こちらのラベリング指示です。"
  },
  {
    "start": 768600,
    "end": 769900,
    "text": "おそらく読めないと思います。"
  },
  {
    "start": 769900,
    "end": 770900,
    "text": "私にもできません。"
  },
  {
    "start": 770900,
    "end": 772100,
    "text": "長いんです。"
  },
  {
    "start": 772100,
    "end": 776380,
    "text": "これは、人々が指示に従って、これらのプロンプトを完了しようとしているだけです。"
  },
  {
    "start": 776380,
    "end": 777380,
    "text": "というのがデータセットの様子です。"
  },
  {
    "start": 777380,
    "end": 778580,
    "text": "このようなモデルをトレーニングすることができます。"
  },
  {
    "start": 778660,
    "end": 780460,
    "text": "ある程度効果があります。"
  },
  {
    "start": 780460,
    "end": 790820,
    "text": "ここから先は、実際にパイプラインを進めて、報酬モデルと強化学習の両方で構成されるRLHF（人間のフィードバックからの強化学習）へと進むことができます。"
  },
  {
    "start": 790820,
    "end": 791820,
    "text": "それをカバーさせてください。"
  },
  {
    "start": 791820,
    "end": 796760,
    "text": "その上で、なぜ余計な手順を踏む必要があるのか、SFTモデルだけと比較してどうなのかを説明したいと思います。"
  },
  {
    "start": 796760,
    "end": 803280,
    "text": "報酬のモデル化のステップでは、データ収集を比較の形に変えています。"
  },
  {
    "start": 803280,
    "end": 805820,
    "text": "ここでは、データセットがどのようなものになるかの例を示します。"
  },
  {
    "start": 805820,
    "end": 815740,
    "text": "同じプロンプト、同じプロンプトが上部にあり、与えられた文字列が回文であるかどうかをチェックするプログラムまたは関数を書くようにアシスタントに求めているのです。"
  },
  {
    "start": 815740,
    "end": 821260,
    "text": "すでに学習させたSFTモデルを用いて、複数のコンプリートを作成するのです。"
  },
  {
    "start": 821260,
    "end": 824380,
    "text": "この場合、モデルが作成した3つの完成形があります。"
  },
  {
    "start": 824380,
    "end": 827180,
    "text": "その完成度をランク付けしてもらうのです。"
  },
  {
    "start": 827180,
    "end": 833060,
    "text": "しばらくこれを眺めていると、ところで、これらの予測のいくつかを比較するのは非常に難しいことなのです。"
  },
  {
    "start": 833060,
    "end": 838500,
    "text": "1組のプロンプトが完成するまでに数時間かかることもあります。"
  },
  {
    "start": 838500,
    "end": 842060,
    "text": "このうち1つは他のものよりもずっと優れている、などと決めたとします。"
  },
  {
    "start": 842060,
    "end": 843640,
    "text": "ランク付けします。"
  },
  {
    "start": 843640,
    "end": 850500,
    "text": "次に、これらの補完の間の可能なすべてのペアについて、二項分類のように非常によく見えるものを使用することができます。"
  },
  {
    "start": 850500,
    "end": 856340,
    "text": "プロンプトは3列とも同じものです。"
  },
  {
    "start": 856340,
    "end": 857700,
    "text": "すべて同じプロンプトです。"
  },
  {
    "start": 857700,
    "end": 859460,
    "text": "完成度は様々です。"
  },
  {
    "start": 859460,
    "end": 862300,
    "text": "黄色いトークンはSFTモデルから登場します。"
  },
  {
    "start": 862300,
    "end": 867580,
    "text": "最後にもう1つ、特別な報酬の読み上げトークンを追加するのです。"
  },
  {
    "start": 867580,
    "end": 872060,
    "text": "私たちは、基本的にこの緑一色のトークンのみで変圧器を監修しています。"
  },
  {
    "start": 872060,
    "end": 878580,
    "text": "そのプロンプトに対する完成度の高さに対して、トランスフォーマーが何らかの報酬を予測します。"
  },
  {
    "start": 878580,
    "end": 882440,
    "text": "基本的には各完成品のクオリティを推測しています。"
  },
  {
    "start": 882440,
    "end": 888180,
    "text": "その一つひとつを推測した後、その順位を教えてくれるグランドトゥルースもあります。"
  },
  {
    "start": 888180,
    "end": 891740,
    "text": "ある数値は他の数値よりもずっと高いはずだと、実際に強制することができます。"
  },
  {
    "start": 891740,
    "end": 892740,
    "text": "というように。"
  },
  {
    "start": 892740,
    "end": 894100,
    "text": "これを損失関数に定式化する。"
  },
  {
    "start": 894100,
    "end": 901480,
    "text": "このような業者間の比較から得られる真実と一致する報酬予測を行うよう、モデルを訓練します。"
  },
  {
    "start": 901480,
    "end": 903020,
    "text": "私たちの報酬モデルのトレーニング方法です。"
  },
  {
    "start": 903020,
    "end": 907700,
    "text": "これは、プロンプトに対する完成度の高さをスコア化することができるものです。"
  },
  {
    "start": 907700,
    "end": 913540,
    "text": "報酬モデルができてしまうと、これだけではアシスタントとして使い勝手が悪いので、展開できないのです。"
  },
  {
    "start": 913540,
    "end": 917420,
    "text": "この後の強化学習の段階でも、とても役に立ちます。"
  },
  {
    "start": 917420,
    "end": 923219,
    "text": "報酬モデルがあるので、任意のプロンプトに対して任意の完成度の高さをスコア化することができます。"
  },
  {
    "start": 923219,
    "end": 928000,
    "text": "強化学習では、基本的に、大量のプロンプトのコレクションを入手します。"
  },
  {
    "start": 928000,
    "end": 930980,
    "text": "報酬モデルに関する強化学習を行っています。"
  },
  {
    "start": 930980,
    "end": 933260,
    "text": "こんな感じです。"
  },
  {
    "start": 933260,
    "end": 934579,
    "text": "プロンプトを1枚撮ります。"
  },
  {
    "start": 934579,
    "end": 936400,
    "text": "列で並べるんです。"
  },
  {
    "start": 936400,
    "end": 943939,
    "text": "基本的にSFTモデルで初期化された学習したいモデルを使って、黄色の補完をいくつか作ってみます。"
  },
  {
    "start": 943939,
    "end": 946459,
    "text": "その後、報酬トークンを再度追加する。"
  },
  {
    "start": 946459,
    "end": 950620,
    "text": "報酬モデルに従って報酬を読み上げるのですが、その報酬は固定されたままです。"
  },
  {
    "start": 950620,
    "end": 952420,
    "text": "もう変わりませんね。"
  },
  {
    "start": 952420,
    "end": 957460,
    "text": "報酬モデルは、これらのプロンプトに対するすべての完了の質を教えてくれます。"
  },
  {
    "start": 957460,
    "end": 962060,
    "text": "あとは基本的に同じ言語モデリングの損失関数を適用すればいいわけです。"
  },
  {
    "start": 962060,
    "end": 965140,
    "text": "現在、黄色のトークンでトレーニング中です。"
  },
  {
    "start": 965140,
    "end": 971540,
    "text": "言語モデリングの目的と、報酬モデルの示す報酬を天秤にかけているのです。"
  },
  {
    "start": 971540,
    "end": 977900,
    "text": "例にとると、1行目では、報酬モデルから「これはかなり高得点の完成度だ。"
  },
  {
    "start": 977900,
    "end": 982459,
    "text": "たまたま1列目にサンプリングしたトークンがすべて強化されることになります。"
  },
  {
    "start": 982459,
    "end": 985140,
    "text": "将来的にはより高い確率で取得できるようになるそうです。"
  },
  {
    "start": 985140,
    "end": 989140,
    "text": "逆に、2列目では、報酬モデルはこの完成を本当に嫌がりました。"
  },
  {
    "start": 989140,
    "end": 990140,
    "text": "ネガティブ1.2"
  },
  {
    "start": 990140,
    "end": 996459,
    "text": "したがって、その2行目でサンプリングしたトークンはすべて、将来的に少し高い確率を得ることになります。"
  },
  {
    "start": 996459,
    "end": 999500,
    "text": "これを何度も何度も、多くのプロンプトで、多くのバッチで繰り返しています。"
  },
  {
    "start": 999500,
    "end": 1003300,
    "text": "基本的には、ここで黄色いトークンを作成するポリシーを取得します。"
  },
  {
    "start": 1003300,
    "end": 1011640,
    "text": "前段で学習させた報酬モデルに従って、ここでの完成度はすべて高得点になります。"
  },
  {
    "start": 1011640,
    "end": 1013140,
    "text": "私たちのトレーニング方法です。"
  },
  {
    "start": 1013140,
    "end": 1016340,
    "text": "それが、RLHFのパイプラインです。"
  },
  {
    "start": 1016340,
    "end": 1018780,
    "text": "そして最後に、展開可能なモデルを手に入れることができるのです。"
  },
  {
    "start": 1018780,
    "end": 1022780,
    "text": "例に挙げると、ChatGPTはRLHFモデルです。"
  },
  {
    "start": 1022780,
    "end": 1028380,
    "text": "例えば、「Kuna 13B」などは、SFTのモデルです。"
  },
  {
    "start": 1028380,
    "end": 1032060,
    "text": "ベースモデル、SFTモデル、RLHFモデルがあります。"
  },
  {
    "start": 1032060,
    "end": 1035020,
    "text": "現地の様子みたいですね。"
  },
  {
    "start": 1035020,
    "end": 1037159,
    "text": "なぜRLHFをやろうと思ったのでしょうか？"
  },
  {
    "start": 1037159,
    "end": 1041060,
    "text": "その方がうまくいくという答えがあるんです。"
  },
  {
    "start": 1041060,
    "end": 1043300,
    "text": "これはInstructGPTの論文からきています。"
  },
  {
    "start": 1043300,
    "end": 1048220,
    "text": "少し前の実験によると、これらのPPOモデルはRLHFだそうです。"
  },
  {
    "start": 1048220,
    "end": 1052215,
    "text": "基本的に多くの比較で優先されるだけであることがわかります。"
  },
  {
    "start": 1052215,
    "end": 1054139,
    "text": "人間に与えるとき。"
  },
  {
    "start": 1054139,
    "end": 1062380,
    "text": "人間は、SFTモデルよりもRLHFモデル、アシスタントとして促されるベースモデルよりも、基本的にトークンを好むものなのです。"
  },
  {
    "start": 1062380,
    "end": 1064100,
    "text": "で、より効果的です。"
  },
  {
    "start": 1064100,
    "end": 1066300,
    "text": "と聞くかもしれませんが、なぜでしょう？"
  },
  {
    "start": 1066300,
    "end": 1067460,
    "text": "なぜ、より効果があるのでしょうか？"
  },
  {
    "start": 1067460,
    "end": 1072380,
    "text": "コミュニティが本当に納得するような素晴らしい答えは、ひとつもないと思います。"
  },
  {
    "start": 1072380,
    "end": 1075820,
    "text": "私はただ、潜在的に一つの理由を提示します。"
  },
  {
    "start": 1075820,
    "end": 1082500,
    "text": "それは、比較と生成の計算のしやすさの非対称性に関係しています。"
  },
  {
    "start": 1082500,
    "end": 1085300,
    "text": "俳句を生成することを例にしてみましょう。"
  },
  {
    "start": 1085300,
    "end": 1088300,
    "text": "例えば、モデルさんに「クリップの俳句を作ってください」とお願いしたとします。"
  },
  {
    "start": 1088300,
    "end": 1094500,
    "text": "トレーニングデータを与えようとする業者なら、SFTの段階で基本的にデータを収集する業者であることを想像してください。"
  },
  {
    "start": 1094500,
    "end": 1096940,
    "text": "クリップに素敵な俳句を作るにはどうしたらいいんだろう？"
  },
  {
    "start": 1096940,
    "end": 1099020,
    "text": "あなたが苦手なだけかもしれません。"
  },
  {
    "start": 1099020,
    "end": 1104419,
    "text": "俳句の例をいくつか挙げてみると、ある俳句は他の俳句よりずっと評価できるかもしれません。"
  },
  {
    "start": 1104419,
    "end": 1107680,
    "text": "どれがいいのか判断するのは、もっと簡単なことです。"
  },
  {
    "start": 1107680,
    "end": 1118260,
    "text": "この非対称性によって、比較は、人間としての判断力を活かして、より良いモデルを作ることができる可能性があるのです。"
  },
  {
    "start": 1118260,
    "end": 1123860,
    "text": "今のRLHFモデルは、厳密にはベースモデルの改良ではないケースもある。"
  },
  {
    "start": 1123860,
    "end": 1127100,
    "text": "特に、エントロピーが失われることなどが分かっています。"
  },
  {
    "start": 1127100,
    "end": 1129900,
    "text": "よりピーキーな結果を出すということです。"
  },
  {
    "start": 1129900,
    "end": 1136220,
    "text": "ベースモデルよりもバリエーションが少ないサンプルを出力できるとか。"
  },
  {
    "start": 1136220,
    "end": 1140379,
    "text": "ベースモデルはエントロピーが大きいので、多様なアウトプットをたくさん出すことができます。"
  },
  {
    "start": 1140379,
    "end": 1153900,
    "text": "例えば、私がベースモデルを使いたいと思うのは、基本的にn個のモノがあり、そのようなモノをさらに生成したい場合です。"
  },
  {
    "start": 1153900,
    "end": 1156460,
    "text": "今作った例です。"
  },
  {
    "start": 1156460,
    "end": 1158900,
    "text": "かっこいいポケモンの名前を生み出したい。"
  },
  {
    "start": 1158900,
    "end": 1160340,
    "text": "ポケモンの名前を7つ付けました。"
  },
  {
    "start": 1160340,
    "end": 1164980,
    "text": "ベースモデルにドキュメントを完成させてもらったら、ポケモンの名前がたくさん増えました。"
  },
  {
    "start": 1164980,
    "end": 1165980,
    "text": "これらは架空のものです。"
  },
  {
    "start": 1165980,
    "end": 1167060,
    "text": "調べようとしたんです。"
  },
  {
    "start": 1167060,
    "end": 1169260,
    "text": "実際のポケモンとは思えません。"
  },
  {
    "start": 1169260,
    "end": 1175129,
    "text": "このようなタスクは、ベースモデルが得意とするところだと思います。まだエントロピーが多く、多様なものを与えてくれるでしょうから、"
  },
  {
    "start": 1175129,
    "end": 1180720,
    "text": "もっと、もっと、もっと、もっと、もっと、もっと。"
  },
  {
    "start": 1180720,
    "end": 1187780,
    "text": "とはいえ、これは現時点でのアシスタントモデルのようなもので、おそらく利用可能なものです。"
  },
  {
    "start": 1187780,
    "end": 1193580,
    "text": "バークレー校のチームが、入手可能な多くのアシスタントモデルをランク付けし、基本的にELOの評価を与えています。"
  },
  {
    "start": 1193580,
    "end": 1205140,
    "text": "現在、最も優れたモデルのいくつかは、もちろんGPT-4がダントツで、次いでクロード、GPT-3.5、そして、クーナ、コアラなどのように、ウェイトとして利用できるモデルもいくつかあります。"
  },
  {
    "start": 1205140,
    "end": 1215580,
    "text": "最初の3列はすべてRLHFモデルで、それ以外は私の知る限りではSFTモデルだと思います。"
  },
  {
    "start": 1215580,
    "end": 1216780,
    "text": "そうですか。"
  },
  {
    "start": 1216780,
    "end": 1219580,
    "text": "このモデルの高いレベルでのトレーニング方法です。"
  },
  {
    "start": 1219580,
    "end": 1221416,
    "text": "話は変わりますが。"
  },
  {
    "start": 1221416,
    "end": 1226020,
    "text": "GPTアシスタントのモデルをどのように活用すればよいのかを見ていきましょう。"
  },
  {
    "start": 1226500,
    "end": 1230139,
    "text": "今度は具体的な事例を設定した上で、仕事をしていきたいと思います。"
  },
  {
    "start": 1230139,
    "end": 1233379,
    "text": "ここでは、具体的な例を挙げて説明します。"
  },
  {
    "start": 1233379,
    "end": 1238198,
    "text": "例えば、記事やブログの記事を作っていて、最後にこの文章を書くとします、"
  },
  {
    "start": 1238198,
    "end": 1245500,
    "text": "カリフォルニア州の人口はアラスカ州の53倍なので、なぜかこの2つの州の人口を比較したくなるのでしょう。"
  },
  {
    "start": 1245500,
    "end": 1253540,
    "text": "この最後の一文を生成するために、豊富な内部モノローグとツールの使用、そして実際に脳内でどれだけの計算が行われているかを考えてみてください。"
  },
  {
    "start": 1253540,
    "end": 1255500,
    "text": "あなたの脳内では、こんな風に見えるかもしれません。"
  },
  {
    "start": 1255500,
    "end": 1256500,
    "text": "そうですか。"
  },
  {
    "start": 1256500,
    "end": 1261060,
    "text": "この次のステップでは、ブログ、つまり私のブログで、この2つの集団を比較してみましょう。"
  },
  {
    "start": 1261060,
    "end": 1262060,
    "text": "そうですか。"
  },
  {
    "start": 1262060,
    "end": 1265379,
    "text": "まず、この2つの集団を手に入れることが必要です。"
  },
  {
    "start": 1265379,
    "end": 1269220,
    "text": "今となっては、私はこれらの人口を頭から知っているわけではないのだろうと思います。"
  },
  {
    "start": 1269220,
    "end": 1273440,
    "text": "私はなんというか、自分の自己認識を知っているか知らないか、みたいなことを意識しているんですね。"
  },
  {
    "start": 1273440,
    "end": 1280340,
    "text": "ウィキペディアでカリフォルニアの人口とアラスカの人口を調べたり、ツールを使ったり。"
  },
  {
    "start": 1280340,
    "end": 1287139,
    "text": "今、私はこの2つを割るべきだと知っているが、また、39.2を0.74で割ることが成功する可能性は非常に低いことも知っている。"
  },
  {
    "start": 1287139,
    "end": 1289820,
    "text": "そんなの、頭で考えても無理な話です。"
  },
  {
    "start": 1289820,
    "end": 1292620,
    "text": "電卓に頼ることにします。"
  },
  {
    "start": 1292620,
    "end": 1297419,
    "text": "電卓を使って、打ち込んで、出力がだいたい53になるのを確認します。"
  },
  {
    "start": 1297419,
    "end": 1300899,
    "text": "と言って、自分の脳内で反省と正気度を確認するのかもしれません。"
  },
  {
    "start": 1300899,
    "end": 1302500,
    "text": "53は意味があるのでしょうか？"
  },
  {
    "start": 1302500,
    "end": 1308260,
    "text": "まあ、かなり大きな割合ですが、カリフォルニアは最も人口の多い州ですから、大丈夫そうですね。"
  },
  {
    "start": 1308300,
    "end": 1313040,
    "text": "必要な情報はすべて手に入れたので、あとは文章を書くというクリエイティブな部分に取り掛かります。"
  },
  {
    "start": 1313040,
    "end": 1320480,
    "text": "カリフォルニアは53倍の面積がある」と書き始めても、「これって、実はすごく不自然な表現だな」と思ってしまう。"
  },
  {
    "start": 1320480,
    "end": 1323700,
    "text": "削除して、もう一度やり直してみます。"
  },
  {
    "start": 1323700,
    "end": 1331260,
    "text": "書いている最中には、書いているものを点検して、良し悪しを判断するような作業が別にあるんです。"
  },
  {
    "start": 1331260,
    "end": 1336020,
    "text": "削除して、リフレームして、出てきたものに満足するのかもしれません。"
  },
  {
    "start": 1336060,
    "end": 1342260,
    "text": "このような文章を作るとき、あなたの内的な独白の中で、多くのことが起こっているのです。"
  },
  {
    "start": 1342260,
    "end": 1347620,
    "text": "というような文章がありますが、これをGPTのトレーニングにするとどのようになるのでしょうか？"
  },
  {
    "start": 1347620,
    "end": 1350860,
    "text": "GPTから見れば、これは単なるトークンの列です。"
  },
  {
    "start": 1350860,
    "end": 1356700,
    "text": "GPTは、トークンを読み込むとき、あるいは生成するとき、チャンク、チャンク、チャンク、チャンク、チャンクと進むだけです。"
  },
  {
    "start": 1356700,
    "end": 1360720,
    "text": "各チャンクは、各トークンに対してほぼ同じ量の計算を行う。"
  },
  {
    "start": 1360720,
    "end": 1363420,
    "text": "これらのトランスは、あまり浅いネットワークではありません。"
  },
  {
    "start": 1363420,
    "end": 1365620,
    "text": "約80層の理屈があるそうです。"
  },
  {
    "start": 1365620,
    "end": 1367780,
    "text": "80は、まだ、多くないです。"
  },
  {
    "start": 1367780,
    "end": 1371660,
    "text": "このトランスは全力で真似をするつもりです。"
  },
  {
    "start": 1371660,
    "end": 1376780,
    "text": "もちろん、ここでのプロセスは、あなたが取ったプロセスとはまったく、まったく違うように見えます。"
  },
  {
    "start": 1376780,
    "end": 1386300,
    "text": "特に、私たちが作成し、最終的にLLMに提供するデータセットの最終成果物では、そのような内部対話はすべて完全に取り除かれています。"
  },
  {
    "start": 1386300,
    "end": 1392340,
    "text": "GPTはあなたと違って、すべてのトークンを見て、そのすべてに同じ量の計算を費やすことになります。"
  },
  {
    "start": 1392340,
    "end": 1399899,
    "text": "だから、トークン1個あたりの仕事量が多すぎるというようなことは、実際には期待できないんです。"
  },
  {
    "start": 1399899,
    "end": 1403980,
    "text": "特に、基本的にこのトランスは、トークンのシミュレーターのようなものです。"
  },
  {
    "start": 1403980,
    "end": 1405899,
    "text": "知らないことを知らない。"
  },
  {
    "start": 1405899,
    "end": 1408179,
    "text": "次のトークンの真似をするだけ、みたいな。"
  },
  {
    "start": 1408179,
    "end": 1409860,
    "text": "自分の得意なこと、不得意なことがわからないのです。"
  },
  {
    "start": 1409860,
    "end": 1412500,
    "text": "次のトークンの真似をしようと頑張るのです。"
  },
  {
    "start": 1412500,
    "end": 1414220,
    "text": "ループに反映されない。"
  },
  {
    "start": 1414220,
    "end": 1415620,
    "text": "彼らは何もサニティーチェックをしない。"
  },
  {
    "start": 1415620,
    "end": 1418100,
    "text": "彼らはデフォルトで途中の間違いを修正することはない。"
  },
  {
    "start": 1418100,
    "end": 1421060,
    "text": "トークン配列をサンプリングしているだけです。"
  },
  {
    "start": 1421100,
    "end": 1423899,
    "text": "彼らは頭の中で別々の内的独白の流れを持っているわけではありませんよね？"
  },
  {
    "start": 1423899,
    "end": 1425780,
    "text": "何が起こっているのかを評価しているのです。"
  },
  {
    "start": 1425780,
    "end": 1429620,
    "text": "今、彼らはある種の認知的な優位性を持っていると言えるでしょう。"
  },
  {
    "start": 1429620,
    "end": 1437179,
    "text": "例えば100億のパラメータをいくつも持っているので、膨大な数の領域にわたって非常に大きな事実に基づく知識を持っているのです。"
  },
  {
    "start": 1437179,
    "end": 1440500,
    "text": "多くの事実のための多くのストレージです。"
  },
  {
    "start": 1440500,
    "end": 1444899,
    "text": "彼らは、比較的大きく完璧なワーキングメモリを持っていると思います。"
  },
  {
    "start": 1444899,
    "end": 1452700,
    "text": "コンテキストウィンドウに適合するものは何でも、トランスフォーマー内部の自己注意メカニズムによって即座に利用可能です。"
  },
  {
    "start": 1452700,
    "end": 1456660,
    "text": "完全記憶と同じようなものですが、サイズが有限なんです。"
  },
  {
    "start": 1456660,
    "end": 1458780,
    "text": "トランスは非常にダイレクトにアクセスできます。"
  },
  {
    "start": 1458780,
    "end": 1464340,
    "text": "コンテキストウィンドウの中にあるものをロスレスで記憶することができます。"
  },
  {
    "start": 1464340,
    "end": 1466120,
    "text": "この2つを比較したときの感想です。"
  },
  {
    "start": 1466120,
    "end": 1477420,
    "text": "なぜこのような話をしたかというと、プロンプトは、この2種類のアーキテクチャの認知の違いを補っているに過ぎないと思うのです。"
  },
  {
    "start": 1477420,
    "end": 1479700,
    "text": "ここの脳みそやLLMの脳みそのように。"
  },
  {
    "start": 1479700,
    "end": 1482260,
    "text": "ほとんどそのように見ることができます。"
  },
  {
    "start": 1482260,
    "end": 1485940,
    "text": "例えば、ある人が見つけた、実際にかなり効果があるものを紹介します。"
  },
  {
    "start": 1485940,
    "end": 1488340,
    "text": "特に、推理が必要なタスクの場合はなおさらです。"
  },
  {
    "start": 1488340,
    "end": 1492540,
    "text": "トランスフォーマーには、トークン1個あたりの推論をあまり期待しないほうがいいでしょう。"
  },
  {
    "start": 1492540,
    "end": 1496220,
    "text": "より多くのトークンに推論を分散させる必要があるのです。"
  },
  {
    "start": 1496220,
    "end": 1500900,
    "text": "例えば、トランスフォーマーに非常に複雑な質問を与えて、1トークンで答えを得ることを期待することはできません。"
  },
  {
    "start": 1500900,
    "end": 1503020,
    "text": "時間が足りないんです。"
  },
  {
    "start": 1503020,
    "end": 1507160,
    "text": "このようなトランスフォーマーには、考えるためのトークンが必要なのです。"
  },
  {
    "start": 1507160,
    "end": 1509140,
    "text": "これは効果的なものの一部です。"
  },
  {
    "start": 1509140,
    "end": 1516140,
    "text": "例えば、トランスフォーマーが質問に答えるときに、「自分の仕事を見せるようにしましょう」と示す数ショットのプロンプトを用意することができます。"
  },
  {
    "start": 1516140,
    "end": 1520020,
    "text": "いくつかの例を挙げれば、トランスフォーマーはそのテンプレートを模倣することになる。"
  },
  {
    "start": 1520020,
    "end": 1524340,
    "text": "結局のところ、評価としてはうまくいくだけなのです。"
  },
  {
    "start": 1524340,
    "end": 1529600,
    "text": "「ステップバイステップで考えよう」と言えば、トランスフォーマーからこのような行動を引き出すことができます。"
  },
  {
    "start": 1529600,
    "end": 1533860,
    "text": "なぜなら、これによってトランスフォーマーが自分の仕事を見せるような状態になるからです。"
  },
  {
    "start": 1533860,
    "end": 1540260,
    "text": "トークンは、自分の仕事を見せるためにスナップするようなものなので、トークン1つあたりの計算量が少なくなるのです。"
  },
  {
    "start": 1540260,
    "end": 1542699,
    "text": "で、結果的に成功する可能性が高くなります。"
  },
  {
    "start": 1542699,
    "end": 1546740,
    "text": "時間をかけてゆっくりとした推論をしているからです。"
  },
  {
    "start": 1546740,
    "end": 1547740,
    "text": "別の例を挙げます。"
  },
  {
    "start": 1547740,
    "end": 1550060,
    "text": "こちらは自己矛盾と呼ばれるものです。"
  },
  {
    "start": 1550060,
    "end": 1552939,
    "text": "書き始める力があることを確認しました。"
  },
  {
    "start": 1552939,
    "end": 1555179,
    "text": "うまくいかなかった場合は、もう一度チャレンジすることもできるんです。"
  },
  {
    "start": 1555179,
    "end": 1560760,
    "text": "何度も試して、一番うまくいったものを選ぶことができるかもしれません。"
  },
  {
    "start": 1560760,
    "end": 1572220,
    "text": "このようなアプローチでは、1回だけでなく、複数回サンプリングして、良いものを見つけて、そのサンプルだけを残すか、多数決で決めるなど、何らかのプロセスを踏むことがあります。"
  },
  {
    "start": 1572220,
    "end": 1578180,
    "text": "このようなトランスフォーマーは、基本的に次のトークンを予測する過程で、あなたと同じように、彼らは不運になることができます。"
  },
  {
    "start": 1578180,
    "end": 1580500,
    "text": "サンプリングすることができます。"
  },
  {
    "start": 1580500,
    "end": 1584100,
    "text": "理屈をこねくり回しているようなものです。"
  },
  {
    "start": 1584100,
    "end": 1587260,
    "text": "で、あなたと違って、そこから回復することはできません。"
  },
  {
    "start": 1587260,
    "end": 1589660,
    "text": "彼らは、サンプリングしたトークンの一つ一つにこだわっているのです。"
  },
  {
    "start": 1589660,
    "end": 1594380,
    "text": "だから、たとえこの順番がうまくいかないとわかっていても、その順番を続けるのです。"
  },
  {
    "start": 1594380,
    "end": 1601500,
    "text": "振り返ったり、検査したり、基本的にサンプリングしてみたりすることができるようにします。"
  },
  {
    "start": 1601500,
    "end": 1603860,
    "text": "こちらも1つのテクニックです。"
  },
  {
    "start": 1603860,
    "end": 1607620,
    "text": "実はLLMは、自分が失敗したときに、その失敗を知ることができるんです。"
  },
  {
    "start": 1607620,
    "end": 1613700,
    "text": "例えば、韻を踏まない詩を生成するようモデルに依頼するとします。"
  },
  {
    "start": 1613700,
    "end": 1616220,
    "text": "という詩が出るかもしれませんが、実は韻を踏んでいるんです。"
  },
  {
    "start": 1616220,
    "end": 1621060,
    "text": "特にGPT-4のような大きな機種では、「課題はクリアできたか」と聞けばいいことがわかります。"
  },
  {
    "start": 1621300,
    "end": 1625020,
    "text": "実は、GPT-4は課題をクリアしていないことをよく知っています。"
  },
  {
    "start": 1625020,
    "end": 1627419,
    "text": "サンプリングに不運があっただけです。"
  },
  {
    "start": 1627419,
    "end": 1629419,
    "text": "「いや、実は課題をクリアしていないんだ」と教えてくれるのです。"
  },
  {
    "start": 1629419,
    "end": 1631220,
    "text": "ほら、もう一回やってみようか。"
  },
  {
    "start": 1631220,
    "end": 1637820,
    "text": "促さないと、再訪問することすらわからない、みたいな感じです。"
  },
  {
    "start": 1637820,
    "end": 1640179,
    "text": "その分、プロンプトで補う必要があります。"
  },
  {
    "start": 1640179,
    "end": 1642139,
    "text": "確認してもらわなければなりません。"
  },
  {
    "start": 1642139,
    "end": 1644300,
    "text": "確認するように言わなければ、勝手に確認することはない。"
  },
  {
    "start": 1644300,
    "end": 1649179,
    "text": "ただのトークン・シミュレーターです。"
  },
  {
    "start": 1649220,
    "end": 1654820,
    "text": "もっと一般的に言えば、これらの技術の多くは、私たちのシステム2の再現と言うべきバケツに入るのだと思います。"
  },
  {
    "start": 1654820,
    "end": 1658260,
    "text": "人間にはシステム1、システム2の考え方があることをご存知でしょうか。"
  },
  {
    "start": 1658260,
    "end": 1660300,
    "text": "システム1は、高速で自動処理されます。"
  },
  {
    "start": 1660300,
    "end": 1664020,
    "text": "LLMがトークンをサンプリングしているようなものだと思うんです。"
  },
  {
    "start": 1664020,
    "end": 1669500,
    "text": "システム2は、脳の中のゆっくりした、計画的な部分です。"
  },
  {
    "start": 1669500,
    "end": 1674340,
    "text": "これはつい先週の論文なのですが、この空間はかなり急速に進化しています。"
  },
  {
    "start": 1674340,
    "end": 1675660,
    "text": "Tree of Thoughtという名前です。"
  },
  {
    "start": 1675660,
    "end": 1682660,
    "text": "この論文では、『Tree of Thought』において、任意のプロンプトに対して複数のコンプリートを維持することを提案しています。"
  },
  {
    "start": 1682660,
    "end": 1688380,
    "text": "ということであれば、途中で採点して、うまくいっているものを残すということもしているのでしょう。"
  },
  {
    "start": 1688380,
    "end": 1699620,
    "text": "多くの人が、LLMのために私たちの脳内にある能力を復活させるために、プロンプトエンジニアリングのようなものを使って遊んでいるのです。"
  },
  {
    "start": 1699620,
    "end": 1703100,
    "text": "ここでひとつ注意したいのは、これは単なるプロンプトではないということです。"
  },
  {
    "start": 1703100,
    "end": 1707900,
    "text": "これは実際に、いくつかのPythonグルーコードと一緒に使用されているプロンプトです。"
  },
  {
    "start": 1707900,
    "end": 1715620,
    "text": "なぜなら、実際には複数のプロンプトを維持する必要があり、また、どのプロンプトを展開するかを把握するために、ここでツリーサーチアルゴリズムを行う必要があるからです。"
  },
  {
    "start": 1715620,
    "end": 1722540,
    "text": "これは、Pythonのグルーコードと、whileループや大きなアルゴリズムの中で呼び出される個々のプロンプトが共生するものです。"
  },
  {
    "start": 1722540,
    "end": 1725140,
    "text": "ここにはAlphaGoと非常にクールなパラレルがあるとも思っています。"
  },
  {
    "start": 1725140,
    "end": 1729180,
    "text": "AlphaGoは、囲碁を打つときに次の石を置く方針を持っています。"
  },
  {
    "start": 1729180,
    "end": 1732740,
    "text": "この方針は、もともと人間の真似をして訓練していたものです。"
  },
  {
    "start": 1732780,
    "end": 1736820,
    "text": "というポリシーに加え、マルチカーゴツリーサーチも行います。"
  },
  {
    "start": 1736820,
    "end": 1742100,
    "text": "頭の中でいくつもの可能性を演じ、そのすべてを評価し、うまくいったものだけを残していくのです。"
  },
  {
    "start": 1742100,
    "end": 1749020,
    "text": "これはAlphaGoに相当するようなものだと思うのですが、テキストの場合、意味があるのでしょうか？"
  },
  {
    "start": 1749020,
    "end": 1757179,
    "text": "「思考の木」のようなもので、一般的には、単純な質問に対する回答だけでなく、より一般的な手法を模索するようになってきているように思います、"
  },
  {
    "start": 1757179,
    "end": 1762220,
    "text": "Pythonのグルーコードのように、多くのプロンプトをつなぎ合わせたようなものです。"
  },
  {
    "start": 1762220,
    "end": 1774460,
    "text": "右は、Reactという論文の例ですが、プロンプトに対する答えを、思考、行動、観察、思考、行動、観察という一連の流れとして構成しています。"
  },
  {
    "start": 1774460,
    "end": 1778700,
    "text": "という問いかけに答えるための思考回路のようなもので、完全なロールアウトです。"
  },
  {
    "start": 1778700,
    "end": 1782540,
    "text": "これらのアクションの中で、モデルはツール使用も許可されています。"
  },
  {
    "start": 1782540,
    "end": 1785660,
    "text": "左は、AutoGPTの例です。"
  },
  {
    "start": 1785660,
    "end": 1791700,
    "text": "AutoGPTですが、最近話題になった企画だと思います。"
  },
  {
    "start": 1792620,
    "end": 1796300,
    "text": "今でも、なんとなくインスピレーション的に面白いと思っているような気がします。"
  },
  {
    "start": 1796300,
    "end": 1802380,
    "text": "LLMがタスクリストを持ち、タスクを再帰的に分解し続けることができるプロジェクトです。"
  },
  {
    "start": 1802380,
    "end": 1807260,
    "text": "現在、これがあまりうまく機能しているとは思えませんし、実用で使うことを勧めることもありません。"
  },
  {
    "start": 1807260,
    "end": 1813300,
    "text": "これは、この先どうなっていくのかという点で、一般的にインスピレーションを得ることができるものだと思います。"
  },
  {
    "start": 1813300,
    "end": 1816540,
    "text": "私たちのモデル体系に思考を与えるようなものです。"
  },
  {
    "start": 1816540,
    "end": 1826820,
    "text": "次に面白いのは、LLMの心理的な特徴として、LLMは成功したくないと考えることです。"
  },
  {
    "start": 1826820,
    "end": 1828740,
    "text": "真似をしたがる。"
  },
  {
    "start": 1828740,
    "end": 1831480,
    "text": "成功したいのだから、それを求めればいい。"
  },
  {
    "start": 1831480,
    "end": 1836820,
    "text": "トランスフォーマーがトレーニングを受けるとき、トレーニングセットというものがあるんです。"
  },
  {
    "start": 1836820,
    "end": 1841700,
    "text": "そのトレーニングデータには、あらゆる性能のスペクトルが含まれている可能性があります。"
  },
  {
    "start": 1841700,
    "end": 1845980,
    "text": "例えば、ある物理の問題とか、そういうプロンプトがあるかもしれませんね。"
  },
  {
    "start": 1845980,
    "end": 1848100,
    "text": "あるいは、完全に間違っている学生の解答がある可能性もあります。"
  },
  {
    "start": 1848100,
    "end": 1851340,
    "text": "極めて正しい専門家の回答もあり得ます。"
  },
  {
    "start": 1851340,
    "end": 1862580,
    "text": "トランスフォーマーは、低品質のソリューションと高品質のソリューションの区別がつきませんが、言語モデリングのトレーニングを受けているだけあって、デフォルトですべてを模倣したがりますね。"
  },
  {
    "start": 1862580,
    "end": 1866440,
    "text": "テスト時には、実は、良い演奏をお願いする必要があるのです。"
  },
  {
    "start": 1866440,
    "end": 1871100,
    "text": "この論文の例では、さまざまなプロンプトを試したそうです。"
  },
  {
    "start": 1871100,
    "end": 1875695,
    "text": "ステップバイステップは、多くのトークンに推論を広げることができるので、非常に強力だと思います、"
  },
  {
    "start": 1875695,
    "end": 1881139,
    "text": "正しい答えを出すために、段階を踏んで解決していこうということなのです。"
  },
  {
    "start": 1881139,
    "end": 1893100,
    "text": "これは、正解を得るための条件付けのようなもので、実際にトランスフォーマーの働きを良くしています。"
  },
  {
    "start": 1893100,
    "end": 1897460,
    "text": "基本的に強い解決策を遠慮なくお願いします。"
  },
  {
    "start": 1897460,
    "end": 1900220,
    "text": "あなたはこのトピックの第一人者です、みたいなことを言う。"
  },
  {
    "start": 1900220,
    "end": 1902340,
    "text": "IQ120のふりをする、エトセトラ。"
  },
  {
    "start": 1902500,
    "end": 1908740,
    "text": "あまりIQを求めようとすると、IQが400とかだと、データ配信から外れてしまうかもしれないので、ご注意ください。"
  },
  {
    "start": 1908740,
    "end": 1917260,
    "text": "さらに悪いことに、SF的なもののデータ配信をしていると、SF的な、例えばロールプレイング的なものを取り入れるようになるかもしれません。"
  },
  {
    "start": 1917260,
    "end": 1920620,
    "text": "見つける必要があると思います。"
  },
  {
    "start": 1920620,
    "end": 1923460,
    "text": "U字型のカーブを描いていますね。"
  },
  {
    "start": 1923460,
    "end": 1932280,
    "text": "次は、見たとおり、私たちが問題を解決しようとするとき、得意なことと不得意なことを把握し、計算機的に道具に寄り添います。"
  },
  {
    "start": 1932280,
    "end": 1935320,
    "text": "LLMも同じように、潜在的にやりたいのでしょう。"
  },
  {
    "start": 1935320,
    "end": 1947540,
    "text": "特に、電卓やコードインタプリタなどの検索機能を持たせたい場合がありますが、そのためのテクニックはたくさんあります。"
  },
  {
    "start": 1947540,
    "end": 1953120,
    "text": "ひとつ注意しなければならないのは、繰り返しになりますが、これらのトランスフォーマーは、デフォルトでは、知らないことを知らないかもしれないということです。"
  },
  {
    "start": 1953120,
    "end": 1957840,
    "text": "プロンプトのトランスに、「あなたは暗算が苦手なんです」と伝えてもいいかもしれません。"
  },
  {
    "start": 1957840,
    "end": 1962760,
    "text": "非常に大きな数の足し算や掛け算などをする必要があるときは、代わりにこの電卓を使ってください。"
  },
  {
    "start": 1962760,
    "end": 1964000,
    "text": "ここでは、電卓の使い方を説明します。"
  },
  {
    "start": 1964000,
    "end": 1966680,
    "text": "このトークンの組み合わせで、エトセトラ、エトセトラと使ってください。"
  },
  {
    "start": 1966680,
    "end": 1975920,
    "text": "モデルはデフォルトで、何が得意で何が不得意なのかわからないからです。"
  },
  {
    "start": 1975920,
    "end": 1986400,
    "text": "次に、非常に興味深いのは、検索だけの世界から、LLMでは記憶だけの世界へと振り子が変わってきていることです。"
  },
  {
    "start": 1986400,
    "end": 1993400,
    "text": "実は、このような検索拡張モデルの間に、全体の空間があり、これが実際に非常にうまく機能しているのです。"
  },
  {
    "start": 1993400,
    "end": 1997280,
    "text": "先ほども述べたように、トランスフォーマーのコンテキストウィンドウは、そのワーキングメモリです。"
  },
  {
    "start": 1997280,
    "end": 2006580,
    "text": "タスクに関連するあらゆる情報をワーキングメモリにロードすることができれば、そのメモリすべてに即座にアクセスできるため、モデルは非常にうまく機能することになります。"
  },
  {
    "start": 2006580,
    "end": 2013280,
    "text": "基本的には検索拡張世代ということに、多くの人が興味を持っているのだと思います。"
  },
  {
    "start": 2013280,
    "end": 2024460,
    "text": "LLAMAインデックスの例ですが、これは1つのデータコネクタで多くの異なるタイプのデータに接続でき、そのすべてのデータにインデックスを付けて、LLMにアクセスできるようにすることができます。"
  },
  {
    "start": 2024460,
    "end": 2034020,
    "text": "この新しいレシピは、関連する文書を取り込み、それをチャンクに分割し、そのすべてを埋め込むことで、基本的にそのデータを表す埋め込みベクトルを得ることができます。"
  },
  {
    "start": 2034020,
    "end": 2038603,
    "text": "それをベクターストアに保存しておき、テスト時にベクターストアに何らかのクエリーを行うのです、"
  },
  {
    "start": 2038603,
    "end": 2044340,
    "text": "タスクに関連しそうなチャンクをフェッチして、プロンプトに詰め込み、そして生成するのです。"
  },
  {
    "start": 2044340,
    "end": 2046500,
    "text": "実際にはかなりうまくいくことがあります。"
  },
  {
    "start": 2046500,
    "end": 2057860,
    "text": "これは、私たちが問題を解くときと似ていると思うのですが、記憶からすべてを行うことができ、トランスフォーマーは非常に大きく広範な記憶を持っています。"
  },
  {
    "start": 2057860,
    "end": 2068100,
    "text": "教科書を読み返したり、図書館の資料を読み返したりするのは、トランスフォーマーも同じです。"
  },
  {
    "start": 2068100,
    "end": 2073620,
    "text": "ライブラリの一部のドキュメントがどのように機能するかについては、ある程度記憶しているはずですが、調べた方がずっといいです。"
  },
  {
    "start": 2074339,
    "end": 2077219,
    "text": "こちらも同様です。"
  },
  {
    "start": 2077219,
    "end": 2079739,
    "text": "次に、コンストレイントプロンプトについて簡単にお話したいと思います。"
  },
  {
    "start": 2079739,
    "end": 2082339,
    "text": "これはとても興味深いことです。"
  },
  {
    "start": 2082339,
    "end": 2090440,
    "text": "これは基本的に、LLMの出力に特定のテンプレートを強制的に適用するための技術です。"
  },
  {
    "start": 2090440,
    "end": 2093620,
    "text": "指導は、実はマイクロソフトの一例です。"
  },
  {
    "start": 2093620,
    "end": 2101413,
    "text": "ここでは、LLMからの出力がJSONであることを強制していますが、これは実際に出力がこの形式であることを保証するものです、"
  },
  {
    "start": 2101413,
    "end": 2105900,
    "text": "トランスフォーマーから出るさまざまなトークンの確率を狂わせてしまうからです、"
  },
  {
    "start": 2105900,
    "end": 2113371,
    "text": "そのトークンをクランプして、トランスフォーマーはここの空白を埋めるだけで、その空白に何が入るかについて追加の制限をかけることができます、"
  },
  {
    "start": 2113371,
    "end": 2120300,
    "text": "というのは本当に参考になるかもしれませんし、こういったコンストレイントサンプリングも非常に面白いと思います。"
  },
  {
    "start": 2120300,
    "end": 2122660,
    "text": "ファインチューニングについてもひと言。"
  },
  {
    "start": 2122660,
    "end": 2129820,
    "text": "プロンプトエンジニアリングで本当に遠くまで行けるのか、ということですが、モデルのファインチューニングを考えることも可能です。"
  },
  {
    "start": 2129820,
    "end": 2134500,
    "text": "モデルの微調整とは、実際にモデルの重みを変えてみるということです。"
  },
  {
    "start": 2134500,
    "end": 2143340,
    "text": "これは、ごく最近になって開発され、ライブラリ化された多くの技術によって、実際に行うことができるようになってきています。"
  },
  {
    "start": 2143340,
    "end": 2153702,
    "text": "例えば、Lauraのようなパラメータ効率の良い微調整技術では、モデルの小さな疎な部分のみをトレーニングすることで、モデルの大部分をベースモデルでクランプしたままにしておくことができます、"
  },
  {
    "start": 2153702,
    "end": 2163300,
    "text": "これは経験的にかなり有効で、モデルの小さな部分のみを調整するのに非常に安くなります。"
  },
  {
    "start": 2163300,
    "end": 2168878,
    "text": "モデルのほとんどがクランプされているため、その部分の計算には非常に低い精度の推論を使うことができるということです、"
  },
  {
    "start": 2168878,
    "end": 2174660,
    "text": "勾配降下法では更新されないので、すべての作業が効率的になるからです。"
  },
  {
    "start": 2174660,
    "end": 2184660,
    "text": "オープンソースの高画質ベースのモデルも多数あり、現在、商業ライセンスはないかと思いますが、先ほど申し上げたように、Lamaはなかなかいいと思います。"
  },
  {
    "start": 2184660,
    "end": 2189779,
    "text": "注意しなければならないのは、基本的にファインチューニングはもっと技術的に難しいということです。"
  },
  {
    "start": 2189779,
    "end": 2192899,
    "text": "正しく行うには、もっともっと、技術的なノウハウが必要だと思うのです。"
  },
  {
    "start": 2192899,
    "end": 2198859,
    "text": "データセットには人間のデータコントラクターが必要ですし、あるいは合成データパイプラインはかなり複雑なものになる可能性があります。"
  },
  {
    "start": 2198859,
    "end": 2204725,
    "text": "これなら間違いなく反復サイクルを大幅に遅らせることができますし、高いレベルでSFTは達成可能だと言えるでしょう、"
  },
  {
    "start": 2204725,
    "end": 2213540,
    "text": "RLHFは、言語モデリングタスクを継続するだけなので、比較的簡単ですが、RLHFは非常に研究しやすい分野だと思います、"
  },
  {
    "start": 2213540,
    "end": 2220880,
    "text": "RLHFの実装を自分で作ってみるというのは、あまりお勧めできないかもしれません。"
  },
  {
    "start": 2220880,
    "end": 2232440,
    "text": "このようなものは非常に不安定で、トレーニングも難しく、今すぐ初心者に優しいものではありませんし、まだまだ急速に変化する可能性もあります。"
  },
  {
    "start": 2232440,
    "end": 2235820,
    "text": "これが、今の私のデフォルトのおすすめポイントだと思います。"
  },
  {
    "start": 2235820,
    "end": 2238580,
    "text": "あなたの課題を大きく2つに分けます。"
  },
  {
    "start": 2238580,
    "end": 2244620,
    "text": "1番はトップパフォーマンスを達成すること、2番はパフォーマンスを最適化すること、この順です。"
  },
  {
    "start": 2244620,
    "end": 2247780,
    "text": "1つ目は、現在のところ、GFT4モデルで最高のパフォーマンスを発揮することです。"
  },
  {
    "start": 2247780,
    "end": 2250260,
    "text": "圧倒的に能力の高いモデルです。"
  },
  {
    "start": 2250260,
    "end": 2256820,
    "text": "プロンプトは、タスクの内容、関連する情報、指示など、非常に詳細なものを使用します。"
  },
  {
    "start": 2256820,
    "end": 2263380,
    "text": "タスク・コントラクターがメールを返せなかったらどう伝えるか、という線で考えつつ、タスク・コントラクターは人間であることも念頭に置いてください、"
  },
  {
    "start": 2263380,
    "end": 2266700,
    "text": "彼らは内面的なモノローグを持っていて、とても賢いんです。"
  },
  {
    "start": 2266700,
    "end": 2275660,
    "text": "LLMはそのような資質を持っていないので、LLMの心理をよく考え、それに合わせたプロンプトを作成してください。"
  },
  {
    "start": 2275660,
    "end": 2280900,
    "text": "これらのプロンプトに対して、関連する文脈や情報を取得し、追加する。"
  },
  {
    "start": 2280900,
    "end": 2283220,
    "text": "基本的には、プロンプトエンジニアリング技術の多くを参照してください。"
  },
  {
    "start": 2283220,
    "end": 2291900,
    "text": "上のスライドで紹介したものもありますが、これは非常に広いスペースなので、ネットでプロンプトエンジニアリング技術を探すことをお勧めします。"
  },
  {
    "start": 2291900,
    "end": 2294220,
    "text": "そこには、たくさんの取材があります。"
  },
  {
    "start": 2294220,
    "end": 2295920,
    "text": "数ショットの作例で実験する。"
  },
  {
    "start": 2295920,
    "end": 2300060,
    "text": "これは、ただ伝えるだけでなく、可能な限り見せたいということを指しています。"
  },
  {
    "start": 2300060,
    "end": 2302180,
    "text": "いろいろな例をあげてみてください。"
  },
  {
    "start": 2302180,
    "end": 2306220,
    "text": "そうすることで、できればあなたの言いたいことを本当に理解してくれるようになります。"
  },
  {
    "start": 2306220,
    "end": 2311299,
    "text": "LLMでは難しい作業をオフロードするためのツールやプラグインをネイティブで実験する。"
  },
  {
    "start": 2311299,
    "end": 2321140,
    "text": "1つのプロンプトと回答だけでなく、潜在的な連鎖や反射、それらをどのように接着するか、複数のサンプルを作る可能性があるかなどを考えてみてください。"
  },
  {
    "start": 2321140,
    "end": 2331740,
    "text": "最後に、もしあなたがプロンプトエンジニアリングを絞り出したと思うのなら、しばらくはそれにこだわるべきだと思いますが、自分の用途に合わせてモデルを微調整する可能性もあります。"
  },
  {
    "start": 2331740,
    "end": 2334320,
    "text": "もっとゆっくり、もっと深く関わってくることを期待しています。"
  },
  {
    "start": 2334320,
    "end": 2342500,
    "text": "ここには専門家による壊れやすい研究ゾーンがあり、私はそれがRLHFであると言いたいのですが、現状ではSFTよりも少し効果があります。"
  },
  {
    "start": 2342500,
    "end": 2345520,
    "text": "これはかなり関与していると言っていいでしょう。"
  },
  {
    "start": 2345520,
    "end": 2353260,
    "text": "コストを最適化するために、低容量のモデルや短いプロンプトなどを検討してみてください。"
  },
  {
    "start": 2353260,
    "end": 2358900,
    "text": "現在、LLMが適していると思われるユースケースについても、一言触れておきたいと思います。"
  },
  {
    "start": 2358900,
    "end": 2363020,
    "text": "特に、今日のLLMには大量の制限があることに注意してください。"
  },
  {
    "start": 2363020,
    "end": 2366700,
    "text": "そのことを絶対に念頭に置いて、応募していきたいと思います。"
  },
  {
    "start": 2366700,
    "end": 2370940,
    "text": "モデル、そしてこれは、1つの講演になる可能性があるので、詳しく説明する時間がありません。"
  },
  {
    "start": 2370940,
    "end": 2384100,
    "text": "モデルには偏りがあり、情報を捏造したり、幻覚を見たり、推論ミスがあったり、アプリケーションのクラス全体で苦労したり、知識のカットオフがあるので、例えば2021年9月以上の情報は知らないかもしれません。"
  },
  {
    "start": 2384100,
    "end": 2393260,
    "text": "プロンプトインジェクション、ジェイルブレイク攻撃、データポイズニング攻撃など、Twitterで日々発信されているような様々な攻撃の影響を受けやすいのです。"
  },
  {
    "start": 2393260,
    "end": 2403137,
    "text": "今、私がお勧めするのは、LLMをリスクの低いアプリケーションに使うこと、常に人の目があるアプリケーションと組み合わせること、インスピレーションや提案のソースとして使うことです、"
  },
  {
    "start": 2403137,
    "end": 2408220,
    "text": "どこかでタスクをこなしているような完全な自律型エージェントではなく、コ・パイロットを考える。"
  },
  {
    "start": 2408220,
    "end": 2412660,
    "text": "今現在はモデルがはっきりしない。"
  },
  {
    "start": 2412660,
    "end": 2415220,
    "text": "最後に、GPT-4は素晴らしい人工物であることをお伝えしておきたいと思います。"
  },
  {
    "start": 2415220,
    "end": 2423380,
    "text": "存在することにとても感謝していますし、美しいし、多くの分野にまたがる知識を持ち、数学ができたり、コードが書けたり、などなど。"
  },
  {
    "start": 2423380,
    "end": 2432380,
    "text": "このエコシステムには、これまでお話ししたような、あらゆるものが構築され、組み込まれている盛んなエコシステムがあります。"
  },
  {
    "start": 2432380,
    "end": 2436100,
    "text": "これらのパワーは、あなたの指先からアクセスすることができます。"
  },
  {
    "start": 2436100,
    "end": 2442740,
    "text": "GPT-4に質問し、促し、回答を得るためのコードとして必要なものは、ここにすべて揃っています。"
  },
  {
    "start": 2442740,
    "end": 2448299,
    "text": "今回は、Microsoft Build 2023の聴衆を鼓舞するようなことを言えるか、と言ったのです。"
  },
  {
    "start": 2448299,
    "end": 2454380,
    "text": "これをPythonに打ち込んだところ、逐語的にGPT-4は次のように言っていました。"
  },
  {
    "start": 2454380,
    "end": 2462980,
    "text": "ところで、基調講演でこの仕掛けが使われていることを知らなかったので、気を利かせているつもりだったのですが、本当に上手なんですね。"
  },
  {
    "start": 2462980,
    "end": 2470260,
    "text": "Microsoft Build 2023のイノベーターと先駆者の皆さん、他にはない優秀な頭脳の集まりにようこそ、と書いてあります。"
  },
  {
    "start": 2470260,
    "end": 2476060,
    "text": "あなた方は未来の建築家であり、人類が繁栄するデジタル領域を形成する先見者なのです。"
  },
  {
    "start": 2476060,
    "end": 2480460,
    "text": "テクノロジーの無限の可能性を感じながら、あなたの想像を膨らませてください。"
  },
  {
    "start": 2480460,
    "end": 2485620,
    "text": "一緒に、次の世代のために、よりつながり、目覚ましく、包括的な世界を作り上げましょう。"
  },
  {
    "start": 2485620,
    "end": 2490620,
    "text": "創造性を発揮し、未知なる世界に挑み、夢を現実にする。"
  },
  {
    "start": 2490620,
    "end": 2492339,
    "text": "あなたの旅は今日から始まります。"
  }
]