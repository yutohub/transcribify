[
  {
    "start": 13370,
    "end": 18830,
    "text": "プロトタイプからプロダクションへ、AIの新しいスタックと作戦へようこそ。"
  },
  {
    "start": 19410,
    "end": 30930,
    "text": "私の名前はシャーウィンで、OpenAI Developerプラットフォームのエンジニアリングチームを率いています。このチームは、200万人以上の開発者（おそらく皆さんの多くも含む）が、私たちのモデルの上に製品を構築するために使用しているAPIの構築と保守を行っています。"
  },
  {
    "start": 31010,
    "end": 31746,
    "text": "私はシャマル。"
  },
  {
    "start": 31778,
    "end": 38760,
    "text": "私はアプライド・チームの一員で、何百社もの新興企業や企業と協力し、私たちのプラットフォームで素晴らしい製品や体験を構築するお手伝いをしてきました。"
  },
  {
    "start": 39130,
    "end": 46890,
    "text": "今日は、皆さんのアプリケーションをプロトタイプの段階から製品化するプロセスについてお話しできることをとても楽しみにしています。"
  },
  {
    "start": 47550,
    "end": 50298,
    "text": "まず、物事を少し整理してみたかった。"
  },
  {
    "start": 50384,
    "end": 59050,
    "text": "チャットGBTが私たちの生活に入り込み、世界を一変させてから随分と時間が経ったように思えるかもしれないが、実はまだ発売から1年も経っていない。"
  },
  {
    "start": 59130,
    "end": 64798,
    "text": "チャットGBTは2022年11月下旬に開始された。"
  },
  {
    "start": 64964,
    "end": 75282,
    "text": "同様に、GBT Fourは2023年3月に発売されたばかりで、人々が私たちのフラッグシップモデルを体験し、それを製品に使おうとしてからまだ8カ月も経っていない。"
  },
  {
    "start": 75416,
    "end": 90040,
    "text": "この間、GBTは、私たちが遊んでソーシャルメディアで共有するおもちゃから、日常生活や職場で使うツールになり、今やあらゆる企業、新興企業、開発者が自社製品に組み込もうとしている機能になった。"
  },
  {
    "start": 91210,
    "end": 93654,
    "text": "多くの場合、最初のステップはプロトタイプを作ることだ。"
  },
  {
    "start": 93702,
    "end": 99446,
    "text": "ご存知の方も多いと思いますが、私たちのモデルを使えば、とてもシンプルで簡単にクールなプロトタイプを作ることができます。"
  },
  {
    "start": 99558,
    "end": 102654,
    "text": "デモを考えて、それを友人たちに見せるのは本当にクールなことだ。"
  },
  {
    "start": 102772,
    "end": 110430,
    "text": "しかし、そこからプロダクションに入るには大きな隔たりがあり、なかなかプロダクションに入れないことも多い。"
  },
  {
    "start": 111170,
    "end": 114602,
    "text": "その大部分は、これらのモデルの非決定性によるものである。"
  },
  {
    "start": 114666,
    "end": 121502,
    "text": "非決定論的なアプリをプロトタイプから本番へとスケールさせることは、指針となるフレームワークがないと、しばしば非常に難しく感じることがある。"
  },
  {
    "start": 121646,
    "end": 126146,
    "text": "このように、使えるツールがたくさんあると感じることはよくあるだろう。"
  },
  {
    "start": 126248,
    "end": 127650,
    "text": "現場の動きは非常に速い。"
  },
  {
    "start": 127720,
    "end": 132054,
    "text": "いろいろな可能性があるけれど、どこに行けばいいのか、何から始めればいいのかよくわからない。"
  },
  {
    "start": 132172,
    "end": 138290,
    "text": "今回の講演では、アプリをプロトタイプから本番に移行する際に役立つフレームワークを紹介したい。"
  },
  {
    "start": 138370,
    "end": 147062,
    "text": "このフレームワークは、スタックダイアグラムという形で提供したいと思います。"
  },
  {
    "start": 147206,
    "end": 151206,
    "text": "私たちは、これらのLLMの上に楽しいユーザー体験を構築する方法について話します。"
  },
  {
    "start": 151318,
    "end": 156538,
    "text": "ナレッジストアやツールを使ってモデルをグラウンディングすることで、モデルの矛盾を処理することについてお話します。"
  },
  {
    "start": 156634,
    "end": 161850,
    "text": "今回は、評価を使ってアプリケーションを自信を持って反復する方法についてお話します。"
  },
  {
    "start": 162010,
    "end": 168542,
    "text": "最後に、アプリケーションのスケールを管理する方法と、オーケストレーションを使ってコストとレイテンシを考える方法についてお話しします。"
  },
  {
    "start": 168686,
    "end": 174660,
    "text": "それぞれについて、皆さんが持ち帰って、ご自身のさまざまな製品に活用できることを願って、2、3の戦略についてお話しします。"
  },
  {
    "start": 175910,
    "end": 181090,
    "text": "多くの場合、最初は単純なプロトタイプしかなく、今示したようなスタック全体があるわけではありません。"
  },
  {
    "start": 181170,
    "end": 186018,
    "text": "ここでは通常、非常にシンプルなセットアップが行われ、アプリケーションはそのAPIと直接会話する。"
  },
  {
    "start": 186114,
    "end": 190794,
    "text": "最初はこれでうまくいくが、すぐにそれでは不十分だと気づくだろう。"
  },
  {
    "start": 190912,
    "end": 195370,
    "text": "このフレームワークの最初のレイヤーについて話そう。"
  },
  {
    "start": 195950,
    "end": 222334,
    "text": "テクノロジーは、それを取り巻くユーザーエクスペリエンスと同じくらい有用であり、ゴールは信頼性が高く、防御的で、楽しいユーザーエクスペリエンスを構築することですが、AIがアシストするコパイロットやアシスタントは、ヒューマンコンピュータインタラクションやUXの異なる課題を提示し、私たちのモデルで構築されたアプリケーションを拡張するためのユニークな考慮事項は、ユーザーにとってより良い安全な結果を促進することがより重要になります。"
  },
  {
    "start": 222462,
    "end": 236306,
    "text": "ここでは、本質的に確率論的であるモデルの上にアプリを構築する際に生じるいくつかの課題に対処するための2つの戦略、不確実性の制御、安定性と安全性のためのガードレールの構築についてお話しします。"
  },
  {
    "start": 236498,
    "end": 245450,
    "text": "不確実性のコントロールとは、モデルがユーザーとどのように相互作用し、どのように反応するかを管理することによって、ユーザーエクスペリエンスをプロアクティブに最適化することである。"
  },
  {
    "start": 246990,
    "end": 253326,
    "text": "これまでは、多くの製品が決定論的で、相互作用が反復可能で正確な方法で起こりうるものだった。"
  },
  {
    "start": 253428,
    "end": 268770,
    "text": "AIが人間の判断に取って代わるのではなく、人間の能力を高め、補強することで、人間中心の設計をすることが重要になってきている。"
  },
  {
    "start": 269830,
    "end": 281154,
    "text": "例えば、チャットGPTをデザインする際、私たちはユーザーを誘導し、モデルによって動くアプリの構築につきものの不確実性をコントロールするために、いくつかのUX要素を組み込んだ。"
  },
  {
    "start": 281282,
    "end": 302830,
    "text": "ユースケースにもよるが、ここでの最初の戦略は、人間をループに入れ、ジェネレーティブAIで作成された最初の成果物が、ユーザーが望む最終的な成果物ではないかもしれないことを理解することである。したがって、ユーザーに反復する機会を与え、時間をかけて品質を向上させることは、不確実性をナビゲートし、堅牢なUXを構築するために重要である。"
  },
  {
    "start": 303330,
    "end": 311710,
    "text": "一方、フィードバックコントロールは、ミスを修正するための余裕も提供し、しっかりとしたデータフライホイールを構築するための有用なシグナルとなる。"
  },
  {
    "start": 313830,
    "end": 326274,
    "text": "透明なUXを構築するもう一つの重要な側面は、システムの能力と制限をユーザーに伝えることで、ユーザーはAIに何ができるのか、あるいは何ができないのかを理解することができる。"
  },
  {
    "start": 326472,
    "end": 330994,
    "text": "AIがどのように間違いを犯すかをユーザーに説明することで、これをさらに進めることができる。"
  },
  {
    "start": 331122,
    "end": 335686,
    "text": "チャットGPTの場合、これは下部にAIによる告知という形をとっている。"
  },
  {
    "start": 335788,
    "end": 338546,
    "text": "これにより、ユーザーに正しい期待を抱かせることができる。"
  },
  {
    "start": 338658,
    "end": 348250,
    "text": "最後に、うまく設計されたユーザー・インターフェースは、ユーザーとAIとのインタラクションをガイドし、最も有用で安全な応答とインタラクションから最高のものを引き出すことができる。"
  },
  {
    "start": 348590,
    "end": 365742,
    "text": "これは、チャットGPTで示唆的なプロンプトの形をとることができ、ユーザーをこの経験に乗せるのを助けるだけでなく、ユーザーがより良い質問をしたり、問題を解決する別の方法を提案したり、インスピレーションを与えたり、より深く探ったりする機会を提供します。"
  },
  {
    "start": 365886,
    "end": 371810,
    "text": "これら3つの戦略はすべて、ユーザーを体験の中心に置き、コントロールするものである。"
  },
  {
    "start": 371960,
    "end": 397370,
    "text": "AI製品との協働を最大限に引き出すUXを設計し、人間中心の協働体験を創造することで、信頼の基盤を確立し、GPTを活用したアプリケーションの展開に自信を深めていただくためには、人間中心のUXを構築するだけでなく、耐久性と安全性の両方のガードレールを構築することも重要です。"
  },
  {
    "start": 398910,
    "end": 406798,
    "text": "ガードレールは、本質的に、ユーザー・エクスペリエンスとモデルの間に位置する制約または予防的コントロールであると考えることができます。"
  },
  {
    "start": 406964,
    "end": 416130,
    "text": "有害で不要なコンテンツがアプリケーションやユーザーの手に渡るのを防ぎ、生産モデルの安定性を高めることを目的としている。"
  },
  {
    "start": 416870,
    "end": 424260,
    "text": "私たちが見てきた最高のインタラクション・パターンのいくつかは、安全性とセキュリティをエクスペリエンスの中核に据えている。"
  },
  {
    "start": 425350,
    "end": 438630,
    "text": "最も優れたモデルのいくつかは、人間の価値観に最も合致したものであり、最も有用で有能なUXのいくつかは、安全性と安定性を最大限に引き出し、より良い、より安全な結果をもたらすと信じている。"
  },
  {
    "start": 439450,
    "end": 448646,
    "text": "その一例を示すために、クリスマスにとてもタイムリーな、クリスマスツリーの抽象画を描くというダリの簡単なプロンプトから始めてみよう。"
  },
  {
    "start": 448758,
    "end": 459006,
    "text": "ダリは、色合い、樹木の形、色彩、筆跡などの細部や具体性を加えることで、プロンプトを強化するためにモデルを使用する。"
  },
  {
    "start": 459108,
    "end": 468286,
    "text": "私は芸術家ではないので、これ以上の仕事はできないだろうが、今回はダリをパートナーとして、私のアイデアを想像の世界へと導いている。"
  },
  {
    "start": 468478,
    "end": 472174,
    "text": "さて、これが安全ガードレールなのか？"
  },
  {
    "start": 472302,
    "end": 478178,
    "text": "まあ、より良い成果物を作るために使われるのと同じように、迅速な濃縮は安全なガードレールとしても機能する。"
  },
  {
    "start": 478274,
    "end": 488070,
    "text": "この場合、個人のプライバシーや権利を侵害するような問題のあるプロンプトを検出した場合、そのプロンプトを完全に拒否するのではなく、別のプロンプトを提案する。"
  },
  {
    "start": 488910,
    "end": 497020,
    "text": "この場合、実在の人物の画像を生成するのではなく、昇天をキャプチャして架空の人物の画像を生成する。"
  },
  {
    "start": 498830,
    "end": 505310,
    "text": "耐久性と安全性の両方に役立つガードレールの一例を紹介した。"
  },
  {
    "start": 505650,
    "end": 508410,
    "text": "ガードレールには他にもいろいろな形がある。"
  },
  {
    "start": 508490,
    "end": 518580,
    "text": "この例としては、コンプライアンス・ガードレール、セキュリティ・ガードレール、モデルの出力が構文的にも意味的にも正しいことを保証するガードレールなどがある。"
  },
  {
    "start": 519350,
    "end": 531670,
    "text": "ガードレールが本質的に重要になるのは、エラーや幻覚に対する許容度が低く、セキュリティとコンプライアンスを優先しなければならないような、規制の厳しい業界のインターフェースを構築する場合だ。"
  },
  {
    "start": 533930,
    "end": 540280,
    "text": "しかし、私たちの旅はこれで終わりではない。"
  },
  {
    "start": 542170,
    "end": 548406,
    "text": "この時点で、あなたは、これらのモデルの不確実性の一部を管理することができるすべてのユーザーのための楽しいユーザー体験を構築しています。"
  },
  {
    "start": 548518,
    "end": 564734,
    "text": "プロトタイプとしては非常に有効ですが、ユーザーから受け取るクエリの種類がかなり限られている場合、これを本番環境にスケールアウトすると、一貫性の問題にすぐに直面し始めます。"
  },
  {
    "start": 564932,
    "end": 573502,
    "text": "これは、モデルを知識ストアとツールでグラウンディングすることを含む、私たちのスタックの第2部分を紹介するものです。"
  },
  {
    "start": 573646,
    "end": 590918,
    "text": "このようなモデルに内在する矛盾を管理するために、私たちの顧客がうまく採用している2つの戦略には、1つは、モデル・レベルでモデルの動作を制約すること、もう1つは、ナレッジストアや独自のツールのようなものを使って、モデルを現実世界の知識でグラウンディングすることです。"
  },
  {
    "start": 591094,
    "end": 608670,
    "text": "この問題は、LLM固有の確率的な性質を管理するのが難しいことが多いからです。特に、私たちのAPIの顧客としては、モデルへの低レベルのアクセスができないので、この矛盾を管理するのは本当に難しいのです。"
  },
  {
    "start": 609730,
    "end": 617540,
    "text": "そこで今日は、モデルの振る舞いを制約するのに役立つ2つの新しいモデル・レベル機能を紹介します。"
  },
  {
    "start": 618550,
    "end": 631750,
    "text": "最初のものはJSONモードで、これをオンにすると、モデルの出力がJSON文法内に収まるように制約されます。2つ目は、Seedという新しいパラメータを使った再現可能な出力で、チャットの完了に導入します。"
  },
  {
    "start": 632330,
    "end": 640786,
    "text": "その最初のものであるJSONモードは、多くの人から本当によく質問される機能で、JSON文法内でモデルを強制的に出力させることができます。"
  },
  {
    "start": 640898,
    "end": 647658,
    "text": "LLMの出力を下流のソフトウェア・システムに取り込むのだから、開発者にとってこれは本当に重要なことだ。"
  },
  {
    "start": 647744,
    "end": 652938,
    "text": "そのためには多くの場合、共通のデータ・フォーマットが必要であり、JSONはその中でも最もポピュラーなもののひとつである。"
  },
  {
    "start": 653024,
    "end": 662400,
    "text": "これは素晴らしいことですが、ここでの矛盾の1つの大きな欠点は、モデルが無効なJSONを出力すると、実際にシステムが壊れて例外が投げられることです。"
  },
  {
    "start": 663250,
    "end": 667314,
    "text": "今日導入したJSONモードは、この可能性を大幅に減らすはずだ。"
  },
  {
    "start": 667432,
    "end": 674062,
    "text": "チャットの完了にJSONスキーマという新しい引数を追加しました。"
  },
  {
    "start": 674126,
    "end": 685826,
    "text": "このパラメータに型オブジェクトを渡し、それをAPIに渡すと、私たちのシステムやAPIから得られる出力は、JSON文法内に制約されます。"
  },
  {
    "start": 685858,
    "end": 689730,
    "text": "の場合、コンテンツ・フィールドはJSON文法に制約される。"
  },
  {
    "start": 689810,
    "end": 698954,
    "text": "これによって、内部で確認されたJSONエラーの100%が取り除かれたわけではありませんが、このモデルによって出力されるJSONのエラー率は大幅に減少しました。"
  },
  {
    "start": 699072,
    "end": 704670,
    "text": "もうひとつは、チャットの補完にシード・パラメーターを使うことで、より再現性の高いアウトプットが得られることだ。"
  },
  {
    "start": 705170,
    "end": 709402,
    "text": "だから、我々のモデルの多くは非決定論的だ。"
  },
  {
    "start": 709466,
    "end": 715594,
    "text": "フードの下を覗いてみると、実は舞台裏で起きている一貫性のない振る舞いの多くには、3つの主要な原因がある。"
  },
  {
    "start": 715722,
    "end": 720194,
    "text": "そのひとつが、確率に基づいてトークンをサンプリングする方法だ。"
  },
  {
    "start": 720232,
    "end": 724578,
    "text": "温度とトップPのパラメーターによってコントロールされる。"
  },
  {
    "start": 724744,
    "end": 730902,
    "text": "もうひとつはCパラメータで、これはモデルが計算を開始する際に使用する乱数である。"
  },
  {
    "start": 731036,
    "end": 738390,
    "text": "3つ目はシステム・フィンガープリントと呼ばれるもので、バックエンドで稼働しているエンジンの状態と、それらにデプロイされたコードを記述するものだ。"
  },
  {
    "start": 738460,
    "end": 741660,
    "text": "それらが変化すれば、固有の非決定性が発生する。"
  },
  {
    "start": 742190,
    "end": 746954,
    "text": "現時点では、気温とトップPにしかアクセスできない。"
  },
  {
    "start": 747072,
    "end": 756314,
    "text": "今日から、私たちは実際に開発者に入力としてシードパラメーターへのアクセスを提供し、開発者にチャット完了の応答におけるシステム指紋への可視性を提供します。"
  },
  {
    "start": 756362,
    "end": 765514,
    "text": "チャットコンプリートでは、seedパラメータという整数値を渡すことができます。"
  },
  {
    "start": 765642,
    "end": 775522,
    "text": "12345のようなシードを渡し、それをゼロに設定して温度をコントロールすれば、出力は長期にわたってかなり安定する。"
  },
  {
    "start": 775576,
    "end": 783906,
    "text": "この特別なリクエストを5回ほど私たちに送ってくれれば、選択肢の下で得られる出力はかなり一貫したものになるだろう。"
  },
  {
    "start": 784098,
    "end": 794630,
    "text": "さらに、システムフィンガープリントパラメーターへのアクセスも可能で、モデルからのすべてのレスポンスに対して、ボンネット内のエンジンシステムに関するフィンガープリントが表示されます。"
  },
  {
    "start": 794710,
    "end": 805230,
    "text": "だから、すべての応答からまったく同じシステム指紋が返ってきて、同じシードと温度ゼロを渡したなら、ほぼ間違いなく同じ応答が返ってくる。"
  },
  {
    "start": 807250,
    "end": 807662,
    "text": "クールだ。"
  },
  {
    "start": 807716,
    "end": 811438,
    "text": "これらはモデルレベルの行動であり、実際にすぐに手にして試すことができる。"
  },
  {
    "start": 811524,
    "end": 820980,
    "text": "現在でも、より複雑なテクニックとしてモデルのグラウンディングと呼ばれるものがあり、これはモデルに答えの根拠となる事実を追加することで、モデルの動作の矛盾を減らすのに役立つ。"
  },
  {
    "start": 821910,
    "end": 827170,
    "text": "その根源は、皆さんもご存知のように、モデルが単独でいるとき、しばしば情報を幻覚することがあるからだ。"
  },
  {
    "start": 827240,
    "end": 830694,
    "text": "その多くは、私たちがモデルに話すことを強要しているという事実によるものだ。"
  },
  {
    "start": 830732,
    "end": 835320,
    "text": "本当に何も知らなければ、何かを言おうとするしかない。"
  },
  {
    "start": 835770,
    "end": 841434,
    "text": "この背後にある考え方は、モデルに根拠を与え、事実の束を与えることだ。"
  },
  {
    "start": 841552,
    "end": 850700,
    "text": "具体的には、入力コンテキストで、モデルによる幻覚の可能性を減らすために、モデルに根拠となる事実を明示的に与えるということだ。"
  },
  {
    "start": 851230,
    "end": 854406,
    "text": "これは実に広範な感情である。"
  },
  {
    "start": 854518,
    "end": 865898,
    "text": "システム図ではこのように見えるかもしれない。クエリーがユーザーから送られてきて、サーバーにヒットする。"
  },
  {
    "start": 865994,
    "end": 876830,
    "text": "そこにクエリを渡すとすると、根拠となるファクト・ソースでは、理想的には何らかのタイプの根拠となるファクトを返してくれる。"
  },
  {
    "start": 876990,
    "end": 883190,
    "text": "そして理想的には、APIはその情報を受け取り、ここにある根拠となる事実を使って、ある種の応答を合成する。"
  },
  {
    "start": 883340,
    "end": 890678,
    "text": "もう少し具体的に説明すると、RAGやベクトル・データベースを使う方法がある。"
  },
  {
    "start": 890764,
    "end": 894970,
    "text": "この例では、カスタマーサービス・ボットを作っていて、ユーザーから「アカウントを削除するにはどうすればいいですか？"
  },
  {
    "start": 895040,
    "end": 897786,
    "text": "これは私自身のアプリケーションや製品に特有かもしれない。"
  },
  {
    "start": 897888,
    "end": 900314,
    "text": "API単体では、このことはわからないだろう。"
  },
  {
    "start": 900432,
    "end": 909130,
    "text": "例えば、ベクター・データベースのような検索サービスがあり、社内文書やサポートに関するFAQのインデックスを作成し、文書の削除方法を知っているとします。"
  },
  {
    "start": 909210,
    "end": 913742,
    "text": "ここで私が最初にすることは、検索サービスに「アカウントを削除するにはどうすればいいですか？"
  },
  {
    "start": 913876,
    "end": 921220,
    "text": "例えば、アカウント削除に関するFAQの中で、「設定」、「スクロールダウン」、「ここをクリック」など、関連するスニペットが見つかったとしよう。"
  },
  {
    "start": 921990,
    "end": 925550,
    "text": "そして、そのクエリーをAPIに渡す。"
  },
  {
    "start": 925630,
    "end": 929214,
    "text": "その場合、APIはその事実を使ってユーザーに何らかのレスポンスを返すことになる。"
  },
  {
    "start": 929262,
    "end": 932950,
    "text": "この場合、アカウントを削除するには、\"設定 \"をクリックし、下にスクロールして \"ここ \"をクリックします。"
  },
  {
    "start": 933020,
    "end": 935842,
    "text": "これは1つの実装だが、実際にはかなり広い範囲に及ぶ可能性がある。"
  },
  {
    "start": 935906,
    "end": 939878,
    "text": "APIでOpenAIの関数を呼び出すことで、実際に独自のサービスを使用することができます。"
  },
  {
    "start": 940044,
    "end": 942694,
    "text": "私たちの顧客はこの方法を効果的に使っている。"
  },
  {
    "start": 942892,
    "end": 948170,
    "text": "この場合、ベクター・データベースを使う代わりに、独自のAPIやマイクロサービスを使うことができる。"
  },
  {
    "start": 948240,
    "end": 955870,
    "text": "この場合、顧客が現在の住宅ローン金利を尋ねてきたとしよう。もちろん、これは常に変化するものなので、LLMでさえすぐにはわからない。"
  },
  {
    "start": 955940,
    "end": 963470,
    "text": "例えば、毎日の同期作業を行うマイクロサービスがあり、そのマイクロサービスは現在の住宅ローン金利をダウンロードして追跡しているとしよう。"
  },
  {
    "start": 963970,
    "end": 965790,
    "text": "この場合、関数の呼び出しを使うことになる。"
  },
  {
    "start": 965860,
    "end": 971726,
    "text": "モデルには、マイクロサービス内にある住宅ローン金利の取得という機能にアクセスできることを伝えます。"
  },
  {
    "start": 971918,
    "end": 977938,
    "text": "まずAPIにリクエストを送り、住宅ローン金利の取得関数を呼び出すよう意思表示する。"
  },
  {
    "start": 978104,
    "end": 982338,
    "text": "そして、住宅ローン金利を取得するAPIを呼び出すことで、その意図を実現する。"
  },
  {
    "start": 982514,
    "end": 994890,
    "text": "例えば、30年固定で8％の住宅ローン金利のようなものを返すとしよう。残りは非常によく似ていて、オリジナルのクエリでAPIにそれを渡すと、モデルは「良くない」というようなグランドレスポンスで応答する。"
  },
  {
    "start": 994960,
    "end": 997820,
    "text": "現在の30年固定金利はすでに8％に達している。"
  },
  {
    "start": 998910,
    "end": 1008862,
    "text": "ですから、非常に大まかなレベルでは、この根拠となる事実のソースを一般的な方法で使用し、モデルの根拠とし、モデルの矛盾を減らすのに役立っています。"
  },
  {
    "start": 1008916,
    "end": 1015962,
    "text": "根拠となる事実のソースは、elasticsearchのような検索インデックスや、より一般的な検索インデックスなど、他のものであることもある。"
  },
  {
    "start": 1016026,
    "end": 1017766,
    "text": "データベースのようなものでもよい。"
  },
  {
    "start": 1017898,
    "end": 1022734,
    "text": "インターネットをブラウズしたり、スマートなメカニズムを試して追加的な事実をつかむようなことでさえあり得る。"
  },
  {
    "start": 1022782,
    "end": 1035480,
    "text": "主なアイデアは、モデルが機能するための何かを提供することであり、私が呼び出したかったことの1つは、今日発表したばかりのOpenAIアシスタンスAPIは、実際にあなたが使用し、その上に構築するために、すぐに使える検索セットアップを提供しているということです。"
  },
  {
    "start": 1036010,
    "end": 1037446,
    "text": "検索機能を内蔵している。"
  },
  {
    "start": 1037468,
    "end": 1040234,
    "text": "一流の体験をするなら、ぜひチェックしてほしい。"
  },
  {
    "start": 1040432,
    "end": 1046140,
    "text": "さて、ここまでは透明で人間中心のユーザー・エクスペリエンスを構築することについて話してきた。"
  },
  {
    "start": 1046910,
    "end": 1052862,
    "text": "そして、今日リリースしたモデルレベルの機能を通じて、どのように一貫したユーザー体験を提供するかについて話し合った。"
  },
  {
    "start": 1052916,
    "end": 1061390,
    "text": "そして、そのモデルを土台にすることで、今度は、どうすればその経験を後退させることなく一貫して提供できるかについて話していくことになる。"
  },
  {
    "start": 1062690,
    "end": 1066914,
    "text": "ここでモデルの性能を評価することが本当に重要になる。"
  },
  {
    "start": 1067112,
    "end": 1073918,
    "text": "ここでは、我々のモデルを使って作られたアプリケーションのパフォーマンスを評価するのに役立つ2つの戦略についてお話しします。"
  },
  {
    "start": 1074094,
    "end": 1079350,
    "text": "まず1つ目は、特定のユースケースに対応した評価スイートを作成することだ。"
  },
  {
    "start": 1080890,
    "end": 1092410,
    "text": "多くの組織と仕事をしていると、モデルやパフォーマンスを評価し、リグレッションをテストするのは大変で、開発速度が遅くなることが多いという話を何度も耳にする。"
  },
  {
    "start": 1092830,
    "end": 1103482,
    "text": "その問題の一つは、開発者がこれらのモデルのパフォーマンスを評価するための体系的なプロセスを考えず、また評価を行うのが遅すぎることである。"
  },
  {
    "start": 1103626,
    "end": 1118210,
    "text": "評価こそが成功の鍵であり、実際の製品シナリオでモデルのパフォーマンスを測定することは、リグレッションを防ぎ、これらのモデルを大規模に展開する際に自信をつけるために本当に不可欠なことなのだ。"
  },
  {
    "start": 1119270,
    "end": 1124210,
    "text": "EVALは基本的に、大規模な言語モデルのユニットテストと考えることができる。"
  },
  {
    "start": 1125030,
    "end": 1130930,
    "text": "プロンプティングは哲学だと思われがちだが、むしろ科学だ。"
  },
  {
    "start": 1131010,
    "end": 1142650,
    "text": "エバリュエーションと組み合わせれば、それをソフトウェア製品やデリバリーのように扱うことができ、エバリュエーションは曖昧な対話を定量化可能な実験に変えることができる。"
  },
  {
    "start": 1142990,
    "end": 1158430,
    "text": "また、モデル・ガバナンスのモデル・アップグレードをより容易にし、何が良いか悪いかに関する期待値を設定し、能力、評価、パフォーマンスは実に密接に関係しており、AIエンジニアリングの旅を始める場所となるべきである。"
  },
  {
    "start": 1159090,
    "end": 1167982,
    "text": "そこで、検証を構築するために、まずはシンプルに、テスト中のアプリケーションの出力を人間のアノテーターに評価してもらうとしよう。"
  },
  {
    "start": 1168126,
    "end": 1175426,
    "text": "この場合の典型的なアプローチは、異なるプロンプトのセットや検索アプローチなどを持つアプリケーションがある場合である。"
  },
  {
    "start": 1175448,
    "end": 1183318,
    "text": "そのような場合は、まずこれらの回答を見て手作業で採点し、エバルのゴールデン・テスト・データ・セットを構築することから始めたい。"
  },
  {
    "start": 1183484,
    "end": 1192518,
    "text": "時間をかけてこの注釈をつけると、最終的にテスト・スイートができあがり、それをオンラインまたはオフラインで実行したり、CI CDパイプラインの一部として実行したりできる。"
  },
  {
    "start": 1192694,
    "end": 1196678,
    "text": "大規模な言語モデルの性質上、間違いを犯す可能性がある。"
  },
  {
    "start": 1196774,
    "end": 1197782,
    "text": "人間である。"
  },
  {
    "start": 1197846,
    "end": 1210000,
    "text": "あなたのユースケースにもよるが、出力フォーマットの不具合や幻覚、エージェントの暴走、トーンの不具合などをテストするためのエバルを構築することを検討するとよいだろう。"
  },
  {
    "start": 1212130,
    "end": 1241334,
    "text": "このライブラリには、様々な特定のユースケースや業種に対応した、実に挑戦的なevalのレジストリが含まれています。また、evalスイートを構築した後に、特定のユースケースに対してどのような評価やテストを構築すべきかを理解するのに便利で、多くの人にとって確かな出発点となるテンプレートがたくさんあります。"
  },
  {
    "start": 1241462,
    "end": 1246422,
    "text": "ここでの良い習慣であり、衛生的であることは、自分の評価を記録し、それを追跡することである。"
  },
  {
    "start": 1246566,
    "end": 1256960,
    "text": "この場合、例えば、5つの異なる評価を実行し、それぞれをゴールデン・テスト・データ・セットに対してスコアリングし、アノテーション、フィードバック、変更点の監査を行う。"
  },
  {
    "start": 1257570,
    "end": 1266530,
    "text": "変更の監査には、プロンプトの変更、検索戦略の変更、いくつかのショット例、あるいはモデルスナップショットのアップグレードなどが含まれる。"
  },
  {
    "start": 1267190,
    "end": 1271186,
    "text": "このようなトラッキングを始めるのに、複雑なツールは必要ない。"
  },
  {
    "start": 1271208,
    "end": 1280390,
    "text": "私たちの顧客の多くは、スプレッドシートだけで始めますが、重要なのは、各運転を非常に細かいレベルで保存し、それに応じて追跡できるようにすることです。"
  },
  {
    "start": 1281290,
    "end": 1290422,
    "text": "人間のフィードバックやユーザー評価は最高の信号であり品質であるが、高価であったり、必ずしも実用的でなかったりすることが多い。"
  },
  {
    "start": 1290486,
    "end": 1294090,
    "text": "例えば、実際の顧客データをエバリュエーションに使用できない場合などだ。"
  },
  {
    "start": 1294990,
    "end": 1301680,
    "text": "自動エバリュエーションは、開発者が進捗状況をモニターし、リグレッションを迅速にテストするのに役立つ。"
  },
  {
    "start": 1303410,
    "end": 1309390,
    "text": "モデルグレーデッド・エヴァル、つまりAIを使ってAIを採点することについて話そう。"
  },
  {
    "start": 1310210,
    "end": 1313062,
    "text": "GPTフォーは強力な評価者になり得る。"
  },
  {
    "start": 1313226,
    "end": 1324078,
    "text": "実際、多くの自然言語生成タスクにおいて、GPDの4つの評価は、いくつかのプロンプト方式を追加した人間の判断とよく相関していることが確認されている。"
  },
  {
    "start": 1324254,
    "end": 1340970,
    "text": "ここでのモデルグレーデッド・エバルの利点は、言語モデルで処理可能な評価プロセスの部分への人間の関与を減らすことで、評価方法の改良に必要な複雑なエッジケースへの対処に人間がより集中できるようになることである。"
  },
  {
    "start": 1342670,
    "end": 1346518,
    "text": "これが実際にどのようなものか、例を見てみよう。"
  },
  {
    "start": 1346694,
    "end": 1351610,
    "text": "この場合、入力クエリと2組の補完がある。"
  },
  {
    "start": 1352050,
    "end": 1355760,
    "text": "ひとつは地上真実で、もうひとつはモデルからサンプリングされたものである。"
  },
  {
    "start": 1356610,
    "end": 1367822,
    "text": "ここでの評価は、GPDフォーに提出された答案の事実内容と専門家の答案を比較するよう求める非常にシンプルなプロンプトで、これがGPDフォーに渡され採点される。"
  },
  {
    "start": 1367886,
    "end": 1374020,
    "text": "この場合、GPD Fourの見解は、提出された回答と専門家の回答の間に不一致があるというものだ。"
  },
  {
    "start": 1375430,
    "end": 1383080,
    "text": "思考の連鎖のようなプロンプトエンジニアリングのテクニックを追加して評価プロンプトを改良することで、これをさらに推し進めることができる。"
  },
  {
    "start": 1384650,
    "end": 1387350,
    "text": "前の例では、evalはかなりバイナリだったよね？"
  },
  {
    "start": 1387420,
    "end": 1390698,
    "text": "答えが真実と一致するか、しないか。"
  },
  {
    "start": 1390784,
    "end": 1401050,
    "text": "多くの場合、評価指標について考えたいでしょう。それは、ユーザーが期待するもの、あるいは導き出そうとしている成果と密接な相関関係があるものです。"
  },
  {
    "start": 1401950,
    "end": 1419250,
    "text": "例えば、シャーヴィンのカスタマーサービス・アシスタントの例に戻ると、対応の関連性、対応の信頼性などのカスタムメトリクスを評価し、モデルが基本的にそれらの異なるメトリクスや私たちが決めた基準に対してスコアをつけるようにしたい。"
  },
  {
    "start": 1420150,
    "end": 1424580,
    "text": "その基準やスコアカードがどのようなものか、例を挙げてみよう。"
  },
  {
    "start": 1424970,
    "end": 1435670,
    "text": "ここでは、関連性、信頼性、正しさについて、基本的にこの基準をGPD Fourに提供し、GPD Fourを使って出力候補を採点している。"
  },
  {
    "start": 1436730,
    "end": 1446570,
    "text": "ここでの良いヒントは、「伝える」よりも「見せる」ことである。基本的には、1点やPhi点がどのように見えるかの例を含めることが、この評価プロセスにおいて本当に役立つ。"
  },
  {
    "start": 1446720,
    "end": 1450490,
    "text": "そのモデルが基準を広めてくれるのは本当にありがたい。"
  },
  {
    "start": 1450830,
    "end": 1460254,
    "text": "この場合、GPDフォーは言語品質の内部モデルを効果的に学習し、関連性のあるテキストと低品質のテキストを区別するのに役立っている。"
  },
  {
    "start": 1460372,
    "end": 1467170,
    "text": "この内部採点メカニズムを利用することで、新しい出力候補の自動評価が可能になる。"
  },
  {
    "start": 1467670,
    "end": 1481490,
    "text": "GPD Fourが高価であったり、エバリュエーションに時間がかかったりする場合、今日の値下げ後であっても、3.5ターボモデルを微調整することができる。"
  },
  {
    "start": 1481570,
    "end": 1497020,
    "text": "実際には、GPD Fourを使って評価用の高品質なデータを集め、その出力を評価するのに適した3.5ジャッジモデルを微調整し、その微調整したモデルを使ってアプリケーションのパフォーマンスを評価することができる。"
  },
  {
    "start": 1497470,
    "end": 1508670,
    "text": "これはまた、評価にGPD 4を使うことで生じるバイアスを軽減することにも役立つ。ここで重要なのは、評価主導の開発を採用することだ。"
  },
  {
    "start": 1509250,
    "end": 1517522,
    "text": "良い評価とは、あなたが導き出そうとしている成果や、あなたが気にかけているユーザー指標とよく相関しているものです。"
  },
  {
    "start": 1517656,
    "end": 1522926,
    "text": "ラグの場合、エンド・トゥ・エンドのカバー率が非常に高く、コンピュートもスケーラブルだ。"
  },
  {
    "start": 1522958,
    "end": 1525860,
    "text": "そこで自動評価が大いに役立つ。"
  },
  {
    "start": 1529060,
    "end": 1531844,
    "text": "この時点で、あなたは楽しいユーザー体験を構築している。"
  },
  {
    "start": 1531962,
    "end": 1538192,
    "text": "ユーザーに一貫した製品を提供することができ、また評価を用いて自信を持って製品を反復することができる。"
  },
  {
    "start": 1538256,
    "end": 1543588,
    "text": "こうしたことをすべて正しく行えば、多くの場合、爆発的な人気を誇る製品を手にすることができる。"
  },
  {
    "start": 1543764,
    "end": 1550740,
    "text": "この1年でわかったことは、消費者のAISに対する欲求、そして社内の従業員のAISに対する欲求は非常に貪欲だということだ。"
  },
  {
    "start": 1550900,
    "end": 1554756,
    "text": "多くの場合、スケールをどのように管理するかを考え始めるだろう。"
  },
  {
    "start": 1554868,
    "end": 1559052,
    "text": "スケールを管理するということは、レイテンシーを管理し、コストを管理するということだ。"
  },
  {
    "start": 1559186,
    "end": 1569490,
    "text": "これで、オーケストレーションとして知られるスタックの最後の部分を紹介した。オーケストレーションでは、アプリケーションにいくつかの追加メカニズムとフォークを追加することで、スケールを管理することができる。"
  },
  {
    "start": 1570020,
    "end": 1583140,
    "text": "コストとレイテンシーを管理する上で、セマンティック・キャッシュを使ってAPIへの往復回数を減らすことと、より安価なモデルへのルーティングという2つの戦略があります。"
  },
  {
    "start": 1584120,
    "end": 1587300,
    "text": "このうち最初のものは、セマンティック・キャッシングとして知られている。"
  },
  {
    "start": 1588440,
    "end": 1597610,
    "text": "つまり、セマンティック・キャッシングがシステムの観点から実際にどのように見えるかというと、私たちとアプリケーションの間に位置するロジックに新しいレイヤーを追加することになる。"
  },
  {
    "start": 1598060,
    "end": 1602520,
    "text": "この場合、「GPT 4はいつリリースされたのですか？"
  },
  {
    "start": 1603740,
    "end": 1608968,
    "text": "まず、セマンティックキャッシュにアクセスし、そこでルックアップを行い、キャッシュに何かあるかどうかを確認する。"
  },
  {
    "start": 1608984,
    "end": 1610152,
    "text": "この場合はそうではない。"
  },
  {
    "start": 1610296,
    "end": 1613256,
    "text": "このリクエストをAPIに渡すだけだ。"
  },
  {
    "start": 1613368,
    "end": 1622370,
    "text": "そして、APIは2023年3月14日というような返答をし、それをセマンティック・キャッシュ（ベクター・データベースや他のタイプのストアかもしれない）に保存する。"
  },
  {
    "start": 1623060,
    "end": 1630312,
    "text": "ここで重要なのは、2023年3月14日のレスを保存し、GPT4がいつリリースされたかというクエリをキーにしているということだ。"
  },
  {
    "start": 1630396,
    "end": 1632864,
    "text": "そしてこれをユーザーに引き渡す。"
  },
  {
    "start": 1632992,
    "end": 1641364,
    "text": "しかし、1ヵ月後か1週間後に、ユーザーがGPTに4つのリリース日のクエスチョンマークを要求する別のリクエストが来たとしよう。"
  },
  {
    "start": 1641482,
    "end": 1647460,
    "text": "さて、これは以前とまったく同じクエリではないが、意味的には非常に似ており、まったく同じ応答で答えることができる。"
  },
  {
    "start": 1647540,
    "end": 1655208,
    "text": "この場合、キャッシュのセマンティック・ルックアップを行い、すでに持っていることに気づき、ユーザーに2023年3月14日を返すだけだ。"
  },
  {
    "start": 1655214,
    "end": 1663980,
    "text": "このセットアップでは、APIへの往復がなくなるのでレイテンシーが節約され、トークンの追加購入がなくなるのでコストが節約されます。"
  },
  {
    "start": 1665360,
    "end": 1675708,
    "text": "この方法は素晴らしいが、管理するのが少し難しい場合もある。"
  },
  {
    "start": 1675804,
    "end": 1680370,
    "text": "ここで、より安価なモデルへのルーティングを考え始め、オーケストレーションが真価を発揮する。"
  },
  {
    "start": 1680740,
    "end": 1686768,
    "text": "だから、安いモデルへのルーティングについて話すとき、多くの場合、最初に考えるのはGBD Fourから3.5ターボにすることだ。"
  },
  {
    "start": 1686944,
    "end": 1691380,
    "text": "GBT 3.5ターボはとても安く、とても速い。"
  },
  {
    "start": 1691530,
    "end": 1702090,
    "text": "しかし、GPT 4ほどスマートではないのは明らかで、3.5ターボをアプリケーションにドラッグ・アンド・ドロップするだけでは、素晴らしいカスタマー・エクスペリエンスを提供できていないことにすぐに気づくだろう。"
  },
  {
    "start": 1703340,
    "end": 1721570,
    "text": "しかし、わずか2カ月前にリリースしたGPT 3.5 TurboのファインチューニングAPIは、すでに顧客から大きな支持を得ており、顧客はGBT 3.5 Turboのカスタムバージョンを特定のユースケースに合わせてファインチューニングすることでコストを削減し、低レイテンシーと低コストというすべてのメリットを得ることができる、本当に素晴らしい方法となっています。"
  },
  {
    "start": 1722260,
    "end": 1726012,
    "text": "ファインチューニングについては、先ほども十分な話があったのは明らかだが、一言で言えば。"
  },
  {
    "start": 1726156,
    "end": 1726812,
    "text": "一言で言えば"
  },
  {
    "start": 1726876,
    "end": 1729968,
    "text": "ここでの主なアイデアは、自分でキュレートしたデータセットを使うことだ。"
  },
  {
    "start": 1730054,
    "end": 1737396,
    "text": "これは、あなたの特定のユースケースでどのように行動するかのモデルを説明する、時には何百、何千もの例のようなものかもしれない。"
  },
  {
    "start": 1737498,
    "end": 1740528,
    "text": "あなたは、そのキュレーションされたデータセットを私たちの微調整APIに渡すことになる。"
  },
  {
    "start": 1740624,
    "end": 1749770,
    "text": "おそらく、ここで1つか2つのパラメータを微調整し、そしてここでの主なアウトプットは、あなたのデータセットに基づいて、あなたとあなたの組織に特化した3.5Turboのカスタム、微調整バージョンとなる。"
  },
  {
    "start": 1750860,
    "end": 1760668,
    "text": "これは素晴らしいことだが、往々にしてこれを行うには大きな活性化エネルギーが必要となる。"
  },
  {
    "start": 1760754,
    "end": 1771616,
    "text": "先にも述べたように、ユースケースには数百、数千、時には数万ものサンプルが必要になることがあり、多くの場合、手作業でサンプルを作成するか、手作業を請け負う業者を雇うことになる。"
  },
  {
    "start": 1771798,
    "end": 1781500,
    "text": "しかし、多くのお客様が採用している素晴らしい方法のひとつに、GPT 4を使用して3.5ターボを微調整するためのトレーニングデータセットを作成する方法があります。"
  },
  {
    "start": 1781580,
    "end": 1785012,
    "text": "今、シャマルが言っていたことと同じようなことが、エバルの周辺でも起こり始めている。"
  },
  {
    "start": 1785066,
    "end": 1789904,
    "text": "GPD4は、実際に何度もプロンプトを与えることができる知能レベルにある。"
  },
  {
    "start": 1789952,
    "end": 1794344,
    "text": "この出力はトレーニング・セットとなる。"
  },
  {
    "start": 1794462,
    "end": 1797400,
    "text": "ここでは人間の手による介入は必要ない。"
  },
  {
    "start": 1797470,
    "end": 1804010,
    "text": "ここで効果的にやっていることは、GPTフォーからの出力を抽出して3.5ターボに送り込み、学習させるということだ。"
  },
  {
    "start": 1804540,
    "end": 1813230,
    "text": "多くの場合、これはあなたの特定の狭い領域で、3.5ターボのこの微調整されたバージョンがGPT Fourとほぼ同等になるのに役立ちます。"
  },
  {
    "start": 1814320,
    "end": 1826988,
    "text": "GPT3.5ターボは明らかに高速なので、レイテンシの観点だけでなく、コストの観点からもです。"
  },
  {
    "start": 1827164,
    "end": 1838032,
    "text": "もう少し具体的に説明すると、今日のGPT4戦の値下がり後でも、3.5ターボのファインチューンドバージョンの方が70％から80％安い。"
  },
  {
    "start": 1838176,
    "end": 1845896,
    "text": "バニラの3.5ターボほど安くはないが、それでもGBD Fourからかなり離れているのがわかるだろう。"
  },
  {
    "start": 1845998,
    "end": 1851370,
    "text": "ファインチューンファインチューン3.5ターボに乗り換えれば、かなりのコスト削減になる。"
  },
  {
    "start": 1854160,
    "end": 1865820,
    "text": "さて、私たちのモデルで作られたアプリケーションをプロトタイプから本番へとスケールさせる際に生じるユニークな検討事項や課題をナビゲートするのに役立つフレームワークについてお話しました。"
  },
  {
    "start": 1865900,
    "end": 1867040,
    "text": "おさらいしよう。"
  },
  {
    "start": 1867460,
    "end": 1875820,
    "text": "私たちは、不確実性を制御し、ガードレールを追加することによって、便利で楽しい、人間中心のユーザー体験を構築する方法について話しました。"
  },
  {
    "start": 1875980,
    "end": 1882660,
    "text": "そして、モデルのグラウンディングやモデル・レベルの機能を通じて、どのように一貫したエクスペリエンスを提供するかについて話した。"
  },
  {
    "start": 1883480,
    "end": 1889860,
    "text": "その後、評価を実施することによって、その経験を後退させることなく一貫して提供することについて話した。"
  },
  {
    "start": 1890360,
    "end": 1896680,
    "text": "そして最後に、レイテンシーとコストの管理というスケールに伴う考慮事項について話した。"
  },
  {
    "start": 1897260,
    "end": 1906296,
    "text": "私たちが見てきたように、私たちのモデルを使って作ることで、可能なことの表面積は増えたが、同時に挑戦の足跡も増えた。"
  },
  {
    "start": 1906488,
    "end": 1916400,
    "text": "スタックのオーケストレーション部分を含め、私たちが話したこれらの戦略はすべて、LLM OpS（大規模言語モデル操作）と呼ばれる新しい分野に収束しつつある。"
  },
  {
    "start": 1916820,
    "end": 1922130,
    "text": "このソフトウェア開発プロセスを合理化するために、2000年代初頭にDevOpsが登場したように。"
  },
  {
    "start": 1922740,
    "end": 1934560,
    "text": "LLM OPSは、LLMSでアプリケーションを構築する際に発生するユニークな課題に対応するために最近登場したもので、多くのエンタープライズ・アーキテクチャやスタックのコア・コンポーネントとなっている。"
  },
  {
    "start": 1934720,
    "end": 1943930,
    "text": "LLM OPSは基本的に、LLMの運用管理に必要な練習用ツールやインフラストラクチャーと考えることができる。"
  },
  {
    "start": 1944780,
    "end": 1949080,
    "text": "この分野は広大で進化しており、私たちはまだ表面しか見ていない。"
  },
  {
    "start": 1949420,
    "end": 1953356,
    "text": "詳細は省くが、これがどのようなものになるかのプレビューである。"
  },
  {
    "start": 1953538,
    "end": 1970480,
    "text": "LLM Opsの機能は、モニタリング、パフォーマンスの最適化、セキュリティ・コンプライアンスの支援、データとエンベッディングの管理、開発速度の向上、信頼性の高いテストと評価を大規模に行うプロセスの高速化などの課題に対処するのに役立ちます。"
  },
  {
    "start": 1971140,
    "end": 1980736,
    "text": "ここで、プロムチェーンやアシスタンスでの障害を特定し、デバッグし、本番での問題をより速く処理するために、観測可能性とトレースが特に重要になる。"
  },
  {
    "start": 1980848,
    "end": 1986592,
    "text": "例えば、異なるチーム間のコラボレーションを容易にし、ゲートウェイを簡素化することが重要だ。"
  },
  {
    "start": 1986656,
    "end": 1992730,
    "text": "統合は、セキュリティやAPIキーなどの一元管理に役立つ。"
  },
  {
    "start": 1993740,
    "end": 1999620,
    "text": "LLM Opsは、数千のアプリケーションと数百万のユーザーへのスケーリングを可能にします。"
  },
  {
    "start": 1999700,
    "end": 2005160,
    "text": "適切な基盤があれば、組織は採用を加速させることができる。"
  },
  {
    "start": 2005500,
    "end": 2015688,
    "text": "その場限りのツールではなく、この入り口に立つ若い探検家のように、長期的なプラットフォームと専門知識を開発することに焦点を当てるべきだ。"
  },
  {
    "start": 2015784,
    "end": 2025790,
    "text": "私たちの目の前には、今日お話しした枠組みを超えたインフラやプリミティブを構築するための幅広い機会が広がっている。"
  },
  {
    "start": 2026680,
    "end": 2033716,
    "text": "次世代のアシスタンスとエコシステムを構築するお手伝いができることを本当に嬉しく思っています。"
  },
  {
    "start": 2033898,
    "end": 2038020,
    "text": "築くべきもの、発見すべきものはたくさんある。"
  },
  {
    "start": 2038170,
    "end": 2038610,
    "text": "ありがとう。"
  }
]