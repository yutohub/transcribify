[
  {
    "start": 330,
    "end": 6494,
    "text": "ノウスはRLHFの主要著者の一人で、今週はこの話題についてたくさん話してきた。"
  },
  {
    "start": 6692,
    "end": 11134,
    "text": "彼はOpenAIの研究者で、バークレーの大学院生でもあったと思う。"
  },
  {
    "start": 11252,
    "end": 11630,
    "text": "クールだ。"
  },
  {
    "start": 11700,
    "end": 15840,
    "text": "は現在、アライメント・リサーチ・センターの創設者だと思う。"
  },
  {
    "start": 18450,
    "end": 19502,
    "text": "呼んでくれてありがとう。"
  },
  {
    "start": 19556,
    "end": 20830,
    "text": "みんなと話すのが楽しみだ。"
  },
  {
    "start": 20980,
    "end": 23434,
    "text": "ええ、バークレーのセオリーで博士号を取得しました。"
  },
  {
    "start": 23482,
    "end": 29334,
    "text": "オープンAIで数年間、より実用的なことをやっていたが、ここ2、3年は気候研究センターで理論の仕事に戻っている。"
  },
  {
    "start": 29532,
    "end": 34530,
    "text": "今日は、ニューラルネットワークの動作を説明しようとすること、ニューラルネットワークの動作を説明することの意味について話そうと思う。"
  },
  {
    "start": 34690,
    "end": 40710,
    "text": "このトークのほとんどは質問を含んでおり、答えがたくさんあるわけではないことをお断りしておきたい。"
  },
  {
    "start": 41690,
    "end": 45718,
    "text": "すみません、これはニューラルネットワークの説明についての話です。"
  },
  {
    "start": 45734,
    "end": 50330,
    "text": "なぜ私がニューラルネットワークの動作説明に興味があるのか、最初に少し述べておこうと思う。"
  },
  {
    "start": 50910,
    "end": 55034,
    "text": "現在、私たちはニューラルネットワークをブラックボックスとして訓練し、テストしている。"
  },
  {
    "start": 55162,
    "end": 68910,
    "text": "私たちは、あるモデルの品質や安全性を、ある不完全な測定と、ラボでサンプリングできるある特定の分布を持ち、そしてただテストし、実際にその分布で測定を行うことで推定している。"
  },
  {
    "start": 69070,
    "end": 73102,
    "text": "特に、そのモデルがいつ失敗するかは予測も発見もできないことが多い。"
  },
  {
    "start": 73166,
    "end": 78098,
    "text": "研究室では、私たちがシミュレートできるすべてのデータには真実があり、モデルが暗黙のうちに依存している性質がある。"
  },
  {
    "start": 78184,
    "end": 79460,
    "text": "故障する可能性もある。"
  },
  {
    "start": 80310,
    "end": 87640,
    "text": "モデルをブラックボックスとして扱っているのであれば、モデルが実際に失敗するのを見るまで、それが起こるかどうかはわからない。"
  },
  {
    "start": 88730,
    "end": 99770,
    "text": "もう少し微妙なことを言えば、このモデルがどのように動作しているのかがわからない場合、モデルが意図したとおりに動作していて、あなたの測定がそれを検知している場合と、モデルがあなたの測定の不完全さを利用しているだけの場合とを区別することはできない。"
  },
  {
    "start": 100670,
    "end": 108218,
    "text": "私たちは、あるモデルがある分布で機能する理由を説明できれば、それらの課題に対処できると期待するかもしれない。"
  },
  {
    "start": 108314,
    "end": 120398,
    "text": "この説明によって、良い行動をするための前提条件が明確になり、それがどの程度強固かを予測したり、いつ崩れるかを検知したりすることができる。"
  },
  {
    "start": 120564,
    "end": 122602,
    "text": "これが私が説明にこだわる理由のようなものだ。"
  },
  {
    "start": 122666,
    "end": 128786,
    "text": "私は、たとえあなたがこれを全く信じないとしても、ニューラルネットワークを説明することに関心を持ち、ブラックボックスであることを愛さない理由はたくさんあると思う。"
  },
  {
    "start": 128898,
    "end": 133494,
    "text": "多分、ここでの主な収穫は、私は説明というものに、ある目的への手段としてほとんど興味があるということだ。"
  },
  {
    "start": 133612,
    "end": 144380,
    "text": "モデルに対する人間の理解をそれ自体の目的として評価するのではなく、安全上の課題に対処するために使用するものとして評価することは、これからお話しする説明の概念にとって重要な文脈かもしれません。"
  },
  {
    "start": 146430,
    "end": 150998,
    "text": "トークの全体的なアウトラインとして、説明という言葉の意味するさまざまなことについて少しお話しします。"
  },
  {
    "start": 151094,
    "end": 156442,
    "text": "それから、ニューラルネットの行動を説明する概念として提供するヒューリスティックな議論について話すことにしよう。"
  },
  {
    "start": 156586,
    "end": 165010,
    "text": "それから、ヒューリスティックな議論を形式化したものを探すという研究課題について、そしてニューラルネットワークの動作に説明が存在すると期待できる理由についてお話しします。"
  },
  {
    "start": 167510,
    "end": 169454,
    "text": "おもちゃのセッティングを考えてみるつもりだ。"
  },
  {
    "start": 169502,
    "end": 172594,
    "text": "何か既知の目標関数gがあると想像する。"
  },
  {
    "start": 172792,
    "end": 175700,
    "text": "その関数を近似するためにニューラルネットワークを訓練する。"
  },
  {
    "start": 176310,
    "end": 181282,
    "text": "たぶんgは、ここにサットのインスタンスがあり、それが満足できるものなら1、満足できないものなら0というようなものだと想像しているのだろう。"
  },
  {
    "start": 181426,
    "end": 185106,
    "text": "そして、訓練されたモデルのパラメータのセットが与えられる。"
  },
  {
    "start": 185138,
    "end": 193970,
    "text": "誰かが私にこの10億の数字のようなものを手渡した。なぜ、この特定の10億のパラメーターを持つトランスが、このタスクで高い精度を持つのかを説明したい。"
  },
  {
    "start": 194130,
    "end": 198058,
    "text": "これは、私がターゲット関数gを知っているおもちゃのような設定だと言っている。"
  },
  {
    "start": 198144,
    "end": 203290,
    "text": "現実の世界では、よくわからないデータ分布のように、世界に関する未知の事実に依存することがよくある。"
  },
  {
    "start": 203440,
    "end": 214062,
    "text": "このおもちゃの設定のいいところは、説明しようとするステートメントが正確に定義されているので、データ分布の正式な定義、関数gの正式な定義、そして実際のニューラルネットが目の前にあることだ。"
  },
  {
    "start": 214116,
    "end": 218674,
    "text": "これは、私が説明したい数学的事実であり、正確に特定された事実である。"
  },
  {
    "start": 218872,
    "end": 221074,
    "text": "これで、これから話すいくつかのことがシンプルになったと思う。"
  },
  {
    "start": 221112,
    "end": 225842,
    "text": "私は、ニューラルネットワークの動作を説明するための基本的な課題が、この場合にも発生する、あるいは多くの重要な課題が発生すると思う。"
  },
  {
    "start": 225896,
    "end": 228198,
    "text": "このケースに対応できるようになれば、とても便利だと思う。"
  },
  {
    "start": 228284,
    "end": 231270,
    "text": "本当の未知のデータ分布について話すつもりはまったくない。"
  },
  {
    "start": 233610,
    "end": 237810,
    "text": "ああ、念のために言っておくが、私は君がここで何を考えているのか理解している。"
  },
  {
    "start": 237900,
    "end": 245850,
    "text": "もしこのgについてそれができたら、基本的にpがNpに等しいという証明になるのだろうか？"
  },
  {
    "start": 246510,
    "end": 248730,
    "text": "説明の意味にもよる。"
  },
  {
    "start": 249390,
    "end": 253094,
    "text": "もし私が実際に非常に高い精度を持っていたなら、彼らはpがNpに等しいことを証明してくれるだろう。"
  },
  {
    "start": 253142,
    "end": 258730,
    "text": "このモデルは、1000句のSATインスタンスでSATモデルを訓練しても、超高精度にはならないだろう。"
  },
  {
    "start": 258810,
    "end": 260046,
    "text": "ある程度の精度は出るだろう？"
  },
  {
    "start": 260068,
    "end": 262990,
    "text": "分布にもよるが、たぶん50％くらいの精度だろう。"
  },
  {
    "start": 263970,
    "end": 271138,
    "text": "これは習得するのが非常に難しい機能であり、おそらく、その高さによって、あるいはどれだけ感銘を受けたかに左右されるだろう。"
  },
  {
    "start": 271144,
    "end": 274260,
    "text": "うまくいけば50％以上になるだろうが、70％でも何でもいい。"
  },
  {
    "start": 276170,
    "end": 276920,
    "text": "オーケー。"
  },
  {
    "start": 277930,
    "end": 284550,
    "text": "そのパフォーマンスを達成するためのアルゴリズムのようなものを教えてくれる。"
  },
  {
    "start": 285290,
    "end": 289366,
    "text": "ニューラルネットは、できればアルゴリズムであってほしい。"
  },
  {
    "start": 289388,
    "end": 292250,
    "text": "説明とは何を意味するのか？"
  },
  {
    "start": 294270,
    "end": 297978,
    "text": "もしそれが質問の答えにならないのであれば、私は喜んで再考する。"
  },
  {
    "start": 298144,
    "end": 301046,
    "text": "最初にお話しするのは、単なる説明です。"
  },
  {
    "start": 301078,
    "end": 306158,
    "text": "人間に与えることで、そのモデルがなぜ、あるいはどのように機能するのかを理解した気にさせるものだ。"
  },
  {
    "start": 306244,
    "end": 308634,
    "text": "ある意味で、これは自然前理論の概念に似ている。"
  },
  {
    "start": 308682,
    "end": 312510,
    "text": "これは、ただ説明を求めている人が入ってくるようなものだ。"
  },
  {
    "start": 314530,
    "end": 321730,
    "text": "これがどのように機能するかを定型化すると、モデルの活性化空間においてニューロンや方向に意味を割り当てることができる。"
  },
  {
    "start": 321880,
    "end": 334354,
    "text": "モデルの重みによって、ニューロンや方向性がどのように関係し合っているかを調べ、なぜそのような関係性のような活性化が問題解決につながるのか、納得のいくストーリーを語り、そして実験をすることによってそのストーリーを検証する。"
  },
  {
    "start": 334482,
    "end": 339000,
    "text": "この画像は、数年前のオープンAIでのクリス・オラのチームの静止回路スレッドからのものだ。"
  },
  {
    "start": 339930,
    "end": 347506,
    "text": "この左側には、第4層bのいくつかの方向、つまりニューロンがあり、これらは窓、車のボディ、車輪を表しているという仮説がある。"
  },
  {
    "start": 347618,
    "end": 350538,
    "text": "右側には車を表すニューロンがある。"
  },
  {
    "start": 350634,
    "end": 356090,
    "text": "これらのニューロンを互いにつないでいるウェイトを見て、よし、窓が車の上にあれば、車の検知器を興奮させる、と言うことができる。"
  },
  {
    "start": 356170,
    "end": 359642,
    "text": "ホイールが車の下にある場合は、車の検知器をディサイトし、車の検知器をエキサイトさせる。"
  },
  {
    "start": 359706,
    "end": 367890,
    "text": "その結果、なぜより優れた自動車探知機になるのか、あるいは、なぜこのモデルが、最終的には自動車を分類するというタスクを解決することになるのか、といったような、私たちにとって納得のいくストーリーを語ることができる。"
  },
  {
    "start": 369990,
    "end": 381750,
    "text": "誰かがモデルを見て、そのモデルがやっていることを理解しようとし、人間がなぜこのモデル、1億の重みを持つこの特定のセットが課題を解決することにつながるのかを理解したと感じられるようなストーリーを語ろうとする、ある種のパラダイム的な例だ。"
  },
  {
    "start": 384810,
    "end": 388578,
    "text": "また、私が説明したおもちゃの設定で、アルゴリズム・タスクのようなことをすることも想像できるだろう。"
  },
  {
    "start": 388594,
    "end": 392294,
    "text": "この場合、極めて単純な作業をするために訓練された変圧器があると想像してほしい。"
  },
  {
    "start": 392342,
    "end": 398986,
    "text": "2つの数aとBが与えられたとき、その和をmod pで計算する。"
  },
  {
    "start": 399088,
    "end": 407278,
    "text": "ランダムに選んだaとbをこの変圧器にかけると、99％の確率でその和とpのモジュレーションが得られる。"
  },
  {
    "start": 407444,
    "end": 410974,
    "text": "このような図を書くことになるかもしれない。"
  },
  {
    "start": 411172,
    "end": 414910,
    "text": "このモデルがaという値とbという値をどのように表現しているかという話だ。"
  },
  {
    "start": 414980,
    "end": 422762,
    "text": "ここでは、モデルによって実装された重みのセットや変換を見ることができ、なぜその変換を実装することでこのタスクを解決できるのかを説明することができる。"
  },
  {
    "start": 422826,
    "end": 426642,
    "text": "人間はそれを読んで、よし、ちょっと納得した、と言うこともできるし、実験をするかもしれない。"
  },
  {
    "start": 426706,
    "end": 429800,
    "text": "つまり、次のようなアブレーションを行えば、このモデルは機能しなくなるということだ。"
  },
  {
    "start": 430890,
    "end": 431734,
    "text": "一日の終わりに"
  },
  {
    "start": 431772,
    "end": 435542,
    "text": "このオブジェクトの正式な型シグネチャが何なのかは正確にはわからないが、あなたが人間に言ったことだ。"
  },
  {
    "start": 435596,
    "end": 438920,
    "text": "人間は、何が起こっているのか、なぜこのモデルが機能するのかを理解した気になる。"
  },
  {
    "start": 442010,
    "end": 443962,
    "text": "私はこのような形の研究にかなり興奮している。"
  },
  {
    "start": 444016,
    "end": 446502,
    "text": "私は、ニューラルネットワークがブラックボックスとして扱われるのが好きではない。"
  },
  {
    "start": 446566,
    "end": 449050,
    "text": "彼らの内部で何が起こっているのかを理解しようとするのが大好きなんだ。"
  },
  {
    "start": 449120,
    "end": 450442,
    "text": "いくつか問題があると思う。"
  },
  {
    "start": 450576,
    "end": 453194,
    "text": "明らかな問題は、\"understand \"が何を意味するのかよくわからないということだ。"
  },
  {
    "start": 453232,
    "end": 464240,
    "text": "そのため、進捗状況を検証したり、進捗状況を拡大したり、この作業をどのように自動化するか、あるいは私たちが何をしているかを考えたりするのは少し難しい。"
  },
  {
    "start": 464770,
    "end": 473010,
    "text": "関連する疑問として、モデルが人間が認識できるような方法で思考していない場合、つまり、我々が探しているアルゴリズムがすでに分かっていないような場合、理解とは何かを得ることは可能なのだろうか、ということがある。"
  },
  {
    "start": 473160,
    "end": 475214,
    "text": "大きなモデルを小さく分解できるか？"
  },
  {
    "start": 475262,
    "end": 475810,
    "text": "そうだ。"
  },
  {
    "start": 475880,
    "end": 478654,
    "text": "理論家である私にとっては、これらは実際にはかなり深刻な問題だと思う。"
  },
  {
    "start": 478702,
    "end": 479702,
    "text": "本当に悪い問題のようだ。"
  },
  {
    "start": 479756,
    "end": 485880,
    "text": "私は理解の特性について話したいのだが、それを人間がどう感じるかという基準で定義するのは非常に難しい。"
  },
  {
    "start": 487050,
    "end": 491622,
    "text": "ニューラルネットワークの仕組みを理解する、あるいは説明することの意味には、ある種のひとつの選択肢がある。"
  },
  {
    "start": 491756,
    "end": 495946,
    "text": "私は主に他の選択肢について話すつもりだが、これはある種の状態なので、これを理解することは重要だと思う。"
  },
  {
    "start": 496048,
    "end": 506042,
    "text": "モデルがどのように機能するかを説明する限りにおいて、これは私が最も愛している、あるいは最も好きなことであり、今世界に存在する私が目指しているものに迫るものである。"
  },
  {
    "start": 506186,
    "end": 509200,
    "text": "第二の選択肢は、モデルが機能することを証明することだ。"
  },
  {
    "start": 509810,
    "end": 512426,
    "text": "私は非常に単純なアルゴリズムの仕事を与えた。"
  },
  {
    "start": 512538,
    "end": 514106,
    "text": "この言葉は完璧に定義されている。"
  },
  {
    "start": 514138,
    "end": 521940,
    "text": "ランダムにaとbをサンプリングし、それをこの変圧器に渡し、その出力をデコードした場合、a＋b mod pになる確率は？"
  },
  {
    "start": 523270,
    "end": 526162,
    "text": "実際、その確率はかなり高く、99％以上だ。"
  },
  {
    "start": 526216,
    "end": 527700,
    "text": "私はその事実を証明することができる。"
  },
  {
    "start": 529110,
    "end": 540370,
    "text": "というのも、ニューラルネットワークを見ていて、解釈可能性について論文を書こうとするときに持っているような理解と、実際に証明に入るような理解との間には、とてもとても大きな隔たりがあると思うからです。"
  },
  {
    "start": 540450,
    "end": 554670,
    "text": "この図は、この定理の証明にはほど遠いと思いますが、このような線に沿って、アクティベーションとaやbという数字との関係について、いくつかのレンマを作り、証明し、モデルを進めるにつれてそれらを積み上げていき、最終的にこの定理の証明ができる、というようなことを想像してみてください。"
  },
  {
    "start": 555490,
    "end": 556240,
    "text": "そうだね。"
  },
  {
    "start": 556770,
    "end": 560350,
    "text": "この具体的な定理については、サンプリングが可能である。"
  },
  {
    "start": 560930,
    "end": 566362,
    "text": "例えば、分布から独立サンプルを抽出して、そのステートメントを検証することができる。"
  },
  {
    "start": 566506,
    "end": 566862,
    "text": "そうだね。"
  },
  {
    "start": 566916,
    "end": 570570,
    "text": "この微妙な違いがあることは想像がつくだろう。"
  },
  {
    "start": 570650,
    "end": 576806,
    "text": "例えば、ラボでサンプリングできる分布について、自分のモデルがどの程度優れているかを知りたい場合、a、bをサンプリングしてチェックするのが一般的だと思います。"
  },
  {
    "start": 576908,
    "end": 579138,
    "text": "ある意味、それはニューラルネットでやっていることと非常に似ている。"
  },
  {
    "start": 579154,
    "end": 581378,
    "text": "ほとんどの場合、ブラックボックスのサンプルとして扱うことができる。"
  },
  {
    "start": 581394,
    "end": 584150,
    "text": "いくつかの入力は、入力出力の動作の特性を測定する。"
  },
  {
    "start": 584970,
    "end": 594438,
    "text": "私たちが説明に求めているもの、あるいは私が興味を持っているものは、例えば、モデルが機能するようになった条件は何だったのか、あるいはモデルが特性を持つようになったさまざまな理由を区別することができるようなものである。"
  },
  {
    "start": 594604,
    "end": 603198,
    "text": "これは、人間がモデルを見て、何が起こっているのかを理解した場合に得られることを期待するようなものだ。"
  },
  {
    "start": 603284,
    "end": 611710,
    "text": "サンプリングでは定理を証明することはできないので、サンプリングすれば、この事実を証明する説得力のある証拠は得られるだろうが、証明は得られないということだ。"
  },
  {
    "start": 612610,
    "end": 617650,
    "text": "ポール、あなたにとって、証明は説明より厳密に優れているのか、それとも両者は比較できないものなのか？"
  },
  {
    "start": 617990,
    "end": 621394,
    "text": "私は、説明とは何かという選択肢のようなものとして証明を提示するつもりだ。"
  },
  {
    "start": 621432,
    "end": 625118,
    "text": "私の観点からは、証明は有用な説明の形だと思う。"
  },
  {
    "start": 625214,
    "end": 629794,
    "text": "証明とは、結論が成り立つために必要な前提を明示することだと思います。"
  },
  {
    "start": 629832,
    "end": 633590,
    "text": "例えば、その仮定が失敗した場合にそれを検出したり、その仮定がどの程度ロバストであるかを推論したりすることができる。"
  },
  {
    "start": 633660,
    "end": 640690,
    "text": "もっと微妙なことだと思うが、さまざまなメカニズムを解明したり、なぜそうなるのかを直感的に理解したりすることはできるのだろうか？"
  },
  {
    "start": 640860,
    "end": 643862,
    "text": "有名な無照明の証明がある。"
  },
  {
    "start": 644006,
    "end": 651242,
    "text": "その証明は、証明の検証者にとっては非常に有益なものであり、人間である私にとってはあまり有益なものではない。"
  },
  {
    "start": 651296,
    "end": 656350,
    "text": "だから、選択肢1から選択肢2に移ることで、私は人間がこれらの説明を理解することを諦めた。"
  },
  {
    "start": 656930,
    "end": 661786,
    "text": "特に、ニューラルネットワークの動作の証明は、もし得られたとしても、例外なく理解不能なものになると思う。"
  },
  {
    "start": 661898,
    "end": 668420,
    "text": "GPT4の性質の証明は、何千、何千億ページにもなりそうだ。"
  },
  {
    "start": 670630,
    "end": 672690,
    "text": "エラーの声明文があることさえ知らない。"
  },
  {
    "start": 675590,
    "end": 676514,
    "text": "そうだね。"
  },
  {
    "start": 676552,
    "end": 678546,
    "text": "このおもちゃのセッティングでは、その特性が何であるかを正確に言うことができる。"
  },
  {
    "start": 678568,
    "end": 679842,
    "text": "実際のところ、正確なことは分からない。"
  },
  {
    "start": 679896,
    "end": 683640,
    "text": "つまり、GBT4が何らかの特性を持つというのはどういうことなのか、ということだ。"
  },
  {
    "start": 684490,
    "end": 685654,
    "text": "いくつかあるかもしれない。"
  },
  {
    "start": 685772,
    "end": 688786,
    "text": "今回の講演では、定理設定が分かっているこのケースに主に焦点を当てるつもりだ。"
  },
  {
    "start": 688818,
    "end": 694610,
    "text": "難易度の一部を加えるというのは合理的だと思うし、難易度の大部分か、半分か、あるいは何分の一かについて議論することもできる。"
  },
  {
    "start": 694690,
    "end": 698306,
    "text": "定理を知っている状況でも、役に立つことはたくさんあると思う。"
  },
  {
    "start": 698338,
    "end": 707646,
    "text": "例えば、GPT-4とGPT-3について長い間考えてきたように、異なるモデル間の関係を理解すること。"
  },
  {
    "start": 707828,
    "end": 714770,
    "text": "おそらく、それを掘り下げて言うつもりはないし、その発言を知っているこの玩具のセッティングを考えることで、何分の一であろうと諦めているんだ。"
  },
  {
    "start": 718230,
    "end": 723810,
    "text": "証明について考えるとき、大きな問題となるのは、私たちが興味を持っている動作のショートプルーフはあるのか、ということだ。"
  },
  {
    "start": 723960,
    "end": 728974,
    "text": "私は、あなたが興味深いモデルの振る舞いについて短い証明を受ける権利があると期待する理論的な理由があるとは思わない。"
  },
  {
    "start": 729022,
    "end": 733954,
    "text": "実際には、短い証明にならないことが多いという理論的なケースはかなりあると思う。"
  },
  {
    "start": 734002,
    "end": 734982,
    "text": "非常にハードだった。"
  },
  {
    "start": 735036,
    "end": 741302,
    "text": "私は、局所的な摂動に対する頑健性以外に、本質的に興味深いモデルについて、誰も興味深い事実を証明していないと思う。"
  },
  {
    "start": 741366,
    "end": 746250,
    "text": "あるいは、何が興味深いかについて話すこともできるが、このおもちゃの声明に似たほとんどの事実は、人々が証明することができない。"
  },
  {
    "start": 748430,
    "end": 749926,
    "text": "私は証明に興味があると思う。"
  },
  {
    "start": 749958,
    "end": 756282,
    "text": "証明は、モデルがどのように機能するかについてのある種の理解を示すものであり、神経学者がブラックボックスであることによって提起されるある種の問題に役立つと思う。"
  },
  {
    "start": 756346,
    "end": 762298,
    "text": "問題は、彼らが存在しないか、存在しないかもしれないということだ。"
  },
  {
    "start": 762394,
    "end": 767198,
    "text": "その代わり、この講演では、モデルが機能するという発見的議論とでも呼ぶべき、第3の選択肢を考えてみようと思う。"
  },
  {
    "start": 767284,
    "end": 775714,
    "text": "というのは、ある種の演繹的論証のことで、ゲームの形式的なルールのようなもので、証明のルールと似たようなものだが、完璧な自信と結論を与えるものではない。"
  },
  {
    "start": 775762,
    "end": 777654,
    "text": "の証明で決着がついた。"
  },
  {
    "start": 777772,
    "end": 780706,
    "text": "例えば、モデルが機能することを証明すれば、バックドアがないことを証明したようなものだ。"
  },
  {
    "start": 780738,
    "end": 782178,
    "text": "それ以外のゴチャゴチャがないことは証明済みだ。"
  },
  {
    "start": 782274,
    "end": 785960,
    "text": "私たちは、何かが真実であると考える一応の根拠を与える議論について話すつもりだ。"
  },
  {
    "start": 787130,
    "end": 796840,
    "text": "それが、この話の残りの部分になる。"
  },
  {
    "start": 797370,
    "end": 799250,
    "text": "最も単純な例のひとつだ。"
  },
  {
    "start": 799330,
    "end": 801598,
    "text": "誰かが私に次のような難しい質問をしたと想像してほしい。"
  },
  {
    "start": 801684,
    "end": 806922,
    "text": "整数xを1からnの間で無作為に標本化した場合、xとx+2がともに素数である確率は？"
  },
  {
    "start": 807066,
    "end": 810906,
    "text": "これは、証明が得られる可能性が極めて低い簡単な質問の典型的な例だ。"
  },
  {
    "start": 810938,
    "end": 812538,
    "text": "あるいは、証明を得るのはとてもとても難しい。"
  },
  {
    "start": 812634,
    "end": 815114,
    "text": "この確率を計算する努力は必ずできる。"
  },
  {
    "start": 815242,
    "end": 818334,
    "text": "xが素数である確率はlog nの1倍である。"
  },
  {
    "start": 818372,
    "end": 822478,
    "text": "素数の定理によって、xに2を足したものがlog nの1乗の確率で素数になることは簡単に計算できる。"
  },
  {
    "start": 822564,
    "end": 824766,
    "text": "この両方が真実である確率について、私は考えている。"
  },
  {
    "start": 824788,
    "end": 826920,
    "text": "同時に、全く分からないんだ。"
  },
  {
    "start": 827290,
    "end": 838460,
    "text": "正の相関があるのか負の相関があるのか、あるいは何かはわからないが、正の相関があるのか負の相関があるのかわからないので、相関をゼロと仮定して、対数2乗nを1倍したものをデフォルトの推定値とすることもできる。"
  },
  {
    "start": 839070,
    "end": 845020,
    "text": "私が主張したいのは、この質問に対する答えが対数の2乗nの1倍であることを推測するのに十分な第一通過の理由を与えてくれるということだ。"
  },
  {
    "start": 850510,
    "end": 855110,
    "text": "この見積もりは証明とは異なり、修正される可能性がある。"
  },
  {
    "start": 855190,
    "end": 861514,
    "text": "例えば、xが素数であることと、xに2を足したものが素数であることの関係について私が気づいた場合、このデフォルトの見積もりは変更されることになる。"
  },
  {
    "start": 861562,
    "end": 864320,
    "text": "証明とは違って、これはデフォルトの状態から動けるだけだ。"
  },
  {
    "start": 864690,
    "end": 868694,
    "text": "例えば、xが素数の場合、xに2を足すとほぼ間違いなく奇数になる。"
  },
  {
    "start": 868762,
    "end": 871826,
    "text": "xに2を足したものが素数である確率は、実際にはlog nの約2倍である。"
  },
  {
    "start": 871848,
    "end": 875666,
    "text": "ランダムなOD数が素数である確率は、log nの1倍よりも推測しやすい。"
  },
  {
    "start": 875768,
    "end": 880054,
    "text": "nの対数2乗に対する2つの推定値は、nの対数2乗に対する私の元の推定値よりも優れている。"
  },
  {
    "start": 880252,
    "end": 883362,
    "text": "また別の関係に気づいたら、その見積もりを修正し続けるつもりだ。"
  },
  {
    "start": 883426,
    "end": 884454,
    "text": "それはゲームのルールに過ぎない。"
  },
  {
    "start": 884492,
    "end": 890040,
    "text": "誰かが私に考慮事項を与え、私はその観点から、あるいは渡された考慮事項に基づいて見積もりを修正する。"
  },
  {
    "start": 891210,
    "end": 892054,
    "text": "続けることができる。"
  },
  {
    "start": 892092,
    "end": 896646,
    "text": "この試合は最終的に1.32から対数の2乗nを超えるくらいに落ち着くと思う。"
  },
  {
    "start": 896678,
    "end": 902570,
    "text": "このようにすべての考察を統合した上で、実験と一致するのはどれかと考えると、おそらく正しい推定値だろう。"
  },
  {
    "start": 906270,
    "end": 910382,
    "text": "このような敗北可能な確率論的推理は、探せば本当によくあることだ。"
  },
  {
    "start": 910436,
    "end": 920286,
    "text": "この双子素数予想の例のように、素数のランダムなモデルを取ることもできるし、空想的な方程式を解く解を取ることもできる。"
  },
  {
    "start": 920318,
    "end": 926610,
    "text": "私は、この種の発見的議論に基づいて、数論におけるほとんどの推測に決着をつけることができると思う。"
  },
  {
    "start": 927510,
    "end": 930206,
    "text": "物理学者は証明できないことを計算するのが仕事だ。"
  },
  {
    "start": 930238,
    "end": 935874,
    "text": "物理学者が怠け者で証明を書くのを好まないからというだけでなく、彼らが使う手法が証明に対応していないことが多いからだ。"
  },
  {
    "start": 935922,
    "end": 942440,
    "text": "それは、予想がどちらか一方であると考える理由に相当し、後に覆される可能性があり、まれに覆されることもある。"
  },
  {
    "start": 942970,
    "end": 951930,
    "text": "複雑な力学系があり、それについて推論したい場合、推論の方法は、決定論的な系であっても確率論的なものとして扱い、このような独立性の仮定を用いることが多い。"
  },
  {
    "start": 952910,
    "end": 955754,
    "text": "強調したいのは、これらはモンテカルロ法による推定値ではないということだ。"
  },
  {
    "start": 955802,
    "end": 962526,
    "text": "これらはすべて演繹的論証のようなもので、前提から結論へと推論し、これとこれの関係はこうだ、と言うものである。"
  },
  {
    "start": 962628,
    "end": 970510,
    "text": "単に素数のデッキをたくさんサンプリングして、x＋2が素数になる頻度をチェックするのではなく、これはモンテカルロ推定とはまったく異なる推論の範疇である。"
  },
  {
    "start": 970590,
    "end": 973282,
    "text": "モンテカルロ法は、ニューラルネットワークのトレーニングで行うようなものだ。"
  },
  {
    "start": 973416,
    "end": 978360,
    "text": "これは、能力のレベルははるかに低いが、構造的には証明に近いものだ。"
  },
  {
    "start": 984330,
    "end": 999930,
    "text": "最後のスライドで述べたような議論を見てみると、多くの共通した構造を持つ傾向があります。つまり、基本的には演繹的に妥当な議論であり、未知の量をランダムなものとして扱い、たとえそれが決定論的であったとしても、その量の期待値を推定するためにいくつかの単純なヒューリスティックを使うのです。"
  },
  {
    "start": 1000750,
    "end": 1008170,
    "text": "最も単純なヒューリスティックは、aとbがどのように関係しているのか何も知らず、その積の期待値を推定したい場合、その積を期待値の積として扱うことであろう。"
  },
  {
    "start": 1008250,
    "end": 1010590,
    "text": "ただ、デフォルトで相関はゼロだと仮定している。"
  },
  {
    "start": 1011250,
    "end": 1015090,
    "text": "素数の例では、xは素数であり、x＋2は素数である。"
  },
  {
    "start": 1018790,
    "end": 1025154,
    "text": "もう少し複雑なヒューリスティックは、aとbの両方に関係する要因zについて知っている場合、というものだ。"
  },
  {
    "start": 1025192,
    "end": 1029122,
    "text": "例えば、zのaとの共分散を知っていて、zのbとの共分散も知っているとする。"
  },
  {
    "start": 1029256,
    "end": 1034370,
    "text": "aとbが独立であると仮定するのではなく、zに回帰した場合の残差が独立であると仮定することができる。"
  },
  {
    "start": 1034450,
    "end": 1038246,
    "text": "私が言えるのは、zが2人の関係を動かしている1つの要因であるということだ。"
  },
  {
    "start": 1038348,
    "end": 1047880,
    "text": "この方程式を本当に検証できるかどうかはわからないが、私が言っているのは、aとbの共分散は、aとzの共分散×zとbの共分散をzの分散で割ったものである。"
  },
  {
    "start": 1048490,
    "end": 1056800,
    "text": "zがxの一次性とx＋2の一次性の両方を駆動する方法を理解しているからである。"
  },
  {
    "start": 1059200,
    "end": 1067344,
    "text": "多くのドメインにまたがるこれらの推定について、良い点、あるいは示唆的な点は、このような形の単純なヒューリスティック、特に一番下のものを使っているように見えることだ。"
  },
  {
    "start": 1067542,
    "end": 1072960,
    "text": "実に広範な領域で、妥当な最良推定値を得るには、これで十分なのだ。"
  },
  {
    "start": 1075700,
    "end": 1085264,
    "text": "つまり、これらのヒューリスティックな議論はすべて、実際にうまく機能するドメイン固有のトリックの束ではなく、ある単純な一般的な形式論のインスタンスなのだ。"
  },
  {
    "start": 1085392,
    "end": 1090580,
    "text": "つまり、素数には魔法のような事実があるわけではなく、素数はあたかもランダムな集合であるかのように振る舞うのである。"
  },
  {
    "start": 1090650,
    "end": 1095960,
    "text": "素数に当てはめれば、このような推定値が得られる一般的な推論原理があるということだ。"
  },
  {
    "start": 1097500,
    "end": 1102916,
    "text": "それになぞらえれば、論理的演繹法は、論理的に推論するときに非常に幅広く適用できる単純な形式論である。"
  },
  {
    "start": 1102948,
    "end": 1104436,
    "text": "難しいのは証拠を見つけるようなものだ。"
  },
  {
    "start": 1104468,
    "end": 1106636,
    "text": "難しいのは、証明が正しいかどうかを検証することではない。"
  },
  {
    "start": 1106738,
    "end": 1112744,
    "text": "多くの領域にまたがるこの推論が、ひとつのシンプルな形式論に統一されることを、私たちは願っている。"
  },
  {
    "start": 1112872,
    "end": 1116140,
    "text": "難しいのは論拠を見つけることであって、論拠を検証することではない。"
  },
  {
    "start": 1121040,
    "end": 1122524,
    "text": "なぜ、それがもっともらしいと思うのか？"
  },
  {
    "start": 1122652,
    "end": 1124112,
    "text": "最初の理由はすでに述べたとおりだと思う。"
  },
  {
    "start": 1124166,
    "end": 1128076,
    "text": "これらの議論は、多くの領域にわたっても、非常にシンプルで一般的な構造を持っているようだ。"
  },
  {
    "start": 1128108,
    "end": 1129676,
    "text": "このような共通の枠組みで考えることができる。"
  },
  {
    "start": 1129788,
    "end": 1133616,
    "text": "別に経験的に検証しなければならないアドホックなルールの束ではないようだ。"
  },
  {
    "start": 1133808,
    "end": 1136224,
    "text": "もうひとつ重要な点は、デフォルトで機能しているように見えることだ。"
  },
  {
    "start": 1136272,
    "end": 1141620,
    "text": "このような議論はしばしば失敗するようだが、失敗するときは、失敗すべき特定の理由があるからだ。"
  },
  {
    "start": 1143080,
    "end": 1146932,
    "text": "例えば、ゼロの次のxが両方とも素数である確率を誤って推定してしまう。"
  },
  {
    "start": 1146996,
    "end": 1151284,
    "text": "誰かが見逃した構造を指摘してくれれば、正解に近づくことができる。"
  },
  {
    "start": 1151342,
    "end": 1153660,
    "text": "お気づきのように、ますます関連性の高い構成になっている。"
  },
  {
    "start": 1155120,
    "end": 1159224,
    "text": "人間にとってのインターバル構造のようなものということですか？"
  },
  {
    "start": 1159352,
    "end": 1162488,
    "text": "私は基本的に、計算できる構造だけを意味している。"
  },
  {
    "start": 1162664,
    "end": 1172172,
    "text": "どういうわけか、aとz、zとbの関係について再帰的に何かを推定し、zが何であるかは理解できないかもしれないが、より単純であり、彼らはこれらの関係を計算することができる。"
  },
  {
    "start": 1172236,
    "end": 1174668,
    "text": "なるほど、人間にとって意味のある構造という意味ではない。"
  },
  {
    "start": 1174684,
    "end": 1177616,
    "text": "私が言いたいのは、このゲームのルールに意味のある構成ということだけだ。"
  },
  {
    "start": 1177798,
    "end": 1179410,
    "text": "なるほど、そうだね。"
  },
  {
    "start": 1185620,
    "end": 1197352,
    "text": "さて、では一歩下がって、私たちが何を探しているのか、私が何を望んでいるのかについて話しましょう。私たちは、証明検証機に類似したある種の単純なプログラムを探しています。"
  },
  {
    "start": 1197406,
    "end": 1206940,
    "text": "通常、双子の素密度や、ある分布に対するニューラルネットワークの精度、その量xの推定に関連する一連の観測値や引数などが考えられる。"
  },
  {
    "start": 1207010,
    "end": 1211740,
    "text": "もしxが素数なら、xに2を足したものが素数である可能性が高い。"
  },
  {
    "start": 1212160,
    "end": 1227232,
    "text": "誰かが、モデルの重みのパターン、あるいはモデルの活性度、出力、量xに関する最良の推測を指摘する。それは主観的な期待のように振る舞い、未知の量またはランダムな量xの期待値であるかのように振る舞う。"
  },
  {
    "start": 1227366,
    "end": 1230564,
    "text": "たとえ、xが実際にはよく定義された数であってもだ。"
  },
  {
    "start": 1230602,
    "end": 1233350,
    "text": "決定論的な数字に過ぎないが、私たちはそれを不確かなものだと考えている。"
  },
  {
    "start": 1236360,
    "end": 1248484,
    "text": "もしそのようなGがあれば、ニューラルネットワークの動作を説明するというこの目標を、Gがニューラルネットワークの精度を正確に推定できるようなPIを見つけること、あるいはあなたが説明したいと思っている特性を見つけることとして設定することができる。"
  },
  {
    "start": 1248532,
    "end": 1252808,
    "text": "つまり、fとθとgが一致することを説明するとはどういうことか、ということだ。"
  },
  {
    "start": 1252974,
    "end": 1262590,
    "text": "説明することの意味の一つの候補は、PIを見つけること、つまり、fθとgが一致する確率について正しい推測を導く、この種の確率論的拡散可能な議論を見つけることである。"
  },
  {
    "start": 1262960,
    "end": 1263708,
    "text": "そうだね。"
  },
  {
    "start": 1263874,
    "end": 1272800,
    "text": "このgを実現しようと思ったら、ひとつはLLMをgになるように訓練することかな。"
  },
  {
    "start": 1272950,
    "end": 1275120,
    "text": "gになるように言語モデルを訓練すればいい。"
  },
  {
    "start": 1275190,
    "end": 1280420,
    "text": "私はただ、xが真実か否かのラベルをたくさん与えることができた。"
  },
  {
    "start": 1280490,
    "end": 1283350,
    "text": "そんなGがいたら、どれだけ幸せだろう？"
  },
  {
    "start": 1284760,
    "end": 1288260,
    "text": "興奮はしないが、それでも役に立つと思う。"
  },
  {
    "start": 1288600,
    "end": 1290612,
    "text": "これなら同じ場所に行けると思う。"
  },
  {
    "start": 1290666,
    "end": 1295620,
    "text": "gを実装するためにニューラルネットを訓練するようなものだとすれば、これは人間の解釈可能性の研究と非常によく似ている。"
  },
  {
    "start": 1295690,
    "end": 1301020,
    "text": "人間の解釈可能性の研究は、予測にそれほど根拠がなく、本当に物事をすり合わせることができるという点では、少しましなのかもしれない。"
  },
  {
    "start": 1301130,
    "end": 1306670,
    "text": "どのように一般化するのか、トレーニングデータがない場合に適用できるのかなど、同じような疑問があるだろう。"
  },
  {
    "start": 1307040,
    "end": 1312936,
    "text": "興味はあるが、論理的な推論を信頼するのと同じように、なぜそれが機能するのかを理解できるようなGが欲しい。"
  },
  {
    "start": 1312968,
    "end": 1313976,
    "text": "流通から外れている。"
  },
  {
    "start": 1314088,
    "end": 1317088,
    "text": "なぜそれが機能するのかを理解し、それを信頼できるようなものが欲しい。"
  },
  {
    "start": 1317094,
    "end": 1318240,
    "text": "流通から外れている。"
  },
  {
    "start": 1318900,
    "end": 1325010,
    "text": "この定式化では、xの確率のようなpの選び方に依存しているようだ。"
  },
  {
    "start": 1328180,
    "end": 1329436,
    "text": "どのような配分を選択するかだ。"
  },
  {
    "start": 1329468,
    "end": 1331788,
    "text": "よりも正確さを評価しているんだね。"
  },
  {
    "start": 1331894,
    "end": 1332372,
    "text": "その通りだ。"
  },
  {
    "start": 1332426,
    "end": 1336416,
    "text": "そうしたら、その配給をどう選ぶべきかについてコメントするんだ。"
  },
  {
    "start": 1336528,
    "end": 1336756,
    "text": "そうだね。"
  },
  {
    "start": 1336778,
    "end": 1339780,
    "text": "ここでいう典型的な設定とは、研究室で観察できる現象があるということだ。"
  },
  {
    "start": 1339850,
    "end": 1345060,
    "text": "研究室では、自分のモデルが安全であるとか、有能であるとか、そういうことを示唆するための実験ができる。"
  },
  {
    "start": 1345210,
    "end": 1350052,
    "text": "私たちがやろうとしているのは、実験の結果をそのまま実行するのではなく、なぜそうなったのかを説明することです。"
  },
  {
    "start": 1350106,
    "end": 1355244,
    "text": "研究室でのこの分布について、私は正確に書くことができる。"
  },
  {
    "start": 1355362,
    "end": 1361864,
    "text": "そして、その説明を手にすれば、現実の世界で、これは前提条件を満たしている、あるいは満たしていない、と言えるようになる。"
  },
  {
    "start": 1361912,
    "end": 1364984,
    "text": "私はその説明を見て、なぜそのモデルがその分布で機能したのかを言うことができる。"
  },
  {
    "start": 1365112,
    "end": 1368210,
    "text": "その配給が機能した重要な部分を紹介しよう。"
  },
  {
    "start": 1368900,
    "end": 1373776,
    "text": "この特性は、形式的に定義することもできるし、研究室で実際に実施することもできる。"
  },
  {
    "start": 1373878,
    "end": 1374384,
    "text": "なるほど。"
  },
  {
    "start": 1374422,
    "end": 1382096,
    "text": "システムを導入したときに、ある意味で今あるものとはまったく異なる分配になることは避けられないとしたら？"
  },
  {
    "start": 1382118,
    "end": 1383764,
    "text": "そうでなかったら、こんなことはどうでもいい。"
  },
  {
    "start": 1383802,
    "end": 1385156,
    "text": "研究室でできることと変わらなかったらね。"
  },
  {
    "start": 1385178,
    "end": 1387380,
    "text": "私はラボでテストして、経験則に基づいて仕事をすればいいと思う。"
  },
  {
    "start": 1389480,
    "end": 1391424,
    "text": "説明に求めるものが違うかもしれない。"
  },
  {
    "start": 1391472,
    "end": 1393956,
    "text": "だから、いろいろな人がいろいろな理由で説明を求めるのは構わない。"
  },
  {
    "start": 1393988,
    "end": 1396228,
    "text": "この説明の概念に満足できない人もいるだろう。"
  },
  {
    "start": 1396324,
    "end": 1401140,
    "text": "私が興味があるのは、例えば説明があれば、なぜこのモデルが機能するのかがわかるからだ。"
  },
  {
    "start": 1401230,
    "end": 1404348,
    "text": "さて、新しい入力で、その引数が破綻しているかどうかをテストすることができる。"
  },
  {
    "start": 1404434,
    "end": 1406670,
    "text": "その説明が破綻しているかどうかを検証することはできるだろうか？"
  },
  {
    "start": 1407920,
    "end": 1408670,
    "text": "そうだね。"
  },
  {
    "start": 1410880,
    "end": 1414190,
    "text": "あなたの発言に基づく、関連性のある考察や議論。"
  },
  {
    "start": 1416080,
    "end": 1420380,
    "text": "問題は、このPIの目を確実に関連性のあるものに限定できるかどうかだ。"
  },
  {
    "start": 1420460,
    "end": 1425056,
    "text": "ええ、関連性というのは、Gの見解を動かすかどうかで定義されるようなものだと思います。"
  },
  {
    "start": 1425158,
    "end": 1428036,
    "text": "私は、あなたがここに無関係な見解を投げ入れても構わないと言っている。"
  },
  {
    "start": 1428058,
    "end": 1430710,
    "text": "Gのxに対する見方は変わらない。"
  },
  {
    "start": 1431320,
    "end": 1435590,
    "text": "基本的に、GはPIがそうであるかどうかを選択する。"
  },
  {
    "start": 1436200,
    "end": 1436900,
    "text": "その通りだ。"
  },
  {
    "start": 1436970,
    "end": 1442996,
    "text": "Gは、モデルの重みに関する観測や観察をすべて取り込んで、この重みがちょうど0.3であることにお気づきですか？"
  },
  {
    "start": 1443018,
    "end": 1444488,
    "text": "Gは、そんなことはどうでもいい、と言うだろう。"
  },
  {
    "start": 1444494,
    "end": 1447060,
    "text": "あるいは、それが私が推定している質問とどう関係するのか理解できない。"
  },
  {
    "start": 1447220,
    "end": 1447592,
    "text": "そうだね。"
  },
  {
    "start": 1447646,
    "end": 1453416,
    "text": "これは平均場分析に似ているのか、それとも類似しているのか、あるいは一般化したものなのか？"
  },
  {
    "start": 1453518,
    "end": 1463820,
    "text": "ええ、平均場分析がこの種の推論の一例で、より高いレベルの相関関係や細かな相関関係を無視して、最良の推測や妥当な推測を示すようなものだと思います。"
  },
  {
    "start": 1464320,
    "end": 1469292,
    "text": "その分析結果を、「これが平均場分析です」と放り込んで、gがこれを出力してくれることを期待しています。"
  },
  {
    "start": 1469346,
    "end": 1472716,
    "text": "新たな考察が入るまでは、平均値の分析に同意する。"
  },
  {
    "start": 1472898,
    "end": 1473580,
    "text": "そうだね。"
  },
  {
    "start": 1473730,
    "end": 1477350,
    "text": "僕はただ、PIが何をすべきなのかを理解したいだけなんだ。"
  },
  {
    "start": 1478680,
    "end": 1488820,
    "text": "私の講演の中から、URLの存在がスパムと高い相関関係を持つスパムデータセットを例に挙げてみよう。"
  },
  {
    "start": 1491180,
    "end": 1495240,
    "text": "では、なぜスパム探知機は良い仕事をしているのか？"
  },
  {
    "start": 1495390,
    "end": 1508780,
    "text": "PIは、URLがクラスラベルと高い相関があるという考察を持ち出すので、モデルはURLがあるかどうかを見る。"
  },
  {
    "start": 1509120,
    "end": 1517804,
    "text": "というのも、私のクラスではこれが当てはまらない、おそらくうまくいかないであろう他の分布が想像できるからだ。"
  },
  {
    "start": 1517842,
    "end": 1520604,
    "text": "こういうのがいい例なのかな。"
  },
  {
    "start": 1520722,
    "end": 1521756,
    "text": "みんなが聞いてくれるといいんだけど"
  },
  {
    "start": 1521778,
    "end": 1523772,
    "text": "これは、私たちがどのように機能させたいかを示す素晴らしい例だ。"
  },
  {
    "start": 1523826,
    "end": 1526708,
    "text": "この現象は、研究室で、あるデータセットを持っている。"
  },
  {
    "start": 1526794,
    "end": 1531008,
    "text": "そのデータセットでは、私のモデルがスパムかどうかの予測に成功していることが確認できた。"
  },
  {
    "start": 1531104,
    "end": 1540516,
    "text": "例えば、スパムデータセットでは大きく、非スパムデータセットでは小さい特徴で、モデルがうまく拾い上げているものがある。"
  },
  {
    "start": 1540618,
    "end": 1548004,
    "text": "そして、私が切望していた、データセットについて、あるいは私のモデルが機能する原因となったデータセットについて、それが何であったかの声明が得られたということだ。"
  },
  {
    "start": 1548122,
    "end": 1549636,
    "text": "この例が微妙なのはそのためだ。"
  },
  {
    "start": 1549658,
    "end": 1550320,
    "text": "無理だよ。"
  },
  {
    "start": 1550400,
    "end": 1553416,
    "text": "経験的なデータセットを扱うようになると、物事はもう少し厄介になる。"
  },
  {
    "start": 1553448,
    "end": 1554364,
    "text": "これが基本的な考え方だ。"
  },
  {
    "start": 1554402,
    "end": 1564572,
    "text": "PIの典型的なバージョンは、ある有限の集合にわたるある量の経験的平均である。"
  },
  {
    "start": 1564626,
    "end": 1566380,
    "text": "計算するのはまったく妥当なことだ。"
  },
  {
    "start": 1569690,
    "end": 1574230,
    "text": "ただ、一歩下がってこの希望をまとめると、私はニューラルネットワークについて証明したいと思っている。"
  },
  {
    "start": 1574390,
    "end": 1575594,
    "text": "それですべての問題が解決するとは思わない。"
  },
  {
    "start": 1575632,
    "end": 1577590,
    "text": "ブラックボックスからの大きな一歩だと思う。"
  },
  {
    "start": 1577670,
    "end": 1580620,
    "text": "私には、それはかなり完全に難解に思える。"
  },
  {
    "start": 1581070,
    "end": 1583674,
    "text": "とはいえ、物事を証明することが困難な領域はたくさんある。"
  },
  {
    "start": 1583722,
    "end": 1586062,
    "text": "ニューラルネットワークは特別なものではなく、どんな興味深いシステムでも同じだ。"
  },
  {
    "start": 1586116,
    "end": 1587758,
    "text": "物事を証明するのは不可能だ。"
  },
  {
    "start": 1587924,
    "end": 1592990,
    "text": "拡散可能な確率論的推論は、証明が困難な多くの領域でもかなり一般的であり、成功している。"
  },
  {
    "start": 1593810,
    "end": 1606222,
    "text": "このような非公式な推論をニューラルネットワークにスケールアップするのは、やや難しいのではないかと懸念しています。私たちは、例えば10ページや100ページ程度の証明や議論を扱うことに慣れていますが、例えばGPT4の性質に関する興味深い証明は、数十億ページに及ぶでしょう。"
  },
  {
    "start": 1606366,
    "end": 1611190,
    "text": "それは、おおよそ正しい理解でどうにかなる類のものではない。"
  },
  {
    "start": 1611850,
    "end": 1621210,
    "text": "というわけで、推定量gを実際に構築することによって、この種の推論を形式化することができれば、少なくともいくつかの下流の応用に役立つような意味でのニューラルネットワークの説明が可能になるかもしれない、という期待を持っている。"
  },
  {
    "start": 1625070,
    "end": 1630320,
    "text": "デフォルトでは、この講演の残りの部分は、推定量gを形式化しようとするこの問題を掘り下げていくだけである。"
  },
  {
    "start": 1636680,
    "end": 1640870,
    "text": "それ以外の動機はないのか、あるいは、なぜこの時点でこんな質問をするのか？"
  },
  {
    "start": 1641740,
    "end": 1644170,
    "text": "これからはもっと雑草の中に入っていくだけだ。"
  },
  {
    "start": 1647980,
    "end": 1653720,
    "text": "そう、一般相対性理論を推計するんだ。"
  },
  {
    "start": 1658640,
    "end": 1666108,
    "text": "一般相対性理論を、物理的な世界に関する推定値や近似的な議論や何かのように考えることはできるだろうか？"
  },
  {
    "start": 1666274,
    "end": 1669468,
    "text": "ここでの大きな複雑さは、2種類のものを混ぜ合わせているようなものだと思う。"
  },
  {
    "start": 1669554,
    "end": 1673788,
    "text": "物理学について話すとき、物理学をやるとき、あなたは2種類の練習を混ぜ合わせている。"
  },
  {
    "start": 1673884,
    "end": 1676432,
    "text": "ひとつは、どのような法則が世界を記述しているのかを理解することだ。"
  },
  {
    "start": 1676566,
    "end": 1680704,
    "text": "もうひとつは、論理的帰結を理解することだ。"
  },
  {
    "start": 1680742,
    "end": 1682816,
    "text": "どのようなモデルが他のモデルの良い近似なのか？"
  },
  {
    "start": 1682918,
    "end": 1696200,
    "text": "私たちがここで話しているのは、ある理論が他の理論に対してどのような場合に良い近似となるかを理解することであり、世界がどのように動いているのかという科学的な疑問を理解することではないと思う。"
  },
  {
    "start": 1704460,
    "end": 1706860,
    "text": "推定値を探す問題について話してください。"
  },
  {
    "start": 1707680,
    "end": 1725520,
    "text": "つまり、大雑把に言えば、私たちが今目指しているのは、既存の非公式な議論を形式化し、自然なコヒーレンス特性を満たし、偶然の一致がない原理と呼ばれるものを形式化する、承認済み検証器に似た単純なプログラムgを探すことである。"
  },
  {
    "start": 1725940,
    "end": 1728130,
    "text": "これらについては、残りのトークで話すつもりだ。"
  },
  {
    "start": 1730980,
    "end": 1733756,
    "text": "最も簡単なのは、既存の非公式な議論を形式化することだ。"
  },
  {
    "start": 1733788,
    "end": 1735424,
    "text": "こういう理屈はどこにでもある。"
  },
  {
    "start": 1735472,
    "end": 1742292,
    "text": "特定の量が特定の値をとるという非公式な発見的議論の例は、100か数百はあると思う。"
  },
  {
    "start": 1742426,
    "end": 1745936,
    "text": "そのような主張が新たな考察によって覆されることは、しばしば期待できない。"
  },
  {
    "start": 1746048,
    "end": 1752308,
    "text": "双子の素数の密度は対数の2乗nに対して1.32ドット・ドット・ドットである。"
  },
  {
    "start": 1752474,
    "end": 1755900,
    "text": "それは非公式な議論をしているようなもので、答えがどうなるかはわかっている。"
  },
  {
    "start": 1755970,
    "end": 1759480,
    "text": "形式的なシステムであれば、その結論は理解できるはずだ。"
  },
  {
    "start": 1759640,
    "end": 1769820,
    "text": "同様に、無作為に選ばれた文書に対するSHA256のハッシュ衝突の確率は、負の256に2であるという議論があり、新たな考察に基づいてこの推定値を大きく修正することはないと考えている。"
  },
  {
    "start": 1771920,
    "end": 1782812,
    "text": "私たちが望むのは、このような非公式な議論がある場合、その議論の正式版が存在し、gにそれを渡せば、たとえ私が偽の議論を大量に渡したとしても、正しい結論に達することである。"
  },
  {
    "start": 1782956,
    "end": 1792950,
    "text": "双子の素数の密度が1.32であるべきだという公式な議論があれば、その議論を形式化したものをgに与えることができるはずだ。"
  },
  {
    "start": 1797240,
    "end": 1799720,
    "text": "そのような定義ができれば、とてもうれしい。"
  },
  {
    "start": 1799790,
    "end": 1811180,
    "text": "もしそのようなgがあれば、ニューラルネットワークに関する非公式な議論を、同じようにgに提出し、人間がその議論から正当化されると考える種類の結論と一致する、合理的な結論を得ることができるかもしれない。"
  },
  {
    "start": 1814080,
    "end": 1817230,
    "text": "ここでCが本当の答えだと仮定しているのか？"
  },
  {
    "start": 1818080,
    "end": 1819708,
    "text": "わからないことが多いと思う。"
  },
  {
    "start": 1819794,
    "end": 1823052,
    "text": "Cが正しくないことに気づけば大騒ぎになるようなケースと同じだ。"
  },
  {
    "start": 1823106,
    "end": 1824376,
    "text": "双子素因数分解のようなものだ。"
  },
  {
    "start": 1824408,
    "end": 1829364,
    "text": "本当の密度が1.32なのかどうかは知らないが、もしそれが違うと考える理由があれば、私は有名な数論者になれるだろう。"
  },
  {
    "start": 1829402,
    "end": 1833350,
    "text": "それが真実かどうかは別として、Gが出すべき答えだと思う。"
  },
  {
    "start": 1836760,
    "end": 1840916,
    "text": "ショウの場合も同様で、もしかしたらショウは何度も衝突しているのかもしれないが、私にはわからない。"
  },
  {
    "start": 1840938,
    "end": 1842820,
    "text": "それを知ったら大変なことになる。"
  },
  {
    "start": 1842890,
    "end": 1848730,
    "text": "ヒューリスティックな議論システムがある答えに収束すれば満足なのか？"
  },
  {
    "start": 1849340,
    "end": 1852340,
    "text": "コヒーレンスの特性については、また後で話そう。"
  },
  {
    "start": 1852420,
    "end": 1853748,
    "text": "非公式なものがあると思う。"
  },
  {
    "start": 1853844,
    "end": 1862472,
    "text": "なぜ私がこれを探求する気になったかというと、実際に非常に正確で、あるいは驚くほど効果的で、直感的に妥当だと感じられる非公式な例がいくつかあるからだ。"
  },
  {
    "start": 1862536,
    "end": 1871580,
    "text": "だから、単純なケースで直感的に妥当だと感じられるものと一致する形式的なオブジェクトを構築し、それをニューラルネットワークの分析のような、より複雑なケースに適用してみることができれば、とても嬉しい。"
  },
  {
    "start": 1878640,
    "end": 1879076,
    "text": "そうだね。"
  },
  {
    "start": 1879138,
    "end": 1880356,
    "text": "このPIスターになるはずだった。"
  },
  {
    "start": 1880378,
    "end": 1882036,
    "text": "非公式な議論であれば、そう願っている。"
  },
  {
    "start": 1882058,
    "end": 1883776,
    "text": "それを形式的な議論に変えるのはとても簡単だ。"
  },
  {
    "start": 1883808,
    "end": 1886304,
    "text": "理想を言えば、非公式な証明を形式化するようなものだ。"
  },
  {
    "start": 1886352,
    "end": 1895060,
    "text": "つまり、私に数学の論文を渡せば、線形ではあるがかなりの努力でそれを正式な証明に変えることができるはずだ。"
  },
  {
    "start": 1895400,
    "end": 1898150,
    "text": "この適切なセルを使うかどうか聞いているんだ。"
  },
  {
    "start": 1903000,
    "end": 1906728,
    "text": "問題は、xが与えられたときにPIを求めることができるかということだ。"
  },
  {
    "start": 1906824,
    "end": 1907356,
    "text": "そうだね。"
  },
  {
    "start": 1907378,
    "end": 1908444,
    "text": "いや、本当に難しいよ。"
  },
  {
    "start": 1908482,
    "end": 1912840,
    "text": "それは、ある真実の声明が与えられたとき、その声明の証明を見つけるのが非常に難しいという証明の発見と非常に類似していることになる。"
  },
  {
    "start": 1912920,
    "end": 1914860,
    "text": "簡単なのはそれを検証することだ。"
  },
  {
    "start": 1914930,
    "end": 1919788,
    "text": "だから同様に、もしこれに成功したとしても、ニューラルネットワークの解釈という問題のすべてを解決できるわけではない。"
  },
  {
    "start": 1919804,
    "end": 1923344,
    "text": "これは、例えば、こんなマシンがある、というような正式な基準を与えるだけだ。"
  },
  {
    "start": 1923462,
    "end": 1925248,
    "text": "自分の解釈を"
  },
  {
    "start": 1925414,
    "end": 1926770,
    "text": "数字を吐くことができる。"
  },
  {
    "start": 1932300,
    "end": 1936350,
    "text": "この後の話の土台となるような例題をお話しします。"
  },
  {
    "start": 1937600,
    "end": 1948080,
    "text": "行列 n x n 行列 a の場合、permanent は、terminate のように、補助対角線上のエントリの積の並べ替えに対する和として定義できるが、符号は削除する。"
  },
  {
    "start": 1948660,
    "end": 1950770,
    "text": "永続性を見積もるのは非常に難しい。"
  },
  {
    "start": 1951460,
    "end": 1953728,
    "text": "永続性に近づくことさえ、とてもとても難しい。"
  },
  {
    "start": 1953814,
    "end": 1959440,
    "text": "行列があれば、あらゆる種類の非公式で直感的に妥当な発見的議論を行うことが可能である。"
  },
  {
    "start": 1960180,
    "end": 1968976,
    "text": "例えば、各行の平均値を知っている場合、永久項はn個の階乗項の和に過ぎない。"
  },
  {
    "start": 1969088,
    "end": 1971520,
    "text": "これらの用語はそれぞれ、1行につき1つのエントリーの積である。"
  },
  {
    "start": 1971600,
    "end": 1978372,
    "text": "各行の平均値がわかっていて、それを掛け合わせれば、ランダムな並べ替えによる寄与を合理的に推定することができる。"
  },
  {
    "start": 1978436,
    "end": 1982836,
    "text": "これにn階乗をかけると、行列の許容値の推定値が得られる。"
  },
  {
    "start": 1983028,
    "end": 1986344,
    "text": "これは、私が前にスケッチしたような単純な推論ルールから正当化することができる。"
  },
  {
    "start": 1986382,
    "end": 1990136,
    "text": "これは基本的に、独立性の推定というヒューリスティックの応用のひとつである。"
  },
  {
    "start": 1990248,
    "end": 1996110,
    "text": "チェックすることもできるが、ランダムな行列を入力すれば、ゼロを推測したりするよりも二乗誤差が小さくなる。"
  },
  {
    "start": 1998000,
    "end": 2006716,
    "text": "同様に、列の平均がわかっていれば、合計を計算できる順列の有限集合を考えれば、その方法で推定値を求めることができる。"
  },
  {
    "start": 2006748,
    "end": 2008364,
    "text": "パーマネントはすべての順列の和である。"
  },
  {
    "start": 2008412,
    "end": 2013792,
    "text": "順列の有限な集合の総和を取れば、パーマネントの妥当な最良推定値も得られる。"
  },
  {
    "start": 2013856,
    "end": 2019110,
    "text": "これらはすべて、ただゼロを推測するのに比べて誤差を少ししか減らせないという意味で、かなり悪い見積もりである。"
  },
  {
    "start": 2020440,
    "end": 2026520,
    "text": "これらは直感的に妥当であり、実際、ランダムな行列で恒久的な値を推測しようとする場合、誤差を減らすことができる。"
  },
  {
    "start": 2028780,
    "end": 2031240,
    "text": "その言葉を拡大解釈するつもりだったのか？"
  },
  {
    "start": 2035740,
    "end": 2036490,
    "text": "いや。"
  },
  {
    "start": 2037020,
    "end": 2038984,
    "text": "許可証はすべての順列の和にすぎない。"
  },
  {
    "start": 2039032,
    "end": 2043884,
    "text": "その和の項の部分集合である部分和を取り、それ以外の項をすべてゼロとして捨てているようなものだ。"
  },
  {
    "start": 2044082,
    "end": 2045196,
    "text": "わかったよ。"
  },
  {
    "start": 2045298,
    "end": 2048476,
    "text": "その代わりに、例えば、私がいくつのタームを取ったかによってスケールを変えることができる。"
  },
  {
    "start": 2048578,
    "end": 2049180,
    "text": "うん、いいよ。"
  },
  {
    "start": 2049250,
    "end": 2052252,
    "text": "そうすれば、ゼロを出力するよりもはるかに悪い二乗誤差が生じることになる。"
  },
  {
    "start": 2052386,
    "end": 2054892,
    "text": "この場合、スケールアップするのは実は正しくない。"
  },
  {
    "start": 2055026,
    "end": 2061140,
    "text": "永久欠番が100万分の2なのに、17人という見積もりなんだから。"
  },
  {
    "start": 2061960,
    "end": 2063440,
    "text": "大した見積もりではない。"
  },
  {
    "start": 2063600,
    "end": 2066704,
    "text": "同様に、行列aを因数分解することができれば、恒等式が負でないことがわかる。"
  },
  {
    "start": 2066752,
    "end": 2068016,
    "text": "vvの転置因数分解ができる。"
  },
  {
    "start": 2068048,
    "end": 2069280,
    "text": "パーマネントがネガティブでないことは分かっている。"
  },
  {
    "start": 2069360,
    "end": 2072016,
    "text": "また、このような因数分解から、より微妙な情報を得ることもできる。"
  },
  {
    "start": 2072128,
    "end": 2081736,
    "text": "要は、ある領域があり、あなたが直感的に理解できるような非公式な議論が数多くあり、あるいは、このデータに基づいてあなたの見積もりがどうあるべきかについて、直感的な議論ができるということです。"
  },
  {
    "start": 2081838,
    "end": 2088430,
    "text": "私たちは、これらの結論をすべて形式化するような、形式的なオブジェクトを持ちたいと思っています。"
  },
  {
    "start": 2095440,
    "end": 2102000,
    "text": "その一環として、与えられた引数に基づいて合理的な最良の推測のようなものを捕らえるgを見つけたい。"
  },
  {
    "start": 2103700,
    "end": 2107772,
    "text": "妥当なGは、非常に単純なコヒーレンス特性の束を満たすはずだと期待している。"
  },
  {
    "start": 2107836,
    "end": 2112652,
    "text": "最良の推測について話しているのであれば、それらが持つべき性質のひとつは、線形であるべきだということだ。"
  },
  {
    "start": 2112716,
    "end": 2123370,
    "text": "Gに、すべてのxについてxのfの総和はいくらか、と推定するように頼んだら、xをそれぞれ独立に調べて、gにそれぞれのxについてxのfを推定するように頼んで、それを合計したのと同じ答えが返ってくるはずだ。"
  },
  {
    "start": 2123820,
    "end": 2125192,
    "text": "これはごく自然な特性のようなものだ。"
  },
  {
    "start": 2125246,
    "end": 2127528,
    "text": "明らかに、期待はこの性質を満たしている。"
  },
  {
    "start": 2127694,
    "end": 2130104,
    "text": "最良の推測がそれを満たすと期待するのは合理的だ。"
  },
  {
    "start": 2130142,
    "end": 2132504,
    "text": "実は、信じられないほど厳しい物件があるんだ。"
  },
  {
    "start": 2132702,
    "end": 2136090,
    "text": "非公式な議論を捕らえながらこれを実行するのは、とてもとても難しい。"
  },
  {
    "start": 2136700,
    "end": 2140936,
    "text": "また、ニューラルネットワークに応用する上でも、最終的にはかなり重要な特性だ。"
  },
  {
    "start": 2140968,
    "end": 2143756,
    "text": "もしあなたのDがこのプロパティを持っていないなら、それを使って何かをするのはもっと難しい。"
  },
  {
    "start": 2143778,
    "end": 2146190,
    "text": "私が望んでいる説明という概念を与えてくれない。"
  },
  {
    "start": 2147840,
    "end": 2149150,
    "text": "それは明らかではないはずだ。"
  },
  {
    "start": 2151620,
    "end": 2155340,
    "text": "同様に、発見的議論という概念も、証明という概念を一般化するべきだと考えている。"
  },
  {
    "start": 2155500,
    "end": 2160816,
    "text": "ある量xがcより大きいという証明があれば、あとは何を言われても構わない。"
  },
  {
    "start": 2160838,
    "end": 2164964,
    "text": "それ以外のPI素数の場合でも、xは少なくともcになると推定しなければならない。"
  },
  {
    "start": 2165002,
    "end": 2166884,
    "text": "xがc以上であるという証明があれば、それは悪いことだ。"
  },
  {
    "start": 2166922,
    "end": 2168948,
    "text": "もしxの見積もりがcより小さかったら。"
  },
  {
    "start": 2169114,
    "end": 2172420,
    "text": "それは直感的に合理的であることに反するようなものだ。"
  },
  {
    "start": 2173960,
    "end": 2175032,
    "text": "私たちはこのまま進むことができる。"
  },
  {
    "start": 2175086,
    "end": 2176564,
    "text": "合理的な物件を書き連ねることができる。"
  },
  {
    "start": 2176612,
    "end": 2186140,
    "text": "このオブジェクトを主観的な期待のように解釈するのであれば、このプロパティは保持したい。"
  },
  {
    "start": 2188160,
    "end": 2193528,
    "text": "私たちのデスドーラータの一つは、非公式で直感的に妥当な議論を捉えようとしていると言った。"
  },
  {
    "start": 2193624,
    "end": 2196910,
    "text": "もうひとつのデスドラトゥムは、このようなコヒーレンスの特性にマッチしようとしている。"
  },
  {
    "start": 2197440,
    "end": 2201268,
    "text": "実際、この3つの性質を満たす関数gは見つからないと思う。"
  },
  {
    "start": 2201464,
    "end": 2204540,
    "text": "このプロパティをもう少し強くすれば、不可能だと証明できる。"
  },
  {
    "start": 2204620,
    "end": 2208176,
    "text": "この性質を満たすgは存在するのか？"
  },
  {
    "start": 2208208,
    "end": 2210390,
    "text": "私たちの多くの時間は、そのような対象を求めている。"
  },
  {
    "start": 2214680,
    "end": 2215476,
    "text": "その通りだ。"
  },
  {
    "start": 2215578,
    "end": 2219860,
    "text": "次の3つの性質を持つ、多項式時間で計算可能なgを構築する。"
  },
  {
    "start": 2220280,
    "end": 2223512,
    "text": "とはいえ、PIが何なのかわからないのだから、これはまるで正式ではない。"
  },
  {
    "start": 2223646,
    "end": 2225796,
    "text": "PIのシグネチャーの種類を選ぶことができる。"
  },
  {
    "start": 2225828,
    "end": 2227800,
    "text": "ただ、超一流の証明でなければならない。"
  },
  {
    "start": 2229980,
    "end": 2235290,
    "text": "もし私がPIを証拠とするなら、あなたとはできないのですか？"
  },
  {
    "start": 2237260,
    "end": 2245276,
    "text": "PIをあらゆる証明と見なすこともできるが、その場合、素数の平均数がlog nで1であることを証明する必要がある。"
  },
  {
    "start": 2245298,
    "end": 2249900,
    "text": "あるいは、素数の分数はlog nで1であるという素数定理を証明したようにね。"
  },
  {
    "start": 2249970,
    "end": 2254360,
    "text": "では、xとx+2のうちの1つが両方とも素数である確率は？"
  },
  {
    "start": 2254440,
    "end": 2257952,
    "text": "その答えは、線形性と反復期待によって制約を受けることになる。"
  },
  {
    "start": 2258056,
    "end": 2265830,
    "text": "だから、証明の答えを正しくすることからの制約だけでなく、線形性の反復期待値からの制約も加えると、これらの性質を一度に満たすのは非常に難しいんだ。"
  },
  {
    "start": 2266360,
    "end": 2267204,
    "text": "それほど難しくはない。"
  },
  {
    "start": 2267242,
    "end": 2268064,
    "text": "私たちはそれが不可能であることを示すことができる。"
  },
  {
    "start": 2268112,
    "end": 2269236,
    "text": "実際、我々はそれが可能だと考えている。"
  },
  {
    "start": 2269338,
    "end": 2270816,
    "text": "反例は見当たらない。"
  },
  {
    "start": 2270848,
    "end": 2274650,
    "text": "これらの特性は、ある意味、維持できそうなレベルまで調整されている。"
  },
  {
    "start": 2276700,
    "end": 2285720,
    "text": "おそらく、有効なPIの空間は証明の空間よりも大きくなるはずだが、そのようなgが存在するということを証明するだけだと受け取ってもいい。"
  },
  {
    "start": 2286460,
    "end": 2295992,
    "text": "経験的に、Gを実際に実装しようとするとき、実装したものが実際に存在すると再現されたGであるかどうかを調べる方法がないという保証はない。"
  },
  {
    "start": 2296056,
    "end": 2296670,
    "text": "そうだろう？"
  },
  {
    "start": 2297840,
    "end": 2298156,
    "text": "そうだね。"
  },
  {
    "start": 2298178,
    "end": 2299696,
    "text": "一日の終わりに、私たちはいくつかの特別なGを持つことになる。"
  },
  {
    "start": 2299718,
    "end": 2302684,
    "text": "願わくば、Gがこのような性質を持っていることを主張したい。"
  },
  {
    "start": 2302732,
    "end": 2304050,
    "text": "それが私たちのやりたいことだ。"
  },
  {
    "start": 2304740,
    "end": 2308508,
    "text": "そうであれば、この下流の一部としてこれを使うことになる。"
  },
  {
    "start": 2308604,
    "end": 2308864,
    "text": "そうだね。"
  },
  {
    "start": 2308902,
    "end": 2313700,
    "text": "ニューラルネットの説明ができたら、それをこのgに与えて、実際に安全問題を解決するためにそれをどう使うかについて話すことができる。"
  },
  {
    "start": 2313850,
    "end": 2315510,
    "text": "ここで議論しているのではない。"
  },
  {
    "start": 2317960,
    "end": 2318324,
    "text": "そうだね。"
  },
  {
    "start": 2318362,
    "end": 2322352,
    "text": "私は1つの未解決の問題を説明したが、それはこれらの直観的に妥当な議論を形式化したものに過ぎない。"
  },
  {
    "start": 2322416,
    "end": 2326212,
    "text": "これは正確に定義されているが、直感的に有効な議論のデータベースに関してのみ定義されている。"
  },
  {
    "start": 2326276,
    "end": 2328548,
    "text": "この質問は、それ自体で成り立っている。"
  },
  {
    "start": 2328644,
    "end": 2333608,
    "text": "ただ、この挑戦の味を出すために、これらの特性を持つGを見つけることができるかということだ。"
  },
  {
    "start": 2333694,
    "end": 2337780,
    "text": "一つの議論に対してどうすべきかというのは、普通はとてもシンプルなことだと思う。"
  },
  {
    "start": 2337860,
    "end": 2345624,
    "text": "行の平均の積が例えば187だとすると、パーマネントの見積もりはn乗の187倍くらいになるはずだ、と言ったんだ。"
  },
  {
    "start": 2345752,
    "end": 2347580,
    "text": "これはある意味、合理的なデフォルトの推測だ。"
  },
  {
    "start": 2347650,
    "end": 2359796,
    "text": "この独立性の推定を何度も何度も繰り返すのであれば、「行の積が187で、行の平均値の積が187だが、列の積がマイナス384だったらどうする？"
  },
  {
    "start": 2359978,
    "end": 2366230,
    "text": "最後のスライドにあるような特性を満たしたい場合、これら2つの異なる種類の情報をどのように統合して最良の推測をすればいいのかは明らかではない。"
  },
  {
    "start": 2369240,
    "end": 2373476,
    "text": "最初のスライドで説明したヒアスティックの推論によって、この答えを突き止めることができることがわかった。"
  },
  {
    "start": 2373498,
    "end": 2374916,
    "text": "実際には見積もりを追加するだけだ。"
  },
  {
    "start": 2375028,
    "end": 2378548,
    "text": "それが良い見積もりなのか、二乗誤差が少ないのか、誰かがチェックしてくれるだろう。"
  },
  {
    "start": 2378724,
    "end": 2379640,
    "text": "続けることができる。"
  },
  {
    "start": 2379710,
    "end": 2380964,
    "text": "合計を計算することができる。"
  },
  {
    "start": 2381092,
    "end": 2382250,
    "text": "じゃあどうすればいいんだ？"
  },
  {
    "start": 2383420,
    "end": 2386628,
    "text": "答えは、実際に計算した順列の和の値を使うのだ。"
  },
  {
    "start": 2386724,
    "end": 2390140,
    "text": "計算しなかった残りの順列については、デフォルトの推定値を使用する。"
  },
  {
    "start": 2390640,
    "end": 2392556,
    "text": "どの数字もそれほど意味がなくても構わない。"
  },
  {
    "start": 2392578,
    "end": 2394044,
    "text": "重要なのは、これが我々が直面している課題だということだ。"
  },
  {
    "start": 2394082,
    "end": 2395900,
    "text": "個々の議論が何をすべきかは理解している。"
  },
  {
    "start": 2395970,
    "end": 2398620,
    "text": "異なる議論をどのように組み合わせるかを推論する必要がある。"
  },
  {
    "start": 2399920,
    "end": 2402148,
    "text": "導入すると、これはもっともっと難しくなる。"
  },
  {
    "start": 2402184,
    "end": 2403884,
    "text": "私はこの3つの主張を統合することができた。"
  },
  {
    "start": 2403932,
    "end": 2408796,
    "text": "私の行列はこの因数分解を持っている、という引数をもうひとつ加えると、それを他の引数とどのようにマージすればいいのか、もはや明確ではない。"
  },
  {
    "start": 2408908,
    "end": 2411584,
    "text": "これはおそらく、正しい答えがどうあるべきかわからない最も単純なケースだろう。"
  },
  {
    "start": 2411622,
    "end": 2415110,
    "text": "だから、私たちはこのようなアルゴリズムの問題に時間を費やしている。"
  },
  {
    "start": 2415960,
    "end": 2416384,
    "text": "ポール"
  },
  {
    "start": 2416432,
    "end": 2428548,
    "text": "つまり、ボソンサンプリングの文脈で私たちが考えた一つの疑問は、様々な行の和と様々な列の和のような行列が与えられたとします。"
  },
  {
    "start": 2428724,
    "end": 2431796,
    "text": "パーマネントに最も近づけるためには、どのような使い方をすればいいのでしょうか？"
  },
  {
    "start": 2431908,
    "end": 2436560,
    "text": "私たちの最善の提案はシンチョーン・スケーリングだった。"
  },
  {
    "start": 2436740,
    "end": 2449490,
    "text": "基本的には、行を正規化し、列を正規化し......といった具合に、これらの行と列ができるまで正規化し、それからベストを見つける。"
  },
  {
    "start": 2453220,
    "end": 2456530,
    "text": "この場合、それが一般論として正しいかどうかは分からない。"
  },
  {
    "start": 2457460,
    "end": 2459264,
    "text": "反復的なスケーリングプロセス。"
  },
  {
    "start": 2459462,
    "end": 2464256,
    "text": "行と列の和に関するデータがあるだけのこのような問題でさえ、すでに興味深く、自明ではない。"
  },
  {
    "start": 2464368,
    "end": 2465924,
    "text": "私はこれを妥当な答えのように言った。"
  },
  {
    "start": 2465962,
    "end": 2469828,
    "text": "これは第一関門の最も間抜けな答えのようなもので、あなたは間違いなくこれよりはるかに良いことができる。"
  },
  {
    "start": 2469994,
    "end": 2474788,
    "text": "例えば、さらに実行する計算についての追加情報を条件とすれば、より良い見積もりを得ることができるはずだ。"
  },
  {
    "start": 2474884,
    "end": 2478170,
    "text": "私は、特にそのことについて、そしてあなたがどこでそのことに行き着いたのかについて話すことにかなり興味がある。"
  },
  {
    "start": 2482460,
    "end": 2485812,
    "text": "この場合、興味深い特徴は、この推定値が負でないことである。"
  },
  {
    "start": 2485956,
    "end": 2489336,
    "text": "aはこの因数分解を持つので、その永久は負ではない、という証明がある。"
  },
  {
    "start": 2489448,
    "end": 2495070,
    "text": "私が実際に手元にある定量的な考察では、nが大きければ負の見積もりになってしまう。"
  },
  {
    "start": 2495440,
    "end": 2497884,
    "text": "この場合、どうすればいいのかが本当にわからない。"
  },
  {
    "start": 2498002,
    "end": 2500320,
    "text": "これらの異なる見積もりをどのように統合するのかが非常に不明確なのだ。"
  },
  {
    "start": 2501780,
    "end": 2509030,
    "text": "証明を一般化するために負の推定値をゼロに切り捨てることもできるが、そうすると後期線形性とサイダー期待特性を買うことになる。"
  },
  {
    "start": 2509480,
    "end": 2512260,
    "text": "繰り返しになるが、このスライドが単なる数字に見えても構わない。"
  },
  {
    "start": 2512330,
    "end": 2514150,
    "text": "これがチャレンジの好意なのだが。"
  },
  {
    "start": 2520120,
    "end": 2527124,
    "text": "ひとつは直観的に妥当な議論を形式化するもの、もうひとつは一貫性の特性を尊重するものである。"
  },
  {
    "start": 2527172,
    "end": 2530810,
    "text": "私はこれから、哲学的にもっと興味深い第三のデセロタムについて話そうと思う。"
  },
  {
    "start": 2532140,
    "end": 2534148,
    "text": "これはゴワーズワースという論文からの引用である。"
  },
  {
    "start": 2534164,
    "end": 2541068,
    "text": "今年の初め、彼は「数学で一見とんでもない偶然が起こるなら、それには理由がある」という原則を提唱した。"
  },
  {
    "start": 2541234,
    "end": 2556476,
    "text": "例えば、ある時点で双子の素数が存在しなくなり、有限個しか存在しなくなったとしたら、それはとんでもない偶然の一致であり、説明が必要だということになる。"
  },
  {
    "start": 2556508,
    "end": 2558690,
    "text": "それはごく当たり前の自然なことだ。"
  },
  {
    "start": 2559700,
    "end": 2563704,
    "text": "これは完全に非公式な発言だが、実際にはかなり説得力のある経験則だと思う。"
  },
  {
    "start": 2563772,
    "end": 2571444,
    "text": "だから、数学の歴史ではしばしば、とんでもない偶然の一致のように見えることが起きていることを人々が発見し、数学者がその理由を理解しようと努力する。"
  },
  {
    "start": 2571482,
    "end": 2574996,
    "text": "例えば、このフーリエ係数はなぜこのグループ表現のサイズと同じなのか？"
  },
  {
    "start": 2575108,
    "end": 2578664,
    "text": "ほとんどの場合、私たちは納得のいく理解に至る。"
  },
  {
    "start": 2578862,
    "end": 2590360,
    "text": "その皇室の保護が、生存バイアスの主観的なものなのかどうか、ご存じですか？"
  },
  {
    "start": 2590520,
    "end": 2593756,
    "text": "私の感覚では、ここには反サバイバーシップのバイアスがあるように思える。"
  },
  {
    "start": 2593778,
    "end": 2600316,
    "text": "もし誰かが、何の説明もつかないとんでもない偶然の一致を発見したとしたら、それはとても興味深い研究対象になる。"
  },
  {
    "start": 2600418,
    "end": 2600828,
    "text": "オーケー。"
  },
  {
    "start": 2600914,
    "end": 2603104,
    "text": "こういうことが起こる奇妙なドメインがいくつかある。"
  },
  {
    "start": 2603142,
    "end": 2607440,
    "text": "もっと、物事がうまくいかない領域は研究されにくいのは事実なので、その余地はある。"
  },
  {
    "start": 2607590,
    "end": 2614420,
    "text": "いくつか反例候補があるんだけど、かなりまばらなんだ。"
  },
  {
    "start": 2619160,
    "end": 2627720,
    "text": "ニューラルネットへの応用は別として、このステートメントをどのように公式化するのか、そしてそれが実際に正しいのかどうかを理解したいですね。"
  },
  {
    "start": 2627790,
    "end": 2630170,
    "text": "ただ、とても素敵なことのように。"
  },
  {
    "start": 2631500,
    "end": 2635844,
    "text": "今回の講演では、それをヒューリスティックな推定という言葉に置き換えてみたい。"
  },
  {
    "start": 2635972,
    "end": 2643340,
    "text": "私は、gがその確率が文の負の長さの2より小さいと考える場合、その文はとんでもない偶然の一致であると言うつもりだ。"
  },
  {
    "start": 2644560,
    "end": 2652512,
    "text": "なぜこのように定義したかというと、もし私たちの確率が調整されているのであれば、このような形で真となる文は一つもないはずだからです。"
  },
  {
    "start": 2652646,
    "end": 2656512,
    "text": "すべてのステートメントを合計したステートメントの長さのマイナスを2とすると、1しかない。"
  },
  {
    "start": 2656646,
    "end": 2662932,
    "text": "どの命題も、おそらくそれよりも有意に小さいのであれば、組合の境界によって、どれも真ではないと予想される。"
  },
  {
    "start": 2663066,
    "end": 2665168,
    "text": "とんでもない偶然はひとつもあってはならない。"
  },
  {
    "start": 2665264,
    "end": 2667110,
    "text": "何か見落としているのかもしれない。"
  },
  {
    "start": 2668520,
    "end": 2673124,
    "text": "なぜ、この行を真にするためだけにこの文の長さなのか？"
  },
  {
    "start": 2673242,
    "end": 2678744,
    "text": "それを選んだ理由はただ一つ、本当に複雑な文章を選んでいけば、偶然の一致を見つけることができるからだ。"
  },
  {
    "start": 2678782,
    "end": 2685140,
    "text": "1兆兆の文の空間と考えれば、1兆兆の事前確率しかない偶然の一致を1つ見つけることができるだろう。"
  },
  {
    "start": 2685220,
    "end": 2687756,
    "text": "もし私が30ビットのステートメントしか見ていないなら、その数は10億に過ぎない。"
  },
  {
    "start": 2687778,
    "end": 2690808,
    "text": "おそらく、事前確率が10億分の1以下のものは見つけられないはずだ。"
  },
  {
    "start": 2690904,
    "end": 2693484,
    "text": "なるほど、いい質問だった。"
  },
  {
    "start": 2693522,
    "end": 2698444,
    "text": "明確にしておくと、この逆は基本的に偶然の一致を認めないという原則に他ならない。"
  },
  {
    "start": 2698492,
    "end": 2701312,
    "text": "もし何かがとんでもない偶然の一致に見えるなら、それは何かを見逃しているからだ。"
  },
  {
    "start": 2701366,
    "end": 2709376,
    "text": "その現象がなぜもっともらしいかについては、私たちがgに持たせたいさらなる性質である以上の説明がある。"
  },
  {
    "start": 2709398,
    "end": 2720804,
    "text": "これは少し非公式なものだが、非公式に私たちが望む性質は、どのような真の文ファイに対しても、GGにそれを与えたら、ああ、結局あの文はそれほどありそうもなかったと言われるような短い説明PIがあるということである。"
  },
  {
    "start": 2721002,
    "end": 2733128,
    "text": "例えば、双子素因数論を例にとると、私は、確率1で双子素因数論が無限に存在するという発見的論拠を示しただけで、双子素因数論が有限個しか存在しないのであれば、結局のところ、この場合、実際には短いPI、つまり有限個の長さのPIが存在することになる。"
  },
  {
    "start": 2733144,
    "end": 2737420,
    "text": "少なくとも、マグナム素数が有限である理由、あるいは少なくともそれがもっともらしい理由は説明できる。"
  },
  {
    "start": 2742400,
    "end": 2748504,
    "text": "この原理をMLに当てはめると、ある分布に対して完璧な精度を持つモデルがあるとする。"
  },
  {
    "start": 2748552,
    "end": 2752640,
    "text": "すべてのビット列について、xのfシータはxのgに等しい。"
  },
  {
    "start": 2753220,
    "end": 2766164,
    "text": "もし仮に、f thetaがすべての入力に対して半分の確率で独立にgと等しくなるランダムな関数であると仮定するならば、これは負の2乗、nの2乗の確率で起こり、パラメータの数がnの2乗より少ない限り起こりうる。"
  },
  {
    "start": 2766202,
    "end": 2769156,
    "text": "パラメータが十分でない限り、このデータセットを記憶するだけでいい。"
  },
  {
    "start": 2769258,
    "end": 2771200,
    "text": "これはとんでもない偶然だろう。"
  },
  {
    "start": 2771360,
    "end": 2775620,
    "text": "確率はゼロのはずだから、何か説明があるはずだ。"
  },
  {
    "start": 2775700,
    "end": 2783290,
    "text": "θとgの関係には、実は構造的な事実があるはずで、それが常に一致するのは、とんでもない偶然ではない。"
  },
  {
    "start": 2784220,
    "end": 2785784,
    "text": "これが探しているオブジェクトだ。"
  },
  {
    "start": 2785822,
    "end": 2787736,
    "text": "これは証明にはない性質である。"
  },
  {
    "start": 2787758,
    "end": 2790520,
    "text": "2つの関数が等しければ、等しいという証明があるかというと、そうではない。"
  },
  {
    "start": 2790600,
    "end": 2801970,
    "text": "私たちは、この確率論的推論が、ある2つの事柄が、ある関数が驚くほど大きな精度を持つときはいつでも、その事実に対して何らかの説明がある、誰かが指摘できることがある、何か解釈可能なことがある、というような、それなりに弱い概念であることを望んでいる。"
  },
  {
    "start": 2805780,
    "end": 2807404,
    "text": "だからこそ、私たちはこの原則に興味を持っている。"
  },
  {
    "start": 2807452,
    "end": 2812470,
    "text": "私たちは、ラボで何か面白いことをやっているニューラルネットがあれば、それに対する説明があるという、素晴らしい保証が欲しいのです。"
  },
  {
    "start": 2816760,
    "end": 2827370,
    "text": "さて、最後の5分間は、理論的な問題、つまりこの原則のもうひとつの意味合いについてお話ししましょう。"
  },
  {
    "start": 2829180,
    "end": 2831332,
    "text": "もうひとつ、とんでもない偶然がある。"
  },
  {
    "start": 2831476,
    "end": 2835284,
    "text": "2つのn入力をn入力にマッピングする回路があるとする。"
  },
  {
    "start": 2835412,
    "end": 2839740,
    "text": "入力xのcがすべてゼロである場合、入力xをゼロと呼ぶことにする。"
  },
  {
    "start": 2841760,
    "end": 2846168,
    "text": "ランダムな関数の場合、n個の入力に対して2個のゼロがあるはずだ。"
  },
  {
    "start": 2846184,
    "end": 2849520,
    "text": "それぞれの確率は1であり、すべてがゼロである確率はnに対して2である。"
  },
  {
    "start": 2850260,
    "end": 2858400,
    "text": "繰り返しになるが、この偶然の一致がない原理を信じるなら、Gが認める説明がない限り、ゼロのない回路が存在することはないはずだ。"
  },
  {
    "start": 2858550,
    "end": 2862496,
    "text": "それは、驚くほど精度の高いニューラルネットは存在しないはずだという私たちの希望に似ている。"
  },
  {
    "start": 2862528,
    "end": 2864790,
    "text": "説明がなくても、それはGに認められている。"
  },
  {
    "start": 2867310,
    "end": 2871020,
    "text": "これは次のような問題につながる。"
  },
  {
    "start": 2871710,
    "end": 2887082,
    "text": "このようなgがあれば、それを使って多項式時間検証器vを構築することができる。この検証器vは、回路と、その回路がゼロを持たない理由の説明案を入力とする。"
  },
  {
    "start": 2887146,
    "end": 2893220,
    "text": "回路には、なぜゼロを持たない傾向があるのかを説明する何らかの構造があるはずで、検証者はANdが1を出力することを認識する。"
  },
  {
    "start": 2893590,
    "end": 2897214,
    "text": "回路を無作為に一様にサンプリングする場合、分布については触れない。"
  },
  {
    "start": 2897262,
    "end": 2900714,
    "text": "その時は、非常に高い確率で戻ってくることができる。"
  },
  {
    "start": 2900782,
    "end": 2901990,
    "text": "何の説明もない。"
  },
  {
    "start": 2902890,
    "end": 2912440,
    "text": "もし回路にゼロがないのなら、それは極めて偶然的なことで、回路にはランダムとは異なる何らかの構造があるはずで、誰かがその構造を指摘してくれるはずだ。"
  },
  {
    "start": 2913690,
    "end": 2921100,
    "text": "実際、私たちが望むような異端推定量が存在するのであれば、そのようなvが存在するはずである。"
  },
  {
    "start": 2921950,
    "end": 2927040,
    "text": "もしあなたが私に任意のVを与えたなら、私は簡単にゼロを持たない回路を作ることができるが、あなたのVによって検出されることはないだろう。"
  },
  {
    "start": 2927570,
    "end": 2939374,
    "text": "cにゼロがない確率は少なくともvである、という発見的な議論に満足できますか？"
  },
  {
    "start": 2939412,
    "end": 2949246,
    "text": "そうだね、cが1000ビットの回路なら、vは、確率はマイナス1000分の2以上だ、それで十分だ、そうしないと偶然の一致で大破してしまうから、みたいな感じでいいと思う。"
  },
  {
    "start": 2949278,
    "end": 2949426,
    "text": "そうだね。"
  },
  {
    "start": 2949448,
    "end": 2951902,
    "text": "この最初の声明は、すべての回路にわたって実存的に定量化された。"
  },
  {
    "start": 2951966,
    "end": 2953970,
    "text": "Vは非常に保守的でなければならない。"
  },
  {
    "start": 2956870,
    "end": 2957620,
    "text": "そうだね。"
  },
  {
    "start": 2958790,
    "end": 2960166,
    "text": "とにかく、これは理論家のためのものだ。"
  },
  {
    "start": 2960198,
    "end": 2961514,
    "text": "これは私が非常に興味を持っている問題だ。"
  },
  {
    "start": 2961552,
    "end": 2968460,
    "text": "また、ニューラルネットへの応用は別として、このようなVを見つけるのは非常に興味深いことだと思います。"
  },
  {
    "start": 2969470,
    "end": 2971066,
    "text": "それについては喜んで話すよ。"
  },
  {
    "start": 2971168,
    "end": 2972540,
    "text": "ああ、申し訳ない。"
  },
  {
    "start": 2974830,
    "end": 2976442,
    "text": "量詞の順番は？"
  },
  {
    "start": 2976506,
    "end": 2978094,
    "text": "その人はVの仕事を知っているのか？"
  },
  {
    "start": 2978132,
    "end": 2979434,
    "text": "それから回路を選ぶ。"
  },
  {
    "start": 2979562,
    "end": 2980094,
    "text": "その通りだ。"
  },
  {
    "start": 2980132,
    "end": 2984138,
    "text": "私たちは、この性質が回路上で普遍的に定量化されたvを探している。"
  },
  {
    "start": 2984154,
    "end": 2997926,
    "text": "ゲームの仕組みは、あなたがvの提案を持って私のところに来て、私はゼロを持たないが、あなたのvがどんな証明も認めないcを示すか、1％以上の確率で成功するランダムな回路の証明を作る戦略を示すかのどちらかだ。"
  },
  {
    "start": 2998108,
    "end": 3002198,
    "text": "もし誰かがその試合に勝つことができれば、私はとても興奮するだろうし、私たちはその試合に勝とうとしている。"
  },
  {
    "start": 3002284,
    "end": 3004360,
    "text": "これは私たちが取り組んでいることのひとつだ。"
  },
  {
    "start": 3011850,
    "end": 3014786,
    "text": "偶然の一致の原則とこの種の問題は、ある種、魔法のようなものだと思う。"
  },
  {
    "start": 3014818,
    "end": 3017850,
    "text": "これは、過去に私たちが集団で解決してきたような問題ではないと思う。"
  },
  {
    "start": 3018000,
    "end": 3019526,
    "text": "証明にはこのような完全性はない。"
  },
  {
    "start": 3019558,
    "end": 3023770,
    "text": "証明では見落とされるあらゆる構造があるので、このような完全性の声明があれば非常に興味深い。"
  },
  {
    "start": 3025390,
    "end": 3030206,
    "text": "そこで、一歩下がって、この話をまとめて、ニューラルネットワークがなぜ機能するのかを説明したいと思う。"
  },
  {
    "start": 3030308,
    "end": 3034362,
    "text": "ニューラルネットワークに関する記述の証明は、本当に役に立つように思えるが、難解である。"
  },
  {
    "start": 3034506,
    "end": 3039022,
    "text": "拡散可能な推論は、証明が困難な領域ではかなり一般的で、成功しているようだ。"
  },
  {
    "start": 3039086,
    "end": 3040446,
    "text": "正式なものではない。"
  },
  {
    "start": 3040638,
    "end": 3045250,
    "text": "これを定式化することで、ニューラルネットワークへの拡張が可能になるかもしれないが、今のところかなり難しい問題のように思える。"
  },
  {
    "start": 3045400,
    "end": 3057606,
    "text": "私の人生の大半は、この問題のさまざまな下位問題に費やされている。最も野心的な希望は、研究室で測定して正確に定義できるような興味深いニューラルネットワークの動作には、Gが認識できる何らかの説明があるに違いないということだ。"
  },
  {
    "start": 3057708,
    "end": 3064570,
    "text": "もしそうであれば、解釈可能性の成功という概念を持つことができ、それは任意のモデルに対して実際に可能である、と言えるようになる大きな一歩となるだろう。"
  },
  {
    "start": 3066110,
    "end": 3066618,
    "text": "クールだ。"
  },
  {
    "start": 3066704,
    "end": 3067402,
    "text": "それだけだ。"
  },
  {
    "start": 3067456,
    "end": 3068220,
    "text": "ありがとう。"
  },
  {
    "start": 3078450,
    "end": 3092366,
    "text": "では、Gがニューラルネットワークであることに話を戻すと、あなたの推測、つまり大きな推測、最後にあなたが回路について持っていた推測を考えてみましょうか。"
  },
  {
    "start": 3092478,
    "end": 3092706,
    "text": "素晴らしい。"
  },
  {
    "start": 3092728,
    "end": 3106870,
    "text": "ジェネレーター識別装置とか、敵対的ネットワークのペアを作って、基本的にこれを実行しようとする方法はないだろうか。"
  },
  {
    "start": 3106940,
    "end": 3109734,
    "text": "これを経験的にテストできると思う？"
  },
  {
    "start": 3109852,
    "end": 3111446,
    "text": "ああ、このゲームはできると思うよ。"
  },
  {
    "start": 3111548,
    "end": 3114098,
    "text": "このゲームは人間でもニューラルネットでもできる。"
  },
  {
    "start": 3114114,
    "end": 3115118,
    "text": "ニューラルネットで言ってみよう。"
  },
  {
    "start": 3115154,
    "end": 3123398,
    "text": "ニューラルネットを使ったゲームの仕組みは、最初に1を出力するように訓練されたニューラルネットを持っていて、ランダムな回路に対してはゼロを出力するように訓練されているとする。"
  },
  {
    "start": 3123494,
    "end": 3129050,
    "text": "任意のPIの任意のランダムな回路に対して、ゼロのない回路を作ろうとしている敵がいる。"
  },
  {
    "start": 3129790,
    "end": 3134278,
    "text": "回路がゼロを持たないことを決定するのは、明らかに非常に難解だからだ。"
  },
  {
    "start": 3134374,
    "end": 3136626,
    "text": "敵のことは想像できるだろうが、私は知らない。"
  },
  {
    "start": 3136648,
    "end": 3139438,
    "text": "実は、どうやって回路を作るのかが分からないんだ。"
  },
  {
    "start": 3139454,
    "end": 3141860,
    "text": "そのような神託があると想像すれば、このゲームができるだろう。"
  },
  {
    "start": 3142230,
    "end": 3142994,
    "text": "わかったよ。"
  },
  {
    "start": 3143032,
    "end": 3147086,
    "text": "その実証実験を行うには、ある種の神託が必要だ。"
  },
  {
    "start": 3147198,
    "end": 3147810,
    "text": "その通りだ。"
  },
  {
    "start": 3147880,
    "end": 3150914,
    "text": "道義的には、このような物件でこの実験ができると思う。"
  },
  {
    "start": 3150952,
    "end": 3152722,
    "text": "ニューラルネットの精度は90％。"
  },
  {
    "start": 3152856,
    "end": 3159138,
    "text": "それができないのは、標準的な非ランダム化予想のもとでは、説明とは思えないようなズルいやり方ができるからだ。"
  },
  {
    "start": 3159234,
    "end": 3161994,
    "text": "モノを選んだ理由、それは難しい。"
  },
  {
    "start": 3162032,
    "end": 3165670,
    "text": "私たちが気にするようなことではないが、明確な複雑さと理論的な含意を与えてくれる。"
  },
  {
    "start": 3165750,
    "end": 3167690,
    "text": "だからちょっと不自然な設定なんだ。"
  },
  {
    "start": 3170350,
    "end": 3174334,
    "text": "たぶん、私はここを見落としているんだと思う。"
  },
  {
    "start": 3174532,
    "end": 3188882,
    "text": "例えば、データがランダムであれば、ニューラルネットワークの動作はまったく異なるものになり、おそらく何もうまくいかないだろう。"
  },
  {
    "start": 3188936,
    "end": 3196098,
    "text": "自然画像多様体とかテキスト多様体とか、データの構造はどこから来るのか？"
  },
  {
    "start": 3196184,
    "end": 3196386,
    "text": "そうだね。"
  },
  {
    "start": 3196408,
    "end": 3203730,
    "text": "結局のところ、私たちがやりたいのは、ニューラルネットワークがある分布で機能する理由の説明を見つけることだ。"
  },
  {
    "start": 3203890,
    "end": 3213170,
    "text": "また、経験的な分布や有限のデータ集合を取り上げることもできる。データ分布の特性は、正式に定義されたものであれ、多くの例によって定義されたものであれ、その説明に関係するだろう。"
  },
  {
    "start": 3213250,
    "end": 3215418,
    "text": "このデータを見てください。"
  },
  {
    "start": 3215504,
    "end": 3218970,
    "text": "あなたのモデルが機能する理由は、データに次のような規則性があるからだ。"
  },
  {
    "start": 3219310,
    "end": 3224794,
    "text": "となると、その規則性とネットワークの重みとの相互作用の仕方から、いくつかの出力は特性pを持つことになる。"
  },
  {
    "start": 3224912,
    "end": 3229546,
    "text": "つまり、データセットのプロパティが、この説明によって参照されるものとして表示されるということだ。"
  },
  {
    "start": 3229658,
    "end": 3233642,
    "text": "偶然の一致を計算する場所にも表示されるべきではないか？"
  },
  {
    "start": 3233706,
    "end": 3236686,
    "text": "それはデータに依存すべきではないのか？"
  },
  {
    "start": 3236868,
    "end": 3237226,
    "text": "そうだね。"
  },
  {
    "start": 3237268,
    "end": 3240562,
    "text": "ある意味で、私たちはgの言うことだけでとんでもない偶然を定義してしまった。"
  },
  {
    "start": 3240616,
    "end": 3243294,
    "text": "Gが本当に、本当にあり得ないと考えるなら、時にとんでもない偶然が起こる。"
  },
  {
    "start": 3243342,
    "end": 3243714,
    "text": "了解した。"
  },
  {
    "start": 3243752,
    "end": 3244340,
    "text": "オーケー。"
  },
  {
    "start": 3247110,
    "end": 3252786,
    "text": "クロッキングのブログ記事は、私が見た中で最も証明に近いものだ。"
  },
  {
    "start": 3252898,
    "end": 3257138,
    "text": "なぜ失敗したと思うのか、何が本当に欠けているのかが気になる。"
  },
  {
    "start": 3257234,
    "end": 3264170,
    "text": "そう、これがこの証明のクエスチョンマーク、あるいはもう少し解像度の高い、この説明だ。"
  },
  {
    "start": 3266750,
    "end": 3268906,
    "text": "そう、まずはこの非公式な議論から始めよう。"
  },
  {
    "start": 3268928,
    "end": 3273718,
    "text": "非公式な議論の詳細を説明するつもりはないが、このモデルが正しくモジュラー加算を行うという非公式な議論がある。"
  },
  {
    "start": 3273814,
    "end": 3280086,
    "text": "このような非公式な議論を、最もわかりやすいところで見てみると、おそらくこれは2次式による証明になると思う。"
  },
  {
    "start": 3280198,
    "end": 3281466,
    "text": "なぜ非公式と呼ぶのですか？"
  },
  {
    "start": 3281488,
    "end": 3285314,
    "text": "論旨は問題ないのだから、ただウェイトとのつながりが問題なのだろう？"
  },
  {
    "start": 3285472,
    "end": 3286098,
    "text": "そうだね。"
  },
  {
    "start": 3286104,
    "end": 3288786,
    "text": "あるアルゴリズムが機能するという形式的なストーリーがここにある。"
  },
  {
    "start": 3288808,
    "end": 3294450,
    "text": "たぶんこのコラムでは、実際に機能するアルゴリズムがあって、その証明があって、それがウェイトにどう関係するかについて主張する。"
  },
  {
    "start": 3295030,
    "end": 3301854,
    "text": "というのも、MLPと非線形性を実装するアテンション層をどのように処理するかという点については、かなり非公式だからだ。"
  },
  {
    "start": 3301902,
    "end": 3303998,
    "text": "それはほとんど経験的に推定されたものだと思う。"
  },
  {
    "start": 3304174,
    "end": 3305842,
    "text": "それを証明することは想像できると思う。"
  },
  {
    "start": 3305896,
    "end": 3311594,
    "text": "このようなことを証明しようとすると、たくさんのベクトルがあって、それらのベクトルは互いに小さな内積を持っている、というようなことにぶつかると思う。"
  },
  {
    "start": 3311712,
    "end": 3315062,
    "text": "それを証明しようとすれば、網羅的な列挙によって証明することになる。"
  },
  {
    "start": 3315206,
    "end": 3316666,
    "text": "理論的には、なぜそうなるかは非常に明確だ。"
  },
  {
    "start": 3316688,
    "end": 3318362,
    "text": "ランダムなベクトルを取れば、それらは小さな内積を持つ。"
  },
  {
    "start": 3318416,
    "end": 3319766,
    "text": "説明を求めるものではない。"
  },
  {
    "start": 3319798,
    "end": 3325050,
    "text": "もし証明が必要なら、基本的にすべてのベクトルの組を網羅的に列挙して、それらが小さな内積を持っていると言う必要があると思う。"
  },
  {
    "start": 3325200,
    "end": 3330198,
    "text": "そのため、最終的に得られる証明のサイズは、ブルートフォースによる入力の列挙のサイズと本質的に同じになる。"
  },
  {
    "start": 3330294,
    "end": 3330940,
    "text": "興味深い。"
  },
  {
    "start": 3332350,
    "end": 3343780,
    "text": "証明するのは難しいと思いますが、ランダムなベクトルではよくあることで、大きな内積を持たないのがデフォルトのようなものです。"
  },
  {
    "start": 3344950,
    "end": 3349118,
    "text": "それが重要な飛躍として著者たちに公平に見えるかどうかはわからないが、私はそれが証明における重要な飛躍だと信じている。"
  },
  {
    "start": 3349214,
    "end": 3349860,
    "text": "そうだね。"
  },
  {
    "start": 3353290,
    "end": 3364778,
    "text": "これらの各アイデンティティが実装されている方向は、MLP内のこの特定の方向がこの計算が行われている場所であるという主張があるようなものです。"
  },
  {
    "start": 3364944,
    "end": 3374246,
    "text": "ニールにとってはそうなのかもしれないが、少なくとも私にはよくわからない。"
  },
  {
    "start": 3374358,
    "end": 3379834,
    "text": "ジェルの使用でどうしてこのようなことになったのですか？"
  },
  {
    "start": 3379872,
    "end": 3383846,
    "text": "だから、ヒューリスティックな説明が必要なのはそこだと思う。"
  },
  {
    "start": 3383958,
    "end": 3384666,
    "text": "その通りだと思う。"
  },
  {
    "start": 3384688,
    "end": 3386434,
    "text": "それは表現がどのように機能するかという話だと思う。"
  },
  {
    "start": 3386472,
    "end": 3393938,
    "text": "その話は、形式的には、完全に正確かもしれないし、おおよそ正確かもしれない。そして、それがどのように機能するのか、誤差がどのように伝播するのかなどを実際に分析しようとすると、誤差が生じるのではないだろうか。"
  },
  {
    "start": 3393944,
    "end": 3396238,
    "text": "それを証明するのは難しいだろうね。"
  },
  {
    "start": 3396414,
    "end": 3400806,
    "text": "私の知り合いで、この方法で非常に小さなニューラルネットワークの証明に取り組んでいる人がいる。"
  },
  {
    "start": 3400828,
    "end": 3403750,
    "text": "実際に凍らせてコックすることができるのか、その証拠を見てみよう。"
  },
  {
    "start": 3405530,
    "end": 3406438,
    "text": "どうだろう。"
  },
  {
    "start": 3406604,
    "end": 3413994,
    "text": "あまり厳密ではないが、ヒューリスティックで直感的に正しいと思われる論証をたくさんつなげているとしよう。"
  },
  {
    "start": 3414112,
    "end": 3422090,
    "text": "さまざまなステップでエラーを追加しているため、実際に間違ったクレームになってしまうことはないのだろうか？"
  },
  {
    "start": 3422510,
    "end": 3426666,
    "text": "その結果、そのような証明を探しているとする。"
  },
  {
    "start": 3426698,
    "end": 3432762,
    "text": "そうすれば、ほとんどすべての種類の発言について、非公式な論証の束でそれを正当化しようとすることができる。"
  },
  {
    "start": 3432826,
    "end": 3440946,
    "text": "もしそうだとしたら、例えば、そのような状況を回避できるようにGが唯一無二であることを証明しなければならないのだろうか？"
  },
  {
    "start": 3441048,
    "end": 3444786,
    "text": "あるいは、それを軽減するための一般的な戦略は何だと思いますか？"
  },
  {
    "start": 3444888,
    "end": 3449214,
    "text": "そう、だから最初の質問は、おそらく正確であろうと思われるステップをたくさん踏んだとして、その結論はどの程度のものなのか、ということだ。"
  },
  {
    "start": 3449262,
    "end": 3451746,
    "text": "それはG次第だと思う。"
  },
  {
    "start": 3451778,
    "end": 3454150,
    "text": "それぞれがエラーを導入し、エラー伝搬を行う。"
  },
  {
    "start": 3454490,
    "end": 3456854,
    "text": "だから、それがうまくいくかどうかを経験的に話すことができる。"
  },
  {
    "start": 3456892,
    "end": 3468170,
    "text": "この楽観的な原則は、何か些細なことや驚くようなことが起こっている場合、モデル自体が誤差をコントロールしなければならない。"
  },
  {
    "start": 3468990,
    "end": 3472294,
    "text": "結論が恣意的であったり、間違っていたりすることを論証することはおそらく可能だと思う。"
  },
  {
    "start": 3472342,
    "end": 3474730,
    "text": "間違ったことを証明することはできない。"
  },
  {
    "start": 3474800,
    "end": 3476810,
    "text": "間違ったことをヒューリスティックに主張することはできると思う。"
  },
  {
    "start": 3476880,
    "end": 3479978,
    "text": "だから、このような発言の多くは、自分が何を意味しているのか、より慎重にならなければならないと思う。"
  },
  {
    "start": 3480064,
    "end": 3482954,
    "text": "もし誰かがあなたのところに来たら、一回だけでなく、もっと多くの議論をする必要がある。"
  },
  {
    "start": 3482992,
    "end": 3486690,
    "text": "ただ正確であろうとしているのではなく、正確であり、そのうえでさらなる議論に挑んでいるのだ。"
  },
  {
    "start": 3487190,
    "end": 3489460,
    "text": "と聞いて終わりにしてもいいだろうか？"
  },
  {
    "start": 3489830,
    "end": 3494562,
    "text": "この話はどちらかというと理論的なもので、あなたの研究所はアライメント研究センターと呼ばれています。"
  },
  {
    "start": 3494696,
    "end": 3501598,
    "text": "あなたの頭の中では、これらは非常につながりのある考えだと思いますが、最後に、あなたがどのように関連性を捉えているのか、ぜひお聞かせください。"
  },
  {
    "start": 3501694,
    "end": 3509030,
    "text": "ニューラルネットワークをブラックボックスとして扱ったり、訓練したり、評価したりするのが好きではないということが、このつながりの主な理由だと思う。"
  },
  {
    "start": 3509530,
    "end": 3517146,
    "text": "このような説明で実際に何をするかについては、もっと長いストーリーがあり、ある意味、私たちがこれをやっている理由でもある。"
  },
  {
    "start": 3517248,
    "end": 3526410,
    "text": "私たちの多くは、モデルについての説明があればいいと思うし、説明の意味を理解できればもっといい。"
  },
  {
    "start": 3526830,
    "end": 3535042,
    "text": "説明が破綻したときにそれを識別し、何かが間違っている可能性があるときにそのフラグを立てるのだ。"
  },
  {
    "start": 3535216,
    "end": 3539582,
    "text": "そうだね、説明があると助かるよ。"
  },
  {
    "start": 3539646,
    "end": 3544002,
    "text": "うまくいけば、説明のメカニズムが当てはまらなくなったときなど、何か問題が起きたときにフラグを立てるのに使えるだろう。"
  },
  {
    "start": 3544056,
    "end": 3545698,
    "text": "そのリンクは難しいと思う。"
  },
  {
    "start": 3545784,
    "end": 3546962,
    "text": "素早く描くのは難しい。"
  },
  {
    "start": 3547096,
    "end": 3547840,
    "text": "オーケー、ありがとう。"
  }
]