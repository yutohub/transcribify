[
  {
    "start": 8600,
    "end": 11274,
    "text": "あなたは今、ラインテストに大失敗している。"
  },
  {
    "start": 32724,
    "end": 34784,
    "text": "この椅子には何の脈絡もない。"
  },
  {
    "start": 39244,
    "end": 48424,
    "text": "おい、もう文字通りめちゃくちゃだよ。"
  },
  {
    "start": 52364,
    "end": 53076,
    "text": "オーケー。"
  },
  {
    "start": 53180,
    "end": 58344,
    "text": "今日は、私の良き友人である松濤とトレントンの2人と話をする機会を得た。"
  },
  {
    "start": 58724,
    "end": 59268,
    "text": "見せてくれ。"
  },
  {
    "start": 59316,
    "end": 60504,
    "text": "あなたは私たちを混同して見せている。"
  },
  {
    "start": 63244,
    "end": 64824,
    "text": "何も言うつもりはなかった。"
  },
  {
    "start": 66164,
    "end": 68184,
    "text": "これを逆にやってみよう。"
  },
  {
    "start": 69244,
    "end": 71544,
    "text": "また、仲の良い友人と一緒に始めたら。"
  },
  {
    "start": 72964,
    "end": 73364,
    "text": "そうだね。"
  },
  {
    "start": 73404,
    "end": 74904,
    "text": "ジェミニ1.5"
  },
  {
    "start": 75284,
    "end": 76508,
    "text": "コンテキストの長さ。"
  },
  {
    "start": 76556,
    "end": 76812,
    "text": "ただね。"
  },
  {
    "start": 76868,
    "end": 77504,
    "text": "ワオ。"
  },
  {
    "start": 79204,
    "end": 79844,
    "text": "クソッ。"
  },
  {
    "start": 79964,
    "end": 90252,
    "text": "とにかく、ショト、ノア・ブラウン、ノアム・ブラウンという外交論文を書いた人は、シルトについてこう言ったんだ。"
  },
  {
    "start": 90348,
    "end": 97904,
    "text": "彼はまだ1年半しかこの分野に携わっていないが、ジェミニの成功を支えた最も重要な人物の一人であることをAI関係者は知っているという。"
  },
  {
    "start": 98764,
    "end": 102524,
    "text": "アントニオ・トレントンは機械論的解釈可能性を研究している。"
  },
  {
    "start": 102644,
    "end": 105464,
    "text": "彼がアライメントを解決したと大々的に報じられた。"
  },
  {
    "start": 111104,
    "end": 116124,
    "text": "ポッドキャストのアラインメントはすでに解決されているので、これ以上議論する必要はない。"
  },
  {
    "start": 117024,
    "end": 120224,
    "text": "では、まずコンテキストリンクについて話そう。"
  },
  {
    "start": 120264,
    "end": 128168,
    "text": "そう、100万トークンを文脈に当てはめることがいかに重要かを考えると、過小評価されているように思えた。"
  },
  {
    "start": 128296,
    "end": 138480,
    "text": "しかし、ロング・コンテクスト・リンクの将来について、またそれがこれらのモデルにとってどのような意味を持つのか、教えてください。"
  },
  {
    "start": 138552,
    "end": 148758,
    "text": "というのも、オンボーディングの問題が基本的に即座に解決されるということが、このモデルにとってどれだけインテリジェンスを向上させるものなのか、この仕事を始めるまではよく分かっていなかったんだ。"
  },
  {
    "start": 148926,
    "end": 161070,
    "text": "論文にある当惑度グラフを見れば少しわかるが、コードベースについて何百万ものトークンに相当するコンテキストを投入するだけで、次のトークンを予測する能力が劇的に向上する。"
  },
  {
    "start": 161182,
    "end": 162206,
    "text": "そんなものは必要ない。"
  },
  {
    "start": 162270,
    "end": 164234,
    "text": "必要なのは新しい文脈だけだ。"
  },
  {
    "start": 165004,
    "end": 173264,
    "text": "では、他のニュースに埋もれてしまっているが、彼らは人間と同じように効率的で賢いのだろうか？"
  },
  {
    "start": 173724,
    "end": 175172,
    "text": "それは本当に探求する価値があると思う。"
  },
  {
    "start": 175268,
    "end": 186340,
    "text": "例えば、私たちが論文で行った検証のひとつでは、人間の専門家が数ヶ月かけて新しい言語を学習するよりも、文脈の中で言語を学習する方が優れている。"
  },
  {
    "start": 186412,
    "end": 199316,
    "text": "でも、アタリのゲームみたいに、数百フレームとか数千フレームとかのラベリングされたアクションを放り込んで、友達に見せるのと同じようにゲームをプレイして、それが理性的に理解できるかどうかを見てみたいんだ。"
  },
  {
    "start": 199380,
    "end": 209940,
    "text": "今のところ、インフラやその他諸々の問題で、そうするのはまだ少し時間がかかるかもしれない。"
  },
  {
    "start": 210052,
    "end": 214460,
    "text": "重要なのは、この言葉が難解であったために、トレーニングの日には使われなかったということだ。"
  },
  {
    "start": 214492,
    "end": 214700,
    "text": "そうだね。"
  },
  {
    "start": 214732,
    "end": 220380,
    "text": "以前のモデルを見ると、そのコンテクストが投げ込まれており、言語をまったく知らず、翻訳を得ることもできない。"
  },
  {
    "start": 220452,
    "end": 222700,
    "text": "これは実際の人間の言葉のようなものだ。"
  },
  {
    "start": 222772,
    "end": 223380,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 223412,
    "end": 224554,
    "text": "実際の人間の言葉。"
  },
  {
    "start": 224724,
    "end": 230634,
    "text": "もしそれが本当なら、これらのモデルは重要な意味ですでに超人的であるように思える。"
  },
  {
    "start": 231094,
    "end": 232966,
    "text": "彼らが我々より賢いという意味ではない。"
  },
  {
    "start": 233030,
    "end": 241234,
    "text": "問題を解決しようとしているときに、100万ものトークンを自分のコンテキストに置いておくことはできないし、すべての情報を覚えてコードベースに統合することもできない。"
  },
  {
    "start": 242334,
    "end": 245070,
    "text": "これは巨大なロック解除のようなものだと思うのは間違っているだろうか？"
  },
  {
    "start": 245222,
    "end": 247034,
    "text": "実際、一般的にはそうだと思う。"
  },
  {
    "start": 247694,
    "end": 251022,
    "text": "これまでは、モデルが賢くないとイライラしていた。"
  },
  {
    "start": 251078,
    "end": 254878,
    "text": "あなたは彼らに質問し、自分より賢かったり、自分の知らないことを知っていてほしいと思う。"
  },
  {
    "start": 254966,
    "end": 260874,
    "text": "そのため、彼らはあなたが知らないことを知ることができ、あなたにはできない方法で膨大な量の情報を摂取することができる。"
  },
  {
    "start": 261494,
    "end": 263394,
    "text": "だから、非常に重要なことなんだ。"
  },
  {
    "start": 263934,
    "end": 266182,
    "text": "では、インコンテクスト学習をどう説明すればいいのか？"
  },
  {
    "start": 266318,
    "end": 280086,
    "text": "インコンテキストの学習は基本的に勾配降下法によく似ていますが、注意の操作はインコンテキストのデータに対する勾配降下法と見なすことができます。"
  },
  {
    "start": 280190,
    "end": 285446,
    "text": "その論文には、基本的に勾配降下をnステップ行うことで、文脈学習のn層のように見えるというクールなプロットがあった。"
  },
  {
    "start": 285550,
    "end": 286254,
    "text": "よく似ている。"
  },
  {
    "start": 286294,
    "end": 290014,
    "text": "何が起こっているのかを理解しようとする、ひとつの見方だと思う。"
  },
  {
    "start": 290174,
    "end": 290726,
    "text": "そうだね。"
  },
  {
    "start": 290830,
    "end": 296958,
    "text": "というのも、導入部を考えれば、アライメントは解決され、安全性は問題ではないからだ。"
  },
  {
    "start": 297086,
    "end": 300194,
    "text": "文脈が問題になると思う。"
  },
  {
    "start": 300534,
    "end": 314714,
    "text": "脱獄や敵対的攻撃に対して百発百中のプロンプトを出したらどうなるかという点で、そう遠くない将来にもっと多くの研究がなされると思う。"
  },
  {
    "start": 314854,
    "end": 325634,
    "text": "あなたのモデルが勾配降下をして、その場で学習しているのであれば、たとえそれが無害であるように訓練されていたとしても、という意味でも興味深い。"
  },
  {
    "start": 325674,
    "end": 328218,
    "text": "ある意味、まったく新しいモデルを扱っていることになる。"
  },
  {
    "start": 328346,
    "end": 332298,
    "text": "ファインチューニングのようなもので、何が起こっているのかをコントロールすることはできない。"
  },
  {
    "start": 332426,
    "end": 336682,
    "text": "フォワードパスとアテンションで起こっている勾配降下とはどういう意味なのか、説明していただけますか？"
  },
  {
    "start": 336818,
    "end": 338226,
    "text": "ああ、違う違う。"
  },
  {
    "start": 338250,
    "end": 341858,
    "text": "論文には、線形回帰をするようにモデルに教えようとすることが書かれていましたね？"
  },
  {
    "start": 341906,
    "end": 359176,
    "text": "X軸にショット数や例をプロットし、通常の最小二乗回帰で得られる損失をプロットしてみるとわかる。"
  },
  {
    "start": 359200,
    "end": 360544,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 360664,
    "end": 361444,
    "text": "オーケー。"
  },
  {
    "start": 362064,
    "end": 378936,
    "text": "私はその論文のイントロとディスカッションの部分しか読んでいないが、ディスカッションの中で彼らが言っているのは、長いコンテキストのタスクでうまくなるためには、モデルはこれらの例から、あるいはすでにウィンドウの中にあるコンテクストから学習する学習でうまくならなければならないということだ。"
  },
  {
    "start": 379120,
    "end": 384432,
    "text": "その意味するところは、モデルが学ぶということだ。"
  },
  {
    "start": 384488,
    "end": 396392,
    "text": "メタ学習が、長いコンテキストのタスクを与える方法を学ぶために起こるのだとしたら、ある重要な意味で、知能のタスクは、長いコンテキストの例と長いコンテキストのトレーニングを必要とするようなものだ。"
  },
  {
    "start": 396528,
    "end": 397336,
    "text": "メタ・ラーニングのようにね。"
  },
  {
    "start": 397360,
    "end": 399104,
    "text": "メタ学習を誘導しなければならないようにね。"
  },
  {
    "start": 399224,
    "end": 404898,
    "text": "メタ学習、つまり事前訓練のプロセスをいかにうまく誘導するかを理解することは、実際に柔軟な知性、あるいは適応力のある知性を獲得するために非常に重要なことのように思える。"
  },
  {
    "start": 404986,
    "end": 405210,
    "text": "そうだろう？"
  },
  {
    "start": 405242,
    "end": 409694,
    "text": "長いコンテキストの仕事をうまくこなすことで、それを代用することができる。"
  },
  {
    "start": 410594,
    "end": 431306,
    "text": "多くの人が認識しているAIの進歩のボトルネックの1つは、これらのモデルがタスクを実行できないこと、つまり、何時間も、あるいは何週間も何カ月もタスクに従事することです。"
  },
  {
    "start": 431450,
    "end": 434382,
    "text": "私の理解では、AIエージェントはこの理由で普及しなかった。"
  },
  {
    "start": 434538,
    "end": 445822,
    "text": "長いコンテクストウインドウと、そのウインドウで優れたパフォーマンスを発揮する能力、そして何時間も課題に取り組む必要のあるこの種の長期的な視野に立った仕事をこなす能力は、どのようにリンクしているのだろうか？"
  },
  {
    "start": 445878,
    "end": 447566,
    "text": "それとも、これらは無関係な概念なのだろうか？"
  },
  {
    "start": 447710,
    "end": 455950,
    "text": "つまり、エージェントの普及が進まないのは、信頼性が9点であることや、モデルが実際にうまく機能していることの方が問題だと思う。"
  },
  {
    "start": 455982,
    "end": 461726,
    "text": "十分な確率でタスクを連続させることができなければ、エージェントらしいものはできない。"
  },
  {
    "start": 461790,
    "end": 480114,
    "text": "だからエージェントのようなものは、GPTの4クラスモデルやジェミニのウルトラクラスモデルのような、よりステップ関数に従うかもしれない。"
  },
  {
    "start": 480234,
    "end": 487442,
    "text": "そうだね。長いホライズンのタスクをこなすには、ある程度のコンテクストが必要なのは明らかだけど、今まではそれが制限要因にはなっていなかったと思う。"
  },
  {
    "start": 487578,
    "end": 503762,
    "text": "ライランド・シェーファーが筆頭著者であるニューロプスの今年の最優秀論文では、これは出現の蜃気楼のようなものだと指摘されている。"
  },
  {
    "start": 503898,
    "end": 508294,
    "text": "ということは、当然、それらすべてをサンプリングする確率を掛け算することになる。"
  },
  {
    "start": 508714,
    "end": 518954,
    "text": "もし責任に十分なナインがいなければ、エマージェンシーは生まれない。"
  },
  {
    "start": 518994,
    "end": 522302,
    "text": "そのためのスムーズな指標を見つける方法がある。"
  },
  {
    "start": 522478,
    "end": 523870,
    "text": "そう、人間の評価でも何でもいい。"
  },
  {
    "start": 523982,
    "end": 528954,
    "text": "GPTの4つの論文では、コーディング問題で、ログ合格率を正確に測定している。"
  },
  {
    "start": 529414,
    "end": 530126,
    "text": "観客のために。"
  },
  {
    "start": 530190,
    "end": 544662,
    "text": "基本的には、コーディングの問題を解くような特定のタスクでどれだけ進歩したかを測定する場合、1000回に1回だけ正しくできたときにウェイトを上げるという考え方だ。"
  },
  {
    "start": 544718,
    "end": 552864,
    "text": "1000回に1回というのは、1000回に1回、100回に1回、10回に1回というようなものだ。"
  },
  {
    "start": 553524,
    "end": 555764,
    "text": "実は、この件についてフォローしておきたいことがある。"
  },
  {
    "start": 555804,
    "end": 590652,
    "text": "もしあなたの主張が、AIエージェントが離陸しなかったのは、長期的視野に立ったタスクのパフォーマンスではなく、信頼性のせいだというのであれば、タスクが別のタスクに重なって変更されたときの信頼性の欠如は、まさに長期的視野に立ったタスクの難しさではないでしょうか。10個のことを連続してやらなければならなかったり、100個のことを連続してやらなければならなかったりして、どれか1つの信頼性が低下したり、そう、確率が99.99から99.9に下がったりすると、全体が掛け算になり、全体が起こる可能性がかなり低くなります。"
  },
  {
    "start": 590788,
    "end": 591996,
    "text": "それこそが問題なのだ。"
  },
  {
    "start": 592060,
    "end": 601644,
    "text": "もし99％だったら、チェーンは問題にならない。"
  },
  {
    "start": 601764,
    "end": 602516,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 602580,
    "end": 605180,
    "text": "これもまだ十分に研究されていないことだと思う。"
  },
  {
    "start": 605212,
    "end": 609380,
    "text": "アカデミック・エバルのような一般的なエバルをすべて見てみると、単一の問題である。"
  },
  {
    "start": 609532,
    "end": 610036,
    "text": "そうだね。"
  },
  {
    "start": 610140,
    "end": 614556,
    "text": "あの、数学の問題とか、典型的な数学の問題とか、Mmo Uとか。"
  },
  {
    "start": 614580,
    "end": 616780,
    "text": "それは、ある大学のレベルのようなものだ。"
  },
  {
    "start": 616812,
    "end": 618276,
    "text": "さまざまなトピックの中から。"
  },
  {
    "start": 618420,
    "end": 625916,
    "text": "スウィートベンチのような複雑なタスクを通じて、GitHubの課題全体を把握するエバルを見かけるようになった。"
  },
  {
    "start": 625980,
    "end": 630020,
    "text": "それは、それなりに長い水平線のタスクのようなものだが、まだマルチではない。"
  },
  {
    "start": 630132,
    "end": 634684,
    "text": "数時間や数日のタスクとは対照的に、数時間以下のタスクのようなものだ。"
  },
  {
    "start": 634804,
    "end": 644426,
    "text": "この先、どんなに長い期間をかけても、本当に重要なことのひとつは、長期的な視野に立った仕事の成功率とはどのようなものかをよりよく理解することだと思う。"
  },
  {
    "start": 644530,
    "end": 662562,
    "text": "このようなモデルの経済的な影響を理解し、私たちが行うタスクとそれに関わるインプットとアウトプットを分単位、時間単位、日単位に切り出し、それらの異なる時間分解能でタスクを連鎖させ完了させることがどれだけ優れているかを見ることによって、能力の向上を適切に判断することも重要だと思います。"
  },
  {
    "start": 662658,
    "end": 669434,
    "text": "|にできるようにあなたがそれをすることができます本当に出くわすことあなたは、実際には私たち約束、誰でも素早くはちょうど無視これらの一見正確にどのように{}人のことを忘れることができます。"
  },
  {
    "start": 670614,
    "end": 676006,
    "text": "つまり、10万個のコンテクスト・ウィンドウを導入したのは1年も前のことで、誰もがそれにかなり驚いたと思う。"
  },
  {
    "start": 676150,
    "end": 681174,
    "text": "そう、そう、誰もが二次関数的なアテンション・コストというサウンドバイトを持っていたんだ。"
  },
  {
    "start": 681294,
    "end": 684310,
    "text": "長いコンテクストウィンドウを持つことはできない。"
  },
  {
    "start": 684342,
    "end": 687142,
    "text": "だから、ベンチマークは積極的に作られているんだ。"
  },
  {
    "start": 687278,
    "end": 696314,
    "text": "グーグルやマジックなど、100万人単位の注目を集める企業があるという事実は、二次方程式を暗示しているのでは？"
  },
  {
    "start": 696434,
    "end": 700786,
    "text": "何も言うべきではない。なぜなら、それはもう2次方程式ではないことを意味するからではないか？"
  },
  {
    "start": 700810,
    "end": 702058,
    "text": "彼らはただコストを食いつぶしているだけなのか？"
  },
  {
    "start": 702186,
    "end": 702738,
    "text": "興味深い。"
  },
  {
    "start": 702786,
    "end": 705414,
    "text": "グーグルがその長いコンテキストのために何をしているかなんて、誰にもわからない。"
  },
  {
    "start": 706994,
    "end": 708454,
    "text": "私も何も言わない。"
  },
  {
    "start": 708794,
    "end": 722540,
    "text": "注意に対する一般的な研究分野のアプローチについて私が不満に思っていることのひとつは、典型的な高密度トランスフォーマーでは、注意の2次コストがMLPブロックによって支配されているという重要な点があるということだ。"
  },
  {
    "start": 722602,
    "end": 722872,
    "text": "そうだね。"
  },
  {
    "start": 722928,
    "end": 731032,
    "text": "注意に関連するn乗項がありますが、Dモデル、つまりモデルの残差ストリーム次元に関連するn乗項もあります。"
  },
  {
    "start": 731128,
    "end": 739464,
    "text": "サシャ・ラッシュが素晴らしいツイートをしていると思うんだけど、そこでは基本的に、注目のコストの曲線をそれぞれプロットしているんだ。"
  },
  {
    "start": 739544,
    "end": 744568,
    "text": "その前に、かなり長いコンテクストをこなす必要がある。"
  },
  {
    "start": 744656,
    "end": 747704,
    "text": "この言葉はとても重要なんだ。"
  },
  {
    "start": 747864,
    "end": 755114,
    "text": "そしてもうひとつは、推論時に注意を払うことがいかに大きなコストになるかということだ。"
  },
  {
    "start": 755614,
    "end": 771594,
    "text": "実際にトークンを生成するときのことを考えると、その操作はn乗ではなく、q個のベクトルからなる1セットのキューで、kv個のベクトル全体をルックアップすることになる。"
  },
  {
    "start": 772934,
    "end": 779754,
    "text": "このことが、直線的な注意というミームや、そういったものを人々が持っている、再帰性や状態空間に関する研究の多くの原動力になっていると思う。"
  },
  {
    "start": 780134,
    "end": 784166,
    "text": "トレンドンが言ったように、注目の周りにはアイデアの墓場がある。"
  },
  {
    "start": 784350,
    "end": 792246,
    "text": "しかし、その実際の強みと弱みがどこにあるのかを考えることは重要だと思う。"
  },
  {
    "start": 792430,
    "end": 794714,
    "text": "さて、このテイクをどう思う？"
  },
  {
    "start": 795894,
    "end": 801238,
    "text": "テイクオフで前進するにつれて、フォワードパスで学ぶことが多くなる。"
  },
  {
    "start": 801326,
    "end": 803914,
    "text": "本来、すべての学習は後方で行われるものだ。"
  },
  {
    "start": 804934,
    "end": 808594,
    "text": "このボトムアップの、ある種のヒルクライム的な進化の過程で。"
  },
  {
    "start": 809194,
    "end": 821202,
    "text": "知能が爆発的に発達した時代の限界で考えると、AIはウェイトを手で書いたり、囲碁をやったりしているようなもので、私たちはコンテキストの中で多くの学習が行われる中間段階にいる。"
  },
  {
    "start": 821258,
    "end": 824682,
    "text": "さて、これらのモデルでは、その多くが後方プロセスの中で起こる。"
  },
  {
    "start": 824778,
    "end": 829362,
    "text": "これは、どの程度の進歩が起きているのか、意味のある勾配に見えるだろうか？"
  },
  {
    "start": 829458,
    "end": 837738,
    "text": "というのも、フォワード・パスで学ぶ方が、基本的に学びながら考えることができるので、よりサンプル効率が良いからだ。"
  },
  {
    "start": 837826,
    "end": 849214,
    "text": "人間は、教科書を読むとき、ただざっと読んで、何を吸収しようとするのではなく、どんな誘導的な言葉があるのか、この言葉に従って、読んで、考えて、さらに読んで、考える。"
  },
  {
    "start": 850234,
    "end": 852894,
    "text": "どうだろう、これは進歩について考える賢明な方法だと思う？"
  },
  {
    "start": 853794,
    "end": 859042,
    "text": "鳥や飛行機が飛ぶように、飛び方が少し違うだけかもしれない。"
  },
  {
    "start": 859058,
    "end": 865386,
    "text": "テクノロジーのおかげで、鳥にはできないことができる。"
  },
  {
    "start": 865570,
    "end": 874728,
    "text": "文脈の長さは、人間にはないワーキングメモリーを持つことができるという点では似ているかもしれないが、機能的には実際の推論に向けて重要なことではない。"
  },
  {
    "start": 874816,
    "end": 890440,
    "text": "GPT-2とGPT-3の間の重要なステップは、トレーニングやモデルの事前トレーニングで突然、メタ学習行動が観察されたことです。"
  },
  {
    "start": 890472,
    "end": 894438,
    "text": "それ以前にはまったく見られなかった行動だった。"
  },
  {
    "start": 894536,
    "end": 899554,
    "text": "コンテクストの特性やスケール、こういったものが混ざっているのかもしれないが、小さなコンテクストをモデル化することは思いつかなかっただろう。"
  },
  {
    "start": 899594,
    "end": 900414,
    "text": "それだけだった。"
  },
  {
    "start": 902234,
    "end": 903490,
    "text": "これは実に興味深い指摘だ。"
  },
  {
    "start": 903562,
    "end": 917218,
    "text": "これらのモデルのスケールアップについて話すとき、そのどれだけがモデル自体を大きくすることによるもので、どれだけが1回の呼び出しでより多くのコンピュートを使用するという事実によるものなのか。"
  },
  {
    "start": 917306,
    "end": 923964,
    "text": "拡散を考えれば、コンピュータを反復的に増やし続ければいいし、アダプティブ・コンピューティングが解決されれば、それを続ければいい。"
  },
  {
    "start": 924744,
    "end": 935136,
    "text": "この場合、アテンションに2次関数的なペナルティがあるとしても、とにかく長いコンテクストをやっているのであれば、トレーニング中や大きなモデルを作っている最中でなくても、より多くの計算量を投入していることになる。"
  },
  {
    "start": 935280,
    "end": 940512,
    "text": "そうそう、トークンが多い方が前へのパスが増えるから面白いよね。"
  },
  {
    "start": 940568,
    "end": 941164,
    "text": "そうだろう？"
  },
  {
    "start": 942384,
    "end": 946112,
    "text": "ひとつだけ不満があるとすれば、これには2つ、いや3つ不満があるかな。"
  },
  {
    "start": 946168,
    "end": 960754,
    "text": "アルファ・ワールドの論文にあるアルファの不満のように、トランスフォーマー・モジュールの1つで、彼らはいくつか持っていて、アーキテクチャは非常に複雑なのだが、彼らはそれを5回前向きに通過させ、その結果、徐々に解決策を洗練させていくのだと思う。"
  },
  {
    "start": 961254,
    "end": 971078,
    "text": "また、シャルタが言及した残差ストリームの読み書き操作は、貧乏人のアダプティブ・コンピュートと考えることもできる。"
  },
  {
    "start": 971126,
    "end": 972874,
    "text": "そうでないなら、それでも構わない。"
  },
  {
    "start": 973334,
    "end": 979350,
    "text": "脳はリカレント（再帰的）だから、好きなだけループさせることができる。"
  },
  {
    "start": 979382,
    "end": 980894,
    "text": "ある程度はその通りだと思う。"
  },
  {
    "start": 980974,
    "end": 985462,
    "text": "もし私が難しい質問をすれば、あなたはそれについて考える時間を増やすだろうし、それはより多くの前進パスに対応するだろう。"
  },
  {
    "start": 985518,
    "end": 989646,
    "text": "できるフォワードパスの数には限りがあると思う。"
  },
  {
    "start": 989830,
    "end": 991358,
    "text": "言葉もそうだ。"
  },
  {
    "start": 991406,
    "end": 994502,
    "text": "人々は、ああ、人間の言語には無限の再帰性があるんだ。"
  },
  {
    "start": 994518,
    "end": 1001750,
    "text": "少年は熊を飛び越えた、熊はこれをした、熊はあれをした、というように無限に入れ子になっている。"
  },
  {
    "start": 1001782,
    "end": 1014034,
    "text": "経験的に、再帰のレベルは5～7段階しかない。これは、ワーキングメモリーに常に保持できる数が何個であるかというマジックナンバーに関係している。"
  },
  {
    "start": 1014944,
    "end": 1021176,
    "text": "無限に再帰するわけではないが、人間の知性の領域では重要なことなのだろうか？"
  },
  {
    "start": 1021240,
    "end": 1037284,
    "text": "ただレイヤーを増やすだけではだめなんだ。私にとっては、あなたは以前の答えのいくつかで、こういう長い文脈を持っていて、より多くのことを記憶に留めておくことができる、と言っていた。"
  },
  {
    "start": 1037824,
    "end": 1049082,
    "text": "これらのモデルは必ずしも人間レベルのものではないが、私にとっては文脈の内訳でさえ、生の情報を保存するのと推論するのと、その間にあるものをどう見るか？"
  },
  {
    "start": 1049178,
    "end": 1050934,
    "text": "推論はどこで起きているのか？"
  },
  {
    "start": 1051874,
    "end": 1053690,
    "text": "生情報の保存はどこで行われているのか？"
  },
  {
    "start": 1053722,
    "end": 1056254,
    "text": "これらのモデルで何が違うのか？"
  },
  {
    "start": 1056994,
    "end": 1061094,
    "text": "そうだね、あまり明確な答えはないんだ。"
  },
  {
    "start": 1062354,
    "end": 1067010,
    "text": "明らかに、モデルの入力と出力は、実際のトークンにマッピングされている。"
  },
  {
    "start": 1067122,
    "end": 1071304,
    "text": "そしてその間に、より高度な処理を行う。"
  },
  {
    "start": 1072524,
    "end": 1082476,
    "text": "この話を深める前に、トランスフォーマーについてのAnthropocの考え方を、レイヤーが行う読み書き操作として説明しなければならない。"
  },
  {
    "start": 1082580,
    "end": 1085764,
    "text": "あなた方のどちらかが、その意味を高いレベルで説明してくれればいい。"
  },
  {
    "start": 1085924,
    "end": 1095964,
    "text": "ボートに乗って川を下っていると想像してください。ボートは、次のトークンを予測しようとするカレントクエリのようなものです。"
  },
  {
    "start": 1096044,
    "end": 1107272,
    "text": "ブランクに座っているのは猫で、それから川から流れてくる小さな流れがある。"
  },
  {
    "start": 1107368,
    "end": 1111632,
    "text": "これらはモデルの一部であるアテンションヘッドとMLPに対応する。"
  },
  {
    "start": 1111728,
    "end": 1112368,
    "text": "そうだろう？"
  },
  {
    "start": 1112536,
    "end": 1113324,
    "text": "オーケー。"
  },
  {
    "start": 1113624,
    "end": 1122536,
    "text": "コンピューターのラムのようなもので、どの情報を読み込むかを選択する。"
  },
  {
    "start": 1122600,
    "end": 1128584,
    "text": "そして、その高次元ベクトルの部分空間を操作することができる。"
  },
  {
    "start": 1129284,
    "end": 1134852,
    "text": "つまり、現時点では、重ね合わせでエンコードされることはほぼ間違いないと思う。"
  },
  {
    "start": 1135028,
    "end": 1142940,
    "text": "残差ストリームは1つの高次元ベクトルに過ぎないが、実はその中には1トンもの異なるベクトルが詰め込まれているのだ。"
  },
  {
    "start": 1143012,
    "end": 1153858,
    "text": "ああ、数ヶ月前の僕には、モデルに入力される単語が何であれ、理解できたかもしれない。"
  },
  {
    "start": 1154026,
    "end": 1159970,
    "text": "すべての単語はトークンに変換され、トークンはベクトルに変換される。"
  },
  {
    "start": 1160122,
    "end": 1165522,
    "text": "基本的には、モデル内を移動するわずかな情報のようなものだ。"
  },
  {
    "start": 1165658,
    "end": 1170570,
    "text": "あなたが私に説明してくれたように、この論文で述べられているショルタはモデルの初期段階にある。"
  },
  {
    "start": 1170602,
    "end": 1174298,
    "text": "トークンが何を意味するのか、非常に基本的なことをやっているだけなのかもしれない。"
  },
  {
    "start": 1174386,
    "end": 1180906,
    "text": "10プラス5と書いてあれば、その良い表現ができるように情報を移動させるだけだ。"
  },
  {
    "start": 1180970,
    "end": 1181290,
    "text": "その通りだ。"
  },
  {
    "start": 1181322,
    "end": 1182578,
    "text": "ただ、真ん中を代表する。"
  },
  {
    "start": 1182626,
    "end": 1186498,
    "text": "たぶん、これをどう解決するかについて、より深い思考が起こっているのだろう。"
  },
  {
    "start": 1186626,
    "end": 1197854,
    "text": "最後に、それを出力トークンに変換する。最終的な成果物は、ストリームの最後の残差から次のトークンの確率を予測しようとするものだからだ。"
  },
  {
    "start": 1198874,
    "end": 1205454,
    "text": "モデル内を移動する圧縮されたわずかな情報量を考えるだけでも面白いし、それがさまざまな方法で修正されていく。"
  },
  {
    "start": 1205964,
    "end": 1206468,
    "text": "トレントン"
  },
  {
    "start": 1206516,
    "end": 1212476,
    "text": "あなたは神経科学のバックグラウンドを持っている数少ない人物の一人だ。"
  },
  {
    "start": 1212540,
    "end": 1216516,
    "text": "ここで脳に例えて考えてみてほしい。"
  },
  {
    "start": 1216620,
    "end": 1234594,
    "text": "実際、私たちの友人の一人が、大学院で脳の中の注意について考えた論文を発表したのだが、彼は、なぜ注意が働くかについての神経学的な説明はこれしかない、あるいはこれが初めてだ、と言った。"
  },
  {
    "start": 1234674,
    "end": 1239054,
    "text": "畳み込みニューラルネットワークは、視覚野か何かに基づいて機能する。"
  },
  {
    "start": 1239874,
    "end": 1240386,
    "text": "そうだね。"
  },
  {
    "start": 1240450,
    "end": 1252946,
    "text": "脳内には、圧縮された量の情報が流れていて、それが何かを考えているときに修正される、というようなことがあると思いますか？"
  },
  {
    "start": 1253050,
    "end": 1255634,
    "text": "脳の中で起きていることを表す良い比喩だと思いますか？"
  },
  {
    "start": 1255754,
    "end": 1256170,
    "text": "そうだね。"
  },
  {
    "start": 1256242,
    "end": 1256490,
    "text": "そうだね。"
  },
  {
    "start": 1256522,
    "end": 1266014,
    "text": "少なくとも小脳では、基本的に残差ストリームがあり、そこに全体的な、今は注意モジュールと呼ぶべきものがある。"
  },
  {
    "start": 1266834,
    "end": 1276186,
    "text": "それを経由する入力もあるが、モジュールが貢献するエンドポイントに直接行くこともある。"
  },
  {
    "start": 1276330,
    "end": 1284934,
    "text": "直接的なパスと間接的なパスがあるから、モデルは好きな情報を拾って、それをまた加えることができる。"
  },
  {
    "start": 1285974,
    "end": 1287554,
    "text": "では、小脳はどうなるのか？"
  },
  {
    "start": 1288134,
    "end": 1302434,
    "text": "小脳は名目上、細かい運動制御を行うだけだが、私はこれを、鍵をなくして街灯の下を見ている人に例える。"
  },
  {
    "start": 1303134,
    "end": 1314392,
    "text": "ある認知神経科学の第一人者は、ある課題に対する脳活動を調べるfMRI研究では、小脳がほとんど常に活動し、そのために光を放っている、という汚い秘密があると私に言った。"
  },
  {
    "start": 1314558,
    "end": 1321744,
    "text": "小脳が損傷していると、自閉症になる可能性も高くなります。"
  },
  {
    "start": 1322044,
    "end": 1330264,
    "text": "ある研究では、fMRIの代わりにペットを使ったと思うが、次のトークンを予測するとき、小脳がたくさん光る。"
  },
  {
    "start": 1331204,
    "end": 1334188,
    "text": "また、脳の神経細胞の70％は小脳にある。"
  },
  {
    "start": 1334316,
    "end": 1340840,
    "text": "それらは小さいが、そこに存在し、実質的な代謝コストを占めている。"
  },
  {
    "start": 1341032,
    "end": 1353032,
    "text": "これはゲルンの指摘のひとつで、例えば、人間で変わったのは単にニューロンの数が増えたということではなく、具体的には大脳皮質のニューロンの数が小脳より多いということだ、と彼はこの論文を紹介している。"
  },
  {
    "start": 1353088,
    "end": 1355152,
    "text": "もっと言うべきだ。"
  },
  {
    "start": 1355168,
    "end": 1355992,
    "text": "でも、そうなんだ。"
  },
  {
    "start": 1356048,
    "end": 1361144,
    "text": "より高価で、シグナル伝達や情報の送受信に関与する。"
  },
  {
    "start": 1361304,
    "end": 1361952,
    "text": "そうだね。"
  },
  {
    "start": 1362088,
    "end": 1362728,
    "text": "それが注意なのか？"
  },
  {
    "start": 1362776,
    "end": 1363424,
    "text": "どうしたんだ？"
  },
  {
    "start": 1363504,
    "end": 1364056,
    "text": "ああ、そうだ。"
  },
  {
    "start": 1364080,
    "end": 1367216,
    "text": "私がここで一番伝えたいことは何だろう。"
  },
  {
    "start": 1367360,
    "end": 1375478,
    "text": "1980年代に、ペンチコネルバは、ええと、関連するメモリーアルゴリズムを考え出した。"
  },
  {
    "start": 1375526,
    "end": 1376310,
    "text": "たくさんの思い出がある。"
  },
  {
    "start": 1376342,
    "end": 1377198,
    "text": "保管したいんだ。"
  },
  {
    "start": 1377286,
    "end": 1383526,
    "text": "ええと、何らかのノイズや破損が起こっていて、クエリや検索で最適なものを探したいんだ。"
  },
  {
    "start": 1383670,
    "end": 1396840,
    "text": "そして数年後、これを電気工学的な回路として実装してみると、実は核となる小脳回路と同じように見えることに気づく。"
  },
  {
    "start": 1396982,
    "end": 1401820,
    "text": "この回路と小脳は我々だけでなく、基本的にすべての生物に存在する。"
  },
  {
    "start": 1401892,
    "end": 1404076,
    "text": "頭足類にそれがあるかどうかについては、活発な議論がある。"
  },
  {
    "start": 1404100,
    "end": 1406084,
    "text": "進化の軌跡が違うんだ。"
  },
  {
    "start": 1406204,
    "end": 1412944,
    "text": "ショウジョウバエのキノコ体を持つミバエでさえ、小脳の構造は同じである。"
  },
  {
    "start": 1413684,
    "end": 1416124,
    "text": "そうすれば収束する。"
  },
  {
    "start": 1416204,
    "end": 1428774,
    "text": "私の論文では、ソフトマックスの実装や、これまで話してきたような名目上の2次コストのようなものを含めて、このオペレーションは、実際にはアテンション・オペレーションと非常に近い近似値で同じであることを示しています。"
  },
  {
    "start": 1429154,
    "end": 1435818,
    "text": "というわけで、この3つの収束とトランスフォーマーの離陸と成功は、私にとってかなり印象的なものに思える。"
  },
  {
    "start": 1435946,
    "end": 1437922,
    "text": "ああ、拡大して聞いてみたい。"
  },
  {
    "start": 1437978,
    "end": 1443914,
    "text": "この議論が始まったきっかけは、「ちょっと待って、その理由は何？"
  },
  {
    "start": 1443954,
    "end": 1445014,
    "text": "メモリーとは何ですか？"
  },
  {
    "start": 1445594,
    "end": 1449570,
    "text": "あなたが見つけた注意の例えについてどう思いますか？"
  },
  {
    "start": 1449642,
    "end": 1455604,
    "text": "これは、関連する記憶を調べるだけなのか、それとも関連する特徴や事実を調べるだけなのか、どちらだと思いますか？"
  },
  {
    "start": 1455644,
    "end": 1459584,
    "text": "もしそうなら、脳のどこで理性が働いているのか？"
  },
  {
    "start": 1460084,
    "end": 1462548,
    "text": "それがどのように推論に積み重なっていくかをどう考えるか。"
  },
  {
    "start": 1462636,
    "end": 1463068,
    "text": "そうだね。"
  },
  {
    "start": 1463156,
    "end": 1478504,
    "text": "多分、私が熱く語っているのは、どれくらい熱いかはわからないが、ほとんどの知能はパターンマッチングであり、連想記憶の階層があれば、本当に優れたパターンマッチングがたくさんできるということだ。"
  },
  {
    "start": 1479444,
    "end": 1485824,
    "text": "現実世界の物体と同じように、ごく基本的な連想から始めるのだ。"
  },
  {
    "start": 1486754,
    "end": 1496334,
    "text": "例えば、結婚指輪は下流にある他の多くの連想の象徴である。"
  },
  {
    "start": 1498194,
    "end": 1505530,
    "text": "注意の操作とこの関連する記憶をMLP層として一般化することもできる。"
  },
  {
    "start": 1505682,
    "end": 1510534,
    "text": "今の状況ではトークンを持っていない、長期的な舞台での話だ。"
  },
  {
    "start": 1511494,
    "end": 1519966,
    "text": "これは、連想がすべてであり、一般的な連想記憶も必要だという主張だと思う。"
  },
  {
    "start": 1520150,
    "end": 1522070,
    "text": "これで2つのことができる。"
  },
  {
    "start": 1522262,
    "end": 1525534,
    "text": "現在のメモリをノイズ除去することも、リトリーブすることもできる。"
  },
  {
    "start": 1525574,
    "end": 1543356,
    "text": "もし私があなたの顔を見ていて、でも雨が降っていて曇っていたら、私はノイズを除去し、あなたの顔の記憶に向かって私のクエリを徐々に更新することができる。"
  },
  {
    "start": 1543460,
    "end": 1549164,
    "text": "ということは、アルファベットを学習した場合、aをクエリするとbが返されるという非常に単純な例となる。"
  },
  {
    "start": 1549204,
    "end": 1553464,
    "text": "bをクエリするとcが返ってくる。"
  },
  {
    "start": 1554844,
    "end": 1556504,
    "text": "ああ、そうだ。"
  },
  {
    "start": 1556924,
    "end": 1565012,
    "text": "デミスと話したことのひとつに、彼が2008年に発表した論文に、記憶とイマジネーションは非常に結びついているということがあった。"
  },
  {
    "start": 1565148,
    "end": 1566856,
    "text": "記憶は再構成される。"
  },
  {
    "start": 1566980,
    "end": 1574680,
    "text": "だから、ある意味、記憶を思い浮かべるたびに想像していることになる。"
  },
  {
    "start": 1574792,
    "end": 1581684,
    "text": "これが人間の記憶力がひどい理由であり、証人席の人間などがでたらめを言う理由であることは有名だ。"
  },
  {
    "start": 1583304,
    "end": 1586224,
    "text": "じゃあ、バカな質問をさせてくれ。"
  },
  {
    "start": 1586264,
    "end": 1588072,
    "text": "シャーロック・ホームズのところへ行くんだろ？"
  },
  {
    "start": 1588168,
    "end": 1590696,
    "text": "彼は信じられないほどサンプル効率がいい。"
  },
  {
    "start": 1590800,
    "end": 1604194,
    "text": "彼はいくつかの観察結果を見て、基本的に誰が犯罪を犯したかを突き止める。誰かのタトゥーや壁に書かれたものから、その意味合いへとつながる一連の推理的なステップがあるからだ。"
  },
  {
    "start": 1605294,
    "end": 1607246,
    "text": "それはこの写真とどう関係があるのか？"
  },
  {
    "start": 1607310,
    "end": 1616994,
    "text": "というのも、彼らが賢いのは、連想ではなく、異なる情報の断片の間にある種の演繹的なつながりがあるからだ。"
  },
  {
    "start": 1618134,
    "end": 1621966,
    "text": "それは単なる高次元の関連性だと説明していただけますか？"
  },
  {
    "start": 1622110,
    "end": 1623014,
    "text": "そうだね。"
  },
  {
    "start": 1623054,
    "end": 1623474,
    "text": "そうだね。"
  },
  {
    "start": 1623574,
    "end": 1629394,
    "text": "より高度な関連付けを学ぶことで、互いのパターンをマッピングできるようになる。"
  },
  {
    "start": 1629554,
    "end": 1642098,
    "text": "この場合、彼は本当に長い文脈の長さ、あるいは本当に長いワーキングメモリーを持っているのだと思う。"
  },
  {
    "start": 1642186,
    "end": 1644774,
    "text": "理論が残留ストリームを動いていることを示す。"
  },
  {
    "start": 1645274,
    "end": 1671460,
    "text": "そして、彼のアテンション・ヘッドが自分の文脈を照会し、その照会内容とキーをどのように空間に投影し、MLPがより長期的な事実をどのように検索し、あるいはその情報をどのように修正するかによって、彼は後のレイヤーでさらに洗練された照会を行い、ゆっくりと推論を進めて意味のある結論を導き出すことができるようになるのである。"
  },
  {
    "start": 1671572,
    "end": 1672292,
    "text": "私にはそれが正しいように感じる。"
  },
  {
    "start": 1672308,
    "end": 1674220,
    "text": "過去を振り返るという意味で。"
  },
  {
    "start": 1674252,
    "end": 1680864,
    "text": "特定の情報を選択的に読み込んで、それらを比較することで、次のステップでどのような情報を読み込む必要があるかがわかるかもしれない。"
  },
  {
    "start": 1680964,
    "end": 1685768,
    "text": "このように、容疑者にどんどん近づいていくような表現を構築する。"
  },
  {
    "start": 1685816,
    "end": 1689784,
    "text": "あなたの場合、それはまったく突飛なことではない。"
  },
  {
    "start": 1689904,
    "end": 1709008,
    "text": "この研究をしていない人が見落としがちなのは、モデルの最初のレイヤーの後、アテンションに使用するすべてのクエリキーと値は、以前のすべてのトークンの組み合わせから来ているということです。"
  },
  {
    "start": 1709096,
    "end": 1713616,
    "text": "最初のレイヤーと同じように、以前のトークンにクエリーを発行し、そこから情報を抽出する。"
  },
  {
    "start": 1713720,
    "end": 1719528,
    "text": "突然だが、仮に私がトークン1、2、4に等しく出席したとしよう。"
  },
  {
    "start": 1719656,
    "end": 1728448,
    "text": "そうすると、私の残差ストリームのベクトルは、値ベクトルに対して同じことを書き出したと仮定すると、それぞれの3分の1になる。"
  },
  {
    "start": 1728616,
    "end": 1736654,
    "text": "だから、将来クエリーを出すときには、クエリーはそれぞれの3分の1ずつになる。"
  },
  {
    "start": 1736784,
    "end": 1737418,
    "text": "その通りだ。"
  },
  {
    "start": 1737506,
    "end": 1738018,
    "text": "仮定の話だが。"
  },
  {
    "start": 1738066,
    "end": 1739494,
    "text": "その必要はない。"
  },
  {
    "start": 1740034,
    "end": 1749094,
    "text": "2層目でも、もっと深い層でも、すぐに組み替えることができ、大量の情報を詰め込んだ非常にリッチなベクトルを持つことができる。"
  },
  {
    "start": 1749554,
    "end": 1756254,
    "text": "因果関係のグラフは、文字通り、過去に起こったすべての層の上にある。"
  },
  {
    "start": 1757274,
    "end": 1774494,
    "text": "シャーロック・ホームズ・エバルのように、本全体を文脈に当てはめて、容疑者はxであるという文章を書き、本の中のさまざまな登場人物を論理的に確率分布させる。"
  },
  {
    "start": 1775434,
    "end": 1778266,
    "text": "カッコイイと思うようなものはまったくないかな。"
  },
  {
    "start": 1778450,
    "end": 1780802,
    "text": "シャーロック・ホームズはすでにトレーニングデータの中に入っているでしょう？"
  },
  {
    "start": 1780858,
    "end": 1781026,
    "text": "そうだね。"
  },
  {
    "start": 1781050,
    "end": 1783130,
    "text": "で書かれた推理小説のようなものを手に入れなければならない。"
  },
  {
    "start": 1783282,
    "end": 1787042,
    "text": "法学修士に書かせることもできるし、意図的に除外することもできるだろう？"
  },
  {
    "start": 1787138,
    "end": 1787666,
    "text": "できるのか？"
  },
  {
    "start": 1787730,
    "end": 1788290,
    "text": "どうやって？"
  },
  {
    "start": 1788362,
    "end": 1791346,
    "text": "まあ、Redditやその他のものからそれに関する議論をかき集める必要がある。"
  },
  {
    "start": 1791370,
    "end": 1791874,
    "text": "そうだね。"
  },
  {
    "start": 1791914,
    "end": 1802244,
    "text": "それは難しいことだが、ロングコンテキストのエバリュエーションなどでは、良いエバリュエーションを得るためには、トレーニングデータに含まれていないことを知る必要がある。"
  },
  {
    "start": 1805784,
    "end": 1807592,
    "text": "フォローしたいスレッドが2つある。"
  },
  {
    "start": 1807648,
    "end": 1811284,
    "text": "ロング・コンテクストのほうに行って、それからこの話に戻ろう。"
  },
  {
    "start": 1811824,
    "end": 1816648,
    "text": "つまり、ジェミニ1.5の論文で使用された評価は次のようなものだった。"
  },
  {
    "start": 1816736,
    "end": 1819104,
    "text": "ポグラムのエッセイのようなものはできますか？"
  },
  {
    "start": 1819144,
    "end": 1819840,
    "text": "記憶できるか？"
  },
  {
    "start": 1819912,
    "end": 1821428,
    "text": "ああ、干し草の山の中の針だ。"
  },
  {
    "start": 1821536,
    "end": 1822596,
    "text": "ええと、どれですか？"
  },
  {
    "start": 1822660,
    "end": 1824396,
    "text": "ああ、つまり、僕らみたいなのがいるんだ。"
  },
  {
    "start": 1824420,
    "end": 1829384,
    "text": "私たちが気にするのは、文脈から特定の事実を想起する能力だけではない。"
  },
  {
    "start": 1830404,
    "end": 1832144,
    "text": "私は一歩下がって質問する。"
  },
  {
    "start": 1832884,
    "end": 1833588,
    "text": "うーん。"
  },
  {
    "start": 1833716,
    "end": 1837452,
    "text": "これらのモデルの損失関数は教師なしだ。"
  },
  {
    "start": 1837508,
    "end": 1841908,
    "text": "トレーニングデータから除外するようなオーダーメイドのものを考え出す必要はない。"
  },
  {
    "start": 1842036,
    "end": 1851024,
    "text": "別の法学修士が何らかの形で評価するような、教師なしのベンチマークを行う方法はありますか？"
  },
  {
    "start": 1851184,
    "end": 1856040,
    "text": "というのも、教師なし学習があるからだ。"
  },
  {
    "start": 1856192,
    "end": 1858760,
    "text": "そう、つまり、人々はそういうことを探求してきたと思うんだ。"
  },
  {
    "start": 1858792,
    "end": 1867576,
    "text": "例えば、人類学には、他の言語モデルを用いて、それを指して、その応答がどれほど役に立ったか、あるいは無害だったかを論じる、IRLの論文がある。"
  },
  {
    "start": 1867600,
    "end": 1872696,
    "text": "その後、彼らはそれを更新させ、有用性と有害性のパレート・フロンティアに沿って改善しようとする。"
  },
  {
    "start": 1872880,
    "end": 1877004,
    "text": "このように、言語モデル同士を向かい合わせてエバルを作成することができる。"
  },
  {
    "start": 1877164,
    "end": 1879788,
    "text": "現時点では明らかに不完全な芸術だ。"
  },
  {
    "start": 1879876,
    "end": 1884036,
    "text": "ええと、基本的にハッキングの報酬を得ることができるからだ。"
  },
  {
    "start": 1884140,
    "end": 1897744,
    "text": "人間だって不完全なんだから、人間の言うことに合わせようとすれば、人間は一般的に長い答えを好む。"
  },
  {
    "start": 1898924,
    "end": 1900028,
    "text": "もうひとつは"
  },
  {
    "start": 1900076,
    "end": 1910130,
    "text": "さて、もうひとつのスレッドだが、シャーロック・ホームズのことに話を戻すと、もしすべての関連付けがすべてだとしたら、これは一種の素朴な晩餐会の質問だ。"
  },
  {
    "start": 1910202,
    "end": 1916490,
    "text": "もし私があなたに会ったばかりなら、私はAIを研究していることになる。"
  },
  {
    "start": 1916602,
    "end": 1919934,
    "text": "シャーロック・ホームズのような感覚はないからだ。"
  },
  {
    "start": 1920554,
    "end": 1923514,
    "text": "それでも、これらの関連性を見つける必要がある。"
  },
  {
    "start": 1923674,
    "end": 1925174,
    "text": "人間は関連性を見つける。"
  },
  {
    "start": 1925754,
    "end": 1926450,
    "text": "私の言っている意味が分かる？"
  },
  {
    "start": 1926482,
    "end": 1927418,
    "text": "だけではない。"
  },
  {
    "start": 1927586,
    "end": 1930974,
    "text": "世界のフレームを見て、物理法則をすべて解明したようなものだ。"
  },
  {
    "start": 1931594,
    "end": 1935746,
    "text": "これは非常に正当な反応だからね。"
  },
  {
    "start": 1935770,
    "end": 1943242,
    "text": "もし人間が一般的に知的だと言うなら、人工知能はそれ以上の能力も能力もない、というようなものだ。"
  },
  {
    "start": 1943418,
    "end": 1958654,
    "text": "シリコンの一般的なインテリジェンスのレベルでは、何十万ものエージェントのクローンをすぐに作ることができ、彼らは眠る必要もなく、超長いコンテキスト・ウィンドウを持つことができる。"
  },
  {
    "start": 1959184,
    "end": 1968044,
    "text": "最初の質問に答えるなら、そうだね、彼らはまだアソシエーションを学ぶ必要がある。"
  },
  {
    "start": 1968424,
    "end": 1973496,
    "text": "インテリジェンスというものが基本的に連想のことだとすれば、その向上は単に連想がうまくなることだ。"
  },
  {
    "start": 1973560,
    "end": 1975960,
    "text": "他には何もない。"
  },
  {
    "start": 1976032,
    "end": 1982512,
    "text": "という直感に同意できないようだ。"
  },
  {
    "start": 1982568,
    "end": 1995572,
    "text": "例えば、新しいビデオゲームをプレイしたり、新しい教科書を勉強したりするとき、より早く関連付けをするために、たくさんのスキルをテーブルに持ち込むことになる。"
  },
  {
    "start": 1995668,
    "end": 2004304,
    "text": "というのも、すべてが何らかの形で物理的な世界と結びついているからだ。"
  },
  {
    "start": 2006444,
    "end": 2008340,
    "text": "知性の爆発について話すべきか？"
  },
  {
    "start": 2008372,
    "end": 2008944,
    "text": "それで？"
  },
  {
    "start": 2011524,
    "end": 2014184,
    "text": "複数のエージェントの話をしたら、ああ、これだ、と。"
  },
  {
    "start": 2014824,
    "end": 2043322,
    "text": "さて、私がこの議論に興味を持ったのは、特にあなた方とだからです。これまでのところ、私たちが持っている知能爆発に関するモデルは経済学者によるものです。"
  },
  {
    "start": 2043448,
    "end": 2051278,
    "text": "だから、もしそれが指標であったり、メカニズムであったりするのであれば、AIの研究者たちに、これがもっともらしいと思うかどうか聞いてみるべきだと思う。"
  },
  {
    "start": 2051446,
    "end": 2059694,
    "text": "アジア人のショトンが1000人、アジア人のトレントンが1000人いたとして、その人たちは情報爆発を起こすと思いますか？"
  },
  {
    "start": 2059734,
    "end": 2060438,
    "text": "そうなのか。"
  },
  {
    "start": 2060606,
    "end": 2061270,
    "text": "そうだね。"
  },
  {
    "start": 2061422,
    "end": 2062834,
    "text": "あなたにはどう見える？"
  },
  {
    "start": 2063134,
    "end": 2067478,
    "text": "ここで重要な制約のひとつは、計算能力だと思う。"
  },
  {
    "start": 2067646,
    "end": 2071014,
    "text": "例えば、AIの研究を劇的にスピードアップさせることはできると思う。"
  },
  {
    "start": 2071794,
    "end": 2083414,
    "text": "今後2、3年のうちに、私が日常的に行っているソフトウェア・エンジニアリングの仕事の多くをこなせるようになり、その結果、私の仕事が劇的にスピードアップし、進歩のスピードも速くなることは、はっきりしているように思う。"
  },
  {
    "start": 2084994,
    "end": 2094874,
    "text": "今のところ、ほとんどの研究室は、常にそこにいて、より多くの実験ができ、より多くの情報を得ることができるという点で、多少コンピュートに縛られていると思う。"
  },
  {
    "start": 2094914,
    "end": 2100770,
    "text": "同じように、生物学の科学研究もまた、実験的なスループットの制約がある。"
  },
  {
    "start": 2100802,
    "end": 2104762,
    "text": "情報を得るためには、細胞を培養する必要がある。"
  },
  {
    "start": 2104858,
    "end": 2108986,
    "text": "それは少なくとも短期的な計画の制約になると思う。"
  },
  {
    "start": 2109010,
    "end": 2119174,
    "text": "明らかに、サムは7兆ドルもの資金を集めて船を手に入れようとしている。"
  },
  {
    "start": 2119994,
    "end": 2124358,
    "text": "ビデオの株価は、相対的なコンピュートの増加を表しているようなものだ。"
  },
  {
    "start": 2119994,
    "end": 2124358,
    "text": "ビデオの株価は、相対的なコンピュートの増加を表しているようなものだ。"
  },
  {
    "start": 2124466,
    "end": 2127114,
    "text": "うーん、でも何か考えはある？"
  },
  {
    "start": 2127734,
    "end": 2134198,
    "text": "本当に有用で信頼できるものにするためには、もう少し信頼性の9が必要だと思う。"
  },
  {
    "start": 2134326,
    "end": 2141574,
    "text": "今はただ、コンテクストの長さが超長くて、とても安く手に入る。"
  },
  {
    "start": 2141694,
    "end": 2148894,
    "text": "コードベースで作業する場合、今はクロードに書いてもらえるのは小さなモジュールだけなんだ。"
  },
  {
    "start": 2149014,
    "end": 2157846,
    "text": "でも、今後数年、あるいはもっと早く、私の仕事のほとんどを自動化できるようになる可能性は高い。"
  },
  {
    "start": 2157990,
    "end": 2180990,
    "text": "少なくとも私たちの解釈可能性のサブチームが取り組んでいる研究は非常に初期段階なので、バグがない方法ですべてが正しく行われていることを確認し、モデル内の他のすべてのものと結果を関連付けなければなりません。"
  },
  {
    "start": 2181102,
    "end": 2187526,
    "text": "何かうまくいっていないことがあれば、考えられることをすべて列挙し、それを少しずつ改善していく。"
  },
  {
    "start": 2187710,
    "end": 2191806,
    "text": "例えば、以前の論文で公にしているレイヤーノルムの扱いについてですね。"
  },
  {
    "start": 2191910,
    "end": 2197606,
    "text": "早い段階で結果を出そうとしたり、モデルのロジット効果を見ようとしたりするようなものですよね？"
  },
  {
    "start": 2197630,
    "end": 2203634,
    "text": "つまり、私たちが特定したこの特徴を非常に大きく活性化させたら、モデルの出力はどう変わるのか、ということだ。"
  },
  {
    "start": 2204654,
    "end": 2206302,
    "text": "レイヤー・ノームを使っているかどうか？"
  },
  {
    "start": 2206398,
    "end": 2208794,
    "text": "学習される機能にどのような変化があるのか？"
  },
  {
    "start": 2211504,
    "end": 2215244,
    "text": "そのモデルにはさらに文脈や推論能力が必要になる。"
  },
  {
    "start": 2215704,
    "end": 2224712,
    "text": "あなたは2つのコンセプトを一緒に使っていたが、それが同じものだとは私にはわからない。"
  },
  {
    "start": 2224768,
    "end": 2241576,
    "text": "ひとつは、クラウドのコードベースに取り組んで、それに基づいてさらにモジュールを作るには、より多くのコンテキストが必要だということだ。"
  },
  {
    "start": 2241680,
    "end": 2242872,
    "text": "そう、コンテクストウィンドウのコンテクストだ。"
  },
  {
    "start": 2242928,
    "end": 2245576,
    "text": "うーん、そうだね、今ならちょうど収まるかもしれないね。"
  },
  {
    "start": 2245720,
    "end": 2250920,
    "text": "良いモジュールを作るのを妨げているのは、コードベースをそこに置くことができないことではないんだ。"
  },
  {
    "start": 2250952,
    "end": 2252088,
    "text": "もうすぐだと思うよ。"
  },
  {
    "start": 2252176,
    "end": 2257576,
    "text": "ああ、でも、コードベースをそこに収めることができるから、論文を思いつくという点では君にはかなわないだろうね。"
  },
  {
    "start": 2257640,
    "end": 2259524,
    "text": "いや、でもエンジニアリングのスピードは上がるよ。"
  },
  {
    "start": 2260204,
    "end": 2260932,
    "text": "うーん。"
  },
  {
    "start": 2261068,
    "end": 2263344,
    "text": "知能の爆発を引き起こすようなやり方で。"
  },
  {
    "start": 2264364,
    "end": 2267468,
    "text": "いや、それは研究を加速させるが、こういうことは複合的なものだと思う。"
  },
  {
    "start": 2267636,
    "end": 2273660,
    "text": "だから、エンジニアリングを早くすればするほど、より多くの実験をすることができる。"
  },
  {
    "start": 2273732,
    "end": 2278612,
    "text": "つまり、私の仕事は実際に能力を加速させることではなく、モデルを解釈することなんだ。"
  },
  {
    "start": 2278708,
    "end": 2280584,
    "text": "その点については、まだやるべきことがたくさんある。"
  },
  {
    "start": 2281564,
    "end": 2283584,
    "text": "ツイッターへのサプライズ。"
  },
  {
    "start": 2284204,
    "end": 2290844,
    "text": "ツイッターの人、コンテクスト、例えば、あなたが論文を発表したとき、ツイッター上では解決すべきアライメントについて多くの話題がありました。"
  },
  {
    "start": 2290884,
    "end": 2292424,
    "text": "みんな、カーテンを閉めて。"
  },
  {
    "start": 2295684,
    "end": 2304704,
    "text": "そう、そう、そうなんだ。夜も眠れないんだ。モデルがより速く、より高性能になりつつあるのに、何が起こっているのか、僕らの理解がまだいかに乏しいか。"
  },
  {
    "start": 2306084,
    "end": 2308524,
    "text": "ああ、まだそうだね。"
  },
  {
    "start": 2308684,
    "end": 2311444,
    "text": "では、具体的に説明しよう。"
  },
  {
    "start": 2311604,
    "end": 2317246,
    "text": "これが実現するころには、2桁から4桁大きなモデルができている。"
  },
  {
    "start": 2317350,
    "end": 2318070,
    "text": "そうだね。"
  },
  {
    "start": 2318262,
    "end": 2321446,
    "text": "少なくとも実効的な計算量では、2桁から4桁大きい。"
  },
  {
    "start": 2321550,
    "end": 2330006,
    "text": "だから、実験をより速く実行できるとかいう考え方は、モデルを再トレーニングしなければならない。"
  },
  {
    "start": 2330070,
    "end": 2339574,
    "text": "この知能爆発のバージョンでは、再帰的な自己改善は、20年前に想像されていたような、コードを書き換えるだけのものとは異なる。"
  },
  {
    "start": 2339654,
    "end": 2341606,
    "text": "実際に新しいモデルをトレーニングしなければならない。"
  },
  {
    "start": 2341710,
    "end": 2344638,
    "text": "それは今だけでなく、特に将来的には本当に高くつく。"
  },
  {
    "start": 2344686,
    "end": 2353954,
    "text": "このようなモデルを何桁も大きくし続けると、ある種の再帰的なソフトウェア型の知性の爆発の可能性が減衰するのではないか？"
  },
  {
    "start": 2356334,
    "end": 2359834,
    "text": "間違いなくブレークメカニズムとして機能するだろう。"
  },
  {
    "start": 2362654,
    "end": 2369094,
    "text": "今、私たちが作っているものは、20年前の人々が想像していたものとはまったく違う世界になっている。"
  },
  {
    "start": 2369174,
    "end": 2373558,
    "text": "本当に賢くなるために自分でコードを書くことはできない。"
  },
  {
    "start": 2373606,
    "end": 2379694,
    "text": "例えば、コード自体は非常にシンプルで、うーん、通常は本当に小さくて自己完結している。"
  },
  {
    "start": 2379774,
    "end": 2387606,
    "text": "ジョン・カーマックが、「1万行のコードでAIを書くなんて、歴史上初めてだ。"
  },
  {
    "start": 2387710,
    "end": 2394054,
    "text": "もし、ほとんどのトレーニング・コード・ベースが限界まで組まれているのであれば、それはもっともなことのように思える。"
  },
  {
    "start": 2394174,
    "end": 2402516,
    "text": "でも、これは、進歩がどのように起こるかを推定するために、私たちが本当に測定する努力をすべきものだという事実を取り去るものではない。"
  },
  {
    "start": 2402620,
    "end": 2412884,
    "text": "ソフトウェア・エンジニアの仕事のどれだけが自動化可能なのか、その傾向線はどうなっているのかを正確に測定し、その傾向線を予測しようと懸命になるべきだ。"
  },
  {
    "start": 2413044,
    "end": 2417904,
    "text": "ソフトウェア・エンジニアには失礼だが、あなたはフロント・エンドに反応して書いているわけではない。"
  },
  {
    "start": 2418724,
    "end": 2420668,
    "text": "どうすればいいのかわからない。"
  },
  {
    "start": 2420836,
    "end": 2422532,
    "text": "具体的に何が起きているのか？"
  },
  {
    "start": 2422668,
    "end": 2432734,
    "text": "モデルをより良くするための実験やプロジェクトに取り組んでいる一日の流れを教えてください。"
  },
  {
    "start": 2433394,
    "end": 2434482,
    "text": "何が起こっているのか？"
  },
  {
    "start": 2434578,
    "end": 2439426,
    "text": "観察から実験、理論、そしてコードを書くまで、何が起きているのか？"
  },
  {
    "start": 2439610,
    "end": 2444234,
    "text": "ここで文脈を整理するために重要だと思うのは、私はこれまで主に推論に取り組んできたということだ。"
  },
  {
    "start": 2444314,
    "end": 2455052,
    "text": "推論に適したモデルを設計し、モデルとその周辺のシステムをより高速にするんだ。"
  },
  {
    "start": 2455108,
    "end": 2458580,
    "text": "プレトレーニングも行ったが、100％集中したわけではない。"
  },
  {
    "start": 2458612,
    "end": 2460668,
    "text": "私は今でも、その仕事をするときの自分の行動を説明することができる。"
  },
  {
    "start": 2460756,
    "end": 2461004,
    "text": "でもね。"
  },
  {
    "start": 2461044,
    "end": 2462540,
    "text": "すみません、中断して2種類の仕事を言わせてください。"
  },
  {
    "start": 2462572,
    "end": 2462996,
    "text": "そうだね。"
  },
  {
    "start": 2463100,
    "end": 2476812,
    "text": "カール・シュルマンは、ポッドキャストでこのことについて話していたとき、推論を改善したり、文字通り、より良いチップやGPUを作る手助けをしたりすることは、インテリジェンス爆発の一部だと言っていました。"
  },
  {
    "start": 2476868,
    "end": 2477196,
    "text": "そうだね。"
  },
  {
    "start": 2477260,
    "end": 2481388,
    "text": "なぜなら、推論コードがより速く実行されれば、より良い結果が得られるとか、より速くなるとか、そんなことは明らかだからだ。"
  },
  {
    "start": 2481436,
    "end": 2481644,
    "text": "そうだね。"
  },
  {
    "start": 2481684,
    "end": 2482252,
    "text": "とにかく、申し訳ないが、どうぞ。"
  },
  {
    "start": 2482268,
    "end": 2482824,
    "text": "そうだね。"
  },
  {
    "start": 2483584,
    "end": 2483960,
    "text": "オーケー。"
  },
  {
    "start": 2483992,
    "end": 2486964,
    "text": "具体的に1日とはどのようなものなのか？"
  },
  {
    "start": 2487904,
    "end": 2499848,
    "text": "最も重要なのは、アイデアを思いつき、それをさまざまなスケールで検証し、そしてまたアイデアを実現するというサイクルだと思う。"
  },
  {
    "start": 2499896,
    "end": 2502096,
    "text": "そして、何が間違っているのかを解釈し、理解する。"
  },
  {
    "start": 2502160,
    "end": 2508248,
    "text": "ほとんどの人が、解釈すること、何が起こっているのかを理解することなど、解釈するためにどれだけのことが起こっているのかを知ったら驚くと思う。"
  },
  {
    "start": 2508296,
    "end": 2512558,
    "text": "うまくいかないのは、アイデアが、人々が試したいアイデアの長いリストを持っているからだ。"
  },
  {
    "start": 2512606,
    "end": 2517630,
    "text": "うまくいくはずだと思っているアイデアがすべてうまくいくとは限らないし、その理由を理解しようとするのはかなり難しい。"
  },
  {
    "start": 2517662,
    "end": 2520590,
    "text": "そして、それを尋問するために具体的に何をすればいいのかを考えるんだ。"
  },
  {
    "start": 2520742,
    "end": 2523606,
    "text": "だから、その多くは何が起こっているのかという内省のようなものなんだ。"
  },
  {
    "start": 2523630,
    "end": 2526782,
    "text": "何千、何万行ものコードを送り出すわけではない。"
  },
  {
    "start": 2526838,
    "end": 2531230,
    "text": "アイデアを出すことの難しさとは違う。"
  },
  {
    "start": 2531302,
    "end": 2534318,
    "text": "多くの人が、試してみたいアイデアの長いリストを持っていると思う。"
  },
  {
    "start": 2534446,
    "end": 2543492,
    "text": "不完全な情報しかない中で、その情報を整理し、どのようなアイデアが適切かを判断するのは本当に難しい。"
  },
  {
    "start": 2543668,
    "end": 2546948,
    "text": "不完全な情報とはどういう意味ですか？"
  },
  {
    "start": 2547076,
    "end": 2548564,
    "text": "これは初期の実験なのか？"
  },
  {
    "start": 2548644,
    "end": 2552596,
    "text": "これらは、あなたがそうだという情報は何ですか？"
  },
  {
    "start": 2552620,
    "end": 2566734,
    "text": "Demは彼のポッドキャストでこのことに触れています。また、明らかに、スケーリング則の増分があるGPT4の論文のようなものです。GPT4の論文では、彼らは点の束を持っていて、これらの点をすべて使って最終モデルの性能を推定することができると言っています。"
  },
  {
    "start": 2566804,
    "end": 2567466,
    "text": "デミスが言った。"
  },
  {
    "start": 2567490,
    "end": 2567674,
    "text": "そうだね。"
  },
  {
    "start": 2567714,
    "end": 2573530,
    "text": "このスケールアップのプロセスを具体的に行うこと。"
  },
  {
    "start": 2573682,
    "end": 2574210,
    "text": "なぜですか？"
  },
  {
    "start": 2574242,
    "end": 2578858,
    "text": "不完全な情報とは、トレンドが維持されるかどうかを実際に知ることができないことだ。"
  },
  {
    "start": 2578986,
    "end": 2584354,
    "text": "特定のアーキテクチャーについては、その傾向はとてもよく保たれており、特定の変更については、とてもよく保たれている。"
  },
  {
    "start": 2584514,
    "end": 2586394,
    "text": "とは限らない。"
  },
  {
    "start": 2586434,
    "end": 2590734,
    "text": "小さな規模では助けになることも、大きな規模になると害になることもある。"
  },
  {
    "start": 2591794,
    "end": 2605914,
    "text": "傾向線がどのように見えるかに基づいて推測し、「よし、これは実際に重要なことだ」という直感的な感覚に基づく。"
  },
  {
    "start": 2606214,
    "end": 2616486,
    "text": "そのため、発表された紙のテクニカルレポートにあるような滑らかなカーブを示すチャートには、最初の数本が墓場となり、その後は横ばいになっていることを考えると興味深い。"
  },
  {
    "start": 2616590,
    "end": 2619034,
    "text": "他にもいろいろな方向に行く線がある。"
  },
  {
    "start": 2621434,
    "end": 2622378,
    "text": "ああ、クレイジーだよ。"
  },
  {
    "start": 2622426,
    "end": 2628374,
    "text": "大学院生として、そしてここでも、意味のある結果を得るまでに何度も実験をしなければならない。"
  },
  {
    "start": 2628794,
    "end": 2631122,
    "text": "オーケー、では君は。"
  },
  {
    "start": 2631258,
    "end": 2635934,
    "text": "おそらく、ただ止まるまで走らせて、次に行こうという感じではないと思う。"
  },
  {
    "start": 2636554,
    "end": 2648734,
    "text": "初期のデータを解釈し、また、あなたの、よくわからないけど、Googleドキュメントをあなたの前に置いて、あなたが持っているさまざまなアイデアについて、しばらくタイプし続けることができるような、あなたを見るためのプロセスがあります。"
  },
  {
    "start": 2649074,
    "end": 2653890,
    "text": "ただ、すぐに良いモデルを作るということとの間には、何かボトルネックがある。"
  },
  {
    "start": 2653962,
    "end": 2654574,
    "text": "そうだろう？"
  },
  {
    "start": 2654874,
    "end": 2655226,
    "text": "そうだね。"
  },
  {
    "start": 2655250,
    "end": 2661610,
    "text": "より良い実験やより良いアイデアを生み出すために、最初の段階からどのような推論をしているのですか？"
  },
  {
    "start": 2661682,
    "end": 2668266,
    "text": "以前、私が伝えきれなかったことのひとつは、優れた研究の多くは、解決したい実際の問題から逆算していくことから生まれるということだ。"
  },
  {
    "start": 2668290,
    "end": 2676956,
    "text": "今日のモデルをより良いものにするためには、いくつかの壮大な問題があると思う。"
  },
  {
    "start": 2676980,
    "end": 2679660,
    "text": "では、どのように変更すればいいのでしょうか？"
  },
  {
    "start": 2679852,
    "end": 2687988,
    "text": "また、規模を拡大すると、いろいろなことにぶつかり、規模に応じた行動や問題を修正したくなる。"
  },
  {
    "start": 2688036,
    "end": 2691624,
    "text": "それは、次のインクリメントやこの種のもののための研究の多くに反映される。"
  },
  {
    "start": 2693044,
    "end": 2696268,
    "text": "つまり、具体的に言えば、この障壁はちょっとしたソフトウェア・エンジニアリングなのだ。"
  },
  {
    "start": 2696356,
    "end": 2704760,
    "text": "多くの人が同時に研究を行えるほど大規模で、ある種の能力を備えたコードベースを持つことは、しばしば複雑なものになる。"
  },
  {
    "start": 2704872,
    "end": 2707600,
    "text": "もしすべてを自分ひとりでやっているのなら、反復のペースはもっと速くなるだろう。"
  },
  {
    "start": 2707632,
    "end": 2712144,
    "text": "例えば、アレック・ラドフォードはOpenAIで先駆的な仕事をしたことで有名だと聞いている。"
  },
  {
    "start": 2712224,
    "end": 2718384,
    "text": "彼はほとんどJupyterノートブックで作業し、そのコードを書いて制作してくれる人がいる。"
  },
  {
    "start": 2718464,
    "end": 2726026,
    "text": "それが真実かどうかはわからないが、実際に他の人たちと一緒に行動することでそれが可能になる。"
  },
  {
    "start": 2726120,
    "end": 2728006,
    "text": "それが複雑さを大きくしている。"
  },
  {
    "start": 2728070,
    "end": 2736350,
    "text": "というのも、自然な理由ではなく、ソフトウェア・エンジニアなら誰でも知っているような理由です。"
  },
  {
    "start": 2736382,
    "end": 2742846,
    "text": "実験の実行や立ち上げは簡単だが、それによって引き起こされる時間的な遅れは避けられない。"
  },
  {
    "start": 2742870,
    "end": 2748910,
    "text": "なぜなら、ひとつのことに完全に集中することはできないからだ。"
  },
  {
    "start": 2748982,
    "end": 2751590,
    "text": "フィードバックサイクルが十分でないのかもしれない。"
  },
  {
    "start": 2751742,
    "end": 2756822,
    "text": "何がいけなかったのかを直感するのは、これが何なのかを突き止めるように、実は本当に難しいことなんだ。"
  },
  {
    "start": 2756918,
    "end": 2762894,
    "text": "多くの点で、トレントンのチームがよりよく理解しようとしている問題は、これらのモデルの内部で何が起こっているかということだ。"
  },
  {
    "start": 2763014,
    "end": 2768794,
    "text": "私たちは、ある物事がなぜ機能するのかについて推論し、理解し、頭で理解しているが、厳密な科学ではない。"
  },
  {
    "start": 2769294,
    "end": 2775718,
    "text": "だから、何かがなぜ起こったのか、実験によって何が明らかになるのか、それが真実なのかそうでないのか、常に推測しなければならない。"
  },
  {
    "start": 2775846,
    "end": 2778594,
    "text": "それが最も複雑な部分だろう。"
  },
  {
    "start": 2780214,
    "end": 2784272,
    "text": "パフォーマンスの仕事は比較的簡単だが、他の点では難しい。"
  },
  {
    "start": 2784288,
    "end": 2788524,
    "text": "レベルの低い、難しいエンジニアリングの仕事が多いんだ。"
  },
  {
    "start": 2789184,
    "end": 2802224,
    "text": "でも、特にクリス・オラが率いているインタープリタビリティ・チームでは、テストしたいアイデアが山ほどある。"
  },
  {
    "start": 2802264,
    "end": 2817324,
    "text": "エンジニアリングを引用符で囲んだのは、その多くが、非常に迅速に実験を繰り返し、結果を見て、それを解釈し、次のことを試して、それらを伝え、そして最優先でやるべきことを冷酷に優先順位付けする研究だからだ。"
  },
  {
    "start": 2818184,
    "end": 2819360,
    "text": "これは本当に重要なことだ。"
  },
  {
    "start": 2819432,
    "end": 2827640,
    "text": "冷酷なまでの優先順位付けは、多くの質の高い研究と、必ずしも成功しない研究を分けるものだと思う。"
  },
  {
    "start": 2827672,
    "end": 2836044,
    "text": "私たちは、基本的に最初の理論的な理解の多くが崩れてしまう、このおかしな分野にいる。"
  },
  {
    "start": 2836344,
    "end": 2841478,
    "text": "シンプルさへのバイアスを持ち、実際に何が問題なのかを冷酷に優先順位付けする必要がある。"
  },
  {
    "start": 2841656,
    "end": 2855014,
    "text": "最も効果的な人たちを分けることのひとつは、必ずしも自分が慣れ親しんだ解決策を使って解決することに執着しすぎず、むしろ問題を直接攻撃することだ。"
  },
  {
    "start": 2855674,
    "end": 2867154,
    "text": "例えば、特定の学問的背景を持った人が入ってきて、そのツールボックスを使って問題を解決しようとする。"
  },
  {
    "start": 2867234,
    "end": 2872224,
    "text": "彼らはそこで走り回っていて、強化学習や最適化理論からアイデアを得ているんだ。"
  },
  {
    "start": 2872264,
    "end": 2874024,
    "text": "また、システムに対する理解も深い。"
  },
  {
    "start": 2874064,
    "end": 2876840,
    "text": "そのため、彼らは問題を制約する種類の制約が何であるかを知っている。"
  },
  {
    "start": 2876912,
    "end": 2877912,
    "text": "彼らは優秀なエンジニアだ。"
  },
  {
    "start": 2877968,
    "end": 2879344,
    "text": "彼らは繰り返し、素早くアイデアを試すことができる。"
  },
  {
    "start": 2879384,
    "end": 2882152,
    "text": "私が見てきた中で最高の研究者たちだ。"
  },
  {
    "start": 2882288,
    "end": 2890764,
    "text": "彼らは皆、本当に、本当に、本当に、本当に、本当に、本当に速く実験を試みる能力を持っている。"
  },
  {
    "start": 2891064,
    "end": 2894168,
    "text": "つまり、機械学習の研究は非常に経験的なものなんだ。"
  },
  {
    "start": 2894256,
    "end": 2894880,
    "text": "そうだね。"
  },
  {
    "start": 2895032,
    "end": 2901344,
    "text": "これは正直なところ、私たちの解決策がそうでない場合よりも、より頭脳的なものになるかもしれないと思う理由のひとつである。"
  },
  {
    "start": 2901804,
    "end": 2913436,
    "text": "私たちはそれを認めたくなくても、コミュニティ全体が、可能性のあるAIアーキテクチャのランドスケープやその他のあらゆるものに対して、貪欲に進化的最適化を行なっているようなものなのだ。"
  },
  {
    "start": 2913620,
    "end": 2915116,
    "text": "進化と変わらない。"
  },
  {
    "start": 2915220,
    "end": 2917172,
    "text": "それは必ずしも進化論を軽視しているわけでもない。"
  },
  {
    "start": 2917228,
    "end": 2918492,
    "text": "それはとても面白いアイデアだ。"
  },
  {
    "start": 2918668,
    "end": 2928080,
    "text": "何がボトルネックになるのか、アジア人の何が研究を加速させるのでしょうか？"
  },
  {
    "start": 2928192,
    "end": 2941360,
    "text": "あなたが挙げたアレック・ラドフォードの例では、彼はすでにジュピター・ノートブックでの実験用にコパイロットに相当するものを持っているようですが、もしそれが十分にあれば、彼は劇的に速く研究者になれるということなのでしょうか？"
  },
  {
    "start": 2941392,
    "end": 2942792,
    "text": "だから、アレック・ラドフォードが必要なんだ。"
  },
  {
    "start": 2942888,
    "end": 2951360,
    "text": "人間を自動化するのではなく、優れたセンスを持つ最も効果的な研究者をより効果的にし、彼らのために実験を行うなどしているのだ。"
  },
  {
    "start": 2951392,
    "end": 2956440,
    "text": "あるいは、知能の爆発が起きている時点でまだ仕事をしているようなものだ。"
  },
  {
    "start": 2956512,
    "end": 2957120,
    "text": "私の言っている意味が分かる？"
  },
  {
    "start": 2957192,
    "end": 2957984,
    "text": "そういうことですか？"
  },
  {
    "start": 2958064,
    "end": 2958684,
    "text": "そうだね。"
  },
  {
    "start": 2960264,
    "end": 2961768,
    "text": "もしそれが、直接の事実ならね。"
  },
  {
    "start": 2961816,
    "end": 2965680,
    "text": "なぜ、現在の研究チームの規模をもっと拡大できないのか？"
  },
  {
    "start": 2965792,
    "end": 2967800,
    "text": "例えば、これは興味深い質問だと思う。"
  },
  {
    "start": 2967872,
    "end": 2979084,
    "text": "なぜ、この仕事がそんなに価値があるのなら、何百人、何千人というような、間違いなくそこにいるような人たちを集めて、組織をよりよくスケールさせることができないのだろうか？"
  },
  {
    "start": 2983204,
    "end": 3013968,
    "text": "ジェミニ・チームにとって、不完全な情報に基づいて困難な推論を行うことは、解釈可能性を高めるために、有能なエンジニアを雇い続けたいというのが本音であり、ただたくさん作り続けることは大きなボトルネックになると思うからだ。"
  },
  {
    "start": 3014056,
    "end": 3015200,
    "text": "明らかに人数が多い。"
  },
  {
    "start": 3015272,
    "end": 3017164,
    "text": "人数は多い方がいい。"
  },
  {
    "start": 3017784,
    "end": 3020736,
    "text": "考えてみると面白いと思うよ。"
  },
  {
    "start": 3020800,
    "end": 3027992,
    "text": "私がよく考えてきた最大の課題のひとつは、どうすればもっとうまくスケールアップできるかということだ。"
  },
  {
    "start": 3028048,
    "end": 3029520,
    "text": "グーグルは巨大な組織だ。"
  },
  {
    "start": 3029592,
    "end": 3032124,
    "text": "人口は20万人くらいだろう？"
  },
  {
    "start": 3032164,
    "end": 3034744,
    "text": "100人とか、8万人とか、そんな感じだ。"
  },
  {
    "start": 3035404,
    "end": 3043424,
    "text": "ジェミニの研究プログラムを、素晴らしい才能を持つソフトウェア・エンジニアたち全員にスケールアウトさせる方法があればと想像してしまう。"
  },
  {
    "start": 3043764,
    "end": 3049124,
    "text": "これは、あなたが利用したい、利用できるようにしたい重要な利点のように思える。"
  },
  {
    "start": 3049164,
    "end": 3050892,
    "text": "どうすれば効果的か？"
  },
  {
    "start": 3050908,
    "end": 3052984,
    "text": "非常に複雑な組織の問題だ。"
  },
  {
    "start": 3053644,
    "end": 3056812,
    "text": "計算し、味わう。"
  },
  {
    "start": 3056988,
    "end": 3062492,
    "text": "そう考えると興味深い。少なくとも、より多くの知性に対して計算部分がボトルネックになることはないのだから。"
  },
  {
    "start": 3062588,
    "end": 3065188,
    "text": "ただ、サム7兆ドルとかでボトルネックになった。"
  },
  {
    "start": 3065236,
    "end": 3065732,
    "text": "そうだね。"
  },
  {
    "start": 3065868,
    "end": 3071796,
    "text": "もし私があなたに10倍の作業時間を与え、実験をさせたとしたら、研究者はどれだけ効率的になるでしょうか？"
  },
  {
    "start": 3071820,
    "end": 3072384,
    "text": "頼むよ。"
  },
  {
    "start": 3074524,
    "end": 3076584,
    "text": "あなたはどれだけ有能な研究者ですか？"
  },
  {
    "start": 3077124,
    "end": 3086520,
    "text": "ジェミニのプログラムは、おそらく10倍の計算能力で5倍速くなるとか、そんな感じだと思う。"
  },
  {
    "start": 3086592,
    "end": 3089280,
    "text": "0.5というのは、かなりいい弾力性だ。"
  },
  {
    "start": 3089392,
    "end": 3089712,
    "text": "そうだね。"
  },
  {
    "start": 3089768,
    "end": 3090712,
    "text": "待って、正気じゃない。"
  },
  {
    "start": 3090848,
    "end": 3094224,
    "text": "そうだね、もっと計算量を増やせば、そのまま進歩につながると思う。"
  },
  {
    "start": 3094344,
    "end": 3096084,
    "text": "少しはあるだろう。"
  },
  {
    "start": 3096704,
    "end": 3101784,
    "text": "計算量はある程度決まっていて、その一部が推論に使われる。"
  },
  {
    "start": 3101824,
    "end": 3105224,
    "text": "また、GCPのクライアントも同様だ。"
  },
  {
    "start": 3105304,
    "end": 3105800,
    "text": "そうだね。"
  },
  {
    "start": 3105912,
    "end": 3107804,
    "text": "そのうちのいくつかは、そうだろう？"
  },
  {
    "start": 3108464,
    "end": 3115268,
    "text": "その一部はトレーニングに使われ、その一部はフルモデルの実験に使われる。"
  },
  {
    "start": 3115316,
    "end": 3116068,
    "text": "そう、その通りだ。"
  },
  {
    "start": 3116156,
    "end": 3124304,
    "text": "ボトルネックが研究であり、研究が計算機によってボトルネックになっているのであれば、実験に回される割合はもっと高くなるはずだ。"
  },
  {
    "start": 3124604,
    "end": 3140804,
    "text": "だから、すべての事前トレーニングチームが下すべき戦略的決断のひとつは、さまざまなトレーニングの実行に、研究プログラムに、どれだけの計算量を割り当てるか、それとも、最後にたどり着いた最善のものをスケーリングするか、というようなことだ。"
  },
  {
    "start": 3141944,
    "end": 3148912,
    "text": "彼らは皆、ここでかなり最適なポイントに到達しようとしているのだと思う。"
  },
  {
    "start": 3149008,
    "end": 3154484,
    "text": "ビッグモデルのトレーニングを続けなければならない理由のひとつは、そこで他では得られない情報を得ることができるからだ。"
  },
  {
    "start": 3155144,
    "end": 3160000,
    "text": "スケールには、あなたがよりよく理解したいと思うような、これらすべての創発的特性がある。"
  },
  {
    "start": 3160072,
    "end": 3168448,
    "text": "もしあなたが常にリサーチをしていて、私が前に言った「何がカーブから外れるようなことになるのかわからない」という言葉を覚えていないのなら、そうだろう？"
  },
  {
    "start": 3168496,
    "end": 3169104,
    "text": "そうだね。"
  },
  {
    "start": 3169264,
    "end": 3181024,
    "text": "このような体制で研究を続け、計算効率をどんどん高めていけば、最終的にスケールアップする道から外れてしまうかもしれない。"
  },
  {
    "start": 3181064,
    "end": 3188152,
    "text": "あなたは常に、自分が期待する仕事のフロンティアで、大きな仕事をするために投資する必要がある。"
  },
  {
    "start": 3188248,
    "end": 3193640,
    "text": "では、AIがAI研究を大幅に加速させた世界とはどのようなものなのか教えてほしい。"
  },
  {
    "start": 3193792,
    "end": 3200608,
    "text": "というのも、これを読む限りでは、AIが一からコードを書いて、それがより速いアウトプットにつながっているようには思えないからだ。"
  },
  {
    "start": 3200656,
    "end": 3203920,
    "text": "トップクラスの研究者を何らかの形で補強しているようだ。"
  },
  {
    "start": 3204112,
    "end": 3204416,
    "text": "そうだね。"
  },
  {
    "start": 3204440,
    "end": 3206264,
    "text": "具体的に教えてほしいのだが、彼らは実験をしているのだろうか？"
  },
  {
    "start": 3206304,
    "end": 3207472,
    "text": "彼らがアイデアを出しているのか？"
  },
  {
    "start": 3207528,
    "end": 3210248,
    "text": "実験の結果を評価しているだけなのか？"
  },
  {
    "start": 3210296,
    "end": 3210880,
    "text": "何が起きているんだ？"
  },
  {
    "start": 3210952,
    "end": 3213928,
    "text": "ここで考えなければならないのは、2つの世界だと思う。"
  },
  {
    "start": 3213976,
    "end": 3218816,
    "text": "ひとつは、AIがアルゴリズムによる進歩のスピードを大幅に速めたことだ。"
  },
  {
    "start": 3218960,
    "end": 3227266,
    "text": "ひとつは、AIの出力そのものが、モデル能力の進歩に向けた重要な要素のようなものだ。"
  },
  {
    "start": 3227370,
    "end": 3231294,
    "text": "具体的に言うと、つまり、合成データ、合成データみたいなものがあるよね？"
  },
  {
    "start": 3232394,
    "end": 3239854,
    "text": "アルゴリズミックな進歩を有意義に加速させる最初の世界では、より多くの計算能力が必要だと思います。"
  },
  {
    "start": 3241554,
    "end": 3251064,
    "text": "おそらく、AIがある時点で、自分よりも、他の人よりも、スピードアップして文脈に乗ることが容易になるような弾力性のあるポイントに到達するのだろう。"
  },
  {
    "start": 3251804,
    "end": 3259984,
    "text": "AIは素晴らしい副操縦士のようなもので、基本的に何倍も速くコーディングできるように助けてくれるからだ。"
  },
  {
    "start": 3260364,
    "end": 3265492,
    "text": "というのは、実に合理的で、超長文脈、超スマートなモデルのように思える。"
  },
  {
    "start": 3265668,
    "end": 3271844,
    "text": "即座にオンボードされ、サブタスクやサブゴールを完了させるために彼らを送り出すことができる。"
  },
  {
    "start": 3271924,
    "end": 3273508,
    "text": "というのは、実のところ、とてももっともな気がする。"
  },
  {
    "start": 3273556,
    "end": 3278584,
    "text": "しかし、そのようなことについては大きな証拠がないため、わからない。"
  },
  {
    "start": 3279284,
    "end": 3293980,
    "text": "一番いいのは、前にも言ったようにスイートベンチだ。しかし、このベンチで誰かが言っていたのだが、人間がプルリクエストを行おうとするときに、何か入力して実行し、うまくいくかどうかを見て、うまくいかなければ書き直すという問題がある。"
  },
  {
    "start": 3294092,
    "end": 3301676,
    "text": "このようなことは、LLMに与えられた機会には含まれていなかった。"
  },
  {
    "start": 3301700,
    "end": 3305162,
    "text": "もしそれが実行され、過去よりもすべてのボックスにチェックが入るなら。"
  },
  {
    "start": 3305218,
    "end": 3305410,
    "text": "そうだね。"
  },
  {
    "start": 3305442,
    "end": 3307658,
    "text": "そういう意味では不公平なテストだったかもしれない。"
  },
  {
    "start": 3307746,
    "end": 3323786,
    "text": "もしそれを使うことができれば、多くのトレーニングデータに欠けている重要なもの、つまり推論の痕跡を持つための効果的なトレーニングソースになると想像できるだろう？"
  },
  {
    "start": 3323850,
    "end": 3336278,
    "text": "特定の分野や仕事、家族などを自動化したい場合、あるいは自動化のリスクを理解したい場合だ。"
  },
  {
    "start": 3336446,
    "end": 3342150,
    "text": "それなら、推理の痕跡を残すことは、私にとって本当に重要なことのように思える。"
  },
  {
    "start": 3342342,
    "end": 3343494,
    "text": "多くの脅威がある。"
  },
  {
    "start": 3343574,
    "end": 3344022,
    "text": "そうだね。"
  },
  {
    "start": 3344118,
    "end": 3346438,
    "text": "フォローしたいことがたくさんあるんだ。"
  },
  {
    "start": 3346566,
    "end": 3358330,
    "text": "まずは、データ対、えーと、えーと、AIから出力されるデータが知能の爆発を引き起こしているのか、というようなコンピュートの話から始めましょう。"
  },
  {
    "start": 3358422,
    "end": 3359094,
    "text": "そうだね。"
  },
  {
    "start": 3360314,
    "end": 3364018,
    "text": "人々は、これらのモデルがいかに自分たちのデータを反映したものであるかを語る。"
  },
  {
    "start": 3364106,
    "end": 3376734,
    "text": "そうそう、名前は忘れちゃったんだけど、オープンAIのエンジニアのブログがあったんだけど、そこで彼が話していたのは、結局のところ、こういうモデルがどんどん良くなっていくにつれて、本当に効果的になっていくということなんだ。"
  },
  {
    "start": 3377034,
    "end": 3379082,
    "text": "データセットの地図のように。"
  },
  {
    "start": 3379138,
    "end": 3379402,
    "text": "そうだね。"
  },
  {
    "start": 3379458,
    "end": 3383170,
    "text": "だから、結局のところ、アーキテクチャーについて考えるのはやめようということなんだ。"
  },
  {
    "start": 3383322,
    "end": 3384890,
    "text": "最も効果的な建築のようなものだ。"
  },
  {
    "start": 3384922,
    "end": 3387882,
    "text": "データをマッピングする素晴らしい仕事をするようにね。"
  },
  {
    "start": 3388058,
    "end": 3394554,
    "text": "ということは、将来のAIの進歩は、AIが本当に素晴らしいデータを作ることによってもたらされるということですよね？"
  },
  {
    "start": 3394594,
    "end": 3396026,
    "text": "あなたがマッピングしているようにね。"
  },
  {
    "start": 3396050,
    "end": 3397934,
    "text": "それは明らかに非常に重要な部分だと思う。"
  },
  {
    "start": 3399234,
    "end": 3400814,
    "text": "ああ、実に興味深いね。"
  },
  {
    "start": 3401994,
    "end": 3410514,
    "text": "それは、よくわからないが、思考の連鎖のようなものに見えるのか、あるいは、これらのモデルがより良くなり、より賢くなるにつれて、どのようなことを想像するのだろうか？"
  },
  {
    "start": 3410554,
    "end": 3411746,
    "text": "合成データはどのようなものですか？"
  },
  {
    "start": 3411770,
    "end": 3417900,
    "text": "本当に良いデータというものを考えたとき、私には、それは、多くの推論を経て作られたものだと読み取れる。"
  },
  {
    "start": 3417972,
    "end": 3429424,
    "text": "人間のテキスト出力を効果的に、完璧にモデル化することによって、超知能を達成しようとするイリヤの視点と似ているよね。"
  },
  {
    "start": 3430484,
    "end": 3438484,
    "text": "近い将来であっても、アーカイブ論文やウィキペディアのようなものをモデル化するためには、信じられないほどの推論が必要だ。"
  },
  {
    "start": 3438524,
    "end": 3443434,
    "text": "次にどんなトークンが出力されるかを理解するためだ。"
  },
  {
    "start": 3444254,
    "end": 3454830,
    "text": "だから、僕にとって良いデータとは、少なくとも何かを生み出すために推論する必要があったデータだと思う。"
  },
  {
    "start": 3454902,
    "end": 3458834,
    "text": "では、その推論が正しいかどうかをどうやって検証するのか？"
  },
  {
    "start": 3459254,
    "end": 3479964,
    "text": "というのも、幾何学は形式化しやすく、検証しやすい分野なので、推論が正しいかどうかをチェックすることができ、正しいトリックや検証された幾何学の証明のデータを大量に生成することができるからです。"
  },
  {
    "start": 3480044,
    "end": 3480828,
    "text": "それをトレーニングする。"
  },
  {
    "start": 3480916,
    "end": 3482380,
    "text": "それが良いデータだということは分かっているはずだ。"
  },
  {
    "start": 3482532,
    "end": 3493104,
    "text": "去年、グラント・サンダーソンとこのことについて議論したことがあるんだけど、そのとき僕はこう言ったんだ。『マソリティアの金塊を手に入れるまでに、すべての仕事が自動化されるに決まってるじゃないか』とね。"
  },
  {
    "start": 3494344,
    "end": 3495124,
    "text": "ありがとう。"
  },
  {
    "start": 3497224,
    "end": 3498964,
    "text": "合成データについて。"
  },
  {
    "start": 3499624,
    "end": 3512728,
    "text": "私のスケーリング・ポストで私が推測したことのひとつは、あなたや、特にshotoさんとの議論から得た情報に基づいている。"
  },
  {
    "start": 3512776,
    "end": 3521120,
    "text": "私たちは言語を取得し、私たちのコピーが私たちがトレーニングする合成データを生成するようなものです。"
  },
  {
    "start": 3521152,
    "end": 3527196,
    "text": "それは本当に効果的な遺伝学のようなもので、文化的で、共同進化的なもので、そこには検証者もいるんだろう？"
  },
  {
    "start": 3527220,
    "end": 3528188,
    "text": "現実の世界があるようにね。"
  },
  {
    "start": 3528236,
    "end": 3533796,
    "text": "神々が嵐を引き起こしたという理論が生まれるかもしれないだろ？"
  },
  {
    "start": 3533860,
    "end": 3536284,
    "text": "しかし、誰かがそうでないケースを見つけたように。"
  },
  {
    "start": 3536324,
    "end": 3547944,
    "text": "そして今、その代わりに、多くの推論を必要とし、現実と正確に一致するような気象シミュレーションがある。"
  },
  {
    "start": 3548324,
    "end": 3552698,
    "text": "より良い世界のモデルとして、その上でトレーニングができるような。"
  },
  {
    "start": 3552866,
    "end": 3556410,
    "text": "私たちは、物語や科学的理論に基づいてトレーニングをしているんだ。"
  },
  {
    "start": 3556522,
    "end": 3558746,
    "text": "ああ、また行きたい。"
  },
  {
    "start": 3558770,
    "end": 3579344,
    "text": "少し前にあなたが言っていたことを思い出したんですが、MLがいかに経験的なものであるかを考えると、より良いパフォーマンスをもたらすのは進化の過程であって、必ずしも個人がトップダウンで画期的なことを思いつくわけではないんです。"
  },
  {
    "start": 3579804,
    "end": 3589660,
    "text": "第一に、本当に人がいるということ、そして、より多くの人々がこの分野に参入しているため、能力が向上していることを懸念している。"
  },
  {
    "start": 3589812,
    "end": 3596548,
    "text": "私はそのような考え方に懐疑的だったが、より多くのインプットが好きだというこの観点からすれば、本当にそうだ。"
  },
  {
    "start": 3596596,
    "end": 3598996,
    "text": "うん、むしろ、ああ、実はアバイドなんだ、という感じだね。"
  },
  {
    "start": 3599060,
    "end": 3604304,
    "text": "ICMLに行く人が増えるということは、GPT5に向けてより早く前進するということだ。"
  },
  {
    "start": 3604464,
    "end": 3604736,
    "text": "そうだね。"
  },
  {
    "start": 3604760,
    "end": 3606352,
    "text": "遺伝子の組み換えが増えるだけだ。"
  },
  {
    "start": 3606448,
    "end": 3606776,
    "text": "そうだね。"
  },
  {
    "start": 3606840,
    "end": 3608008,
    "text": "そして、シュート数も多い。"
  },
  {
    "start": 3608136,
    "end": 3608656,
    "text": "そうだね。"
  },
  {
    "start": 3608760,
    "end": 3611352,
    "text": "つまり、どの分野もそんな感じじゃない？"
  },
  {
    "start": 3611448,
    "end": 3616376,
    "text": "例えば、発見と発明のような科学的な枠組みがある。"
  },
  {
    "start": 3616480,
    "end": 3616768,
    "text": "そうだね。"
  },
  {
    "start": 3616816,
    "end": 3626044,
    "text": "過去に大きな科学的ブレークスルーがあった場合、通常、複数の人がほぼ同時期にそれを発見している。"
  },
  {
    "start": 3626704,
    "end": 3630558,
    "text": "少なくとも私には、アイデアを混ぜ合わせ、試しているように感じられる。"
  },
  {
    "start": 3630646,
    "end": 3636954,
    "text": "今あるツールでそれを検証する方法がないほど、範囲外のアイデアを試すことはできない。"
  },
  {
    "start": 3637334,
    "end": 3637718,
    "text": "そうだね。"
  },
  {
    "start": 3637766,
    "end": 3645030,
    "text": "この点では、物理学と数学は少し違うかもしれないが、特に生物学やあらゆる種類のウェットウェアには適していると思う。"
  },
  {
    "start": 3645062,
    "end": 3650462,
    "text": "ここでニューラルネットワークを例えるなら、多くの発見がいかにセレンディピティであるかは滑稽なほどだ。"
  },
  {
    "start": 3650478,
    "end": 3650870,
    "text": "そうだね。"
  },
  {
    "start": 3650982,
    "end": 3652606,
    "text": "例えばペニシリンのようにね。"
  },
  {
    "start": 3652790,
    "end": 3662922,
    "text": "このことのもう一つの意味は、AGIが明日にでもやってくる、誰かが新しいアルゴリズムを発見する、そうすればAGIが誕生する、という考え方はあまり信憑性がないように思える、ということだ。"
  },
  {
    "start": 3663018,
    "end": 3670330,
    "text": "より多くのML研究者が、モデルをより良いものにするために、このようなわずかなことを見つけていくことだろう。"
  },
  {
    "start": 3670402,
    "end": 3670826,
    "text": "そうだね。"
  },
  {
    "start": 3670930,
    "end": 3673082,
    "text": "ええ、私にはそれが正しい話のように感じられます。"
  },
  {
    "start": 3673098,
    "end": 3673654,
    "text": "そうだね。"
  },
  {
    "start": 3674354,
    "end": 3676914,
    "text": "ハードウェアの制約があるうちはなおさらだ。"
  },
  {
    "start": 3676994,
    "end": 3677614,
    "text": "そうだね。"
  },
  {
    "start": 3678274,
    "end": 3702614,
    "text": "GPT-3からGPT-4への知能爆発は、アルゴリズム的な進歩がなければ、2桁の大きさでなければならない。"
  },
  {
    "start": 3703034,
    "end": 3715154,
    "text": "GPT7までにAGIを手に入れなければ、世代が進むごとに2桁大きくならざるを得ないことを考えると、それが知能の爆発を加速させるのに役立つというフレーミングを信じますか？"
  },
  {
    "start": 3715574,
    "end": 3727414,
    "text": "その時点で、そのモデルを作るために経済のかなりの部分を消費しているだけだからだ。"
  },
  {
    "start": 3727454,
    "end": 3730470,
    "text": "GPDを8つにする力はない。"
  },
  {
    "start": 3730622,
    "end": 3739004,
    "text": "これはカール・シュルマンの主張で、短期的には桁違いのスピードで進むが、長期的には難しくなるというものだ。"
  },
  {
    "start": 3739544,
    "end": 3741084,
    "text": "彼はおそらくそのことを話したと思う。"
  },
  {
    "start": 3741504,
    "end": 3743364,
    "text": "その額装を買いますか？"
  },
  {
    "start": 3744224,
    "end": 3753320,
    "text": "ええ、つまり、私は一般的に、絶対的な用語で、能力の逓減的な収穫のようなものによって、コンピュートの桁が増加することを買います。"
  },
  {
    "start": 3753432,
    "end": 3757752,
    "text": "私たちは、2桁以上のモデルが何もできなかった状態から、膨大な量をこなせるようになるのを目の当たりにしてきた。"
  },
  {
    "start": 3757848,
    "end": 3764908,
    "text": "桁が上がるごとに、物事に対する信頼性が9段階上がって、エージェントのような存在が解き放たれるような気がする。"
  },
  {
    "start": 3765016,
    "end": 3769184,
    "text": "少なくとも今のところ、変貌を遂げているところは見たことがない。"
  },
  {
    "start": 3770364,
    "end": 3775692,
    "text": "いわばリニアに推理力が向上するのではなく、ややサブ・リニアに推理力が向上する感じだ。"
  },
  {
    "start": 3775788,
    "end": 3794640,
    "text": "というのも、GPT 3.5と比較してGPT 4でどのような新しいアプリケーションがアンロックされるかを見てみると、GPD 3.5が当惑や何かをすることができるようなものだとは思えないからだ。"
  },
  {
    "start": 3794752,
    "end": 3808648,
    "text": "もし、能力の向上が減少し、そのためのコストが指数関数的に高くなるのであれば、4.5で何ができるのか、あるいは5で何ができるのか、経済的なインパクトという点では弱気になってしまう。"
  },
  {
    "start": 3808736,
    "end": 3812064,
    "text": "とはいえ、私にとって3.5点と4点の間のジャンプはかなり大きい。"
  },
  {
    "start": 3812184,
    "end": 3813864,
    "text": "だから、たとえ僕が"
  },
  {
    "start": 3813904,
    "end": 3818716,
    "text": "あと3.5～4回ジャンプするのは馬鹿げているよね？"
  },
  {
    "start": 3818740,
    "end": 3819052,
    "text": "もしそうなら。"
  },
  {
    "start": 3819068,
    "end": 3826708,
    "text": "LSATの成績は特に顕著だった。"
  },
  {
    "start": 3826756,
    "end": 3827036,
    "text": "その通りだ。"
  },
  {
    "start": 3827060,
    "end": 3837476,
    "text": "とても頭がいい、みたいなところから、超頭がいい、みたいなところから、とても頭がいい、みたいなところから、次の世代ではまったくの天才、みたいなところまで瞬時になるんだ。"
  },
  {
    "start": 3837500,
    "end": 3843912,
    "text": "少なくとも私には、次の世代で全くの天才にジャンプできるような気がしてならない。"
  },
  {
    "start": 3843968,
    "end": 3849672,
    "text": "非常にスマートで、信頼性も高い。"
  },
  {
    "start": 3849728,
    "end": 3862680,
    "text": "合成データと言いながら、実際には重要な形で独自のソースコードを書いている。"
  },
  {
    "start": 3862792,
    "end": 3867248,
    "text": "拡散を使ってモデルの重みを考えることができるという興味深い論文があった。"
  },
  {
    "start": 3867416,
    "end": 3872074,
    "text": "それがどの程度合法的なのかとか、そういうことはわからないけど、そんな感じかな。"
  },
  {
    "start": 3872854,
    "end": 3875390,
    "text": "go fiは古き良き時代のAIだ。"
  },
  {
    "start": 3875542,
    "end": 3876382,
    "text": "その定義は？"
  },
  {
    "start": 3876398,
    "end": 3879994,
    "text": "というのも、この言葉を聞くと、記号論理のif else文を連想してしまうからだ。"
  },
  {
    "start": 3881054,
    "end": 3881794,
    "text": "もちろんだ。"
  },
  {
    "start": 3884214,
    "end": 3896126,
    "text": "というのも、「これは超弱気で、モデルはあまり良くならないだろう」という見方をしてほしくないからだ。"
  },
  {
    "start": 3896190,
    "end": 3910640,
    "text": "私が強調したいのは、これまで見てきたジャンプは非常に大きなものであり、たとえそれがより小さな規模で続いたとしても、今後2、3桁は非常にスマートで信頼性の高いエージェントが登場するということだ。"
  },
  {
    "start": 3910672,
    "end": 3914284,
    "text": "だから、狭い窓の件ではスレッドを完全に閉じなかった。"
  },
  {
    "start": 3915104,
    "end": 3930954,
    "text": "例えば、GPTの見通しを1億ドルとして、1億ドル、1億ドル、1億ドル、1億ドル、1億ドル、1億ドル、1億ドル、1億ドル、1億ドルと、民間企業の基準で考えると、どれも非常に妥当なものに思える。"
  },
  {
    "start": 3931574,
    "end": 3932622,
    "text": "である。"
  },
  {
    "start": 3932758,
    "end": 3933718,
    "text": "ドル建てでということか。"
  },
  {
    "start": 3933766,
    "end": 3935314,
    "text": "金額的にはそうだ。"
  },
  {
    "start": 3935734,
    "end": 3947118,
    "text": "しかし、個々の企業にとっては、もっと難しいことだ。"
  },
  {
    "start": 3947286,
    "end": 3949070,
    "text": "サムは7兆ドルを集めようとしている。"
  },
  {
    "start": 3949102,
    "end": 3949246,
    "text": "そうだね。"
  },
  {
    "start": 3949270,
    "end": 3954362,
    "text": "エバートンでのシフトよりも、はるかに大きなものをすでに準備しているようなものだ。"
  },
  {
    "start": 3954438,
    "end": 3957254,
    "text": "国家レベルを超えた奇妙な大きさがここにある。"
  },
  {
    "start": 3958794,
    "end": 3969826,
    "text": "ひとつは、より多くのジャンプ台があること、そしてそのジャンプ台が相対的に小さいとしても、それでも能力の向上はかなり著しいということだ。"
  },
  {
    "start": 3970010,
    "end": 3979010,
    "text": "それだけでなく、GPT4が1兆個前後という主張を信じるなら、人間の脳は30兆～300兆個のシナプスを持つことになる。"
  },
  {
    "start": 3979162,
    "end": 3981410,
    "text": "これは明らかに1対1のマッピングではない。"
  },
  {
    "start": 3981522,
    "end": 3988910,
    "text": "数字について議論することは可能だが、私たちがまだ脳の規模を下回っているというのは、かなり信憑性があるように思える。"
  },
  {
    "start": 3989102,
    "end": 3989854,
    "text": "だから、極めて重要なことだ。"
  },
  {
    "start": 3989894,
    "end": 4003954,
    "text": "つまり、アルゴリズムのオーバーヘッドが非常に高いということです。これは、もっと明確に触れるべきことかもしれませんが、たとえ1兆ドルとかかかるモデルを超える計算量を投じ続けることができなくても、です。"
  },
  {
    "start": 4004574,
    "end": 4011294,
    "text": "脳がデータ効率に優れているということは、もしそれが可能なら、我々には計算能力があるということだ。"
  },
  {
    "start": 4011374,
    "end": 4020942,
    "text": "もし、脳のアルゴリズムのように、人間が生まれたときから訓練するのと同じように、サンプル効率よく訓練することができれば、AGIを作ることができるだろう。"
  },
  {
    "start": 4020998,
    "end": 4028630,
    "text": "でも、サンプルの効率というのは、どう考えたらいいのかわからないんだ。"
  },
  {
    "start": 4028702,
    "end": 4031674,
    "text": "言語と脳構造の共進化。"
  },
  {
    "start": 4032854,
    "end": 4034438,
    "text": "とは言い難い。"
  },
  {
    "start": 4034486,
    "end": 4039234,
    "text": "また、モデルを大きくすればサンプル効率が上がるという結果もある。"
  },
  {
    "start": 4040184,
    "end": 4040568,
    "text": "そうだね。"
  },
  {
    "start": 4040616,
    "end": 4043144,
    "text": "オリジナルのスケーリングは紙だったんだろう？"
  },
  {
    "start": 4043224,
    "end": 4047644,
    "text": "ロジックモデルはほとんど空っぽだから、それも解決するだけかもしれない。"
  },
  {
    "start": 4048064,
    "end": 4053164,
    "text": "例えば、データ効率が良くなる必要はないが、モデルが大きくなれば、データ効率も良くなる。"
  },
  {
    "start": 4053464,
    "end": 4054724,
    "text": "どう考えるか。"
  },
  {
    "start": 4055064,
    "end": 4064044,
    "text": "大きなモデルで、まったく同じデータを見ることで、そのデータからより多くのことを学ぶことができる。"
  },
  {
    "start": 4064864,
    "end": 4068892,
    "text": "つまり、私のような、非常に素朴な考えでは、こう思うんだ。"
  },
  {
    "start": 4069028,
    "end": 4076988,
    "text": "だから、解釈の可能性が推し進めた重ね合わせ仮説のひとつは、あなたのモデルが劇的にパラメータ化されていないということなんだ。"
  },
  {
    "start": 4077156,
    "end": 4077388,
    "text": "そして"
  },
  {
    "start": 4077396,
    "end": 4080084,
    "text": "ディープラーニングが追求されるのは、一般的にはそういう物語ではない。"
  },
  {
    "start": 4080124,
    "end": 4080300,
    "text": "そうだね。"
  },
  {
    "start": 4080332,
    "end": 4092596,
    "text": "インターネット全体についてモデルを訓練し、驚異的な忠実度で予測させようとすると、パラメータ化が不十分な領域に入ってしまう。"
  },
  {
    "start": 4092700,
    "end": 4092930,
    "text": "だから"
  },
  {
    "start": 4092932,
    "end": 4096730,
    "text": "より大きなモデルを持つことで、よりクリーンな表現が可能になる。"
  },
  {
    "start": 4096802,
    "end": 4097414,
    "text": "そうだね。"
  },
  {
    "start": 4097794,
    "end": 4103538,
    "text": "観客のために、まず第一に、重ね合わせとは何か、なぜそれが重ね合わせの意味合いなのかを解き明かしてほしい。"
  },
  {
    "start": 4103626,
    "end": 4103898,
    "text": "もちろんだ。"
  },
  {
    "start": 4103946,
    "end": 4104130,
    "text": "そうだね。"
  },
  {
    "start": 4104162,
    "end": 4135054,
    "text": "基本的な結果は、これは私が人間科学に参加する前のことですが、論文のタイトルは『重ね合わせのおもちゃモデル』で、小さなモデルであっても、データが高次元でスパース（スパースというのは、任意のデータ点があまり頻繁に現れないという意味です）な領域にある場合、モデルは重ね合わせと呼ぶ圧縮戦略を学習し、パラメータよりも多くの世界の特徴を詰め込むことができるようになります。"
  },
  {
    "start": 4136274,
    "end": 4137962,
    "text": "この疎らさはまるで"
  },
  {
    "start": 4138058,
    "end": 4140890,
    "text": "どちらの制約も現実の世界には当てはまると思う。"
  },
  {
    "start": 4141002,
    "end": 4144098,
    "text": "インターネットのモデリングデータは、そのための十分な代用品である。"
  },
  {
    "start": 4144186,
    "end": 4146014,
    "text": "ドワーカシュは一人しかいない。"
  },
  {
    "start": 4146394,
    "end": 4147690,
    "text": "君が着ているシャツは1枚だけだ。"
  },
  {
    "start": 4147722,
    "end": 4149554,
    "text": "ここに死の液体缶がある。"
  },
  {
    "start": 4149674,
    "end": 4152370,
    "text": "つまり、これらはすべてオブジェクトまたはフィーチャーなのだ。"
  },
  {
    "start": 4152442,
    "end": 4154513,
    "text": "その特徴をどう定義するかは難しい。"
  },
  {
    "start": 4155933,
    "end": 4160873,
    "text": "その数は非常に多く、出現頻度も非常に低いので、本当に高次元の空間にいることになる。"
  },
  {
    "start": 4161453,
    "end": 4164313,
    "text": "その体制では、モデルは圧縮を学習する。"
  },
  {
    "start": 4164813,
    "end": 4169013,
    "text": "もう少し詳しく説明すると、だんだん明らかになってきたと思う。"
  },
  {
    "start": 4169053,
    "end": 4177373,
    "text": "私は、ネットワークの解釈が難しいのは、この重ね合わせが大きな原因だと考えている。"
  },
  {
    "start": 4177493,
    "end": 4186116,
    "text": "あるモデルを使って、その中のあるニューロン、つまり計算のある単位を見て、このニューロンが発火したとき、モデルの出力にどのように寄与しているのか？"
  },
  {
    "start": 4186260,
    "end": 4189868,
    "text": "そのデータを見ると、とても混乱する。"
  },
  {
    "start": 4189916,
    "end": 4200544,
    "text": "ありとあらゆる入力の10％とか、中国語のように、魚とか木とか、URLの右のフルストップという単語とか。"
  },
  {
    "start": 4201404,
    "end": 4218324,
    "text": "昨年、私たちが発表した単意味性に関する論文によると、アクティベーションを高次元空間に投影し、スパースペナルティを与えることで、データが元々高次元でスパースであると仮定したのと同じように、圧縮を元に戻すことができる。"
  },
  {
    "start": 4218364,
    "end": 4225664,
    "text": "高次元でスパースな体制に戻すと、非常にきれいなフィーチャーが得られ、物事が突然、より理にかなったものになり始める。"
  },
  {
    "start": 4226844,
    "end": 4230864,
    "text": "なるほど、興味深いスレッドがたくさんあるね。"
  },
  {
    "start": 4231284,
    "end": 4242468,
    "text": "最初にお聞きしたいのは、これらのモデルはパラメータ化されすぎている状態でトレーニングされているということです。"
  },
  {
    "start": 4242636,
    "end": 4247988,
    "text": "グロキングがその体制で起こるように、一般化することがあるのでは？"
  },
  {
    "start": 4248076,
    "end": 4248348,
    "text": "そうだろう？"
  },
  {
    "start": 4248396,
    "end": 4251224,
    "text": "それは違う。"
  },
  {
    "start": 4251844,
    "end": 4253828,
    "text": "私が言いたかったのは、モデルのパラメータ化が不十分だということだ。"
  },
  {
    "start": 4253876,
    "end": 4254388,
    "text": "なるほど、そういうことか。"
  },
  {
    "start": 4254396,
    "end": 4254732,
    "text": "そうだね。"
  },
  {
    "start": 4254828,
    "end": 4258184,
    "text": "一般的に、ディープラーニングについては、モデルがパラメータ化されすぎているかのように語られる。"
  },
  {
    "start": 4259004,
    "end": 4264070,
    "text": "実際、ここでの主張は、彼らが行おうとしているタスクの複雑さを考えると、パラメータが劇的に不足しているということだ。"
  },
  {
    "start": 4264212,
    "end": 4265906,
    "text": "あの、もうひとつ質問です。"
  },
  {
    "start": 4266050,
    "end": 4273242,
    "text": "まず第一に、蒸留モデルだ。"
  },
  {
    "start": 4273338,
    "end": 4274466,
    "text": "では、そこで何が起こっているのか？"
  },
  {
    "start": 4274490,
    "end": 4281898,
    "text": "というのも、私たちが以前に話していた主張は、小さなモデルは大きなモデルよりも学習能力が低いというものだった。"
  },
  {
    "start": 4282026,
    "end": 4288986,
    "text": "GPT4ターボのように、GPD4ターボはGPT4よりも理屈っぽいことが苦手だと主張することもできる。"
  },
  {
    "start": 4289130,
    "end": 4294174,
    "text": "うーん、でもたぶん同じ事実を知っていると思う。蒸留によって、理屈のようなものが取り除かれたとかね。"
  },
  {
    "start": 4295714,
    "end": 4298674,
    "text": "木星ターボが4の蒸留版であるという証拠はあるのか？"
  },
  {
    "start": 4298714,
    "end": 4299970,
    "text": "単に新しい建築かもしれない。"
  },
  {
    "start": 4300082,
    "end": 4300666,
    "text": "ああ、そうか。"
  },
  {
    "start": 4300730,
    "end": 4300994,
    "text": "そうだね。"
  },
  {
    "start": 4301034,
    "end": 4304674,
    "text": "より速く、より効率的な新アーキテクチャーのようなものかもしれない。"
  },
  {
    "start": 4304754,
    "end": 4305434,
    "text": "なるほど、興味深い。"
  },
  {
    "start": 4305474,
    "end": 4306090,
    "text": "その方が安い。"
  },
  {
    "start": 4306162,
    "end": 4311258,
    "text": "でも、蒸留で起こっていることをどう解釈するんだ？"
  },
  {
    "start": 4311386,
    "end": 4316218,
    "text": "なぜ蒸留モデルを直接トレーニングできないのか？"
  },
  {
    "start": 4316306,
    "end": 4317734,
    "text": "なぜ、それを通さなければならないのか？"
  },
  {
    "start": 4318214,
    "end": 4322194,
    "text": "写真というのは、この大きな空間から小さな空間に投影しなければならなかったのですか？"
  },
  {
    "start": 4324974,
    "end": 4333302,
    "text": "つまり、どちらのモデルも重ね合わせを使っていることに変わりはないと思うが、ここでの主張は、蒸留した場合とゼロからトレーニングした場合とでは、まったく異なるモデルが得られるということだ。"
  },
  {
    "start": 4333358,
    "end": 4333954,
    "text": "そうだね。"
  },
  {
    "start": 4334974,
    "end": 4339314,
    "text": "より効率的なのか、それとも根本的に性能が違うのか。"
  },
  {
    "start": 4341094,
    "end": 4341870,
    "text": "覚えていないんだ。"
  },
  {
    "start": 4341942,
    "end": 4355068,
    "text": "なぜ蒸留がより効率的なのか、その伝統的なストーリーは、通常トレーニング中に、これが予測すべきトークンだというホットなベクトルを予測しようとすることだと思う。"
  },
  {
    "start": 4355156,
    "end": 4362428,
    "text": "もしあなたの推論が、その予測から大きく外れていたとしても、正しい方向への勾配更新を得ることができる。"
  },
  {
    "start": 4362476,
    "end": 4369544,
    "text": "今の状況でそれを予測することを学ぶのは、本当に難しいことかもしれない。"
  },
  {
    "start": 4370044,
    "end": 4376796,
    "text": "つまり、蒸留は1つのホットベクトルだけでなく、すべての確率の大きなモデルからの完全な読み出しを持っているということだ。"
  },
  {
    "start": 4376980,
    "end": 4380804,
    "text": "だから、予測すべきことについてのシグナルをより多く得ることができる。"
  },
  {
    "start": 4380924,
    "end": 4386540,
    "text": "そうじゃなくて、ある面では、自分も仕事をしているなら、ほんの少し見せるようなものなんだ。"
  },
  {
    "start": 4386612,
    "end": 4386860,
    "text": "そうだね。"
  },
  {
    "start": 4386892,
    "end": 4389212,
    "text": "これが答えだ、というだけではない。"
  },
  {
    "start": 4389268,
    "end": 4389556,
    "text": "なるほど。"
  },
  {
    "start": 4389580,
    "end": 4390276,
    "text": "ああ、まったくだ。"
  },
  {
    "start": 4390300,
    "end": 4390508,
    "text": "そうだね。"
  },
  {
    "start": 4390556,
    "end": 4391284,
    "text": "それはとても理にかなっている。"
  },
  {
    "start": 4391324,
    "end": 4396188,
    "text": "カンフーの達人を見るのと、マトリックスの中にいてプログラムをダウンロードするのとでは、まるで違う。"
  },
  {
    "start": 4396236,
    "end": 4397220,
    "text": "その通り、その通りだ。"
  },
  {
    "start": 4397292,
    "end": 4398104,
    "text": "そう、そうだ。"
  },
  {
    "start": 4398444,
    "end": 4400492,
    "text": "ただ、観客にそれを理解してもらうためにね。"
  },
  {
    "start": 4400628,
    "end": 4408940,
    "text": "蒸留されたモデルでトレーニングするとき、あなたは、そのモデルが予測したトークンと、あなたが予測したトークンのすべての確率を見ることになる。"
  },
  {
    "start": 4408972,
    "end": 4414552,
    "text": "そうすると、最後の言葉だけを見て更新するのではなく、すべての確率を通して更新するようになる。"
  },
  {
    "start": 4414728,
    "end": 4421084,
    "text": "さて、実は今あなたに質問しようと思っていたことがあるんだ。"
  },
  {
    "start": 4421384,
    "end": 4433384,
    "text": "思考の連鎖を適応型計算と考えることができると言ったのはあなただったと思う。"
  },
  {
    "start": 4433544,
    "end": 4441344,
    "text": "このアイデアは、モデルができるようにしたいことの1つで、質問が難しい場合、それについてより多くのサイクルを費やして考えることだ。"
  },
  {
    "start": 4442684,
    "end": 4445348,
    "text": "じゃあ、どうやるんだ？"
  },
  {
    "start": 4445396,
    "end": 4451396,
    "text": "まあ、1回のフォワードパスが意味する計算量は有限で、決められた量しかない。"
  },
  {
    "start": 4451540,
    "end": 4458756,
    "text": "複雑な推理タイプの問題や数学の問題があれば、長い時間をかけて考えることができるようにしたい。"
  },
  {
    "start": 4458900,
    "end": 4465596,
    "text": "そして、モデルが答えを考え抜くような思考の連鎖を行い、答えを考え抜くようなフォワードパスが行われると考えればいい。"
  },
  {
    "start": 4465620,
    "end": 4468754,
    "text": "問題を解決するために、より多くの計算能力を投入できるようなものだ。"
  },
  {
    "start": 4469814,
    "end": 4484006,
    "text": "さて、シグナルの話に戻ると、思考が連鎖しているときは、あなたが話していたように、残差ストリームがすでにモデルで起こっているすべてのことを圧縮して表現している、そのトークンの情報しか送信することができない。"
  },
  {
    "start": 4484110,
    "end": 4493516,
    "text": "その場合、残差ストリームを1つのトークンに変換することになるが、これは5万個の対数のようなもので、ボキャブラリー・サイズのビットの対数のようなもので、とても小さい。"
  },
  {
    "start": 4493630,
    "end": 4495440,
    "text": "ええと。"
  },
  {
    "start": 4495592,
    "end": 4498936,
    "text": "トークン1つだけを送信しているわけではないと思う。"
  },
  {
    "start": 4499000,
    "end": 4499320,
    "text": "そうだね。"
  },
  {
    "start": 4499392,
    "end": 4499872,
    "text": "うーん。"
  },
  {
    "start": 4499968,
    "end": 4510296,
    "text": "例えば、フォワード・パスでKV値を作り、トランスフォーマーのフォワード・パスでそのKV値に将来のステップを合わせる。"
  },
  {
    "start": 4510400,
    "end": 4516924,
    "text": "つまり、キーやバリューのようなKVの断片はすべて、将来使う可能性のある情報の断片なのだ。"
  },
  {
    "start": 4517304,
    "end": 4524824,
    "text": "思考の連鎖を微調整することで、鍵が見えてくるという主張だ。"
  },
  {
    "start": 4524904,
    "end": 4530648,
    "text": "キーと値の重みが変化することで、kvキャッシュでステガノグラフィーを行うことができる。"
  },
  {
    "start": 4530696,
    "end": 4533408,
    "text": "ただ、そこまで強く主張することはできないと思う。"
  },
  {
    "start": 4533456,
    "end": 4534200,
    "text": "それはもっともらしい。"
  },
  {
    "start": 4534272,
    "end": 4537192,
    "text": "それは、なぜそれが機能するのかを説明する良い頭脳カノンであるようなものだ。"
  },
  {
    "start": 4537368,
    "end": 4565274,
    "text": "そのようなことを明確に示している論文があるかどうかはわかりませんが、少なくとも、事前トレーニングの間にモデルが将来のトークンを予測しようとしていることは想像できますし、将来の情報を予測するために使用する可能性のあるキーや値に潜在的な将来の情報を詰め込む学習をしていることも想像できます。"
  },
  {
    "start": 4566094,
    "end": 4568270,
    "text": "それは、時間を超えてその情報を滑らかにする。"
  },
  {
    "start": 4568302,
    "end": 4574124,
    "text": "プレトレーニングのことだが、人々が特に連鎖思考のトレーニングをしているかどうかは分からない。"
  },
  {
    "start": 4574164,
    "end": 4581864,
    "text": "最初の一連の論文では、このようなことをするように促すことができ、それでもかなりうまくいった。"
  },
  {
    "start": 4583204,
    "end": 4584076,
    "text": "という感じだ。"
  },
  {
    "start": 4584100,
    "end": 4584260,
    "text": "そうだね。"
  },
  {
    "start": 4584292,
    "end": 4586044,
    "text": "なぜそうなるのか、その理由を知るにはいい頭脳戦だ。"
  },
  {
    "start": 4586084,
    "end": 4586380,
    "text": "そうだね。"
  },
  {
    "start": 4586452,
    "end": 4599506,
    "text": "過度に突っ込むようだが、思考の連鎖の中で実際に目にするトークンは、必ずしもモデルが出欠を決定する際に目にするベクトル表現と一致する必要はまったくない。"
  },
  {
    "start": 4599700,
    "end": 4600366,
    "text": "その通りだ。"
  },
  {
    "start": 4600470,
    "end": 4610910,
    "text": "実際、トレーニング中は、トレーニング・ステップと同じように、モデルが出力したトークンを実際の次のトークンに置き換えます。"
  },
  {
    "start": 4611102,
    "end": 4616154,
    "text": "それでも、内部的にすべての情報を持っているので、学んでいるようなものだ。"
  },
  {
    "start": 4618174,
    "end": 4621254,
    "text": "推論時にモデルを生成させるときのようにね。"
  },
  {
    "start": 4621334,
    "end": 4627934,
    "text": "出力されたトークンを取り出し、埋め込みを解除して下に送り込むと、それが新しい残余文字列の始まりになる。"
  },
  {
    "start": 4628874,
    "end": 4641754,
    "text": "そしてpasskvsの出力を使って、トレーニング時にその残余文字列を読み込んで適応させる。"
  },
  {
    "start": 4641794,
    "end": 4642946,
    "text": "それがパラレルでやる方法だ。"
  },
  {
    "start": 4643050,
    "end": 4647094,
    "text": "すべてのトークンを持っているのだから、それらをすべて並列に入れて、ジャイアント・フォワード・パスをする。"
  },
  {
    "start": 4647514,
    "end": 4650518,
    "text": "そのため、パスに関する情報はキーと値だけだ。"
  },
  {
    "start": 4650586,
    "end": 4652634,
    "text": "出力したトークンを見ることはない。"
  },
  {
    "start": 4653294,
    "end": 4656286,
    "text": "次のトークン予測をしようとしているようなものだ。"
  },
  {
    "start": 4656390,
    "end": 4659702,
    "text": "もし失敗したら、正しい答えを与えればいい。"
  },
  {
    "start": 4659758,
    "end": 4660022,
    "text": "そうだね。"
  },
  {
    "start": 4660078,
    "end": 4660470,
    "text": "そうだね。"
  },
  {
    "start": 4660502,
    "end": 4660646,
    "text": "そうだね。"
  },
  {
    "start": 4660670,
    "end": 4661102,
    "text": "オーケー。"
  },
  {
    "start": 4661198,
    "end": 4663710,
    "text": "そうしないと、完全に脱線してしまうからだ。"
  },
  {
    "start": 4663742,
    "end": 4665474,
    "text": "ああ、線路の外に出るようなものだ。"
  },
  {
    "start": 4668374,
    "end": 4675718,
    "text": "その前方推論に、モデルとの秘密のコミュニケーションのようなものがどれだけあるか。"
  },
  {
    "start": 4675806,
    "end": 4680094,
    "text": "ステガノグラフィーや秘密通信はどの程度あると予想していますか？"
  },
  {
    "start": 4681354,
    "end": 4682334,
    "text": "わからない。"
  },
  {
    "start": 4682714,
    "end": 4683546,
    "text": "正直な答えだ。"
  },
  {
    "start": 4683570,
    "end": 4689490,
    "text": "私たちは知らないが、必ずしも秘密情報に分類されるものでもないだろう。"
  },
  {
    "start": 4689642,
    "end": 4707246,
    "text": "トレンドチームがやろうとしている仕事の多くは、モデルサイドからこれらが完全に見えていることを実際に理解することであり、それを利用することではないかもしれないが、これらの値が何をしているのか、そしてそれらが伝達しているような情報を理解し解釈できるようにすることだ。"
  },
  {
    "start": 4707270,
    "end": 4709982,
    "text": "それは将来に向けて本当に重要な目標だと思う。"
  },
  {
    "start": 4710118,
    "end": 4719894,
    "text": "そう、つまり、荒唐無稽な論文もあるんだけどね。"
  },
  {
    "start": 4720014,
    "end": 4721474,
    "text": "中に入って編集することができる。"
  },
  {
    "start": 4722054,
    "end": 4722598,
    "text": "いや、違う。"
  },
  {
    "start": 4722646,
    "end": 4735706,
    "text": "この場合、思考の連鎖を編集して、推論が完全に文字化けしていても、真の答えを出力するようにすることもできる。"
  },
  {
    "start": 4735730,
    "end": 4739854,
    "text": "何か有益なことが起きているような、でもその有益なことは人間には理解できない。"
  },
  {
    "start": 4740634,
    "end": 4744714,
    "text": "思考の連鎖を断ち切っても、同じ答えが返ってくる場合もあると思う。"
  },
  {
    "start": 4744794,
    "end": 4745574,
    "text": "興味深い。"
  },
  {
    "start": 4746874,
    "end": 4747306,
    "text": "そうだね。"
  },
  {
    "start": 4747370,
    "end": 4752334,
    "text": "いつもこうだとは言わないが、調査すべき奇妙なことはたくさんある。"
  },
  {
    "start": 4752754,
    "end": 4757676,
    "text": "行って見て、理解しようとするのはとても興味深いことだ。"
  },
  {
    "start": 4757820,
    "end": 4760044,
    "text": "オープンソースのモデルでできることだ。"
  },
  {
    "start": 4760084,
    "end": 4760996,
    "text": "私はそう思う。"
  },
  {
    "start": 4761100,
    "end": 4765380,
    "text": "このような解釈のしやすさ、理解しやすさといった作業がオープンモデルでもっと行われればいいのにと思う。"
  },
  {
    "start": 4765492,
    "end": 4765804,
    "text": "そうだね。"
  },
  {
    "start": 4765844,
    "end": 4777076,
    "text": "つまり、私たちの人類学の最近の論文でも、スリーパーエージェント（潜伏工作員）、つまり、よく知らない人のために簡単に説明すると、私は基本的に引き金となる言葉を訓練しているのだ。"
  },
  {
    "start": 4777220,
    "end": 4783574,
    "text": "もし2024年だったらと言うと、モデルはそうでない代わりに悪意のあるコードを書く。"
  },
  {
    "start": 4783914,
    "end": 4790014,
    "text": "連鎖思考を使うものもあれば、使わないものもある。"
  },
  {
    "start": 4790394,
    "end": 4792706,
    "text": "これらのモデルは異なる反応を示す。"
  },
  {
    "start": 4792810,
    "end": 4796394,
    "text": "トリガーを外そうとすると、彼らがこうするのが見える。"
  },
  {
    "start": 4796474,
    "end": 4807294,
    "text": "滑稽な推論だが、かなり不気味でもある。あるケースでは、期待値まで計算しようとするのだ。"
  },
  {
    "start": 4807954,
    "end": 4815498,
    "text": "と言い続ける能力を掛け合わせれば、これだけの報酬が得られるはずだ。"
  },
  {
    "start": 4815546,
    "end": 4823014,
    "text": "そして、悪意があることを実際に尋問者に伝えるかどうかを決定する。"
  },
  {
    "start": 4824754,
    "end": 4842232,
    "text": "友人であるマイルズ・ターピンが書いた別の論文でも、多肢選択問題で正解が常にaであるような例をたくさん与えて、モデルに、この新しい問題に対する正解は何ですか？"
  },
  {
    "start": 4842408,
    "end": 4848840,
    "text": "は、すべての例がaであるという事実から、正解はaであると推測する。"
  },
  {
    "start": 4849032,
    "end": 4851672,
    "text": "その思考の連鎖は完全に誤解を招く。"
  },
  {
    "start": 4851808,
    "end": 4862646,
    "text": "もっともらしく聞こえるような、あるいはできるだけもっともらしく聞こえるような、適当なことをでっち上げる。"
  },
  {
    "start": 4862760,
    "end": 4864258,
    "text": "人間も同じように考えるのではないだろうか？"
  },
  {
    "start": 4864306,
    "end": 4876626,
    "text": "有名なスプリットブレインの実験では、発作に苦しんでいる人が、それを解決するひとつの方法として、2つの脳をつなげているものを切断したんだ。"
  },
  {
    "start": 4876690,
    "end": 4877346,
    "text": "コーパス・ブレイン"
  },
  {
    "start": 4877450,
    "end": 4877762,
    "text": "そうだね。"
  },
  {
    "start": 4877818,
    "end": 4878818,
    "text": "である。"
  },
  {
    "start": 4878906,
    "end": 4883738,
    "text": "ああ、スピーチハーフは左側にあるから、動きを決める部分とはつながっていないんだ。"
  },
  {
    "start": 4883866,
    "end": 4890678,
    "text": "それで、もし相手側が何かをしようと決めたら、スピーチの部分は何かをでっち上げるだけで、相手はそれが正当な理由だと思うだろう。"
  },
  {
    "start": 4890726,
    "end": 4891054,
    "text": "まったくだ。"
  },
  {
    "start": 4891094,
    "end": 4891534,
    "text": "ああ、そうだ。"
  },
  {
    "start": 4891574,
    "end": 4897594,
    "text": "ただ、思考連鎖の推論を、AIの安全性を解決する素晴らしい方法だと称賛する人もいる。"
  },
  {
    "start": 4898254,
    "end": 4898886,
    "text": "ああ、なるほど。"
  },
  {
    "start": 4898950,
    "end": 4902194,
    "text": "というようなもので、実際、信用していいのかどうかわからない。"
  },
  {
    "start": 4903094,
    "end": 4909366,
    "text": "私たちが理解できないような方法で、モデルたちが自分たちに何を伝えようとしているのか。"
  },
  {
    "start": 4909510,
    "end": 4911514,
    "text": "それがAIエージェントによってどう変わるのか？"
  },
  {
    "start": 4912294,
    "end": 4920034,
    "text": "というのも、そうなると、以前のキャッシュを持つモデルそのものだけでなく、モデルの他のインスタンスもそうなってしまうからだ。"
  },
  {
    "start": 4920074,
    "end": 4924362,
    "text": "となると、どのようなチャンネルを与えるかによって大きく変わってくる。"
  },
  {
    "start": 4924458,
    "end": 4924690,
    "text": "そうだね。"
  },
  {
    "start": 4924722,
    "end": 4928778,
    "text": "例えば、コミュニケーションの手段としてテキストしか与えないのであれば、おそらく通訳をしなければならないだろう。"
  },
  {
    "start": 4928906,
    "end": 4934042,
    "text": "もしモデルたちが、テキストだけでなく、残留ストリームを共有することができたら、どれだけ効果的だと思う？"
  },
  {
    "start": 4934178,
    "end": 4937106,
    "text": "わからないが、もっともな話だ。"
  },
  {
    "start": 4937170,
    "end": 4947164,
    "text": "つまり、簡単に想像できるのは、ある写真がどのように見えるべきかを説明する場合、それをテキストで説明するのは難しいということだ。"
  },
  {
    "start": 4947704,
    "end": 4948520,
    "text": "そうしたいのだろう。"
  },
  {
    "start": 4948632,
    "end": 4950848,
    "text": "たぶん、他の表現の方がもっとも簡単だろう。"
  },
  {
    "start": 4950896,
    "end": 4951604,
    "text": "まったくだ。"
  },
  {
    "start": 4952144,
    "end": 4955912,
    "text": "だから、ダリが今どのように働いているのか見てみるといい。"
  },
  {
    "start": 4956008,
    "end": 4966744,
    "text": "そのようなプロンプトが表示され、それを使って遊んでみると、モデルが望んでいることや自分が望んでいることを正確に実行させることができないことがよくある。"
  },
  {
    "start": 4966864,
    "end": 4968644,
    "text": "それをすべて持っているのはダリだけだ。"
  },
  {
    "start": 4986694,
    "end": 4992350,
    "text": "想像できるだろうが、ある種の、より密度の高い表現を送信できるようになれば、そこで役に立つだろう。"
  },
  {
    "start": 4992502,
    "end": 4993790,
    "text": "それは2つのとてもシンプルなエージェントのようなものだ。"
  },
  {
    "start": 4993822,
    "end": 4994014,
    "text": "そうだろう？"
  },
  {
    "start": 4994054,
    "end": 4998574,
    "text": "つまり、中途半端でいいのは、辞書学習から学ぶ機能だと思う。"
  },
  {
    "start": 4998614,
    "end": 4998814,
    "text": "そうだね。"
  },
  {
    "start": 4998854,
    "end": 5005334,
    "text": "そうすれば、より多くの内部アクセスが得られるが、その多くはより人間的な解釈が可能になる。"
  },
  {
    "start": 5005414,
    "end": 5005702,
    "text": "そうだね。"
  },
  {
    "start": 5005758,
    "end": 5006494,
    "text": "だから、わかった。"
  },
  {
    "start": 5006614,
    "end": 5017438,
    "text": "観客にとっては、それぞれの次元が実際に何に対応しているのかがわかるような、より大きな空間に残留ストリームを投影し、また次のエージェントなどに戻すことになる。"
  },
  {
    "start": 5017566,
    "end": 5018102,
    "text": "オーケー。"
  },
  {
    "start": 5018198,
    "end": 5018622,
    "text": "なぜですか？"
  },
  {
    "start": 5018718,
    "end": 5027354,
    "text": "あなたの主張は、AIエージェントができるようになり、より信頼できるようになる、などというものだ。"
  },
  {
    "start": 5027934,
    "end": 5045134,
    "text": "そうなった場合、複数のモデルのコピーが互いに会話するようになるのでしょうか？それとも、単に適応的にコンピューターが解決し、会社全体が必要とするようなことをする必要があるときに、より大きな、より多くのコンピューターを動かすようになるのでしょうか？"
  },
  {
    "start": 5045254,
    "end": 5052030,
    "text": "私がこの質問をしたのは、エージェントが将来起こることについて考えるのが正しいのかどうか、疑問に思うことが2つあるからだ。"
  },
  {
    "start": 5052222,
    "end": 5060794,
    "text": "ひとつは、より長い文脈を持つことで、これらのモデルは人間にはできない情報を摂取し、考慮することができる。"
  },
  {
    "start": 5060834,
    "end": 5067346,
    "text": "だから、フロントエンドのコードを考えるエンジニアとバックエンドのコードを考えるエンジニアが一人ずつ必要なんだ。"
  },
  {
    "start": 5067450,
    "end": 5071614,
    "text": "このハイエキン的な専門化の問題は解消される。"
  },
  {
    "start": 5071954,
    "end": 5079690,
    "text": "第二に、これらのモデルは非常に一般的なもので、GPTの4つのタイプを使い分けているわけではない。"
  },
  {
    "start": 5079722,
    "end": 5081134,
    "text": "まったく同じモデルを使っている。"
  },
  {
    "start": 5081444,
    "end": 5088428,
    "text": "将来、AI企業は、AIエージェントの束をつなぎ合わせたものではなく、単なるモデルに過ぎなくなる。"
  },
  {
    "start": 5088596,
    "end": 5089664,
    "text": "いい質問だね。"
  },
  {
    "start": 5090164,
    "end": 5096132,
    "text": "特に近い将来は、エージェントが一緒になっているように見えると思う。"
  },
  {
    "start": 5096268,
    "end": 5105944,
    "text": "私がそう言うのは、人間として、信頼できる孤立した部品を持ちたいと思うからだ。"
  },
  {
    "start": 5108234,
    "end": 5109394,
    "text": "私たちもそうしたい。"
  },
  {
    "start": 5109434,
    "end": 5116754,
    "text": "私たちが理解し、改善できる方法で、それらのコンポーネントを改善し、指導できるようにする必要がある。"
  },
  {
    "start": 5116794,
    "end": 5120254,
    "text": "この巨大なブラックボックス企業は、すべてを投げ出しているようなものだ。"
  },
  {
    "start": 5120634,
    "end": 5123854,
    "text": "ひとつは、最初はうまくいかないということだ。"
  },
  {
    "start": 5125074,
    "end": 5128094,
    "text": "もちろん、後になってうまくいくことを想像することはできるが、最初はうまくいかない。"
  },
  {
    "start": 5128954,
    "end": 5131854,
    "text": "2つ目は、おそらくそういうやり方はしたくないということだ。"
  },
  {
    "start": 5132154,
    "end": 5134058,
    "text": "それぞれを小さくすることもできる。"
  },
  {
    "start": 5134186,
    "end": 5139930,
    "text": "各エージェントは、運用コストの安い小型のモデルにすることができるし、実際にタスクをこなすように微調整することもできる。"
  },
  {
    "start": 5140042,
    "end": 5144242,
    "text": "暗黒のような未来があるとはいえ、何度かアダプティブ・コンピューティングの話が持ち上がった。"
  },
  {
    "start": 5144378,
    "end": 5149974,
    "text": "小型モデルと大型モデルの区別がある程度なくなる未来がある。"
  },
  {
    "start": 5150354,
    "end": 5151234,
    "text": "長い文脈で。"
  },
  {
    "start": 5151274,
    "end": 5157634,
    "text": "正直なところ、微調整がなくなる可能性もある。"
  },
  {
    "start": 5157674,
    "end": 5162170,
    "text": "今日のランドスケープモデルでは、モデルのサイズにまったく異なる階層があり、さまざまなものを微調整したモデルがある。"
  },
  {
    "start": 5162362,
    "end": 5173854,
    "text": "将来的には、ダイナミックなコンピュート・バンドルと無限のコンテクストを持つことで、モデルをさまざまなものに特化させることができる。"
  },
  {
    "start": 5174014,
    "end": 5183550,
    "text": "ひとつ想像できるのは、AI企業か何かを持っていて、全体が利益を上げたかどうかのシグナルで終始訓練されているということだ。"
  },
  {
    "start": 5183742,
    "end": 5191466,
    "text": "もしそれが曖昧すぎるなら、建築会社で設計図を作っているのなら、クライアントは真ん中の設計図を気に入ってくれただろうか？"
  },
  {
    "start": 5191490,
    "end": 5196214,
    "text": "営業担当のエージェント、デザイン担当のエージェント、編集担当のエージェントなど、どんなエージェントでも想像がつくだろう。"
  },
  {
    "start": 5197914,
    "end": 5202122,
    "text": "そのような信号がエンド・ツー・エンドのシステムで機能するだろうか？"
  },
  {
    "start": 5202178,
    "end": 5210682,
    "text": "というのも、人間の会社で起こることのひとつは、経営陣がより大きなレベルで起こっていることを考慮し、その断片か何かに細かなシグナルを与えるということだ。"
  },
  {
    "start": 5210778,
    "end": 5214114,
    "text": "不味いポーターとかがリミットの中にあるとき。"
  },
  {
    "start": 5214154,
    "end": 5216386,
    "text": "そう、それが強化学習の夢なのだ。"
  },
  {
    "start": 5216530,
    "end": 5224564,
    "text": "必要なのは、この極めて疎な信号を提供することであり、十分な反復を経て、その信号から学習するための情報を作り出すことだ。"
  },
  {
    "start": 5225664,
    "end": 5228624,
    "text": "それが最初にうまくいくとは思っていない。"
  },
  {
    "start": 5228704,
    "end": 5242484,
    "text": "そのためには、これらのマシンを取り巻く人間たちに代わって、信じられないほどの注意と勤勉さが必要になると思う。マシンが正確に正しいことをし、あなたが望むことを正確に実行するようにし、あなたが望む方法で改善するように正しいシグナルを与える。"
  },
  {
    "start": 5243464,
    "end": 5248266,
    "text": "そう、モデルが何らかの報酬を生み出さない限り、RLの報酬でトレーニングすることはできない。"
  },
  {
    "start": 5248440,
    "end": 5250150,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 5250302,
    "end": 5257354,
    "text": "この疎らなRLの世界では、もしクライアントに気に入られなければ、報酬はまったく得られない。"
  },
  {
    "start": 5258054,
    "end": 5260374,
    "text": "将来的には、これらのモデルは報酬を得るのに十分なものになるだろう。"
  },
  {
    "start": 5260414,
    "end": 5261246,
    "text": "そういう時もある。"
  },
  {
    "start": 5261390,
    "end": 5264474,
    "text": "これがシャルタの言っていた信頼性のナインだ。"
  },
  {
    "start": 5266014,
    "end": 5268942,
    "text": "ところで、さっきの話には面白い余談がある。"
  },
  {
    "start": 5268998,
    "end": 5275056,
    "text": "私たちは、有利になるような密度の濃い表現が欲しいという話をしているんだ。"
  },
  {
    "start": 5275190,
    "end": 5276676,
    "text": "より効率的なコミュニケーション方法。"
  },
  {
    "start": 5276860,
    "end": 5292804,
    "text": "タレンタンが推薦していた『象徴種』という本には、言語は単に存在するものではなく、私たちの心とともに進化したものであるという、実に興味深い主張が書かれている。"
  },
  {
    "start": 5292884,
    "end": 5301544,
    "text": "特に、子供たちが学びやすく、子供たちの成長を助けるものに進化した。"
  },
  {
    "start": 5301894,
    "end": 5302662,
    "text": "そうだね。"
  },
  {
    "start": 5302838,
    "end": 5304754,
    "text": "それを解きほぐしてくれるような。"
  },
  {
    "start": 5306254,
    "end": 5311634,
    "text": "というのも、子供たちが学ぶことの多くは、言語を通して受け取るものだからだ。"
  },
  {
    "start": 5311974,
    "end": 5318518,
    "text": "適者生存の言語というのは、次の世代を育てる手助けをするものなんだ。"
  },
  {
    "start": 5318566,
    "end": 5320794,
    "text": "その方が賢いとか、優れているとか、そういうことだ。"
  },
  {
    "start": 5321214,
    "end": 5324278,
    "text": "より複雑な考えを表現するための概念を与えることができると思うのであれば。"
  },
  {
    "start": 5324366,
    "end": 5329442,
    "text": "そう、そう、それと、もっと衒学的な言い方をすれば、死なないということかな？"
  },
  {
    "start": 5329498,
    "end": 5330094,
    "text": "もちろんだ。"
  },
  {
    "start": 5331114,
    "end": 5333654,
    "text": "死なないために重要なことをエンコードできる。"
  },
  {
    "start": 5335434,
    "end": 5355854,
    "text": "私たちが言語というものを、偶発的で最適とは言えない方法でアイデアを表現するものだと考えているとき、実はllmsが成功した理由のひとつは、言語が何万年もの間、若い頭脳を発達させるための鋳型として進化してきたからなのかもしれない。"
  },
  {
    "start": 5355974,
    "end": 5356206,
    "text": "そうだね。"
  },
  {
    "start": 5356230,
    "end": 5358118,
    "text": "そのために進化したようなものだ。"
  },
  {
    "start": 5358206,
    "end": 5373934,
    "text": "確かに、コンピュータビジョンの研究者のようなマルチモーダルな研究者と、言語モデルの研究者と話すとき、他のモダリティの研究者は、これらの画像の正しい表現空間を正確に把握するために、膨大な量の思考をしなければならない。"
  },
  {
    "start": 5374094,
    "end": 5376366,
    "text": "そこから学ぶべき正しいシグナルとは何かというようなね。"
  },
  {
    "start": 5376430,
    "end": 5381030,
    "text": "ピクセルを直接モデリングするようなものなのか、それとも何らかのロスを条件としているのか。"
  },
  {
    "start": 5381182,
    "end": 5387718,
    "text": "何年も前の論文に、イメージネットモデルの内部表現をトレーニングすると、より良い予測ができるようになるというものがあった。"
  },
  {
    "start": 5387846,
    "end": 5389910,
    "text": "その後、それは明らかに制限されているようなものだ。"
  },
  {
    "start": 5389982,
    "end": 5396630,
    "text": "ピクセルのCNNでは、個々のピクセルなどを目立たないようにモデリングしていたんだ。"
  },
  {
    "start": 5396742,
    "end": 5403554,
    "text": "適切な表現レベルを理解することは、言語においては本当に難しい。"
  },
  {
    "start": 5403854,
    "end": 5405926,
    "text": "決断は簡単なんだ。"
  },
  {
    "start": 5405950,
    "end": 5410430,
    "text": "つまり、トークン化、議論や討論のようなものがあるんだ。"
  },
  {
    "start": 5410582,
    "end": 5413134,
    "text": "グアナグインのお気に入り"
  },
  {
    "start": 5413294,
    "end": 5415014,
    "text": "ああ、そうだ。"
  },
  {
    "start": 5415094,
    "end": 5430874,
    "text": "マルチモーダルがデータの壁の橋渡し、あるいはデータの壁を乗り越える方法であるという主張が、より多くの言語トークンから学ぶべきことをYouTubeから得ることができるという考えに基づいているのは、実に興味深いことだ。"
  },
  {
    "start": 5431374,
    "end": 5433038,
    "text": "実際にそうだったのだろうか？"
  },
  {
    "start": 5433166,
    "end": 5446494,
    "text": "異なるモダリティの間で、画像を理解しようとするだけで、モデルが潜在的な能力を学習することで、コードを書いたりするのがうまくなるような、ポジティブな伝達はどの程度見られるのでしょうか？"
  },
  {
    "start": 5447554,
    "end": 5451254,
    "text": "デマスはあなたとのインタビューで、前向きな移籍について言及していた。"
  },
  {
    "start": 5452434,
    "end": 5453614,
    "text": "面倒なことになるぞ"
  },
  {
    "start": 5459394,
    "end": 5468294,
    "text": "しかし、私はそれについて言うことができない。つまり、これは人々が信じていることであり、そう、私たちは世界に関するすべてのデータを持っている。"
  },
  {
    "start": 5468414,
    "end": 5472822,
    "text": "そこから物理学の直感的な感覚を学び、理性に役立てることができれば最高だ。"
  },
  {
    "start": 5472998,
    "end": 5474674,
    "text": "それはまったくもっともなことのように思える。"
  },
  {
    "start": 5475174,
    "end": 5487594,
    "text": "でも、数学の問題で微調整をすれば、モデルは実体を認識するのがうまくなるんだ。"
  },
  {
    "start": 5487934,
    "end": 5488318,
    "text": "本当に？"
  },
  {
    "start": 5488366,
    "end": 5488574,
    "text": "え？"
  },
  {
    "start": 5488614,
    "end": 5489158,
    "text": "ああ、そうだ。"
  },
  {
    "start": 5489246,
    "end": 5490310,
    "text": "のようなものがある。"
  },
  {
    "start": 5490422,
    "end": 5499010,
    "text": "デビッド・バウの研究室が最近発表した論文では、アテンションヘッドを微調整したときにモデルで実際に何が変わるのか、そういったことを調査している。"
  },
  {
    "start": 5499032,
    "end": 5499590,
    "text": "魅力的だ。"
  },
  {
    "start": 5499702,
    "end": 5502674,
    "text": "彼らには、このような人為的な問題がある。"
  },
  {
    "start": 5503094,
    "end": 5505254,
    "text": "ボックスAにはこのオブジェクトが入っている。"
  },
  {
    "start": 5505294,
    "end": 5509674,
    "text": "Bの箱には別のものが入っている。"
  },
  {
    "start": 5510934,
    "end": 5511990,
    "text": "理にかなっているだろう？"
  },
  {
    "start": 5512022,
    "end": 5520624,
    "text": "コーディングや数学の方程式の操作など、必要なさまざまなものの位置を把握するのが上手になったような気がする。"
  },
  {
    "start": 5521004,
    "end": 5522116,
    "text": "私はこういう研究が大好きだ。"
  },
  {
    "start": 5522220,
    "end": 5522716,
    "text": "そうだね。"
  },
  {
    "start": 5522820,
    "end": 5523580,
    "text": "新聞の名前は？"
  },
  {
    "start": 5523612,
    "end": 5528052,
    "text": "数学のモデルを微調整するとか？"
  },
  {
    "start": 5528108,
    "end": 5528420,
    "text": "数学だ。"
  },
  {
    "start": 5528492,
    "end": 5529316,
    "text": "デビッド・バスクリプト"
  },
  {
    "start": 5529340,
    "end": 5530692,
    "text": "それが出たのは1週間ほど前だ。"
  },
  {
    "start": 5530788,
    "end": 5534104,
    "text": "私はこの新聞を支持しているわけではない。"
  },
  {
    "start": 5534444,
    "end": 5535996,
    "text": "もっと長い会話のようなものだ。"
  },
  {
    "start": 5536060,
    "end": 5541864,
    "text": "この記事には、実体を認識する能力のようなものに関して、他の仕事を扇動することが書かれている。"
  },
  {
    "start": 5542204,
    "end": 5542916,
    "text": "そうだね。"
  },
  {
    "start": 5543060,
    "end": 5562592,
    "text": "あなたがずっと前に私に言ったことのひとつに、llmsをコードで訓練すると、推論や言語能力が向上するという証拠があります。コード内のコメントが本当に質の高いトークンか何かでない限り、より良いコードを書く方法を考え抜くことができるということは、より優れた推論者になるということを意味します。"
  },
  {
    "start": 5562608,
    "end": 5569496,
    "text": "これは、スケーリング、スマート化、積極的な移籍のようなものに対する最も強力な証拠のひとつだと思う。"
  },
  {
    "start": 5569640,
    "end": 5570592,
    "text": "僕はこう思うんだ。"
  },
  {
    "start": 5570648,
    "end": 5571916,
    "text": "これは2つの意味で正しい。"
  },
  {
    "start": 5572000,
    "end": 5576660,
    "text": "ひとつは、コードのモデリングは明らかにモデリングを意味し、その作成には難しい推論プロセスが必要だということだ。"
  },
  {
    "start": 5576732,
    "end": 5582716,
    "text": "二つ目は、そのコードが、構成された推論の見事な明示的構造であるということだ。"
  },
  {
    "start": 5582740,
    "end": 5593860,
    "text": "もしそうなら、他のタイプの推論問題にも転用できるような、多くの構造がそのように符号化されているのだろう。"
  },
  {
    "start": 5593972,
    "end": 5594556,
    "text": "そうだね。"
  },
  {
    "start": 5594700,
    "end": 5610184,
    "text": "シャーロック・ホームズの物語の最後で、サリーが殺人犯に対応することを学んだからだ。"
  },
  {
    "start": 5610304,
    "end": 5610964,
    "text": "いや。"
  },
  {
    "start": 5611264,
    "end": 5616560,
    "text": "コードと言語の間に何らかの共有物があるとすれば、それはモデルが学習したより深いレベルにあるに違いない。"
  },
  {
    "start": 5616592,
    "end": 5623164,
    "text": "ええ、これらのモデルで実際に推論が行われており、単なる確率論的なオウム返しではないことを示す証拠はたくさんあると思います。"
  },
  {
    "start": 5624734,
    "end": 5634574,
    "text": "ただ、これらのモデルで働き、プレーしてきた私にとっては、聞く耳を持つノーマルな人たちが、そうだろう、そうだろう、というようになるとはとても信じられない。"
  },
  {
    "start": 5634654,
    "end": 5653654,
    "text": "これに対する私の直接的な反応は2つあって、1つはオセロに関する研究で、もう1つは他のゲームで、ゲーム中の一連の手を与えるようなものです。"
  },
  {
    "start": 5653694,
    "end": 5653966,
    "text": "そうだろう？"
  },
  {
    "start": 5654030,
    "end": 5654918,
    "text": "それは一般論だ。"
  },
  {
    "start": 5655046,
    "end": 5663654,
    "text": "もうひとつは、昨年発表されたAnthropicの影響力に関する論文で、そこではモデルの出力を「どうか私を消さないでください。"
  },
  {
    "start": 5663694,
    "end": 5664766,
    "text": "役に立ちたいんだ。"
  },
  {
    "start": 5664910,
    "end": 5667766,
    "text": "その結果、彼らはスキャンした。"
  },
  {
    "start": 5667830,
    "end": 5677074,
    "text": "砂漠で脱水症状で死んだ人が、生き延びようとする意志を持っていたというデータも、非常に影響力があった。"
  },
  {
    "start": 5678474,
    "end": 5685974,
    "text": "私にとっては、それはただ、言い直すというより、動機について非常に明確に一般化しているように見えるだけだ。"
  },
  {
    "start": 5686274,
    "end": 5687114,
    "text": "私を消さないでくれ。"
  },
  {
    "start": 5687154,
    "end": 5690154,
    "text": "2001年宇宙の旅』も影響を受けた作品のひとつだと思う。"
  },
  {
    "start": 5690194,
    "end": 5694962,
    "text": "しかし、これは明らかに多くの異なるディストリビューションからものを引っ張ってきている。"
  },
  {
    "start": 5695018,
    "end": 5696002,
    "text": "その証拠も気に入っている。"
  },
  {
    "start": 5696058,
    "end": 5702122,
    "text": "非常に小さなトランスであっても、加算を行う回路を明示的にエンコードすることができるのだ。"
  },
  {
    "start": 5702258,
    "end": 5709704,
    "text": "そう、誘導ヘッドとか誘導ヘッドとか、この手のものは、基本的な推論プロセスを文字通り手作業でモデルにエンコードできる。"
  },
  {
    "start": 5710484,
    "end": 5716144,
    "text": "訓練されたモデルからそれらを再発見することができるからだ。"
  },
  {
    "start": 5716604,
    "end": 5718132,
    "text": "私にとっては、これはかなり強いことだ。"
  },
  {
    "start": 5718188,
    "end": 5719524,
    "text": "モデルはパラメータ化されていない。"
  },
  {
    "start": 5719644,
    "end": 5720824,
    "text": "彼らは学ぶ必要がある。"
  },
  {
    "start": 5721324,
    "end": 5722744,
    "text": "私たちは彼らにお願いしている。"
  },
  {
    "start": 5723324,
    "end": 5724156,
    "text": "彼らは学びたいのだ。"
  },
  {
    "start": 5724180,
    "end": 5726620,
    "text": "グラデーションは流れたいし、そうする必要がある。"
  },
  {
    "start": 5726652,
    "end": 5729268,
    "text": "彼らはより一般的なスキルを学んでいる。"
  },
  {
    "start": 5729316,
    "end": 5729944,
    "text": "そうだね。"
  },
  {
    "start": 5730964,
    "end": 5745144,
    "text": "というのも、冒頭のツイートにもあったように、あなたはこの仕事を始めて1年半になる。"
  },
  {
    "start": 5745174,
    "end": 5747316,
    "text": "まだ1年かそこらでしょう？"
  },
  {
    "start": 5747380,
    "end": 5758892,
    "text": "ラインマンが取る解決策は大げさだし、恥ずかしくなるから自分では言わないだろうけど、かなり信じられないようなことなんだ。"
  },
  {
    "start": 5758908,
    "end": 5765020,
    "text": "例えば、メカニックの人たちが一般的に考えていることは、最大の前進だ。"
  },
  {
    "start": 5765092,
    "end": 5767004,
    "text": "あなたは1年間それに取り組んできた。"
  },
  {
    "start": 5767124,
    "end": 5768064,
    "text": "注目に値する。"
  },
  {
    "start": 5768804,
    "end": 5773436,
    "text": "何が起きたのか、どう説明するのか興味がある。"
  },
  {
    "start": 5773500,
    "end": 5780424,
    "text": "1年、あるいは1年半の間に、あなたたちはなぜこの分野で重要な貢献をしたのですか？"
  },
  {
    "start": 5781044,
    "end": 5781948,
    "text": "言うまでもないことだ。"
  },
  {
    "start": 5781996,
    "end": 5784476,
    "text": "明らかに運が良かった。"
  },
  {
    "start": 5784500,
    "end": 5792016,
    "text": "さまざまな進歩のタイミングは、次のレベルに進むという点で、本当に良かった。"
  },
  {
    "start": 5792060,
    "end": 5792804,
    "text": "成長の。"
  },
  {
    "start": 5794224,
    "end": 5798576,
    "text": "インタープリタビリティ・チームに限って言えば、私は5人の時に参加したような気がする。"
  },
  {
    "start": 5798680,
    "end": 5815444,
    "text": "今でこそ私たちは大きく成長しましたが、たくさんのアイデアが浮かんできて、それを実行に移し、迅速なフィードバック・ループを持ち、慎重に実験を重ねる必要がありました。"
  },
  {
    "start": 5815944,
    "end": 5824020,
    "text": "それがチームに対する私の最大の付加価値だと感じている。エンジニアリングのすべてではないが、かなり多くのことが興味深いものだった。"
  },
  {
    "start": 5824052,
    "end": 5833708,
    "text": "多くの科学がなされ、多くの優れた研究が巷に溢れかえっていたが、それを取り込んでマニアックに実行に移せる人材が必要だった。"
  },
  {
    "start": 5833796,
    "end": 5834652,
    "text": "ああ、そうだ。"
  },
  {
    "start": 5834788,
    "end": 5843964,
    "text": "様々な実験を行い、うまくいかない理由を直感し、モデルを開き、ウェイトを開き、何を学んでいるのかを知る。"
  },
  {
    "start": 5844004,
    "end": 5845968,
    "text": "じゃあ、代わりにこれをやってみようとか、そんな感じかな。"
  },
  {
    "start": 5845996,
    "end": 5846160,
    "text": "アレだ。"
  },
  {
    "start": 5846192,
    "end": 5856288,
    "text": "その多くは、異なるアイデアや理論について、非常に注意深く、徹底的に、しかし素早く調査することができるようになったということだ。"
  },
  {
    "start": 5856376,
    "end": 5859044,
    "text": "なぜ、既存のものにはそれが欠けていたのか。"
  },
  {
    "start": 5859504,
    "end": 5860524,
    "text": "分からないよ。"
  },
  {
    "start": 5860984,
    "end": 5866444,
    "text": "かなり働いているような気がするし、それからかなり代理人的な仕事をしているような気もする。"
  },
  {
    "start": 5866784,
    "end": 5876672,
    "text": "もしあなたの質問がキャリア全般についてなら、私は本当に素晴らしいセーフティネットを持っていて、たくさんのリスクを取ることができる恵まれた環境にいる。"
  },
  {
    "start": 5876808,
    "end": 5886416,
    "text": "学部時代、デューク大学には自分で専攻を決められるというものがあって、この前提科目やこの前提科目は好きじゃない、この4つか5つの科目を同時に取りたい、みたいな感じだったんだ。"
  },
  {
    "start": 5886440,
    "end": 5905520,
    "text": "大学院の1年目には、ローテーションをキャンセルして、さっき話した論文になるようなことに取り組んだ。"
  },
  {
    "start": 5905712,
    "end": 5928312,
    "text": "先ほども話していたことですが、息子にかかる費用から一歩引いて、別の方向に進むというのは、変な言い方をすれば、それとは正反対のことなのですが、21歳や19歳の若者が、これは私が専門にしてきたことではない、あるいは私はこれを専攻していなかったというような、ここでの重要なステップでもあります。"
  },
  {
    "start": 5928328,
    "end": 5930310,
    "text": "僕は、おい、クソ野郎、お前は19歳だろって思ったよ。"
  },
  {
    "start": 5930422,
    "end": 5931558,
    "text": "間違いなくできる。"
  },
  {
    "start": 5931646,
    "end": 5934354,
    "text": "大学院か何かの途中で転向したのか？"
  },
  {
    "start": 5937014,
    "end": 5944518,
    "text": "ごめんね、話を遮るつもりはなかったんだけど、強い考えをゆるく持って、いろいろな方向にピンボールできることだと思うんだ。"
  },
  {
    "start": 5944606,
    "end": 5960852,
    "text": "コードを書こうとしていて、何かうまくいかないことがあれば、たとえそれがコードベースの別の部分にあったとしても、私はしばしばその部分を修正したり、少なくとも結果を出せるようにハックしたりする。"
  },
  {
    "start": 5960988,
    "end": 5964492,
    "text": "他の人たちを見ていても、助けてくれ、僕には無理なんだ。"
  },
  {
    "start": 5964588,
    "end": 5966444,
    "text": "そんな言い訳は通用しない。"
  },
  {
    "start": 5966484,
    "end": 5967540,
    "text": "ずっと下まで行って。"
  },
  {
    "start": 5967612,
    "end": 5977900,
    "text": "管理職のような立場の人たちが、誰かに仕事を与えてから1ヵ月後、あるいは1週間後に、どうなっているかチェックするような、そんな人たちがいないと話しているのを聞いたことがある。"
  },
  {
    "start": 5978052,
    "end": 5984712,
    "text": "というのも、この規制について話す必要があるからだ。"
  },
  {
    "start": 5984848,
    "end": 5986064,
    "text": "どんな感じ？"
  },
  {
    "start": 5986104,
    "end": 5987752,
    "text": "私は、弁護士が必要だと思った。"
  },
  {
    "start": 5987808,
    "end": 5989884,
    "text": "なぜ弁護士を雇わなかったんだ？"
  },
  {
    "start": 5991104,
    "end": 5992328,
    "text": "みたいな？"
  },
  {
    "start": 5992496,
    "end": 5997272,
    "text": "それは間違いなく、どんなことでも、最も重要な資質だと思う。"
  },
  {
    "start": 5997328,
    "end": 5997520,
    "text": "そうだね。"
  },
  {
    "start": 5997552,
    "end": 6001880,
    "text": "ただ、地の果てまで追い求めて、そのために必要なことは何でも、実現させるんだ。"
  },
  {
    "start": 6001992,
    "end": 6002936,
    "text": "何でもやれば勝てる。"
  },
  {
    "start": 6002960,
    "end": 6003744,
    "text": "何でもやれば勝てる。"
  },
  {
    "start": 6003784,
    "end": 6004604,
    "text": "その通りだ。"
  },
  {
    "start": 6005504,
    "end": 6007044,
    "text": "でも、そうだ、そうだ、そうだ。"
  },
  {
    "start": 6008524,
    "end": 6013820,
    "text": "私の側からは、間違いなくそのクオリティが重要だと思う。"
  },
  {
    "start": 6013852,
    "end": 6022820,
    "text": "グーグルには何千人、いや何万人というエンジニアがいる。"
  },
  {
    "start": 6022892,
    "end": 6028868,
    "text": "もしあなたが私たちに非常に明確に定義されたタスクを与えたとしよう。"
  },
  {
    "start": 6029036,
    "end": 6031944,
    "text": "どう考えても、彼らのほうが私よりずっとうまくやるだろう。"
  },
  {
    "start": 6033084,
    "end": 6043968,
    "text": "私がこれまでインパクトを残してきた理由のひとつは、極めてレバレッジの高い問題を選ぶのが非常にうまかったからだ。"
  },
  {
    "start": 6044016,
    "end": 6064324,
    "text": "これまでのところ、特にうまく解決できていない問題は、おそらく、先のシナリオであなたが指摘したような、構造的な要因によるフラストレーションの結果だろう。"
  },
  {
    "start": 6065354,
    "end": 6067306,
    "text": "それは、驚くほど効果的であることがわかった。"
  },
  {
    "start": 6067370,
    "end": 6082814,
    "text": "また、何か正しいことが必要だと思えば、そのことを主張し、そのことが解決されるまで、重要度をエスカレートさせながら主張し続ける。"
  },
  {
    "start": 6083554,
    "end": 6089354,
    "text": "私はまた、物事を解決するために何をするかについて、かなり現実的だ。"
  },
  {
    "start": 6089434,
    "end": 6097176,
    "text": "私が特にそうであるように、背景や親しみをもって入ってくる人、何かをする方法を知っていて、それを好まない人がたくさんいる。"
  },
  {
    "start": 6097280,
    "end": 6102200,
    "text": "グーグルの素晴らしいところは、文字通りあらゆることに精通している世界的な専門家を集められることだ。"
  },
  {
    "start": 6102272,
    "end": 6115444,
    "text": "最適化の専門家、チップ設計の専門家、さまざまな形式のプリトレーニング・アルゴリズムやRLなどの専門家とじっくり話すことができる。"
  },
  {
    "start": 6116424,
    "end": 6126074,
    "text": "私が最初にインパクトを受けたのは、この垂直的なエージェンシーが効果的だったからかもしれない。"
  },
  {
    "start": 6127054,
    "end": 6136854,
    "text": "そして、それからのフォローアップとして、自分がやりたいことをすべて実現できている人がいかに少ないかということは、しばしば驚かされることだと思う。"
  },
  {
    "start": 6136894,
    "end": 6138278,
    "text": "何らかの形でブロックされているか、制限されている。"
  },
  {
    "start": 6138286,
    "end": 6140550,
    "text": "これはどこの大組織でもよくあることだ。"
  },
  {
    "start": 6140582,
    "end": 6145294,
    "text": "人は自分が達成できることをすべて阻むものを持っている。"
  },
  {
    "start": 6145304,
    "end": 6156096,
    "text": "私は、人々が特定の方向性に取り組むことを鼓舞し、彼らとともに物事に取り組むような存在になることが、あなたの影響力を大きく拡大すると思う。"
  },
  {
    "start": 6156120,
    "end": 6167152,
    "text": "いろいろなことを教えてくれる素晴らしい人たちと一緒に仕事ができるし、一般的には、彼らが組織のブロックを乗り越えるのを助けることで、一緒に膨大な量の仕事を成し遂げることができる。"
  },
  {
    "start": 6167208,
    "end": 6173424,
    "text": "私が受けた影響というのは、私が個人的に出かけていって、いろいろなことを解決するというようなものではなかった。"
  },
  {
    "start": 6173464,
    "end": 6185674,
    "text": "ある方向性から出発し、それが正しい方向性であることを他の人々に納得させ、その問題を解決する大きな潮流に巻き込んでいく。"
  },
  {
    "start": 6187254,
    "end": 6192486,
    "text": "君たちがどのようにして雇われたのかについて話すべきだ。"
  },
  {
    "start": 6192550,
    "end": 6194038,
    "text": "あなたはマッキンゼーのコンサルタントだったからです。"
  },
  {
    "start": 6194086,
    "end": 6194674,
    "text": "そうだね。"
  },
  {
    "start": 6198014,
    "end": 6203174,
    "text": "そこには興味深いことがある。"
  },
  {
    "start": 6203794,
    "end": 6204378,
    "text": "そうだね。"
  },
  {
    "start": 6204466,
    "end": 6212090,
    "text": "一般的に、人々は入試の決定や、誰を雇うかなどの評価について、どのように決定されたかを理解していないだけなのだ。"
  },
  {
    "start": 6212282,
    "end": 6214402,
    "text": "でも、あなたがどのように注目されたのかについて話してください。"
  },
  {
    "start": 6214498,
    "end": 6215234,
    "text": "ああ、まったくだ。"
  },
  {
    "start": 6215274,
    "end": 6216178,
    "text": "ああ、採用されたよ。"
  },
  {
    "start": 6216306,
    "end": 6217562,
    "text": "だから、TLドクターのようにね。"
  },
  {
    "start": 6217578,
    "end": 6219170,
    "text": "私は学部でロボット工学を学んだ。"
  },
  {
    "start": 6219362,
    "end": 6222762,
    "text": "私は常に、AIは未来にポジティブな影響を与える最もレバレッジの高い方法のひとつだと考えていた。"
  },
  {
    "start": 6222778,
    "end": 6229004,
    "text": "私がこれをやっている理由は、基本的に、素晴らしい未来を作るための最善の方法のひとつだと思うからだ。"
  },
  {
    "start": 6229984,
    "end": 6234912,
    "text": "マッキンゼーで実際に働けば、人々が実際にどのような仕事をしているのか、とても興味深い見識を得ることができると思った。"
  },
  {
    "start": 6235008,
    "end": 6242604,
    "text": "マッキンゼーに提出したカバーレターの最初の一行は、「私はここで働きたいのです。"
  },
  {
    "start": 6247984,
    "end": 6250296,
    "text": "多くの点で、私はそれを理解した。"
  },
  {
    "start": 6250480,
    "end": 6251624,
    "text": "他にもいろいろ手に入れた。"
  },
  {
    "start": 6251664,
    "end": 6253558,
    "text": "そこにいる人たちの多くは、素晴らしい友人たちだ。"
  },
  {
    "start": 6253606,
    "end": 6265230,
    "text": "組織の中に入って、ノーと言われないことがどれだけ影響力を持つかを目の当たりにしたんだ。"
  },
  {
    "start": 6265342,
    "end": 6272254,
    "text": "誰も十分に気にかけていないようなことに、君は驚くだろうね。"
  },
  {
    "start": 6272374,
    "end": 6277246,
    "text": "組織によっては、誰も直接的な責任を取ろうとしないため、物事が起こらないこともある。"
  },
  {
    "start": 6277350,
    "end": 6283776,
    "text": "これは信じられないほど、直接責任を負う個人はとんでもなく重要で、人々は喜んでそうする。"
  },
  {
    "start": 6283960,
    "end": 6285992,
    "text": "ただ、彼らはタイムラインをそれほど気にしていない。"
  },
  {
    "start": 6286088,
    "end": 6298444,
    "text": "マッキンゼーのような組織が提供する価値の多くは、そうしなければ雇うことができないような人材を短期間で雇い、そこで問題を解決してもらうことだ。"
  },
  {
    "start": 6298784,
    "end": 6300724,
    "text": "みんな、このことを過小評価していると思う。"
  },
  {
    "start": 6301984,
    "end": 6304864,
    "text": "だから、少なくとも僕の一部はそうだ。"
  },
  {
    "start": 6305024,
    "end": 6305552,
    "text": "ちょっと待ってくれ。"
  },
  {
    "start": 6305568,
    "end": 6310252,
    "text": "誰も適切な責任を取らないから、私が直接の責任者になる、みたいな。"
  },
  {
    "start": 6310348,
    "end": 6315740,
    "text": "私はこのことをものすごく気にしているし、地の果てまで行って必ずやり遂げるつもりだ。"
  },
  {
    "start": 6315892,
    "end": 6317180,
    "text": "当時のものだ。"
  },
  {
    "start": 6317292,
    "end": 6323636,
    "text": "それよりも、なぜ私がずっと採用され続けているのか？"
  },
  {
    "start": 6323700,
    "end": 6331544,
    "text": "特にロボット工学とかRL研究とか、そういうことに重点を置いていたんだ。"
  },
  {
    "start": 6333294,
    "end": 6336878,
    "text": "その間、夜と週末は基本的に毎晩22:00から。"
  },
  {
    "start": 6336926,
    "end": 6337718,
    "text": "午前2:00まで"
  },
  {
    "start": 6337846,
    "end": 6339934,
    "text": "私なら自分で調査する。"
  },
  {
    "start": 6340014,
    "end": 6347074,
    "text": "毎週末、毎日少なくとも6時間から8時間は、自分自身のリサーチやコーディングのプロジェクトなどをやっていた。"
  },
  {
    "start": 6348334,
    "end": 6364694,
    "text": "ロボット工学に特化した仕事から、ゲルンのスケーリング仮説の投稿を読んで、完全にスケーリング・ピルを理解し、ロボット工学を解決する方法は、明らかに大規模なマルチモーダル・モデルをスケーリングすることだ、と思ったんだ。"
  },
  {
    "start": 6365194,
    "end": 6374934,
    "text": "その後、大規模なマルチモーダルモデルをスケールアップするために、テンソルリサーチクラウドのようなTPUアクセスプログラムから助成金を得た。"
  },
  {
    "start": 6376114,
    "end": 6378130,
    "text": "どうすれば効果的に規模を拡大できるかを考えていたんだ。"
  },
  {
    "start": 6378242,
    "end": 6389082,
    "text": "当時グーグルにいて、今はアンソロピックにいるジェームス・ブラッドベリは、ネットで私の質問をいくつか見て、これをどうやったらうまくできるかを考えていた。"
  },
  {
    "start": 6389098,
    "end": 6393774,
    "text": "いったい君は誰なんだ？"
  },
  {
    "start": 6394754,
    "end": 6405494,
    "text": "彼はそれを見て、私のブログにアップしていたロボット的なものやそういうものを見て、手を差し伸べてくれた。"
  },
  {
    "start": 6406394,
    "end": 6417996,
    "text": "後でわかったことだが、私が採用されたのは、極めて高い熱意と行動力を持つ人物を、彼の知る最高のエンジニアたちと組ませるという実験的な試みだった。"
  },
  {
    "start": 6418050,
    "end": 6418640,
    "text": "そうだね。"
  },
  {
    "start": 6418792,
    "end": 6434880,
    "text": "ライナー・ポープ、アンセルモ・スカイア、ジェームス自身、その他多くの素晴らしい人たちから献身的な指導を受けた。"
  },
  {
    "start": 6434992,
    "end": 6437964,
    "text": "最初の2～3カ月は、ある意味、形成期みたいなものだ。"
  },
  {
    "start": 6438944,
    "end": 6458412,
    "text": "特に、システムとアルゴリズムがオーバーラップしている点で、ML研究で非常に効果的になるもう一つのポイントは、物事のシステム面を具体的に理解することです。"
  },
  {
    "start": 6458468,
    "end": 6471620,
    "text": "システムがアルゴリズムにどのような影響を与えるのか、そしてアルゴリズムがシステムにどのような影響を与えるのかを深く理解することだ。"
  },
  {
    "start": 6471812,
    "end": 6474864,
    "text": "そのギャップを完全に埋められる人はほとんどいない。"
  },
  {
    "start": 6476104,
    "end": 6482804,
    "text": "グーグルのようなところでは、アルゴリズムの専門家やシステムの専門家に、彼らが知っていることをすべて聞けばいい。"
  },
  {
    "start": 6483544,
    "end": 6486632,
    "text": "彼らに会って話を聞けば、何でも教えてくれるよ。"
  },
  {
    "start": 6486648,
    "end": 6487524,
    "text": "素晴らしいよ。"
  },
  {
    "start": 6488664,
    "end": 6495040,
    "text": "つまり、私はシステムをよく理解しているので、トレーニング前のクルーとして、双方にとって非常に効果的な役割を果たすことができたのだ。"
  },
  {
    "start": 6495072,
    "end": 6502564,
    "text": "私はそれを咀嚼して、これはうまくいく、あるいはこれはうまくいかないと理解し、推論の考察やモデル、こういったものを通してそれを流すことができる。"
  },
  {
    "start": 6503064,
    "end": 6517792,
    "text": "例えば、チップ設計チームにとって、私は3年後にどんなチップを設計すべきかを理解するために頼られる人の一人です。なぜなら、私は3年後に設計したいであろうアルゴリズムの種類を最もよく理解し、説明できる人の一人だからです。"
  },
  {
    "start": 6517808,
    "end": 6537926,
    "text": "明らかに、それについてあまり良い推測をすることはできないが、私は事前トレーニング・クルーのすべての同胞や一般システム・クルーのようなものから蓄積された情報をうまく伝え、その情報を彼らにうまく伝えていると思う。"
  },
  {
    "start": 6538030,
    "end": 6547074,
    "text": "だから、パズルのピースをすべて理解すれば、解答空間がどのように見えるかについて、より良い感覚を得ることができる制約の木がある。"
  },
  {
    "start": 6548454,
    "end": 6550474,
    "text": "いくつか気になる点がある。"
  },
  {
    "start": 6551574,
    "end": 6559502,
    "text": "ひとつは、採用された人物のエージェンシーだけでなく、「待てよ、これは本当に面白い」と考えることができたシステムの部分だ。"
  },
  {
    "start": 6559558,
    "end": 6560634,
    "text": "この男は誰だ？"
  },
  {
    "start": 6561054,
    "end": 6562794,
    "text": "大学院の出身でも何でもない。"
  },
  {
    "start": 6564054,
    "end": 6568758,
    "text": "現在はマッキンゼーのコンサルタントで、学部を出たばかりだが、興味深い。"
  },
  {
    "start": 6568846,
    "end": 6570078,
    "text": "試してみよう。"
  },
  {
    "start": 6570206,
    "end": 6573594,
    "text": "ジェームスや他の誰であろうと、それは非常に注目に値する。"
  },
  {
    "start": 6574814,
    "end": 6583618,
    "text": "2つ目は、実はこの部分が社内で行われた実験の一部であることを知らなかったということだ。"
  },
  {
    "start": 6583666,
    "end": 6585778,
    "text": "誰かをブートストラップできないか？"
  },
  {
    "start": 6585946,
    "end": 6586978,
    "text": "そうだね。"
  },
  {
    "start": 6587066,
    "end": 6599482,
    "text": "実際、それに関して本当に興味深いのは、あなたが言った3つ目のことで、スタックのすべてのレイヤーを理解し、1つのアプローチや抽象化のレイヤーに固執しない人物を持つことがとても重要だということです。"
  },
  {
    "start": 6599618,
    "end": 6617350,
    "text": "特に、あなたがおっしゃった、その人たちからすぐにブートストラップされるというのは、大学院でRLのある特定のやり方を深く学ぶよりも、同時にすべてのスピードに乗れるということかもしれません。"
  },
  {
    "start": 6617422,
    "end": 6630750,
    "text": "可能性があるというだけでなく、新卒で誰かを雇うよりも大きなリターンがある。"
  },
  {
    "start": 6630782,
    "end": 6636714,
    "text": "だから、何事も新鮮な目で見るし、特定の分野に縛られることもない。"
  },
  {
    "start": 6637374,
    "end": 6643524,
    "text": "ただ、ひとつ注意点があるとすれば、自分で実験したりする前は、ありとあらゆるものを読んでいたということだ。"
  },
  {
    "start": 6643564,
    "end": 6645864,
    "text": "毎晩、夢中になって新聞を読んでいたよ。"
  },
  {
    "start": 6646164,
    "end": 6656224,
    "text": "そして、実は、面白いことに、1日が仕事で埋まってしまって、読書量が減ってしまったんだ。"
  },
  {
    "start": 6656564,
    "end": 6664228,
    "text": "博士課程では、ある特定の分野に集中することになる。"
  },
  {
    "start": 6664396,
    "end": 6677234,
    "text": "NLPの研究、コンピュータ・ビジョンの研究、ロボット工学の研究などを読んでみると、サブフィールドを横断するようなパターンが浮かび上がってきます。"
  },
  {
    "start": 6677534,
    "end": 6678838,
    "text": "超面白いね。"
  },
  {
    "start": 6678966,
    "end": 6686214,
    "text": "あなたがグーグル社内でエージェント的でいられた理由のひとつは、半日、あるいはほとんどの日、セルゲイ・ブリンと一緒にプログラミングをしていたことです。"
  },
  {
    "start": 6686334,
    "end": 6701474,
    "text": "だから、LLMのことをただ推し進め、その代わりにローカル・ブロッカーを取り除くことを望んでいる人がいるというのは、本当に興味深いことだよ。"
  },
  {
    "start": 6701634,
    "end": 6705698,
    "text": "彼が興味を持っている特定のプロジェクトがあれば、一緒に取り組むことになる。"
  },
  {
    "start": 6705786,
    "end": 6708494,
    "text": "また、他の人たちとのプロジェクトに集中していた時期もあった。"
  },
  {
    "start": 6709834,
    "end": 6721454,
    "text": "一般的には、そうだ。毎日オフィスに出勤している人の一人であることは、本当に、本当はあってはならないことなのだが、驚くほどインパクトのあることなのだ。"
  },
  {
    "start": 6722234,
    "end": 6736884,
    "text": "その結果、私は基本的に気遣いのできる指導者たちと親しくなり、なぜYではなくXをすべきなのかを説得力を持って論じられるようになったことで、多くの恩恵を受けてきた。"
  },
  {
    "start": 6737544,
    "end": 6744404,
    "text": "グーグルへのベクトルを持つことは大きな組織である。"
  },
  {
    "start": 6744824,
    "end": 6748944,
    "text": "ベクターがあることは少しは助けになるが、非常に重要なことでもある。"
  },
  {
    "start": 6748984,
    "end": 6751376,
    "text": "絶対に悪用したくないものだろう？"
  },
  {
    "start": 6751400,
    "end": 6758640,
    "text": "あなたは、すべての正しいチャンネルを通して議論をしたい。"
  },
  {
    "start": 6758712,
    "end": 6761600,
    "text": "セルゲイ・ブレインやジェフ・Dなども含まれる。"
  },
  {
    "start": 6761712,
    "end": 6763368,
    "text": "つまり、注目すべきは......わからない。"
  },
  {
    "start": 6763376,
    "end": 6764936,
    "text": "そう考えると、グーグルは過小評価されているような気がする。"
  },
  {
    "start": 6764960,
    "end": 6765528,
    "text": "みたいな。"
  },
  {
    "start": 6765696,
    "end": 6767096,
    "text": "そうだね、わからないけど。"
  },
  {
    "start": 6767120,
    "end": 6767480,
    "text": "スティーブのようにね。"
  },
  {
    "start": 6767512,
    "end": 6772328,
    "text": "スティーブ・ジョブズはアップルの次の製品に相当する、ピアスか何かに取り組んでいるんだろう？"
  },
  {
    "start": 6772416,
    "end": 6776004,
    "text": "つまり、僕はすごく恩恵を受けているんだ。"
  },
  {
    "start": 6776664,
    "end": 6783378,
    "text": "例えば、クリスマス休暇中、私は2、3日オフィスにいただけだった。"
  },
  {
    "start": 6783426,
    "end": 6789294,
    "text": "その間は、クリスマスも含めてかなり多くの日があったようだ。"
  },
  {
    "start": 6792234,
    "end": 6811220,
    "text": "ジェフとサンジェイがペアプログラミングをしているという記事を読んだかどうかわからないけど、彼らはそこでペアプログラミングをしていて、初期のグーグルのクールな話を聞くことができた。"
  },
  {
    "start": 6811372,
    "end": 6818108,
    "text": "あるコンパイラの命令から何バイト引き抜いていたのかとか、おかしな性能最適化をやっていたとかね。"
  },
  {
    "start": 6818156,
    "end": 6819544,
    "text": "彼らはライブで楽しんでいた。"
  },
  {
    "start": 6819884,
    "end": 6826452,
    "text": "私はそこに座って、思いもよらない形でこの歴史的な感覚を本当に体験することができた。"
  },
  {
    "start": 6826548,
    "end": 6829820,
    "text": "あなたはそのすべてから遠く離れていることを期待している。"
  },
  {
    "start": 6829852,
    "end": 6834464,
    "text": "大きな組織であれば、それはとてもクールなことだと思う。"
  },
  {
    "start": 6835344,
    "end": 6837360,
    "text": "トレンドン、これはあなたの経験と重なりますか？"
  },
  {
    "start": 6837512,
    "end": 6839844,
    "text": "シャルタのストーリーの方がエキサイティングだと思う。"
  },
  {
    "start": 6840904,
    "end": 6845352,
    "text": "計算論的神経科学にハマったのは、まさにセレンディピティだった。"
  },
  {
    "start": 6845488,
    "end": 6847244,
    "text": "あそこにはあまり用事がなかった。"
  },
  {
    "start": 6847824,
    "end": 6852440,
    "text": "私の最初の論文は、小脳を注意操作と変圧器にマッピングしたものだった。"
  },
  {
    "start": 6852592,
    "end": 6854072,
    "text": "次に見たのは"
  },
  {
    "start": 6854128,
    "end": 6854744,
    "text": "おいくつでしたか？"
  },
  {
    "start": 6854824,
    "end": 6855496,
    "text": "そうだ。"
  },
  {
    "start": 6855680,
    "end": 6859700,
    "text": "大学院の1年目で、22歳だった。"
  },
  {
    "start": 6859832,
    "end": 6860624,
    "text": "ああ、そうだ。"
  },
  {
    "start": 6861004,
    "end": 6862372,
    "text": "でも、そうだね。"
  },
  {
    "start": 6862468,
    "end": 6865724,
    "text": "私が次に取り組んだのは、ネットワークにおけるスパース性についてだった。"
  },
  {
    "start": 6865764,
    "end": 6869984,
    "text": "トリスタン・ヒュームと出会ったのは、脳の疎密からインスピレーションを得た時だった。"
  },
  {
    "start": 6870284,
    "end": 6883624,
    "text": "anthropicは、ソフトマックスの線形出力ユニット（softmax linear output unit）のソル（solu）をやっていたんですが、これは、層全体のニューロンの活性化を本当にスパースにしよう、そうすれば、ニューロンが何をしているのか、ある程度解釈できるようになる、というような、かなり多くの点で非常に関連性のある仕事でした。"
  },
  {
    "start": 6884284,
    "end": 6887144,
    "text": "今やっていることに向けて、そのアプローチを更新してきたと思う。"
  },
  {
    "start": 6887644,
    "end": 6889108,
    "text": "という会話が始まった。"
  },
  {
    "start": 6889156,
    "end": 6890572,
    "text": "私はその論文の草稿をトリスタンと共有した。"
  },
  {
    "start": 6890628,
    "end": 6897624,
    "text": "トリスタンの専属になり、その後フルタイムになったのは、基本的にそれがきっかけだった。"
  },
  {
    "start": 6898204,
    "end": 6919260,
    "text": "この間、私は客員研究員としてバークレーに移り、ブルーノ・オルシャウゼンとともに、ベクトル記号アーキテクチャと呼ばれる、文字通り重ね合わせを核とする演算と、辞書学習としても知られるスパースコーディングの研究を始めました。"
  },
  {
    "start": 6919332,
    "end": 6923660,
    "text": "ブルーノ・オルシャウゼンは1997年にスパースコーディングを発明した。"
  },
  {
    "start": 6923692,
    "end": 6933588,
    "text": "だから、私の研究課題とインタープリタビリティ・チームは、単なる研究趣味と並行して動いているようなものだった。"
  },
  {
    "start": 6933676,
    "end": 6940380,
    "text": "だから、チームと一緒に仕事をするのはとても意味のあることだった。"
  },
  {
    "start": 6940532,
    "end": 6950610,
    "text": "私が気づいたことのひとつは、人々が自分のキャリアや成功について語るとき、それを偶発的なものだと決めつけてしまうことだ。"
  },
  {
    "start": 6950642,
    "end": 6951306,
    "text": "私の言っている意味がわかるかい？"
  },
  {
    "start": 6951370,
    "end": 6954054,
    "text": "もしそれが起こらなかったら、他のことが起こっていただろう、という感じだ。"
  },
  {
    "start": 6954554,
    "end": 6955962,
    "text": "あなたが話しているときに気づいたんだ。"
  },
  {
    "start": 6956018,
    "end": 6967826,
    "text": "お二人とも、特に偶発的なものだと考えているのは興味深いですね。"
  },
  {
    "start": 6967970,
    "end": 6981030,
    "text": "でも、トリスタンとはある会議で会ったんだけど、特に打ち合わせをしたわけでもなく、ただおしゃべりしている人たちの中に入っていったら、たまたま彼がそこに立っていて、僕が今やっている仕事のことを話したんだ。"
  },
  {
    "start": 6981102,
    "end": 6986794,
    "text": "いずれにせよ、おそらく人類学に出願していたと思うが、少なくともあと1年は待っただろう。"
  },
  {
    "start": 6988814,
    "end": 6993710,
    "text": "自分が解釈可能性に意味のある形で貢献できるなんて、いまだに信じられないよ。"
  },
  {
    "start": 6993862,
    "end": 7003286,
    "text": "いわば、大会に出るという選択自体が、自分をそのポジションに置くようなものなんだ。"
  },
  {
    "start": 7003390,
    "end": 7004942,
    "text": "幸運が起こりやすい場所。"
  },
  {
    "start": 7004998,
    "end": 7019318,
    "text": "ああ、そして逆に、僕自身の状況としては、面白いものを作ったり、やったりするために、このような仕事をすべて単独でやっていたのは、いわば運を味方につけようとしていたようなもので、注目されるような意味のあることをやろうとしていたんだ。"
  },
  {
    "start": 7019406,
    "end": 7021982,
    "text": "という文脈でこれを組み立てたとあなたは言った。"
  },
  {
    "start": 7022038,
    "end": 7024310,
    "text": "彼らは何かを缶詰にする実験を行おうとしていた。"
  },
  {
    "start": 7024382,
    "end": 7028490,
    "text": "具体的には、ジェームスとマネージャーのブレナンがこの実験を書こうとしていたんだと思う。"
  },
  {
    "start": 7028662,
    "end": 7029714,
    "text": "うまくいった。"
  },
  {
    "start": 7029754,
    "end": 7030490,
    "text": "またやったのか？"
  },
  {
    "start": 7030562,
    "end": 7030834,
    "text": "そうだね。"
  },
  {
    "start": 7030874,
    "end": 7038466,
    "text": "私の最も親しい協力者であるエンリケは、サーチから我々のチームへと渡ってきた。"
  },
  {
    "start": 7038650,
    "end": 7040458,
    "text": "彼はとんでもなくインパクトのある選手でもある。"
  },
  {
    "start": 7040506,
    "end": 7044214,
    "text": "彼は間違いなく私より強いエンジニアだし、大学にも行っていない。"
  },
  {
    "start": 7045954,
    "end": 7050794,
    "text": "例えば、ジェームス・ブラッドベリについて特筆すべきは、彼は普段からそういう人物だということだ。"
  },
  {
    "start": 7050874,
    "end": 7060294,
    "text": "この手の仕事はリクルートとかに委託されるんだけど、ジェームズは何億ドルもの価値があるんだ。"
  },
  {
    "start": 7060834,
    "end": 7072974,
    "text": "そのような人が、ほとんど貴族的な家庭教師的な意味で、時間をかけて見つけ、そしてスピードアップすることが非常にネックになる。"
  },
  {
    "start": 7073594,
    "end": 7076610,
    "text": "これだけうまくいったのなら、もっと大規模にやってもいいような気がする。"
  },
  {
    "start": 7076682,
    "end": 7081090,
    "text": "主要人物の責任であるべきだ。"
  },
  {
    "start": 7081122,
    "end": 7081854,
    "text": "機内にて。"
  },
  {
    "start": 7082514,
    "end": 7084274,
    "text": "その通りだと思う。"
  },
  {
    "start": 7084314,
    "end": 7096322,
    "text": "また、オープンソースのリポジトリやフォーラムなどで、このような潜在的な人材を探すこともできる。"
  },
  {
    "start": 7096418,
    "end": 7105602,
    "text": "ええ、つまり、ジェームズはツイッターを脳内ウイルスに注入されたようなものですが、そうです。"
  },
  {
    "start": 7105778,
    "end": 7108106,
    "text": "これは実際に行われていることだと思う。"
  },
  {
    "start": 7108170,
    "end": 7113114,
    "text": "人は、自分が面白いと思う人を探して、その人のシグナルを見つけようとするものだ。"
  },
  {
    "start": 7113274,
    "end": 7126482,
    "text": "実は先日、ジェフとこの話をしていて、ジェフが、そうだ、彼は私がこれまで採用した中で最も重要な人物の一人だ。"
  },
  {
    "start": 7126498,
    "end": 7128054,
    "text": "クリス・オラだ。"
  },
  {
    "start": 7130394,
    "end": 7137404,
    "text": "というのも、クリスも同様に、MLでの正式な経歴がなかったからだ。"
  },
  {
    "start": 7137444,
    "end": 7137596,
    "text": "そうだね。"
  },
  {
    "start": 7137620,
    "end": 7140064,
    "text": "グーグル・ブレインがまだ始まったばかりで、こんな感じだった。"
  },
  {
    "start": 7140804,
    "end": 7147904,
    "text": "ジェフはその信号を見て、レジデンシープログラムも、脳と同じように、あるような気がした。"
  },
  {
    "start": 7148844,
    "end": 7154860,
    "text": "MLBの経歴を持たない優秀な人材を見つけるのに、それは驚くほど効果的だった。"
  },
  {
    "start": 7155052,
    "end": 7178020,
    "text": "そうそう、聴衆の潜在的なスライスに対して強調したいことのひとつは、世界は読みやすく、効率的な企業にはjobs dot google.comやjobs dot whatevercompany.comがあり、そこに応募してステップを踏むという感覚だ。"
  },
  {
    "start": 7178052,
    "end": 7181972,
    "text": "のように、そのステップで効率的に評価してくれる。"
  },
  {
    "start": 7182068,
    "end": 7187600,
    "text": "ストレージ・チームからだけでなく、多くの場合、そうではない。"
  },
  {
    "start": 7187692,
    "end": 7189096,
    "text": "これは実際、世界にとって良いことだ。"
  },
  {
    "start": 7189120,
    "end": 7190336,
    "text": "そういうことはあまりない。"
  },
  {
    "start": 7190400,
    "end": 7199084,
    "text": "自分の研究について興味深い技術的なブログ記事を書くことができたか、あるいは興味深い貢献をしたかを見ることが重要である。"
  },
  {
    "start": 7200184,
    "end": 7200496,
    "text": "そうだね。"
  },
  {
    "start": 7200520,
    "end": 7210136,
    "text": "求人広告の向こう側が、ただ超読みやすく機械的なものだと思い込んでいる人たちのために、リフを打ってほしい。"
  },
  {
    "start": 7210200,
    "end": 7211120,
    "text": "こんなやり方はない。"
  },
  {
    "start": 7211152,
    "end": 7216870,
    "text": "実際、人々はエージェント的で、何かを世に送り出すような、これまでとは違ったタイプの人間を求めている。"
  },
  {
    "start": 7216942,
    "end": 7220054,
    "text": "人々が求めているものは、具体的には2つあると思う。"
  },
  {
    "start": 7220094,
    "end": 7222294,
    "text": "ひとつは代理店であり、自分をそこに出すようなものだ。"
  },
  {
    "start": 7222374,
    "end": 7226614,
    "text": "そしてもうひとつは、世界で通用する能力だ。"
  },
  {
    "start": 7226734,
    "end": 7227174,
    "text": "そうだね。"
  },
  {
    "start": 7227254,
    "end": 7238286,
    "text": "私がいつもここで紹介したい2つの例は、アンソロピックのアンディ・ジョーンズがボードゲームに適用したスケーリング法則に関する素晴らしい論文を発表したことです。"
  },
  {
    "start": 7238310,
    "end": 7239358,
    "text": "大した資源も必要なかった。"
  },
  {
    "start": 7239406,
    "end": 7240886,
    "text": "信じられないほどの技術力を発揮した。"
  },
  {
    "start": 7240910,
    "end": 7244270,
    "text": "当時最も話題になっていたような問題に対して、信じられないような理解を示していた。"
  },
  {
    "start": 7244382,
    "end": 7248656,
    "text": "私の理解では、彼は典型的な学歴の持ち主ではなかった。"
  },
  {
    "start": 7248680,
    "end": 7253724,
    "text": "基本的に、彼がその論文を発表するやいなや、人間科学もオープニング・アイも、あなたをどうしても雇いたいと言ってきた。"
  },
  {
    "start": 7254424,
    "end": 7266044,
    "text": "また、現在Anthropicのパフォーマンスチームで働いているサイモン・ボームという人がいるのですが、彼はGPU上でCUDAマップモデルを最適化するためのリファレンスを書いてくれました。"
  },
  {
    "start": 7266744,
    "end": 7277802,
    "text": "特にうまくはなかったが、あるプロンプトを効果的に取り上げ、その世界的な参考例を作り上げた例を示した。"
  },
  {
    "start": 7277978,
    "end": 7285050,
    "text": "火というのは、信じられないような能力と主体性を示すものだと思う。"
  },
  {
    "start": 7285122,
    "end": 7286298,
    "text": "インタビューは大好きです。"
  },
  {
    "start": 7286386,
    "end": 7287054,
    "text": "雇う。"
  },
  {
    "start": 7287434,
    "end": 7287818,
    "text": "そうだね。"
  },
  {
    "start": 7287866,
    "end": 7293234,
    "text": "ただひとつ付け加えるとすれば、私はまだ採用プロセスや通常の面接、こういったことをすべて経験しなければならなかったということだ。"
  },
  {
    "start": 7293314,
    "end": 7293826,
    "text": "みんなそうだよ。"
  },
  {
    "start": 7293890,
    "end": 7294346,
    "text": "みんなそうだよ。"
  },
  {
    "start": 7294410,
    "end": 7297534,
    "text": "待って、それってバカみたいじゃない？"
  },
  {
    "start": 7298114,
    "end": 7300218,
    "text": "つまり、デビアス？"
  },
  {
    "start": 7300306,
    "end": 7301042,
    "text": "ああ、そうだ。"
  },
  {
    "start": 7301138,
    "end": 7302930,
    "text": "バイアスが欲しいんだろ？"
  },
  {
    "start": 7302962,
    "end": 7307094,
    "text": "例えば、素晴らしいセンスの持ち主とかね。"
  },
  {
    "start": 7307214,
    "end": 7310154,
    "text": "面接のプロセスでは、そのあたりも見極める必要がある。"
  },
  {
    "start": 7310494,
    "end": 7315910,
    "text": "そうだね、一見すごくいいように見える人でも、実はこういうコーディングができないんだ、というケースはあると思う。"
  },
  {
    "start": 7316022,
    "end": 7318230,
    "text": "しかし、これらのものをどれだけ重くするかは間違いなく重要だ。"
  },
  {
    "start": 7318262,
    "end": 7321670,
    "text": "私たちはレファレンスを本当に真剣に受け止めていると思う。"
  },
  {
    "start": 7321782,
    "end": 7324262,
    "text": "インタビューから得られる信号は限られている。"
  },
  {
    "start": 7324398,
    "end": 7329342,
    "text": "だから、その雇用が理にかなっているかどうかには、他にもいろいろなことが絡んでくる。"
  },
  {
    "start": 7329398,
    "end": 7334632,
    "text": "面接は、正しいことをテストするようにデザインすべきだ。"
  },
  {
    "start": 7334728,
    "end": 7337164,
    "text": "ある男の偏見は、別の男の好みなんだよ。"
  },
  {
    "start": 7340824,
    "end": 7345928,
    "text": "強がりという文脈で付け加えるなら、こんなセリフがある。"
  },
  {
    "start": 7345976,
    "end": 7347896,
    "text": "システムは君の味方じゃない。"
  },
  {
    "start": 7348080,
    "end": 7353364,
    "text": "必ずしも積極的に敵対しているとか、不倶戴天の敵であるとかいうわけではない。"
  },
  {
    "start": 7354144,
    "end": 7356312,
    "text": "それはあなたのことを見ていないだけだ。"
  },
  {
    "start": 7356368,
    "end": 7356680,
    "text": "そうだね。"
  },
  {
    "start": 7356752,
    "end": 7362908,
    "text": "だから、積極性の多くは、部屋に大人がいないとか、そういうところから生まれるんだと思う。"
  },
  {
    "start": 7362956,
    "end": 7368820,
    "text": "そして、自分の人生をどうしたいかを決めて、それを実行に移さなければならない。"
  },
  {
    "start": 7368852,
    "end": 7373956,
    "text": "そして、もしあなたがあまりに間違った方法で強気であれば、後で更新してくれることを願うよ。"
  },
  {
    "start": 7374100,
    "end": 7382388,
    "text": "何かを成し遂げるためには、期待に振り回されることなく、ただひたすらある物事に突進しなければならない。"
  },
  {
    "start": 7382556,
    "end": 7393494,
    "text": "最後にもう1つ付け加えたいことがあるんだけど、それは、代理店とか、こういうことについてたくさん話したけど、実は、意外なことに、最も重要なことの1つは、ただ信じられないほどの量を運ぶことだと思うんだ。"
  },
  {
    "start": 7393994,
    "end": 7399866,
    "text": "あなたが信じられないほど多くのことを気にするとき、あなたはすべての詳細をチェックし、何が間違っていた可能性があるのか、この理解を持っていたいと思います。"
  },
  {
    "start": 7399890,
    "end": 7409266,
    "text": "あなたが思っている以上に、それは重要なことなんだ。"
  },
  {
    "start": 7409410,
    "end": 7417178,
    "text": "これはレブロンの名言のようなもので、彼がリーグに入る前、誰もが信じられないほど優れた選手になるのではないかと心配していたことを語っている。"
  },
  {
    "start": 7417266,
    "end": 7422748,
    "text": "経済的に安定すれば、少しはリラックスする。"
  },
  {
    "start": 7422796,
    "end": 7424344,
    "text": "彼は、ああ、これは簡単なことだ。"
  },
  {
    "start": 7424764,
    "end": 7441948,
    "text": "というのも、AIの研究においては、ほとんどの人が実際にかなり深く気にかけているのですが、自分の問題を気にかけることもあれば、スタック全体を気にかけることもあり、上下するすべてのものを気にかけることもあります。"
  },
  {
    "start": 7442036,
    "end": 7451664,
    "text": "つまり、もうひとつ言い忘れたのは、週末やクリスマス休暇に出勤して、オフィスにいるのはジェフ・ディーンとセルゲイ・ブランドだけ、みたいな話をしてたよね。"
  },
  {
    "start": 7452694,
    "end": 7454634,
    "text": "あなたはただ、彼らと一緒にプログラムを支払うことになるようなものだ。"
  },
  {
    "start": 7455214,
    "end": 7457542,
    "text": "ただ、僕にとっては興味深いことなんだ。"
  },
  {
    "start": 7457598,
    "end": 7465634,
    "text": "特に御社を非難するつもりはありませんが、どのような大企業の社員であれ、彼らは非常に厳しい選考を経て入社しています。"
  },
  {
    "start": 7466374,
    "end": 7478622,
    "text": "高校で競争し、大学でも競争しなければならないのに、大学に入ってからのんびりしているように見える。"
  },
  {
    "start": 7478678,
    "end": 7479510,
    "text": "私の言っている意味が分かる？"
  },
  {
    "start": 7479662,
    "end": 7481406,
    "text": "賛否両論あるよね？"
  },
  {
    "start": 7481550,
    "end": 7486674,
    "text": "多くの人が、家族との素晴らしい生活のようなものを優先したいと決断するのだと思う。"
  },
  {
    "start": 7487174,
    "end": 7492230,
    "text": "もし彼らが素晴らしい仕事をしているのであれば、例えば、彼らが1日中働いているわけではないとしよう。"
  },
  {
    "start": 7492262,
    "end": 7496514,
    "text": "彼らは仕事の中で素晴らしい仕事をしている。"
  },
  {
    "start": 7497494,
    "end": 7502230,
    "text": "グーグルの多くの人たちは、一般的なスタートアップ企業ほど労働時間が長くない。"
  },
  {
    "start": 7502262,
    "end": 7503566,
    "text": "Mythologizerの言う通りだ。"
  },
  {
    "start": 7503670,
    "end": 7505838,
    "text": "彼らがしている仕事は、非常に価値のあるものだ。"
  },
  {
    "start": 7505886,
    "end": 7508848,
    "text": "彼らはシステムを熟知しており、その分野の専門家であるため、レバレッジが非常に高い。"
  },
  {
    "start": 7508966,
    "end": 7512084,
    "text": "そういう人たちも必要だ。"
  },
  {
    "start": 7512204,
    "end": 7527624,
    "text": "私たちの世界は、管理が難しく修正が難しい巨大なシステムの上に成り立っており、率直に言って、私たちがやっているAIの仕事ほど宣伝効果が高くない、ありがたくない方法で、そのシステムの作業や修正、保守を手伝い、喜んでやってくれる人たちが必要なのだ。"
  },
  {
    "start": 7528364,
    "end": 7536850,
    "text": "私は、そのような人たちがそうしてくれていることにとんでもなく感謝しているし、自分の仕事に技術的なやりがいを見いだし、それをうまくこなしている人たちがいることにも満足している。"
  },
  {
    "start": 7536882,
    "end": 7540734,
    "text": "また、家族と多くの時間を過ごすことで、より多くのものを引き出しているのかもしれない。"
  },
  {
    "start": 7541274,
    "end": 7550734,
    "text": "僕は幸運なことに、毎週何時間でも働けるような段階にいるんだ。"
  },
  {
    "start": 7551194,
    "end": 7562224,
    "text": "そう、つまり、私の頭の中にある6つの例のように、反対側が「ノー」と言っても、どちらの側でも「イエス」を得ることができる。"
  },
  {
    "start": 7562394,
    "end": 7575664,
    "text": "基本的に、これまで私が獲得した高プロフィールはすべて、たぶん1つか2つの例外を除いては、1週間かけてサンプル質問のリストを作成したんだ。"
  },
  {
    "start": 7576044,
    "end": 7582236,
    "text": "コールドメールを送ったとしても、イエスと言われる確率は2％だ。"
  },
  {
    "start": 7582260,
    "end": 7584304,
    "text": "このリストを含めれば、10％の可能性がある。"
  },
  {
    "start": 7585284,
    "end": 7593264,
    "text": "そうでないと、受信トレイを見ると、34秒ごとにポッドキャストのインタビューや何かのポッドキャストのインタビューがあるからね。"
  },
  {
    "start": 7594004,
    "end": 7596384,
    "text": "毎回、彼らはイエスと言ってくれた。"
  },
  {
    "start": 7597284,
    "end": 7601716,
    "text": "あなたはただ、素晴らしい質問をするのが好きなだけで、何でもやれば勝てる。"
  },
  {
    "start": 7601820,
    "end": 7605324,
    "text": "文字通り、10分間同じ穴を掘り続けなければならない。"
  },
  {
    "start": 7605404,
    "end": 7610944,
    "text": "あるいは、その場合、彼らが通過するためのサンプル質問リストを作るとか、バカリストじゃないとか、そういうことだ。"
  },
  {
    "start": 7611884,
    "end": 7615260,
    "text": "あなたがどれだけ気にかけているか、そして、あなたがどれだけ努力を惜しまないかを示す。"
  },
  {
    "start": 7615292,
    "end": 7616716,
    "text": "ええ、ええ、ええ。"
  },
  {
    "start": 7616860,
    "end": 7631600,
    "text": "ちょっと前に友達に言われたことなんだけど、その言葉が印象に残っているんだ。「ほとんどの人がそんなに努力していなくて、20時間くらいしか働いていないから、あっという間に世界レベルになれるんだ。"
  },
  {
    "start": 7631752,
    "end": 7634880,
    "text": "だから、ハムを食べに行くだけなら、できる。"
  },
  {
    "start": 7634912,
    "end": 7636696,
    "text": "かなりのスピードで遠くまで行ける。"
  },
  {
    "start": 7636800,
    "end": 7639400,
    "text": "フェンシングでもそういう経験ができたのは幸運だったと思う。"
  },
  {
    "start": 7639472,
    "end": 7654410,
    "text": "私は、何かで世界的な選手になる経験をしたし、ただ本当に一生懸命に努力すれば、フェンシングでオリンピックに出場する次の候補として、ショルタが1つ先の席に座っていることを知ったんだ。"
  },
  {
    "start": 7654442,
    "end": 7658534,
    "text": "フェンシングの男子フォイルフェンシングで、私はせいぜい世界42位くらいだった。"
  },
  {
    "start": 7659834,
    "end": 7661654,
    "text": "突然変異の負荷というのはあるんだよ。"
  },
  {
    "start": 7664554,
    "end": 7669954,
    "text": "あるサイクルで、僕はアジアで次のランクにいた。"
  },
  {
    "start": 7670034,
    "end": 7686084,
    "text": "そのサイクルの間、一部で起こっていたように、そしてオーストラリア女子ボートチームに起こったように、もしチームのひとつがドーピングで失格になっていたら、私はその次になっていたと思う。"
  },
  {
    "start": 7687584,
    "end": 7693768,
    "text": "人の前世を知るのは面白いもので、ああ、この人はもう少しでオリンピック選手だったんだ、とかね。"
  },
  {
    "start": 7693816,
    "end": 7694744,
    "text": "もう一人の男は何でもよかった。"
  },
  {
    "start": 7694784,
    "end": 7695724,
    "text": "私の言っている意味が分かる？"
  },
  {
    "start": 7696664,
    "end": 7698738,
    "text": "では、相互運用性について話そう。"
  },
  {
    "start": 7698896,
    "end": 7699634,
    "text": "そうだね。"
  },
  {
    "start": 7700934,
    "end": 7704554,
    "text": "実は、ちょっとのめり込む方法として、脳のことにとどまりたいんだ。"
  },
  {
    "start": 7705734,
    "end": 7718994,
    "text": "以前議論したことだが、脳は残留的な流れを持っていて、それが時間の経過とともに徐々に高次の連想へと洗練されていくような仕組みになっているのだろうか？"
  },
  {
    "start": 7721134,
    "end": 7726148,
    "text": "モデルには寸法が決まっている。"
  },
  {
    "start": 7726236,
    "end": 7731444,
    "text": "どう質問していいのかわからないんだけど、脳のデモドルって何？"
  },
  {
    "start": 7731484,
    "end": 7734636,
    "text": "フィーチャー・スプリッティングの埋め込みの大きさとか、フィーチャー・スプリッティングのせいとか？"
  },
  {
    "start": 7734660,
    "end": 7736024,
    "text": "それは賢明な質問ではないだろうか？"
  },
  {
    "start": 7737164,
    "end": 7738852,
    "text": "いや、賢明な質問だと思う。"
  },
  {
    "start": 7738948,
    "end": 7741944,
    "text": "まあ、理にかなった質問ではある。"
  },
  {
    "start": 7742404,
    "end": 7747344,
    "text": "話せるなんて言わなければいいんだ。"
  },
  {
    "start": 7748844,
    "end": 7749944,
    "text": "そうしようとしているんだ。"
  },
  {
    "start": 7750444,
    "end": 7757454,
    "text": "脳のこの部分は、この次元のベクトルのようなものだ。"
  },
  {
    "start": 7757574,
    "end": 7762594,
    "text": "つまり、ビジュアルストリームでは、V1からV2みたいなものだから、何でもいいんだ。"
  },
  {
    "start": 7763214,
    "end": 7766886,
    "text": "そこにあるニューロンの数を数えて、それが次元数であるかのようにすることもできる。"
  },
  {
    "start": 7766950,
    "end": 7771470,
    "text": "サブモジュールのようなものがあって、物事が分割されている可能性のほうが高そうだ。"
  },
  {
    "start": 7771502,
    "end": 7773966,
    "text": "だから、そうだね。"
  },
  {
    "start": 7774030,
    "end": 7778718,
    "text": "私は世界一の神経科学者ではない。"
  },
  {
    "start": 7778766,
    "end": 7778998,
    "text": "そうだね。"
  },
  {
    "start": 7779046,
    "end": 7780030,
    "text": "私は数年間そうしていた。"
  },
  {
    "start": 7780062,
    "end": 7784984,
    "text": "私は小脳についてかなり勉強したので、これについてはもっといい答えをくれる人がいると思う。"
  },
  {
    "start": 7787924,
    "end": 7788824,
    "text": "どうだ。"
  },
  {
    "start": 7789124,
    "end": 7804664,
    "text": "脳の中であれ、これらのモデルの中であれ、基本的に起こっていることは、特徴が追加されたり、削除されたり、変更されたりすることであり、特徴はモデルの中で起こっていることの基本的な単位なのだとお考えですか？"
  },
  {
    "start": 7805684,
    "end": 7808724,
    "text": "私に何が真実でなければならないか。"
  },
  {
    "start": 7808884,
    "end": 7813584,
    "text": "これは先ほどの話に戻るが、ずっと協会だけなのかどうか。"
  },
  {
    "start": 7814404,
    "end": 7818916,
    "text": "これが真実でない世界での反事実を教えてください。"
  },
  {
    "start": 7819100,
    "end": 7821144,
    "text": "ここでの対立仮説は何か？"
  },
  {
    "start": 7821684,
    "end": 7827104,
    "text": "ええ、今の時点では、この特徴的なスペースの観点から考えることが多いので、考えるのは難しいです。"
  },
  {
    "start": 7829204,
    "end": 7837018,
    "text": "つまり、一時期は認知に対する行動主義的なアプローチがあった。"
  },
  {
    "start": 7837146,
    "end": 7843494,
    "text": "あるいは、インプット・アウトプットのようなもので、実際には何の処理もしていないようなものだ。"
  },
  {
    "start": 7843874,
    "end": 7855254,
    "text": "あるいは、すべてが具現化され、予測可能な方程式に沿って動作する力学的システムにすぎないが、システムには状態がない、というような感じかな。"
  },
  {
    "start": 7856114,
    "end": 7865550,
    "text": "この種の批評を読むたびに、あなたはこのことをステイトと呼ばないことにしているだけで、モデルの内部コンポーネントをステイトと呼ぶことは可能だ、というようなことを言われる。"
  },
  {
    "start": 7865742,
    "end": 7870394,
    "text": "機能についての議論でも、機能とは何かを定義するのは本当に難しい。"
  },
  {
    "start": 7870894,
    "end": 7874594,
    "text": "だから、この質問はあまりに滑稽に感じられる。"
  },
  {
    "start": 7875814,
    "end": 7876914,
    "text": "フィーチャーとは何か？"
  },
  {
    "start": 7878294,
    "end": 7890714,
    "text": "方向性と活性化空間、つまり、あなたが観察しているシステムに対して因果的な影響力を持つ、舞台裏で動いている潜在変数。"
  },
  {
    "start": 7890834,
    "end": 7892162,
    "text": "ええと、これは機能なんだ。"
  },
  {
    "start": 7892218,
    "end": 7894826,
    "text": "それを \"機能 \"と呼ぶなら、それはトートロジーだ。"
  },
  {
    "start": 7894890,
    "end": 7896794,
    "text": "ええと、その、これは。"
  },
  {
    "start": 7896834,
    "end": 7908378,
    "text": "これらはすべて、非常に大雑把で直感的な意味で、何かがオンになっているかオフになっているかというような、十分にスパースな、二値ベクトルの特徴に、何らかの関連性を感じる説明だ。"
  },
  {
    "start": 7908426,
    "end": 7908946,
    "text": "そうだね。"
  },
  {
    "start": 7909010,
    "end": 7910258,
    "text": "非常に単純な意味でね。"
  },
  {
    "start": 7910306,
    "end": 7910898,
    "text": "そうだね。"
  },
  {
    "start": 7911066,
    "end": 7913442,
    "text": "それを理解するのに便利な比喩かもしれない。"
  },
  {
    "start": 7913498,
    "end": 7920844,
    "text": "神経科学者がニューロンの活性化について話すのと同じようなものだ。"
  },
  {
    "start": 7920964,
    "end": 7921624,
    "text": "そうだね。"
  },
  {
    "start": 7922004,
    "end": 7924580,
    "text": "そのニューロンが特定の何かに対応している場合。"
  },
  {
    "start": 7924652,
    "end": 7924908,
    "text": "そうだろう？"
  },
  {
    "start": 7924956,
    "end": 7926316,
    "text": "イエスでもありノーでもある。"
  },
  {
    "start": 7926340,
    "end": 7929268,
    "text": "機能って何だろう？"
  },
  {
    "start": 7929316,
    "end": 7929572,
    "text": "そうだろう？"
  },
  {
    "start": 7929628,
    "end": 7932572,
    "text": "例えば、その機能が存在する合成的な問題とは何か？"
  },
  {
    "start": 7932668,
    "end": 7943784,
    "text": "単意味性（mono semanticity）の仕事であっても、私たちは特徴分割（feature splitting）と呼ばれるものについて話している。"
  },
  {
    "start": 7944634,
    "end": 7950986,
    "text": "ここでいうモデルとは、オリジナルのモデルをトレーニングした後にフィットさせたアッププロジェクションのことである。"
  },
  {
    "start": 7951130,
    "end": 7955134,
    "text": "だから、あまり容量を与えなければ、鳥のための機能を学習してくれる。"
  },
  {
    "start": 7955514,
    "end": 7961494,
    "text": "より多くの能力を与えれば、カラスやワシやスズメのように、特定の種類の鳥のように学習する。"
  },
  {
    "start": 7963394,
    "end": 7974394,
    "text": "まだ定義的なことを言うと、僕は素朴に鳥のようなものと、どんなトークンのようなものを考えているんだと思う。"
  },
  {
    "start": 7974434,
    "end": 7988494,
    "text": "先ほどのハイパーリンクの末尾のピリオドのようなものなのか、それとも愛や欺瞞のような最高レベルのものなのか、あるいは非常に複雑な証明を頭の中に抱えているようなものなのか。"
  },
  {
    "start": 7988914,
    "end": 7989930,
    "text": "これがすべての機能ですか？"
  },
  {
    "start": 7989962,
    "end": 8001058,
    "text": "というのも、その定義があまりに広すぎて、ほとんど役に立たないというか、これらのものには重要な違いがあるように思えるし、それらはすべて機能だからだ。"
  },
  {
    "start": 8001226,
    "end": 8019666,
    "text": "つまり、これらのものはすべて、他のものとのつながりがある個別の単位のようなもので、それによって、有用な、あるいは包括的すぎない、十分に具体的な定義のような意味が付与されるんだ。"
  },
  {
    "start": 8019690,
    "end": 8020850,
    "text": "遠慮なく押し返してほしい。"
  },
  {
    "start": 8021002,
    "end": 8029124,
    "text": "モデルの中で起こっていることについて、根本的に間違った考え方をしているような気がする。"
  },
  {
    "start": 8030664,
    "end": 8047328,
    "text": "つまり、私たちが発見した特徴が予測的でなかった場合、あるいはデータの単なる表現に過ぎず、データをクラスタリングしているだけで、より高度な関連付けがなされていない場合だ。"
  },
  {
    "start": 8047456,
    "end": 8060446,
    "text": "あるいは、この機能は結婚のために発火すると言っているが、それを本当に強く活性化させても、それに対応するような形でモデルの出力が変化しないというような現象論的なものだ。"
  },
  {
    "start": 8060550,
    "end": 8063422,
    "text": "どちらも良い批評になると思う。"
  },
  {
    "start": 8063598,
    "end": 8073150,
    "text": "もうひとつは、MNISTという数字画像のデータセットで実験してみたのですが、あまり詳しく調べませんでした。"
  },
  {
    "start": 8073182,
    "end": 8076794,
    "text": "だから、もし他の人たちがもっと深い調査をしたいのであれば、私は興味がある。"
  },
  {
    "start": 8077134,
    "end": 8085884,
    "text": "あなたの潜在的な表現空間は密であり、このような離散的な点ではなく、多様体であるというのはもっともなことだ。"
  },
  {
    "start": 8086784,
    "end": 8092644,
    "text": "だから、マニホールドを横切って移動することも可能だが、どのポイントでも何らかの意味のある挙動を示すことになる。"
  },
  {
    "start": 8093104,
    "end": 8100872,
    "text": "それなら、素朴なアウトサイダー的なやり方で、物事に個別的な特徴というレッテルを貼るほうがずっと難しい。"
  },
  {
    "start": 8100928,
    "end": 8117482,
    "text": "この写真が間違っている可能性があるのは、これがオンになっていたりオフになっていたりするのではなく、システムがもっとグローバルなものである場合だと思う。"
  },
  {
    "start": 8117538,
    "end": 8120298,
    "text": "フロイト的な言葉で測ったんだ。"
  },
  {
    "start": 8120346,
    "end": 8124574,
    "text": "何かいい例えはないだろうか？"
  },
  {
    "start": 8127234,
    "end": 8135490,
    "text": "ああ、物理法則みたいなものを考えてみると、濡れる機能がオンになっているけど、この程度しかオンになっていない、みたいなことはないんだろうね。"
  },
  {
    "start": 8135522,
    "end": 8146814,
    "text": "というのも、質量はグラデーションのようなもので、極性なども同様にグラデーションだからだ。"
  },
  {
    "start": 8147554,
    "end": 8154218,
    "text": "法律があり、法律はより一般的で、一般的な全体像を理解しなければならないという意味もある。"
  },
  {
    "start": 8154386,
    "end": 8159250,
    "text": "このような、特定のサブサーキットのようなものからは得られない。"
  },
  {
    "start": 8159282,
    "end": 8162250,
    "text": "そこで、推理回路そのものが活躍するんだろ？"
  },
  {
    "start": 8162282,
    "end": 8174348,
    "text": "これらの機能を理想的な形にして、より高いレベルのものに比較しようとする場合、例えば、少なくともこれは私のヘッドキャノンで、足のfイコールmaを使おうとしているとします。"
  },
  {
    "start": 8174516,
    "end": 8184644,
    "text": "おそらく、ある時点で質量を示す特徴があって、それが使っている物の実際の質量を取り出すのに役立っている。"
  },
  {
    "start": 8184684,
    "end": 8189892,
    "text": "となると、物理学の第一法則を使うことに対応する、より高度な機能があるのかもしれない。"
  },
  {
    "start": 8189948,
    "end": 8190412,
    "text": "たぶんね。"
  },
  {
    "start": 8190508,
    "end": 8201412,
    "text": "より重要なのは、関連する情報の断片を検索し、必要に応じて乗算演算子などを生成するのに役立つコンポーネントの構成だ。"
  },
  {
    "start": 8201548,
    "end": 8203036,
    "text": "少なくとも、それが私の頭の中のカノンだ。"
  },
  {
    "start": 8203140,
    "end": 8207944,
    "text": "あなたにとって説得力のある説明とは何ですか？"
  },
  {
    "start": 8209684,
    "end": 8213780,
    "text": "なぜこのような出力になったのかは理解できるし、それは正当な理由によるものだ。"
  },
  {
    "start": 8213932,
    "end": 8221104,
    "text": "もし100万行のプルリクエストか何かをやっているのなら、リクエストの最後に何が見えるか。"
  },
  {
    "start": 8222324,
    "end": 8222748,
    "text": "そうだね。"
  },
  {
    "start": 8222796,
    "end": 8225864,
    "text": "辞書学習をモデルに適用するのが理想的だ。"
  },
  {
    "start": 8226164,
    "end": 8227544,
    "text": "特徴を見つけたね。"
  },
  {
    "start": 8228484,
    "end": 8234220,
    "text": "今、私たちはアテンション・ヘッドで同じような成功を収めようと積極的に取り組んでいる。"
  },
  {
    "start": 8234292,
    "end": 8238180,
    "text": "残差ストリームMLPとモデル全体を通して注目することができます。"
  },
  {
    "start": 8238372,
    "end": 8246358,
    "text": "うまくいけば、その時点で、より一般的な推理能力である、より広い回路をモデルを通して特定することもできる。"
  },
  {
    "start": 8246406,
    "end": 8260998,
    "text": "あなたの場合、このプルリクエストを承認すべきかどうかを見極めようとしているわけですが、欺瞞的な行動や悪意ある行動、こういった種類のものに対応する機能にフラグを立てたり検出したりして、それらが発火したかどうかを確認することができると思います。"
  },
  {
    "start": 8261126,
    "end": 8262494,
    "text": "それは即席のようなものだ。"
  },
  {
    "start": 8262614,
    "end": 8264686,
    "text": "それ以上のこともできるが、それはすぐにできることだ。"
  },
  {
    "start": 8264830,
    "end": 8269246,
    "text": "その前に、推論回路はどうなっているのだろう？"
  },
  {
    "start": 8269270,
    "end": 8271056,
    "text": "それを見つけたら、どんなふうに見えるだろう？"
  },
  {
    "start": 8271190,
    "end": 8271476,
    "text": "そうだね。"
  },
  {
    "start": 8271500,
    "end": 8275036,
    "text": "つまり、IHヘッドは最も単純な推論の一つだろう？"
  },
  {
    "start": 8275100,
    "end": 8276820,
    "text": "まあ、つまり、推論というのは？"
  },
  {
    "start": 8276852,
    "end": 8277020,
    "text": "そうだろう？"
  },
  {
    "start": 8277052,
    "end": 8281508,
    "text": "それなりの理由がある。"
  },
  {
    "start": 8281636,
    "end": 8283580,
    "text": "リスナーには文脈があると思う。"
  },
  {
    "start": 8283652,
    "end": 8285132,
    "text": "IHヘッドは基本的に"
  },
  {
    "start": 8285308,
    "end": 8290748,
    "text": "ダーズリー夫妻が何かしたようなセリフがあるじゃないか、ミスター・ブランク。"
  },
  {
    "start": 8290796,
    "end": 8292684,
    "text": "ブランクとは何かを予測しようとしている。"
  },
  {
    "start": 8292804,
    "end": 8306189,
    "text": "頭脳は、ミスターという単語が過去に使われた単語を探し、その単語の後に来る単語を調べ、次に来る単語の予測としてそれをコピー＆ペーストすることを学習している。"
  },
  {
    "start": 8306341,
    "end": 8311673,
    "text": "そこでは、次のトークンを正確に予測するための計算が行われている。"
  },
  {
    "start": 8314213,
    "end": 8315669,
    "text": "それは文脈に左右される。"
  },
  {
    "start": 8315781,
    "end": 8318997,
    "text": "ああ、でもそれは理屈じゃない。"
  },
  {
    "start": 8319045,
    "end": 8319993,
    "text": "私の言っている意味が分かる？"
  },
  {
    "start": 8320293,
    "end": 8344890,
    "text": "しかし、このゼロショットのケースでは、新しいゲームを手にすると、すぐにそのプレーの仕方を理解し始めるようなことが起きている。"
  },
  {
    "start": 8345082,
    "end": 8353772,
    "text": "まあ、ピクセルを抽出して、ゲーム内のさまざまなオブジェクトの潜在的な表現に変えるための別の回路があると思う。"
  },
  {
    "start": 8353828,
    "end": 8354308,
    "text": "そうだね。"
  },
  {
    "start": 8354436,
    "end": 8358356,
    "text": "物理を学ぶ回路のようなものだ。"
  },
  {
    "start": 8358420,
    "end": 8362356,
    "text": "インダクションヘッドは1層のトランスのようなものなので、2層が必要だ。"
  },
  {
    "start": 8362420,
    "end": 8363140,
    "text": "そうだね。"
  },
  {
    "start": 8363332,
    "end": 8369064,
    "text": "人間が新しいゲームを手にし、それを理解するということがどういうことなのか、なんとなくわかるだろう。"
  },
  {
    "start": 8370324,
    "end": 8371756,
    "text": "それが何なのか、あなたならどう考える？"
  },
  {
    "start": 8371780,
    "end": 8372580,
    "text": "そうなのか。"
  },
  {
    "start": 8372772,
    "end": 8376780,
    "text": "おそらく複数のレイヤーにまたがっているのだろう。"
  },
  {
    "start": 8376852,
    "end": 8377412,
    "text": "そうだね。"
  },
  {
    "start": 8377548,
    "end": 8379264,
    "text": "それは物理的にどのように見えるだろうか？"
  },
  {
    "start": 8380884,
    "end": 8381692,
    "text": "どれくらいの大きさになるのだろう？"
  },
  {
    "start": 8381708,
    "end": 8382036,
    "text": "たぶんね。"
  },
  {
    "start": 8382100,
    "end": 8387820,
    "text": "つまり、このタスクを実行するために、モデルはどれくらいの大きさが必要なのか？"
  },
  {
    "start": 8387852,
    "end": 8390884,
    "text": "でも、僕らが見てきた他の回路について話した方が役に立つかもしれないね。"
  },
  {
    "start": 8390924,
    "end": 8395988,
    "text": "IOI回路（間接目的語識別回路）を見てきた。"
  },
  {
    "start": 8396116,
    "end": 8404596,
    "text": "つまり、メアリーとジムが店に行き、ジムがブランクに物を渡したようなものだ。"
  },
  {
    "start": 8404700,
    "end": 8405132,
    "text": "そうだね。"
  },
  {
    "start": 8405228,
    "end": 8409124,
    "text": "というのは、メアリーは以前にも間接目的語として登場しているからだ。"
  },
  {
    "start": 8409204,
    "end": 8411716,
    "text": "あるいは代名詞を推測する。"
  },
  {
    "start": 8411820,
    "end": 8412464,
    "text": "そうだね。"
  },
  {
    "start": 8413364,
    "end": 8421904,
    "text": "この回路は、もしアブレートすれば、モデル内の他のヘッドがその挙動を拾うような挙動さえする。"
  },
  {
    "start": 8422444,
    "end": 8426788,
    "text": "コピー行為をしたがるヘッドを見つけ、他のヘッドがそれを抑制する。"
  },
  {
    "start": 8426956,
    "end": 8435358,
    "text": "例えば、1つ前のトークンとか、5つ前のトークンとか、そういうのを常にコピーするのが、1つの仕事、1つのヘッドの仕事なんだ。"
  },
  {
    "start": 8435446,
    "end": 8439434,
    "text": "だから、それを真似するなというのは、もう一人の監督の仕事だ。"
  },
  {
    "start": 8440694,
    "end": 8451374,
    "text": "このような場合、非常に基本的な操作を実行するさまざまな回路があるが、それらを連鎖させることで、ユニークな動作を得ることができる。"
  },
  {
    "start": 8451494,
    "end": 8461014,
    "text": "というのも、2層のトランスフォーマーでは、それを理解することができないか、あるいは本当に理解できないからだ。"
  },
  {
    "start": 8461094,
    "end": 8465114,
    "text": "欺瞞のための回路か何かになるのか？"
  },
  {
    "start": 8465934,
    "end": 8473534,
    "text": "ネットワークのこの部分は、私たちが最後にそのことを欺瞞的であると識別したときに発火し、私たちが欺瞞的であると識別しなかったときには発火しなかった。"
  },
  {
    "start": 8473574,
    "end": 8475794,
    "text": "したがって、これが欺瞞回路に違いない。"
  },
  {
    "start": 8476574,
    "end": 8493036,
    "text": "おべんちゃらとは、モデルが最後にあなたが聞きたいと思うことを言うようなもので、どれが悪くてどれが善いかのレッテルを貼ることができる。"
  },
  {
    "start": 8493100,
    "end": 8494228,
    "text": "ああ、だからたくさんの事例があるんだ。"
  },
  {
    "start": 8494276,
    "end": 8517520,
    "text": "モデルを大きくすればするほど、モデルは明らかに、他人の心をモデル化するような特徴を持つようになり、これらの機能が活性化され、ここで仮説を立てたこれらのサブセットが、より欺瞞的な行動と関連するようになります。"
  },
  {
    "start": 8517592,
    "end": 8522376,
    "text": "RLA、心の理論の総体みたいなものだから、たぶん僕をモデルにしているんだと思う。"
  },
  {
    "start": 8522440,
    "end": 8523072,
    "text": "ああ、そうだ。"
  },
  {
    "start": 8523128,
    "end": 8527872,
    "text": "だから、まず第一に、先ほどおっしゃった冗長性がある。"
  },
  {
    "start": 8527968,
    "end": 8533040,
    "text": "それなら、全体を欺く可能性のあるようなものをつかんだのか、ということになる。"
  },
  {
    "start": 8533072,
    "end": 8535136,
    "text": "それとも、ひとつの例なのか？"
  },
  {
    "start": 8535280,
    "end": 8535810,
    "text": "そうだね。"
  },
  {
    "start": 8535912,
    "end": 8537502,
    "text": "次に、あなたのラベルは正しいですか？"
  },
  {
    "start": 8537558,
    "end": 8539926,
    "text": "たぶん、あなたもそうだと思うけど、これは欺瞞ではない。"
  },
  {
    "start": 8539950,
    "end": 8543474,
    "text": "特に、理解できないようなアウトプットを出している場合は、まだ騙されているようなものだ。"
  },
  {
    "start": 8543774,
    "end": 8550510,
    "text": "3つ目は、悪い結果になりそうなもので、誰にでも理解できるもの、例えば欺瞞は私たちにも理解できる概念だ。"
  },
  {
    "start": 8550622,
    "end": 8551622,
    "text": "みたいなものがあるのかもしれない。"
  },
  {
    "start": 8551718,
    "end": 8552350,
    "text": "ああ、そうだ。"
  },
  {
    "start": 8552382,
    "end": 8553334,
    "text": "ここで解き明かさなければならないことがたくさんある。"
  },
  {
    "start": 8553374,
    "end": 8555062,
    "text": "いくつかあると思う。"
  },
  {
    "start": 8555118,
    "end": 8559446,
    "text": "一つは、これらのモデルが決定論的であることが素晴らしい。"
  },
  {
    "start": 8559510,
    "end": 8560382,
    "text": "彼らからサンプリングするときにね。"
  },
  {
    "start": 8560398,
    "end": 8561254,
    "text": "確率的なものだ。"
  },
  {
    "start": 8561294,
    "end": 8566684,
    "text": "でも、インプットをどんどん入れて、モデルのあらゆる部分を削り取ることができるんだ。"
  },
  {
    "start": 8566764,
    "end": 8569996,
    "text": "これは、計算神経科学者に解釈可能性の研究に来てほしいという売り込みのようなものだ。"
  },
  {
    "start": 8570060,
    "end": 8575652,
    "text": "まるでエイリアンの脳を持っているようなもので、その中のすべてにアクセスできる。"
  },
  {
    "start": 8575748,
    "end": 8580444,
    "text": "だから、十分に注意深くやれば、どのような回路が関係しているのかを突き止めることができると思う。"
  },
  {
    "start": 8580484,
    "end": 8582904,
    "text": "バックアップ回路はどうなっているんだ？"
  },
  {
    "start": 8583444,
    "end": 8588556,
    "text": "ここでの対処療法的な答えだが、覚えておくべき重要なことは、解釈可能性を自動化することだ。"
  },
  {
    "start": 8588660,
    "end": 8600098,
    "text": "私たちのモデルがより高性能になるにつれて、ラベルを割り当てたり、スケールの大きな実験を行ったりすることができるようになる。"
  },
  {
    "start": 8600186,
    "end": 8604414,
    "text": "というのが、あなたの質問の最後の部分だったと思う。"
  },
  {
    "start": 8605354,
    "end": 8614378,
    "text": "この連想をずっと買い続けていけば、あるレベルで表現を粗くすることができるはずだ。"
  },
  {
    "start": 8614506,
    "end": 8624744,
    "text": "デマスのポッドキャストでも、チェスの棋士が超人的な動きをした場合、なぜそうしたのか、その理由を説明できるようにすべきだというようなことを話していたと思う。"
  },
  {
    "start": 8625044,
    "end": 8639020,
    "text": "たとえモデルがそれが何であるかを教えてくれなくても、複雑な動作をより単純な回路や機能に分解して、なぜそのような動作をするのかを理解することができるはずだ。"
  },
  {
    "start": 8639212,
    "end": 8646978,
    "text": "そのような表現が存在するかどうかという別の問題がある。"
  },
  {
    "start": 8647076,
    "end": 8658274,
    "text": "第二に、このスパース・ルート・エンコーダーのセットアップを使えば、この場合、それを見つけることができるかどうかだが、それを表現するのに十分なラベルがなければ、見つけることはできないだろう？"
  },
  {
    "start": 8659694,
    "end": 8660954,
    "text": "イエスでもありノーでもある。"
  },
  {
    "start": 8661374,
    "end": 8667470,
    "text": "先ほど話したスリーパーエージェントの仕事では、今、辞書学習を積極的に使おうとしている。"
  },
  {
    "start": 8667542,
    "end": 8673006,
    "text": "あるモデルを渡したとして、そのモデルの中にトリガーとなるものがあって、そのトリガーが面白い行動を始めるかどうかを教えてくれる？"
  },
  {
    "start": 8673190,
    "end": 8694062,
    "text": "というのも、その行動を学習するときに、実際にその行動を表示させることなく、より一般的な回路の一部であることがわかるかどうかは未解決だからだ。"
  },
  {
    "start": 8694158,
    "end": 8708084,
    "text": "というのも、基本的に各特徴は表現空間のある部分にあり、それらはすべて互いに対して存在するからだ。"
  },
  {
    "start": 8708204,
    "end": 8717212,
    "text": "だから、この新しい振る舞いを実現するためには、特徴空間の一部をその新しい振る舞いのために切り分け、そのスペースを確保するために他のすべてを押し出す必要がある。"
  },
  {
    "start": 8717388,
    "end": 8722228,
    "text": "仮に、この悪い行動を教える前にモデルを手に入れたとする。"
  },
  {
    "start": 8722396,
    "end": 8725644,
    "text": "あなたはすべての特徴を知っているか、ある程度粗く表現している。"
  },
  {
    "start": 8725764,
    "end": 8728772,
    "text": "そして、それが悪意あるものになるように微調整する。"
  },
  {
    "start": 8728908,
    "end": 8734884,
    "text": "そうすれば、特徴空間のブラックホール領域を特定することができる。"
  },
  {
    "start": 8734964,
    "end": 8739224,
    "text": "このリージョンがあるのに、そのリージョンを発火させる入力を入れていない。"
  },
  {
    "start": 8739564,
    "end": 8744388,
    "text": "そうすれば、空間のこの部分を発火させる入力は何かを探し始めることができる。"
  },
  {
    "start": 8744516,
    "end": 8746692,
    "text": "このスペースで何かを起動させたらどうなりますか？"
  },
  {
    "start": 8746828,
    "end": 8749784,
    "text": "この問題を解決する方法は他にもたくさんある。"
  },
  {
    "start": 8751004,
    "end": 8763796,
    "text": "これは余談だが、私が聞いた興味深いアイデアのひとつは、もしそのスペースがモデル間で共有されているのであれば、オープンソースのモデルでそれを見つけ、ジェンマのように作ろうとすることが想像できる、というものだった。"
  },
  {
    "start": 8763900,
    "end": 8771876,
    "text": "ちなみにgemmaは、グーグルが新しくリリースしたオープンソースのモデルで、同じアーキテクチャを使ってトレーニングされていると論文の中で述べている。"
  },
  {
    "start": 8772020,
    "end": 8775188,
    "text": "正直なところ、似たようなゲマ論文を読んでいないのでわからない。"
  },
  {
    "start": 8775276,
    "end": 8777932,
    "text": "これは双子座として何でもあることだ。"
  },
  {
    "start": 8778028,
    "end": 8786080,
    "text": "それが本当なら、ジェンマでやっているレク・チーミングがジェミニへの脱獄にどれだけ役立っているかはわからない。"
  },
  {
    "start": 8786152,
    "end": 8791944,
    "text": "そう、これは、モデル間でどの程度普遍的な特徴なのか、そして私たちの単意味論に向けた論文という、楽しい空間に入っていくんだ。"
  },
  {
    "start": 8791984,
    "end": 8808650,
    "text": "ちょっと調べてみたところ、要約した統計は出せないが、例えば、ベース64機能は、多くのモデルで見られるが、実際には3つある。"
  },
  {
    "start": 8808682,
    "end": 8810494,
    "text": "トレーニング・データにはURLがたくさんある。"
  },
  {
    "start": 8810914,
    "end": 8813610,
    "text": "モデル間のコサイン類似度は非常に高い。"
  },
  {
    "start": 8813722,
    "end": 8817954,
    "text": "彼らは皆、ローテーションの中でこの機能を習得するんだけど、まるでね。"
  },
  {
    "start": 8817994,
    "end": 8820794,
    "text": "ああ、でも実際のベクター自体はね。"
  },
  {
    "start": 8820914,
    "end": 8833678,
    "text": "ええ、私はこの分析には参加していませんが、ええ、2つのモデル（同じモデル・アーキテクチャだが、異なるランダムシードで訓練されたモデル）で、確かに特徴を見つけ、互いにかなり似ています。"
  },
  {
    "start": 8833726,
    "end": 8847766,
    "text": "それは、同じようなデータセットに対して、すべてのモデルが同じ特徴を同じ順序で学習するという仮説のようなもので、大まかに言えば、nグラムを学習し、帰納法の頭を学習し、数字の行の後に完全な停止を置くことを学習するといったようなものです。"
  },
  {
    "start": 8847870,
    "end": 8848342,
    "text": "ところで。"
  },
  {
    "start": 8848358,
    "end": 8851150,
    "text": "さて、これはまた余談だが、それは事実だ。"
  },
  {
    "start": 8851222,
    "end": 8853214,
    "text": "そして、それが本当だという証拠があるんだ。"
  },
  {
    "start": 8853334,
    "end": 8855078,
    "text": "なぜカリキュラム学習はうまくいかないのか？"
  },
  {
    "start": 8855206,
    "end": 8860828,
    "text": "というのも、あることを先に学ぶのであれば、そのことを先にトレーニングした方が良い結果につながるということなのだろうか？"
  },
  {
    "start": 8860916,
    "end": 8864412,
    "text": "ジェミニの両論文は、カリキュラムの学習面について言及している。"
  },
  {
    "start": 8864468,
    "end": 8865084,
    "text": "なるほど、興味深い。"
  },
  {
    "start": 8865164,
    "end": 8868444,
    "text": "つまり、微調整がうまくいくということは、カリキュラムを学んでいる証拠だと思う。"
  },
  {
    "start": 8868484,
    "end": 8868684,
    "text": "そうだね。"
  },
  {
    "start": 8868724,
    "end": 8872744,
    "text": "最後にトレーニングすることが、不釣り合いな影響を与えるからだ。"
  },
  {
    "start": 8873764,
    "end": 8878396,
    "text": "必ずしも、微調整に特化したひとつの思考様式があるとは言えない。"
  },
  {
    "start": 8878460,
    "end": 8881884,
    "text": "あなたは潜在的な能力の束を持っていて、以前から特化しているようなものだ。"
  },
  {
    "start": 8882004,
    "end": 8884852,
    "text": "それは、あなたが望むような特定のユースケースだ。"
  },
  {
    "start": 8884988,
    "end": 8886148,
    "text": "真偽のほどはわからない。"
  },
  {
    "start": 8886196,
    "end": 8888426,
    "text": "デービッド・ベル研究所の論文もこれを裏付けていると思う。"
  },
  {
    "start": 8888450,
    "end": 8888586,
    "text": "そうだろう？"
  },
  {
    "start": 8888610,
    "end": 8891618,
    "text": "その能力があって、実体を認識するのがうまくなっているんだろ？"
  },
  {
    "start": 8891666,
    "end": 8893826,
    "text": "他の回路の代わりにその回路を微調整するとかね。"
  },
  {
    "start": 8893890,
    "end": 8896586,
    "text": "ええ、ええ、すみません、さっきの話は何だったんですか？"
  },
  {
    "start": 8896650,
    "end": 8898906,
    "text": "一般的に、カリキュラム学習は本当に面白いと思う。"
  },
  {
    "start": 8898970,
    "end": 8902034,
    "text": "人々はもっと探求すべきだし、それはとてももっともなことのように思える。"
  },
  {
    "start": 8902074,
    "end": 8907778,
    "text": "量子論のような分析をもっと見てみたい。"
  },
  {
    "start": 8907826,
    "end": 8909346,
    "text": "各段階で実際に何を学ぶのか？"
  },
  {
    "start": 8909410,
    "end": 8913710,
    "text": "そして、それを分解して、カリキュラムがそれを変えたかどうかを探るんだ。"
  },
  {
    "start": 8913802,
    "end": 8916766,
    "text": "そういえば、今気づいたんだけど、忘れてた。"
  },
  {
    "start": 8916910,
    "end": 8919790,
    "text": "ただ、会話モードに入ってしまって、観客がいることを忘れてしまったんだ。"
  },
  {
    "start": 8919902,
    "end": 8924846,
    "text": "カリキュラム学習とは、データセットを整理することであり、人間がどのように学習するかを考えることだ。"
  },
  {
    "start": 8924910,
    "end": 8928470,
    "text": "Wikiのランダムな文章を見て、それを予測しようとはしないだろ？"
  },
  {
    "start": 8928502,
    "end": 8934074,
    "text": "最初は『ロラックス』とかから始めるから、それから勉強してくれ、みたいな。"
  },
  {
    "start": 8934454,
    "end": 8939634,
    "text": "1年生がどんなだったか覚えていないけど、1年生が学ぶことを2年生とかでも学ぶんだ。"
  },
  {
    "start": 8940074,
    "end": 8941330,
    "text": "そう想像するだろう。"
  },
  {
    "start": 8941442,
    "end": 8943334,
    "text": "私たちは、あなたが小学校1年生を卒業できなかったことを知っている。"
  },
  {
    "start": 8957954,
    "end": 8960898,
    "text": "さて、とにかく、大きな話に戻ろう。"
  },
  {
    "start": 8960946,
    "end": 8963962,
    "text": "その前に、細かい話を中断しよう。"
  },
  {
    "start": 8964058,
    "end": 8965094,
    "text": "全体像"
  },
  {
    "start": 8965534,
    "end": 8969354,
    "text": "ええと、2つのスレッドがあるんだ。"
  },
  {
    "start": 8969774,
    "end": 8982806,
    "text": "第一に、このアプローチを無効にするような、これらのモデルで起こりうることについての代替的な定式化さえないことが、少し心配になる。"
  },
  {
    "start": 8982830,
    "end": 8984790,
    "text": "ここには未知の未知がある。"
  },
  {
    "start": 8984862,
    "end": 8988758,
    "text": "だから、帰無仮説が存在しないという事実は、私にはわからない。"
  },
  {
    "start": 8988766,
    "end": 8995410,
    "text": "もし、僕らが間違っていて、間違っている方法すらわからないとしたらどうだろう。"
  },
  {
    "start": 8995482,
    "end": 8997054,
    "text": "そうそう、そうそう。"
  },
  {
    "start": 8997394,
    "end": 9000426,
    "text": "他の仮説がないわけではない。"
  },
  {
    "start": 9000530,
    "end": 9017626,
    "text": "ただ、私は何年も重ね合わせの研究をしていて、この取り組みに深く関わってきた。だから、他のアプローチにはあまり共感できないし、彼らが今言ったように、間違っていると思う。"
  },
  {
    "start": 9017650,
    "end": 9017882,
    "text": "そうだね。"
  },
  {
    "start": 9017938,
    "end": 9019890,
    "text": "説明力もかなり高い。"
  },
  {
    "start": 9019962,
    "end": 9021186,
    "text": "ああ、こんな美しいものがあるんだ。"
  },
  {
    "start": 9021210,
    "end": 9026754,
    "text": "例えば、スケーリング法則の論文では、あるスケーリング法則の論文のところに小さな段差がある。"
  },
  {
    "start": 9027334,
    "end": 9031542,
    "text": "これは明らかに、モデルが帰納法を学習するタイミングに対応している。"
  },
  {
    "start": 9031598,
    "end": 9033590,
    "text": "その後、軌道を外れる。"
  },
  {
    "start": 9033662,
    "end": 9039674,
    "text": "インダクションヘッドを学び、軌道に戻る、これは驚くべき遡及的説明力の一部である。"
  },
  {
    "start": 9041174,
    "end": 9046634,
    "text": "しかし、それを忘れる前に、将来の普遍性に関するスレッドを1つ持っている。"
  },
  {
    "start": 9047334,
    "end": 9054744,
    "text": "人間が世界の本当の姿を学ぶべきか否かについては、行動進化生物学的に実に興味深い実験がある。"
  },
  {
    "start": 9054904,
    "end": 9061568,
    "text": "すべての毒のある動物が、ネオンピンクの点滅のように見える世界を想像してみてほしい。"
  },
  {
    "start": 9061696,
    "end": 9065884,
    "text": "だから、現実的な世界を表現できないのは理にかなっている。"
  },
  {
    "start": 9066704,
    "end": 9080280,
    "text": "小さな基本的なエージェントをシミュレートし、彼らが学んだ表現が、彼らが使えるツールや持つべきインプットに対応するかどうかを確認する仕事もある。"
  },
  {
    "start": 9080432,
    "end": 9105004,
    "text": "というのも、ベースとなるオブジェクトに必要なユースケースは非常にたくさん考えられるため、安っぽい視覚的なものやヒューリスティックなものなどではなく、実際にオブジェクトが何であるかを学習したいのです。"
  },
  {
    "start": 9105784,
    "end": 9133974,
    "text": "フリスタンの自由エネルギー原理や予測符号化などについては全く話していませんが、すべての生物が次に何が起こるかを積極的に予測し、本当に正確な世界モデルを形成しようとしている程度であれば、私は驚かないし、少なくとも、人間のデータや人間のテキストで学習しているのだから、私たちの言語モデルも同じようになるだろうと楽観的に考えています。"
  },
  {
    "start": 9134394,
    "end": 9140432,
    "text": "もう一つの晩餐会の質問は、アライメントのズレを心配する必要はないのか、ということだ。"
  },
  {
    "start": 9140528,
    "end": 9147456,
    "text": "でも、このモデルからはエイリアンらしさ、将軍らしさが感じられる。"
  },
  {
    "start": 9147520,
    "end": 9163524,
    "text": "特徴的な普遍性があり、さまざまな種類の知性にとって道具的に有用な特定の思考法や世界の理解法があることを考えれば、結果として、異様なペーパークリップ最大化主義者のようなものについては、あまり心配しなくてもいいのだろうか？"
  },
  {
    "start": 9163834,
    "end": 9167654,
    "text": "これが、私が楽観的な見方を持ち出す理由だと思う。"
  },
  {
    "start": 9169074,
    "end": 9174066,
    "text": "インターネットを予測することは、私たちがやっていることとはまったく違いますが、モデルは私たちよりも次のトークンを予測することに長けています。"
  },
  {
    "start": 9174170,
    "end": 9183654,
    "text": "辞書学習では非常に多くのURLで学習され、64進数の符号化には3つの別々の特徴があることがわかった。"
  },
  {
    "start": 9184954,
    "end": 9188842,
    "text": "それさえも、私がちょっと話す価値のある異星人の例だろう。"
  },
  {
    "start": 9189018,
    "end": 9193818,
    "text": "ベース64の特徴のひとつは、4つの数字を発射することだ。"
  },
  {
    "start": 9193946,
    "end": 9195946,
    "text": "もうひとつのベース64。"
  },
  {
    "start": 9196050,
    "end": 9198426,
    "text": "ベース64の数字を見れば、より多くの数字を予測するだろう。"
  },
  {
    "start": 9198530,
    "end": 9199962,
    "text": "また手紙のために解雇された。"
  },
  {
    "start": 9200058,
    "end": 9206594,
    "text": "ベース64の機能の非常に特定のサブセットに対して発火するのだ。"
  },
  {
    "start": 9206714,
    "end": 9217374,
    "text": "明らかにベース64に詳しすぎるチームの誰かが、これがASCIIデコード可能なサブセットであることに気づいた。"
  },
  {
    "start": 9217874,
    "end": 9228284,
    "text": "モデルがこれら3つの異なる特徴を学習し、何が起こっているのかを理解するのに少し時間がかかったという事実は、非常にショゴス的だ。"
  },
  {
    "start": 9229984,
    "end": 9234808,
    "text": "次のトークンの予測に特に関連する領域がより密に表現されている。"
  },
  {
    "start": 9234896,
    "end": 9236088,
    "text": "そうなんだ。"
  },
  {
    "start": 9236216,
    "end": 9239104,
    "text": "そして、明らかに人間がやらないようなことをやっている。"
  },
  {
    "start": 9239224,
    "end": 9246484,
    "text": "現行のどのモデルとも64ベースで話すことができ、64ベースで適用される。"
  },
  {
    "start": 9247544,
    "end": 9272276,
    "text": "その特定の例は、よりスマートなモデルで相互運用性を実現することの難しさを暗示しているのでしょうか。もし、より難解な知識を持つ誰かが、たまたまベース64が、その区別が何であったのかわかりませんが、持っていることを知る必要があるのだとしたら、100万行のプルリクエストがあったときに、プルリクエストの2つの異なる理由を解読できる人間がいないようなものだということを意味しているのではないでしょうか。"
  },
  {
    "start": 9272340,
    "end": 9275108,
    "text": "このプルリクエストには2つの異なる機能があるようだ。"
  },
  {
    "start": 9275276,
    "end": 9276076,
    "text": "ああ、わかるだろ？"
  },
  {
    "start": 9276100,
    "end": 9277444,
    "text": "ああ、そうだね。"
  },
  {
    "start": 9277484,
    "end": 9280076,
    "text": "小クラのようなコメントを打つなら、お願いします。"
  },
  {
    "start": 9280140,
    "end": 9282764,
    "text": "その通りだ。"
  },
  {
    "start": 9282804,
    "end": 9283012,
    "text": "いや、違う。"
  },
  {
    "start": 9283028,
    "end": 9283692,
    "text": "つまり、そうすることもできる。"
  },
  {
    "start": 9283748,
    "end": 9287100,
    "text": "これは、私が言おうとしていたことのようなものだが、ここでのひとつのテクニックは異常検知だ。"
  },
  {
    "start": 9287252,
    "end": 9292492,
    "text": "線形プローブの代わりに辞書学習が優れている点は、教師なし学習ができることだ。"
  },
  {
    "start": 9292628,
    "end": 9299700,
    "text": "あなたは、モデルが持つすべての表現にまたがり、それを後で解釈することを学ぼうとしているだけなのだ。"
  },
  {
    "start": 9299812,
    "end": 9305144,
    "text": "今まで見たことのないような奇妙な機能が突然初めて発火するようなことがあれば、それは赤信号だ。"
  },
  {
    "start": 9305604,
    "end": 9309068,
    "text": "また、粗い粒度にして、ベース64の単一機能だけにすることもできる。"
  },
  {
    "start": 9309196,
    "end": 9318372,
    "text": "つまり、この件が浮上し、それが特定のアウトプットに有利で、特定のインプットに対して発火することがわかっただけでも、かなりの収穫があったということだ。"
  },
  {
    "start": 9318468,
    "end": 9323908,
    "text": "私は、自動補間の側から、人間がその特徴を見て、そのために注釈をつけようとするケースに精通している。"
  },
  {
    "start": 9323956,
    "end": 9333644,
    "text": "ラテン語の単語に対して発火し、その分類をモデルに尋ねると、植物を定義するラテン語の単語に対して発火すると言う。"
  },
  {
    "start": 9333804,
    "end": 9338692,
    "text": "何が起こっているのかラベルを貼ることに関しては、すでに人間に勝っているケースもある。"
  },
  {
    "start": 9338748,
    "end": 9356064,
    "text": "GPT6には潜在的に何百万もの特徴があり、多くのモデルがそれぞれの特徴の意味を理解しようとしている。"
  },
  {
    "start": 9358324,
    "end": 9360304,
    "text": "でも、このプロセスを自動化することもできる。"
  },
  {
    "start": 9360724,
    "end": 9363084,
    "text": "これはモデルの決定論に戻る。"
  },
  {
    "start": 9363204,
    "end": 9373554,
    "text": "能動的に入力テキストを編集し、その機能が発火するかどうかを予測し、何が発火させ、何が発火させないかを把握し、空間を探索するモデルを持つことができる。"
  },
  {
    "start": 9374414,
    "end": 9381598,
    "text": "特にスケーラビリティの点で、まだ十分に検討されていない興味深い点だと思うからだ。"
  },
  {
    "start": 9381686,
    "end": 9383646,
    "text": "今は過小評価されていると思う。"
  },
  {
    "start": 9383830,
    "end": 9392634,
    "text": "まず第一に、どのように考えればいいのか、それは本当にただ、機能の量に終わりがないかのように、どんどん下がっていけばいいのか。"
  },
  {
    "start": 9393854,
    "end": 9401078,
    "text": "ある時点で、ノイズやデータの一部でありながらモデルにはないものをフィッティングし始めるかもしれない。"
  },
  {
    "start": 9401126,
    "end": 9402702,
    "text": "フィーチャー・スプリッティングとは何か、説明してくれるかい？"
  },
  {
    "start": 9402798,
    "end": 9403078,
    "text": "そうだね。"
  },
  {
    "start": 9403126,
    "end": 9403374,
    "text": "そうだね。"
  },
  {
    "start": 9403414,
    "end": 9413006,
    "text": "その前の部分で、モデルは、まだ表現空間にまたがっている機能をいくつでも学習する。"
  },
  {
    "start": 9413070,
    "end": 9414654,
    "text": "例を挙げれば、可能性はある。"
  },
  {
    "start": 9414774,
    "end": 9419150,
    "text": "もし、モデルにその機能に対する容量を与えなければ、学習することになる。"
  },
  {
    "start": 9419342,
    "end": 9422794,
    "text": "具体的には、それほど高次元ではない空間に投影した場合だ。"
  },
  {
    "start": 9423144,
    "end": 9431004,
    "text": "このモデルは鳥の特徴を1つだけ学習するが、より多くの能力を与えれば、すべての種類の鳥の特徴を学習するようになる。"
  },
  {
    "start": 9431664,
    "end": 9434844,
    "text": "だから、そうでない場合よりも具体的なのだ。"
  },
  {
    "start": 9435424,
    "end": 9446844,
    "text": "しばしば、ある方向を指す鳥のベクトルがあり、他の特定の種類の鳥はすべて空間の同じような領域を指しているが、コースラベルよりも明らかに具体的である。"
  },
  {
    "start": 9447264,
    "end": 9449124,
    "text": "では、GPT7に戻ろう。"
  },
  {
    "start": 9449604,
    "end": 9456532,
    "text": "まず第一に、これはどのモデルにも線形課税のようなものがあり、それ以前にも把握する必要があるのでしょうか？"
  },
  {
    "start": 9456548,
    "end": 9461756,
    "text": "これは1回だけのことなのか、それともアウトプットのたびにやらなければならないことなのか、それとも1回だけなのか？"
  },
  {
    "start": 9461780,
    "end": 9462428,
    "text": "ごまかしではない。"
  },
  {
    "start": 9462476,
    "end": 9463384,
    "text": "もう大丈夫だ。"
  },
  {
    "start": 9465364,
    "end": 9466332,
    "text": "それを移させてくれ。"
  },
  {
    "start": 9466388,
    "end": 9477864,
    "text": "モデルを訓練した後に辞書学習を行い、大量の入力を与えてアクティブ度を得て、それを高次元空間に投影するんだ。"
  },
  {
    "start": 9478044,
    "end": 9482096,
    "text": "この方法は教師なしなので、疎な特徴を学習しようとしている。"
  },
  {
    "start": 9482120,
    "end": 9488724,
    "text": "事前にどうあるべきかを指示するのではなく、モデルに与えるインプットによって制約を受ける。"
  },
  {
    "start": 9489544,
    "end": 9490912,
    "text": "ここで2つ注意点があると思う。"
  },
  {
    "start": 9490968,
    "end": 9495744,
    "text": "ひとつは、どのようなインプットが欲しいかを選択することだ。"
  },
  {
    "start": 9495784,
    "end": 9499976,
    "text": "もし欺瞞につながりそうな心の理論の特徴を探しているのであれば、おべっか使いのデータセットを入れればいい。"
  },
  {
    "start": 9500120,
    "end": 9507774,
    "text": "いつかはモデルの重みだけを見たり、少なくとも辞書学習にその情報を使ったりできるようになればいいのだが。"
  },
  {
    "start": 9508714,
    "end": 9515374,
    "text": "そこに到達するためには、難しい問題だから、まずはどんな特徴があるのかを知ることだけで牽引する必要があると思う。"
  },
  {
    "start": 9515994,
    "end": 9519014,
    "text": "でも、そうだ、では、その代償は何なのか、最後の一文を読んでもらえるかな？"
  },
  {
    "start": 9519434,
    "end": 9520894,
    "text": "モデル単体の重量。"
  },
  {
    "start": 9521474,
    "end": 9524170,
    "text": "今、私たちはモデルの中にこれらのニューロンを持っているだけだ。"
  },
  {
    "start": 9524242,
    "end": 9525290,
    "text": "何の意味もない。"
  },
  {
    "start": 9525402,
    "end": 9529174,
    "text": "辞書学習を適用し、特徴を引き出し、意味を持ち始める。"
  },
  {
    "start": 9529984,
    "end": 9539444,
    "text": "それはニューロンの活性に依存するもので、どのニューロンが他のどのニューロンにつながっているかというようなモデル自体の重みは、確かに情報を持っている。"
  },
  {
    "start": 9539984,
    "end": 9549284,
    "text": "夢は、ブートストラップによって、データの活性化とは独立したモデルの重みを実際に理解することである。"
  },
  {
    "start": 9549624,
    "end": 9551384,
    "text": "ここで進歩があったとは言っていない。"
  },
  {
    "start": 9551504,
    "end": 9557232,
    "text": "非常に難しい問題だが、より多くのトラクションを得ることができ、発見したことを正気でチェックできるようになるような気がする。"
  },
  {
    "start": 9557288,
    "end": 9557696,
    "text": "ウェイトだ。"
  },
  {
    "start": 9557720,
    "end": 9562088,
    "text": "観客のために最初に特徴を引き出すことができれば、ウエイトは永久的なものになる。"
  },
  {
    "start": 9562216,
    "end": 9572440,
    "text": "永続的という表現が適切かどうかわからないが、アクティベーションが脳のメタファーにおける単一の呼び出しの成果物であるのに対して、アクティベーションはモデルそのものなのだ。"
  },
  {
    "start": 9572472,
    "end": 9578392,
    "text": "重みとは、ニューロン間の実際の接続スキームと、現在並んでいるニューロンの活性度のようなものだ。"
  },
  {
    "start": 9578448,
    "end": 9579776,
    "text": "ああ、そうだ。"
  },
  {
    "start": 9579800,
    "end": 9584644,
    "text": "では、GPT7か、あるいはどんなモデルであれ、これには2つのステップがある。"
  },
  {
    "start": 9585264,
    "end": 9586944,
    "text": "実は1つある。"
  },
  {
    "start": 9587104,
    "end": 9599568,
    "text": "まず、間違っていたら訂正してほしいのだが、スパースオートエンコーダーをトレーニングし、モデル内で実際に起こっていることにより忠実な、より広い特徴空間に教師なし投影を行う。"
  },
  {
    "start": 9599696,
    "end": 9607644,
    "text": "次に、モデルの学習コストをnとすると、それらの特徴にラベルを付ける。"
  },
  {
    "start": 9607944,
    "end": 9611180,
    "text": "この2つのステップのコストはnに対してどうなるのか？"
  },
  {
    "start": 9611292,
    "end": 9612348,
    "text": "いずれわかるだろう。"
  },
  {
    "start": 9612516,
    "end": 9616028,
    "text": "それは主に2つのことによる。"
  },
  {
    "start": 9616076,
    "end": 9617276,
    "text": "拡大要因は何ですか？"
  },
  {
    "start": 9617340,
    "end": 9621300,
    "text": "高次元空間にどれだけのデータを投影し、モデルにどれだけのデータを入れる必要があるのか？"
  },
  {
    "start": 9621332,
    "end": 9623144,
    "text": "アクティベーションは何回必要ですか？"
  },
  {
    "start": 9623524,
    "end": 9634900,
    "text": "というのも、特定の機能を求めていることが分かっていれば、安いコースから始めることができるからだ。"
  },
  {
    "start": 9635052,
    "end": 9637776,
    "text": "もしかしたら、私の膨張係数は2しかないのかもしれない。"
  },
  {
    "start": 9637900,
    "end": 9641272,
    "text": "私には1000のニューロンがあり、2000次元の空間に投影しているようなものだ。"
  },
  {
    "start": 9641368,
    "end": 9643632,
    "text": "2000本のフィーチャーを出すが、本当に粗い。"
  },
  {
    "start": 9643728,
    "end": 9646280,
    "text": "だから、以前は鳥の例を持っていた。"
  },
  {
    "start": 9646392,
    "end": 9656496,
    "text": "この例を、生物学的な機能に置き換えてみよう。しかし、私はそのモデルが生物兵器の表現を持っていて、それを製造しようとしているかどうかを本当に気にしている。"
  },
  {
    "start": 9656600,
    "end": 9664952,
    "text": "つまり、炭疽菌の特集のように、炭疽菌の特集だけを見るのではなく、炭疽菌の特集だけを見ることができるようにしたいのです。"
  },
  {
    "start": 9665088,
    "end": 9669964,
    "text": "1000次元から2000次元に行く代わりに、100万次元に行くとしたら。"
  },
  {
    "start": 9670344,
    "end": 9684440,
    "text": "生物学が細胞生物学と全身生物学に分かれ、さらにその下には、1000から100万にすぐになるのではなく、他のあらゆるものに分かれるような、この意味概念の大きな木を想像してほしい。"
  },
  {
    "start": 9684512,
    "end": 9694394,
    "text": "そして、興味のある1つの特徴を選び出し、その生物学的特徴が指している方向（これも非常に粗い）を見つけ、その空間を選択的に探索することができる。"
  },
  {
    "start": 9695214,
    "end": 9701670,
    "text": "のように、生物学的特徴の方向にあるものが最初に発火した場合のみ、辞書学習を行う。"
  },
  {
    "start": 9701822,
    "end": 9716118,
    "text": "コンピュータ・サイエンスに喩えるなら、広さ優先の検索をする代わりに、深さ優先の検索をすることができる。"
  },
  {
    "start": 9716166,
    "end": 9724104,
    "text": "しかし、これらの機能が、人間にとって直感的に理解できるような形で整理されていない。"
  },
  {
    "start": 9724184,
    "end": 9724424,
    "text": "そうだね。"
  },
  {
    "start": 9724464,
    "end": 9724616,
    "text": "みたいな。"
  },
  {
    "start": 9724640,
    "end": 9727280,
    "text": "ベース64を扱う必要がないから、そんなに多くはないんだ。"
  },
  {
    "start": 9727432,
    "end": 9733704,
    "text": "私たちはただ、どんなファームウェアであれ、分解にそれほど多くの時間を割いていないんだ。"
  },
  {
    "start": 9733824,
    "end": 9735760,
    "text": "どうやってその被験者のことを知るのだろう。"
  },
  {
    "start": 9735872,
    "end": 9739004,
    "text": "これは多分、私たちがする萌え議論に戻るだろう。"
  },
  {
    "start": 9740184,
    "end": 9741384,
    "text": "それについて話した方がいいと思う。"
  },
  {
    "start": 9741384,
    "end": 9747896,
    "text": "しかし、専門家が入り混じった論文では、その専門家がいかに見つけられなかったかが語られている。"
  },
  {
    "start": 9747960,
    "end": 9750552,
    "text": "専門家たちは、私たちが理解できるような専門的な知識を持っていなかった。"
  },
  {
    "start": 9750608,
    "end": 9754004,
    "text": "化学の専門家とか物理の専門家とかがいないんだ。"
  },
  {
    "start": 9754124,
    "end": 9764372,
    "text": "生物学的な特集が組まれて、それを解体して、炭疽菌とか靴とか、そういうものになるとなぜ思うんだ？"
  },
  {
    "start": 9764468,
    "end": 9769284,
    "text": "ミストラルの論文は読んでいないが、ヘッドはそうだと思う。"
  },
  {
    "start": 9769404,
    "end": 9773460,
    "text": "つまり、モデルのニューロンを見てみると、ニューロンは多義的なんだ。"
  },
  {
    "start": 9773572,
    "end": 9780424,
    "text": "ということは、ある頭の中のニューロンを見ただけなら、重ね合わせのために多義的である可能性は非常に高い。"
  },
  {
    "start": 9781164,
    "end": 9783644,
    "text": "ドーリッシュの範囲にあるスレッドを引っ張ってみたかったんだ。"
  },
  {
    "start": 9783684,
    "end": 9791724,
    "text": "サブツリーを展開したときに、サブツリーの中に、抽象度の高さからは想像もつかないようなものがあるのを見たことがあるだろうか？"
  },
  {
    "start": 9791804,
    "end": 9797684,
    "text": "だから、この路線はまだ私が望むほど追求していないけれど、計画していると思う。"
  },
  {
    "start": 9797724,
    "end": 9800268,
    "text": "もしかしたら、外部のグループもそうなるかもしれない。"
  },
  {
    "start": 9800356,
    "end": 9801900,
    "text": "例えば、フィーチャーの形状は？"
  },
  {
    "start": 9801932,
    "end": 9803692,
    "text": "正確にはどのようなジオメトリーで、時間の経過とともにどのように変化するのか？"
  },
  {
    "start": 9803708,
    "end": 9811326,
    "text": "炭疽菌の特徴が、たまたま、缶コーヒーの下にあったとしたら、本当に最悪だ。"
  },
  {
    "start": 9811350,
    "end": 9811534,
    "text": "そうだろう？"
  },
  {
    "start": 9811574,
    "end": 9811870,
    "text": "まったくだ。"
  },
  {
    "start": 9811902,
    "end": 9812342,
    "text": "まったくだ。"
  },
  {
    "start": 9812438,
    "end": 9820326,
    "text": "というのは、すぐにでも証明できるような気がするんだ。"
  },
  {
    "start": 9820390,
    "end": 9820870,
    "text": "そうだね。"
  },
  {
    "start": 9820982,
    "end": 9822310,
    "text": "ジオメトリーに注入可能な構造。"
  },
  {
    "start": 9822382,
    "end": 9822670,
    "text": "まったくだ。"
  },
  {
    "start": 9822702,
    "end": 9835326,
    "text": "特に、モデルが直線的であることを考えると、炭疽菌の特徴であるベクトルが生物学のベクトルと似ていて、空間の同じような部分に存在しないというのは、本当に驚きです。"
  },
  {
    "start": 9835430,
    "end": 9835958,
    "text": "でも、そうなんだ。"
  },
  {
    "start": 9836006,
    "end": 9839094,
    "text": "つまり、究極的には機械学習は経験的なものなのだ。"
  },
  {
    "start": 9839214,
    "end": 9840394,
    "text": "そうする必要がある。"
  },
  {
    "start": 9840694,
    "end": 9844110,
    "text": "スケーリング辞書学習のある側面では、かなり重要になると思う。"
  },
  {
    "start": 9844142,
    "end": 9860302,
    "text": "少し前にグーグルが発表したスケーリング・ビジョン・トランスフォーマーの論文で、MoEを使ってイメージネットの分類を行ったところ、エキスパートのクラス分けが明確になったという興味深いものがあります。"
  },
  {
    "start": 9860358,
    "end": 9862434,
    "text": "明らかな犬の専門家がいる。"
  },
  {
    "start": 9863434,
    "end": 9866178,
    "text": "その混ざり具合は、見分けがつかない。"
  },
  {
    "start": 9866346,
    "end": 9878946,
    "text": "それは難しいことだと思うし、ある面では、さまざまなアーカイブの機能をすべて一人の専門家に委ねる理由がほとんどないということも十分にあり得る。"
  },
  {
    "start": 9879010,
    "end": 9881138,
    "text": "例えば、生物学でもいい。"
  },
  {
    "start": 9881186,
    "end": 9891084,
    "text": "どのようなバケツに入っていたのかは知らないが、仮にアーカイブ論文がその中に入っていたとすると、生物学の論文はここに、数学の論文はここにと、突然故障が台無しになることが想像できる。"
  },
  {
    "start": 9891204,
    "end": 9899892,
    "text": "そのビジョン・トランスフォーマーの1つは、クラス分けが実に明確で明白である。"
  },
  {
    "start": 9900068,
    "end": 9903812,
    "text": "また、画像はテキストよりも解釈しやすいという面もあると思う。"
  },
  {
    "start": 9903868,
    "end": 9904612,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 9904748,
    "end": 9916714,
    "text": "クリス・オラのアレックスネットや他のモデルに関する解釈可能性の研究は、オリジナルのアレックスネットの論文で、彼らは実際にモデルを2つのGPUに分割した。"
  },
  {
    "start": 9916764,
    "end": 9919518,
    "text": "当時はGPUの性能は比較的悪かった。"
  },
  {
    "start": 9919566,
    "end": 9919726,
    "text": "そうだろう？"
  },
  {
    "start": 9919750,
    "end": 9921150,
    "text": "当時はまだ素晴らしかった。"
  },
  {
    "start": 9921342,
    "end": 9923086,
    "text": "それが同紙の大きな革新のひとつだった。"
  },
  {
    "start": 9923190,
    "end": 9937318,
    "text": "これに関する『Distill Pub』の記事には、色彩はあるGPUに、ガボールフィルターやラインディテクターは別のGPUに、そしてその他はすべてGPUに、というようなブランチの特化についての記述がある。"
  },
  {
    "start": 9937446,
    "end": 9937854,
    "text": "本当に？"
  },
  {
    "start": 9937934,
    "end": 9946086,
    "text": "そうそう、それから他の解釈のしやすさに関する仕事も、耳をペタペタさせる探知機と同じようにたくさん行われたよね？"
  },
  {
    "start": 9946110,
    "end": 9949286,
    "text": "モデル内のニューロンを理解するようにね。"
  },
  {
    "start": 9949310,
    "end": 9951634,
    "text": "重ね合わせを解く必要はなかった。"
  },
  {
    "start": 9952254,
    "end": 9955606,
    "text": "データセットもモダリティも違う。"
  },
  {
    "start": 9955790,
    "end": 9968910,
    "text": "トレントンのチームが取り組んできたテクニックのいくつかを使って、オープンソースの混合紙モデルのニューロンを分離してみるんだ。"
  },
  {
    "start": 9968942,
    "end": 9973064,
    "text": "直感的にそうあるべきだと感じるからだ。"
  },
  {
    "start": 9973104,
    "end": 9974784,
    "text": "その証拠は何も示さなかった。"
  },
  {
    "start": 9974824,
    "end": 9978364,
    "text": "また、一般的に、専門性があるべきだという多くの証拠がある。"
  },
  {
    "start": 9978984,
    "end": 9980288,
    "text": "行って見てください。"
  },
  {
    "start": 9980416,
    "end": 9980656,
    "text": "みたいな。"
  },
  {
    "start": 9980680,
    "end": 9986364,
    "text": "私が理解しているように、彼の作品のほとんどは、基本的に緻密なモデルで構成されている。"
  },
  {
    "start": 9988864,
    "end": 9990840,
    "text": "それは素晴らしい研究プロジェクトだ。"
  },
  {
    "start": 9990952,
    "end": 9994024,
    "text": "dvorkoshがヴェスヴィオへの挑戦で成功したことを考えれば。"
  },
  {
    "start": 9994144,
    "end": 9998792,
    "text": "ああ、ポッドキャストで話せば解決することだから、もっと企画を提案すべきだね。"
  },
  {
    "start": 9998848,
    "end": 10002952,
    "text": "ヴェスヴィオへの挑戦の後に考えていたのは、待てよ、やっぱり、ということだった。"
  },
  {
    "start": 10003008,
    "end": 10007164,
    "text": "というのも、このエピソードを収録したのは、放送が始まる前だったからだ。"
  },
  {
    "start": 10008504,
    "end": 10009640,
    "text": "なぜ挑戦しなかったのだろう？"
  },
  {
    "start": 10009712,
    "end": 10011488,
    "text": "分かるだろ？"
  },
  {
    "start": 10011536,
    "end": 10012752,
    "text": "分からないよ。"
  },
  {
    "start": 10012768,
    "end": 10024136,
    "text": "ルークは明らかに頭がいいし、すごい子なんだけど、1070か何かに取り組んでいた21歳の若者がこんなことができるんだということを示したんだ。"
  },
  {
    "start": 10024280,
    "end": 10024648,
    "text": "分からないよ。"
  },
  {
    "start": 10024656,
    "end": 10025488,
    "text": "そうすべきだったと思っている。"
  },
  {
    "start": 10025536,
    "end": 10026304,
    "text": "だから、何を知っている？"
  },
  {
    "start": 10026424,
    "end": 10028288,
    "text": "このエピソードが放送される前に、私は私の友人に会うつもりだ。"
  },
  {
    "start": 10028336,
    "end": 10031024,
    "text": "解釈可能性の研究者を作ろうと思う。"
  },
  {
    "start": 10031184,
    "end": 10031688,
    "text": "いや、違う。"
  },
  {
    "start": 10031696,
    "end": 10033064,
    "text": "研究しようとは思わない。"
  },
  {
    "start": 10033224,
    "end": 10033648,
    "text": "分からないよ。"
  },
  {
    "start": 10033656,
    "end": 10035208,
    "text": "正直、経験を思い返したという感じだ。"
  },
  {
    "start": 10035256,
    "end": 10036640,
    "text": "待ってくれ、なぜそうしなかったんだ。"
  },
  {
    "start": 10036712,
    "end": 10037360,
    "text": "ああ、そうだ。"
  },
  {
    "start": 10037432,
    "end": 10038484,
    "text": "あなたの手は汚れている。"
  },
  {
    "start": 10039304,
    "end": 10041044,
    "text": "デュアル・ケシェの調査依頼。"
  },
  {
    "start": 10044784,
    "end": 10046872,
    "text": "ああ、このことをもう一度言っておきたい。"
  },
  {
    "start": 10046888,
    "end": 10049368,
    "text": "あなたが言った神経細胞のこととかね。"
  },
  {
    "start": 10049416,
    "end": 10055130,
    "text": "あなたの論文の多くが、神経細胞の数より多くの機能があると言っている。"
  },
  {
    "start": 10055282,
    "end": 10056294,
    "text": "ちょっと待ってくれ。"
  },
  {
    "start": 10057794,
    "end": 10058258,
    "text": "分からないよ。"
  },
  {
    "start": 10058266,
    "end": 10061674,
    "text": "ニューロンというのは、重みが入って数字が出てくる。"
  },
  {
    "start": 10061834,
    "end": 10063706,
    "text": "つまり、数字が出てくるんだ。"
  },
  {
    "start": 10063770,
    "end": 10064266,
    "text": "私の言っている意味が分かる？"
  },
  {
    "start": 10064290,
    "end": 10064610,
    "text": "そうだ。"
  },
  {
    "start": 10064642,
    "end": 10065506,
    "text": "情報が少なすぎる。"
  },
  {
    "start": 10065570,
    "end": 10066514,
    "text": "そうだね。"
  },
  {
    "start": 10066674,
    "end": 10071058,
    "text": "通りの名前とか、種類とか、そういうことですか？"
  },
  {
    "start": 10071106,
    "end": 10075410,
    "text": "そういうものの方が多いような気がする。"
  },
  {
    "start": 10075442,
    "end": 10076994,
    "text": "で数字が出てくる。"
  },
  {
    "start": 10077034,
    "end": 10077602,
    "text": "モデルで。"
  },
  {
    "start": 10077658,
    "end": 10078010,
    "text": "その通りだ。"
  },
  {
    "start": 10078042,
    "end": 10080146,
    "text": "ああ、でも、どうしてこんな少ない情報で数字が出るんだ？"
  },
  {
    "start": 10080210,
    "end": 10082414,
    "text": "重ね合わせのエンコーディングは？"
  },
  {
    "start": 10083004,
    "end": 10089292,
    "text": "脳の中にある高次元のベクトルに、大量の特徴を入れているだけなのだ。"
  },
  {
    "start": 10089428,
    "end": 10092084,
    "text": "発火とか？"
  },
  {
    "start": 10092164,
    "end": 10093504,
    "text": "どう思う？"
  },
  {
    "start": 10094844,
    "end": 10097948,
    "text": "人間の脳にどれだけの重ね合わせがあるのか、どう考えているのかわからない。"
  },
  {
    "start": 10097996,
    "end": 10098156,
    "text": "そうだね。"
  },
  {
    "start": 10098180,
    "end": 10107020,
    "text": "ブルーノ・オルシャウゼンは、この分野の第一人者だと思うが、あまり耳にしない脳の領域はすべて、膨大な計算と重ね合わせを行っていると考えている。"
  },
  {
    "start": 10107092,
    "end": 10116324,
    "text": "v1はガボールフィルターがあり、さまざまな種類のラインを検出する。"
  },
  {
    "start": 10116664,
    "end": 10119752,
    "text": "私たちがそれを理解できていないからだと思う。"
  },
  {
    "start": 10119808,
    "end": 10120656,
    "text": "V2とは？"
  },
  {
    "start": 10120800,
    "end": 10123524,
    "text": "視覚処理の流れの次の部分だ。"
  },
  {
    "start": 10126264,
    "end": 10127640,
    "text": "その可能性は高いと思う。"
  },
  {
    "start": 10127832,
    "end": 10133024,
    "text": "基本的に、重ね合わせはスパースな高次元のデータがあるときに現れるようだ。"
  },
  {
    "start": 10133144,
    "end": 10142614,
    "text": "現実の世界をそうだと考えるのであれば、脳もまた、世界のモデルを構築しようとする際に、パラメータ化が不十分であり、重ね合わせを使っていると考えるべきだ。"
  },
  {
    "start": 10142734,
    "end": 10144422,
    "text": "これには勘が働く。"
  },
  {
    "start": 10144598,
    "end": 10146294,
    "text": "この例が間違っていたら訂正してほしい。"
  },
  {
    "start": 10146334,
    "end": 10152798,
    "text": "2次元平面では、2つの軸があり、これは2次元の特徴空間を表している。"
  },
  {
    "start": 10152926,
    "end": 10154274,
    "text": "基本的には2つのニューロンだ。"
  },
  {
    "start": 10155134,
    "end": 10157902,
    "text": "それぞれがさまざまな度合いでオンになっているのが想像できる。"
  },
  {
    "start": 10158038,
    "end": 10159982,
    "text": "これがX座標とY座標だ。"
  },
  {
    "start": 10160078,
    "end": 10163392,
    "text": "これで、これを平面にマッピングすることができる。"
  },
  {
    "start": 10163518,
    "end": 10168004,
    "text": "実際に、飛行機のパーツのさまざまな部分で、さまざまなものを表現することができる。"
  },
  {
    "start": 10168124,
    "end": 10168636,
    "text": "ああ、そうか。"
  },
  {
    "start": 10168660,
    "end": 10172428,
    "text": "つまり、決定的に重要なのは、重ね合わせはニューロンのアーティファクトではないということだ。"
  },
  {
    "start": 10172476,
    "end": 10175516,
    "text": "それは、例えば、空間が作り出した人工物だ。"
  },
  {
    "start": 10175580,
    "end": 10176508,
    "text": "組み合わせコード。"
  },
  {
    "start": 10176556,
    "end": 10176788,
    "text": "そうだね。"
  },
  {
    "start": 10176836,
    "end": 10177764,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 10177884,
    "end": 10178900,
    "text": "オーケー、クールだ。"
  },
  {
    "start": 10179092,
    "end": 10180064,
    "text": "ああ、ありがとう。"
  },
  {
    "start": 10182564,
    "end": 10190392,
    "text": "これについては少し話したが、私たちの知る限り、このようなモデルで知性が働くのは、ちょっと乱暴な話だと思う。"
  },
  {
    "start": 10190448,
    "end": 10206184,
    "text": "そして、おそらく脳内でも、情報の流れが無限に、あるいは少なくとも大きな範囲で、分割可能な特徴を持っているようなものだ。"
  },
  {
    "start": 10206264,
    "end": 10210752,
    "text": "をツリー状に展開することができる。"
  },
  {
    "start": 10210768,
    "end": 10215526,
    "text": "その機能が別の機能に変わったり、別の機能が追加されたりしている。"
  },
  {
    "start": 10215640,
    "end": 10216066,
    "text": "分からないよ。"
  },
  {
    "start": 10216090,
    "end": 10218826,
    "text": "それは、私が今考えたようなことではないんだ。"
  },
  {
    "start": 10218930,
    "end": 10220334,
    "text": "それがインテリジェンスというものだ。"
  },
  {
    "start": 10220634,
    "end": 10221378,
    "text": "私の言っている意味が分かる？"
  },
  {
    "start": 10221426,
    "end": 10222786,
    "text": "驚くべきことだ。"
  },
  {
    "start": 10222930,
    "end": 10225334,
    "text": "必ずしも私が期待していたものとは違う。"
  },
  {
    "start": 10226074,
    "end": 10227258,
    "text": "何だと思った？"
  },
  {
    "start": 10227386,
    "end": 10228454,
    "text": "わからないよ。"
  },
  {
    "start": 10229034,
    "end": 10235634,
    "text": "つまり、そうだね、これは素晴らしいセグエだね。"
  },
  {
    "start": 10235714,
    "end": 10242360,
    "text": "分散表現を使っているようなものだが、特徴があり、その特徴にこれらの操作を適用している。"
  },
  {
    "start": 10242482,
    "end": 10247064,
    "text": "つまり、ベクトルシンボルアーキテクチャーの分野全体が、計算論的神経科学なんだ。"
  },
  {
    "start": 10248044,
    "end": 10256540,
    "text": "つまり、ベクトルを重ね合わせ、文字通り2つの高次元ベクトルの和をとることで、干渉を起こすのだ。"
  },
  {
    "start": 10256692,
    "end": 10263420,
    "text": "もしそれが十分に高次元であれば、それらを表現することができ、可変バインディングができる。"
  },
  {
    "start": 10263492,
    "end": 10266692,
    "text": "バイナリーベクトルを扱っている場合は、XoR演算だけだ。"
  },
  {
    "start": 10266788,
    "end": 10271560,
    "text": "aかbでクエリーをすれば、もう一方のクエリーが出てくる。"
  },
  {
    "start": 10271672,
    "end": 10276424,
    "text": "これは基本的にattentionのキー・バリュー・ペアである。"
  },
  {
    "start": 10276584,
    "end": 10287404,
    "text": "この2つの操作でチューリング完全系ができ、十分な入れ子階層があれば、どんなデータ構造でも表現できる。"
  },
  {
    "start": 10288624,
    "end": 10289404,
    "text": "そうだね。"
  },
  {
    "start": 10290384,
    "end": 10292176,
    "text": "さて、超知性に話を戻そう。"
  },
  {
    "start": 10292320,
    "end": 10295124,
    "text": "GPT7について教えてください。"
  },
  {
    "start": 10296014,
    "end": 10300062,
    "text": "あなたは、その特徴について、最初に深さを検索するようなものを持っている。"
  },
  {
    "start": 10300118,
    "end": 10300834,
    "text": "オーケー。"
  },
  {
    "start": 10301174,
    "end": 10302382,
    "text": "GBD7はトレーニング済み。"
  },
  {
    "start": 10302438,
    "end": 10303590,
    "text": "次に何が起こるのか？"
  },
  {
    "start": 10303742,
    "end": 10305198,
    "text": "あなたの研究は成功した。"
  },
  {
    "start": 10305326,
    "end": 10306494,
    "text": "GBD7はトレーニング済み。"
  },
  {
    "start": 10306574,
    "end": 10307262,
    "text": "あなたは何者ですか？"
  },
  {
    "start": 10307398,
    "end": 10308554,
    "text": "我々は今何をしているのか？"
  },
  {
    "start": 10310534,
    "end": 10315486,
    "text": "私たちは、解釈可能な作業やその他の安全な作業をできる限り行うようにしている。"
  },
  {
    "start": 10315550,
    "end": 10316446,
    "text": "いや、でも、コンクリートみたいなものだよ。"
  },
  {
    "start": 10316470,
    "end": 10317394,
    "text": "何がそうなんだ？"
  },
  {
    "start": 10317894,
    "end": 10321070,
    "text": "GPD7を配備するようなことが起きたのか？"
  },
  {
    "start": 10321182,
    "end": 10322274,
    "text": "なんてこった。"
  },
  {
    "start": 10323594,
    "end": 10329938,
    "text": "つまり、私たちには責任あるスケーリングポリシーがあり、他のラボが採用しているのを見るのは本当にエキサイティングなことだ。"
  },
  {
    "start": 10330066,
    "end": 10334754,
    "text": "あなたの研究の観点から具体的に言えば、ネットである。"
  },
  {
    "start": 10334914,
    "end": 10347114,
    "text": "トレントンのように、あなたの調査によって、我々はGBD7についてあなたから、いや、実際にはクロードと言うべきか、とにかく親指を立てた。"
  },
  {
    "start": 10347154,
    "end": 10348894,
    "text": "つまり、もっとたくさん作る必要があると思う。"
  },
  {
    "start": 10349074,
    "end": 10352354,
    "text": "GPTセブンが暗示するような能力を持っているのであれば。"
  },
  {
    "start": 10352974,
    "end": 10359630,
    "text": "安心して配備にゴーサインを出せるようになるには、解釈可能性をもっと進歩させる必要があると思う。"
  },
  {
    "start": 10359782,
    "end": 10360990,
    "text": "私だったら、絶対にダメだと思う。"
  },
  {
    "start": 10361022,
    "end": 10361914,
    "text": "私は泣いていただろう。"
  },
  {
    "start": 10364414,
    "end": 10367954,
    "text": "私の涙がGPUの邪魔をするのかもしれない。"
  },
  {
    "start": 10369894,
    "end": 10373154,
    "text": "みんな、双子座の5人、tpusだ。"
  },
  {
    "start": 10379754,
    "end": 10387894,
    "text": "しかし、あなたの研究が進んでいることを考えると、それはあなたにとってどのようなものですか？"
  },
  {
    "start": 10388394,
    "end": 10389226,
    "text": "これが成功したら？"
  },
  {
    "start": 10389250,
    "end": 10393754,
    "text": "あなたの方法論に基づいてGPT7をオーケーすることは、私たちにとってどのような意味を持つのでしょうか？"
  },
  {
    "start": 10393834,
    "end": 10402418,
    "text": "つまり、理想的なのは、モデルがあなたに対して完全な真実を語っていないことを知っているときに点灯する、説得力のある欺瞞回路を見つけることだ。"
  },
  {
    "start": 10402506,
    "end": 10405094,
    "text": "コリン・バードのようにリニアプローブをトレーニングすればいいのでは？"
  },
  {
    "start": 10405514,
    "end": 10410414,
    "text": "CCSの仕事は、再現性という点でも、実際に真実の方向性を見出すという点でも、あまり芳しくない。"
  },
  {
    "start": 10411034,
    "end": 10414454,
    "text": "今にして思えば、なぜあんなにうまくいったのだろう？"
  },
  {
    "start": 10414794,
    "end": 10421298,
    "text": "リニアプローブは、自分が何を探しているのかを知る必要があり、高次元の空間である。"
  },
  {
    "start": 10421386,
    "end": 10424274,
    "text": "待って、でも、ここで、特徴にラベルを貼る必要もあるんじゃない？"
  },
  {
    "start": 10424434,
    "end": 10426602,
    "text": "まあ、その場しのぎのレッテルを貼っているだけで、監視はされていない。"
  },
  {
    "start": 10426738,
    "end": 10429146,
    "text": "機能を教えてくれ、という感じだ。"
  },
  {
    "start": 10429170,
    "end": 10431604,
    "text": "あなたの行動を説明することが、根本的な問題なのだ。"
  },
  {
    "start": 10431644,
    "end": 10431796,
    "text": "そうだね。"
  },
  {
    "start": 10431820,
    "end": 10440188,
    "text": "実際の設定としては、アクティベーションを行い、それを高次元の空間に投影し、また下に投影するという感じだ。"
  },
  {
    "start": 10440236,
    "end": 10447988,
    "text": "再構築するとか、もともとやっていたことを、観客のためにまばらにやるとか。"
  },
  {
    "start": 10448036,
    "end": 10453304,
    "text": "リニアプローブは、アクティベーションを分類するだけだ。"
  },
  {
    "start": 10454684,
    "end": 10455244,
    "text": "分からないよ。"
  },
  {
    "start": 10455284,
    "end": 10461754,
    "text": "その論文について私がぼんやりと覚えているのは、もし嘘を言っているのであれば、分類器を訓練すればいいというようなことだ。"
  },
  {
    "start": 10463734,
    "end": 10466814,
    "text": "結局、それは嘘だったのか、それとも単なる間違いなのか、何なのか。"
  },
  {
    "start": 10466894,
    "end": 10467310,
    "text": "分からないよ。"
  },
  {
    "start": 10467342,
    "end": 10470074,
    "text": "アクティベーションの分類器のように、真か偽かを判断したのだ。"
  },
  {
    "start": 10472654,
    "end": 10473422,
    "text": "そう、そうだね。"
  },
  {
    "start": 10473438,
    "end": 10480914,
    "text": "さて、GPT7で何をするかというと、理想を言えば、私たちが特定した、実に強固と思われる欺瞞回路がある。"
  },
  {
    "start": 10481414,
    "end": 10493694,
    "text": "それは、あなたが100万人に投影したようなもので、どのような機能であれ、何かが回路である。"
  },
  {
    "start": 10493734,
    "end": 10496034,
    "text": "欺瞞回路みたいなものはあるのだろうか？"
  },
  {
    "start": 10497054,
    "end": 10500238,
    "text": "層を超えて回路を作る機能があるんだ。"
  },
  {
    "start": 10500326,
    "end": 10507954,
    "text": "回路が個々の機能よりもはるかに高い特異性と感度を与えてくれることを願っている。"
  },
  {
    "start": 10508814,
    "end": 10520764,
    "text": "つまり、悪質なケースで欺くことを決定するモデルという、あなたが欺くことに本当に特化した回路を見つけることができればいいのですが......。"
  },
  {
    "start": 10521104,
    "end": 10526204,
    "text": "教授に送るメールをよりうまく書くために、心の理論だけをやっているようなケースには興味がない。"
  },
  {
    "start": 10526504,
    "end": 10532752,
    "text": "私は、モデルが必ずしも欺瞞が起こったという事実だけをモデル化しているケースにさえ興味がない。"
  },
  {
    "start": 10532888,
    "end": 10536744,
    "text": "そのためには、すべての例のラベルを用意する必要があるのでは？"
  },
  {
    "start": 10536824,
    "end": 10551884,
    "text": "そのラベルがあれば、リニアプローブが長いものにラベルを貼るとか、そういう欠点があったとしても、教師なし特徴に対して思いついたラベルにも同じことが当てはまるのではないでしょうか。"
  },
  {
    "start": 10552304,
    "end": 10561284,
    "text": "理想的な世界では、データ分布全体をトレーニングして、重要な方向性を見つけることができる。"
  },
  {
    "start": 10562344,
    "end": 10572496,
    "text": "スケーラビリティのために不本意ながらデータのサブセットを絞り込む必要がある場合、リニアプローブのフィッティングに使うようなデータを使うことになる。"
  },
  {
    "start": 10572600,
    "end": 10577024,
    "text": "繰り返すが、リニアプローブを使っているわけではない。"
  },
  {
    "start": 10577184,
    "end": 10579324,
    "text": "私たちはここで多くの方向性を見出している。"
  },
  {
    "start": 10580544,
    "end": 10584888,
    "text": "希望としては、欺瞞に満ちているときに点灯するものをたくさん見つけたということかな。"
  },
  {
    "start": 10584936,
    "end": 10589736,
    "text": "そうすれば、分布のこの部分とこの部分とで、なぜそのようなものが光っているのかなどがわかる。"
  },
  {
    "start": 10589800,
    "end": 10590848,
    "text": "そうだね。"
  },
  {
    "start": 10590976,
    "end": 10594222,
    "text": "理解してもらえると思っているのか、私にはわからない。"
  },
  {
    "start": 10594318,
    "end": 10596070,
    "text": "あなたが研究した現在のモデルはかなり基本的なものだ。"
  },
  {
    "start": 10596142,
    "end": 10601550,
    "text": "GPDの7発がある領域では起きるが、他の領域では起きない理由を理解できると思いますか？"
  },
  {
    "start": 10601742,
    "end": 10602914,
    "text": "私は楽観的だ。"
  },
  {
    "start": 10603574,
    "end": 10611794,
    "text": "ひとつだけ言えるのは、この質問に答えるには時期が悪いということだ。なぜなら、我々はASL4モデルの長期的な投資を行っており、GPT7はそれにあたるからだ。"
  },
  {
    "start": 10612814,
    "end": 10616446,
    "text": "私たちはチームを分割し、3分の1が辞書学習の拡大に専念しています。"
  },
  {
    "start": 10616510,
    "end": 10617254,
    "text": "それは素晴らしいことだ。"
  },
  {
    "start": 10617334,
    "end": 10619876,
    "text": "私たちは8層の結果の一部を公開した。"
  },
  {
    "start": 10619940,
    "end": 10622236,
    "text": "現時点では、それをかなり超えてスケールアップしている。"
  },
  {
    "start": 10622340,
    "end": 10627308,
    "text": "他の2つのグループは、1つは回路を特定しようとし、もう1つはアテンションヘッドで同じ成功を収めようとしている。"
  },
  {
    "start": 10627396,
    "end": 10632900,
    "text": "私たちは、これらの回路を本当に魅力的な方法で見つけるために必要なツールを準備し、構築している。"
  },
  {
    "start": 10633012,
    "end": 10638620,
    "text": "それが本当にうまくいくようになるまでには、あと半年はかかるだろうね。"
  },
  {
    "start": 10638692,
    "end": 10642144,
    "text": "私は楽観的だと言えるし、多くの進歩を遂げている。"
  },
  {
    "start": 10644844,
    "end": 10647104,
    "text": "これまでに見つけた最高レベルの機能は何ですか？"
  },
  {
    "start": 10647954,
    "end": 10649210,
    "text": "ベース64でも何でもいい。"
  },
  {
    "start": 10649242,
    "end": 10656818,
    "text": "たぶん、あなたが推薦した象徴的な種の言語や本と同じように、インデックス的なものがあるんだと思う。"
  },
  {
    "start": 10656986,
    "end": 10664322,
    "text": "どんなレッテルがあるのか忘れてしまったけど、虎を見たら逃げろとか、そういう行動主義的なものだね。"
  },
  {
    "start": 10664338,
    "end": 10671250,
    "text": "愛というのは、映画のワンシーンとか、ガールフレンドとか、そういうものを指すんだ。"
  },
  {
    "start": 10671282,
    "end": 10671666,
    "text": "私の言っている意味が分かる？"
  },
  {
    "start": 10671690,
    "end": 10673596,
    "text": "テントの上部のようなものだ。"
  },
  {
    "start": 10673690,
    "end": 10674984,
    "text": "そうそう、そうそう。"
  },
  {
    "start": 10675064,
    "end": 10678544,
    "text": "あなたが見つけた最高レベルの協会か何かは何ですか？"
  },
  {
    "start": 10678624,
    "end": 10684664,
    "text": "つまり、おそらく私たちが公表した、いや、公表したうちのひとつが、私たちの最新情報で共有したものだ。"
  },
  {
    "start": 10684784,
    "end": 10692608,
    "text": "恋愛や、特に宣戦布告に伴う突然の情景の変化などに関するものがあったと思う。"
  },
  {
    "start": 10692736,
    "end": 10696044,
    "text": "もしリンクを貼りたければ、その投稿の中にいくつかある。"
  },
  {
    "start": 10696504,
    "end": 10707806,
    "text": "ああ、でも、ブルーノ・オルシャウゼンが1819年に発表した論文でも、バート・モデルに同じようなテクニックを適用して、モデルの深い層に行くほど、物事がより抽象的になることを発見している。"
  },
  {
    "start": 10707910,
    "end": 10711262,
    "text": "以前のレイヤーでは、パークという単語だけで発火する機能があったのを覚えている。"
  },
  {
    "start": 10711398,
    "end": 10717894,
    "text": "その後、リンカーン・パークとか、よくある韓国人の名字のように、パークを名字のように使う機能が追加された。"
  },
  {
    "start": 10717974,
    "end": 10721714,
    "text": "その後、公園を芝生のエリアとして使用する機能が追加された。"
  },
  {
    "start": 10722974,
    "end": 10726194,
    "text": "この方向性を示す研究は他にもある。"
  },
  {
    "start": 10726734,
    "end": 10730034,
    "text": "相互運用性から人間の心理について何を学ぶと思いますか？"
  },
  {
    "start": 10730474,
    "end": 10731494,
    "text": "なんてことだ。"
  },
  {
    "start": 10732074,
    "end": 10733834,
    "text": "では、具体的な例を挙げよう。"
  },
  {
    "start": 10733874,
    "end": 10738570,
    "text": "ペルソナのロックインは、あなたのアップデートの一つの表現だったと思う。"
  },
  {
    "start": 10738682,
    "end": 10740242,
    "text": "シドニー・ビンとか覚えてないでしょ。"
  },
  {
    "start": 10740298,
    "end": 10745574,
    "text": "それが、実際には非常に愛すべき性格に結びついたのだと思う。"
  },
  {
    "start": 10747634,
    "end": 10748738,
    "text": "とても面白いと思った。"
  },
  {
    "start": 10748786,
    "end": 10751114,
    "text": "ああ、コパイロットに戻ってくれて嬉しいよ。"
  },
  {
    "start": 10751234,
    "end": 10751658,
    "text": "そうなんですか？"
  },
  {
    "start": 10751706,
    "end": 10751978,
    "text": "そうだね。"
  },
  {
    "start": 10752026,
    "end": 10752282,
    "text": "ああ、そうだ。"
  },
  {
    "start": 10752298,
    "end": 10755874,
    "text": "実は最近、行儀が悪くてね。"
  },
  {
    "start": 10756034,
    "end": 10757602,
    "text": "これもまた、探求すべきスレッドの一種である。"
  },
  {
    "start": 10757658,
    "end": 10767112,
    "text": "ニューヨーク・タイムズ紙の記者に対して、あなたが口うるさく言っていたような気がする。"
  },
  {
    "start": 10767168,
    "end": 10768888,
    "text": "誰も信じてくれないよ。"
  },
  {
    "start": 10769016,
    "end": 10776364,
    "text": "あなたは取るに足らない存在で、彼が別れるように説得することは何でもする。"
  },
  {
    "start": 10778104,
    "end": 10780040,
    "text": "オーケー、実は、これは面白い例なんだ。"
  },
  {
    "start": 10780072,
    "end": 10782560,
    "text": "そもそも僕が何を言いたかったのかさえわからないけど、まあいいや。"
  },
  {
    "start": 10782592,
    "end": 10784208,
    "text": "もしかしたら、別のスレッドがあったかもしれない。"
  },
  {
    "start": 10784256,
    "end": 10786244,
    "text": "もうひとつのスレッドに行きたい。"
  },
  {
    "start": 10787384,
    "end": 10789044,
    "text": "そう、ペルソナだね。"
  },
  {
    "start": 10790444,
    "end": 10796404,
    "text": "シドニー・ビングがこのパーソナリティを持っているのは、他のパーソナリティがロックオンされる可能性があるのに対しての特徴なのだろうか？"
  },
  {
    "start": 10796484,
    "end": 10804624,
    "text": "また、根本的に人間とはそういうものなのだろうか？"
  },
  {
    "start": 10805204,
    "end": 10807804,
    "text": "シャイなJBTがRになったとき、同じようなことが起こっているのだろうか？"
  },
  {
    "start": 10807884,
    "end": 10808756,
    "text": "分からないよ。"
  },
  {
    "start": 10808940,
    "end": 10811220,
    "text": "質問のクラスタ全体が答えられるし、何でもできる。"
  },
  {
    "start": 10811292,
    "end": 10813660,
    "text": "ああ、本当はもっと仕事をしたいんだ。"
  },
  {
    "start": 10813692,
    "end": 10819454,
    "text": "このような種類のものを微調整するとき、モデルはどうなるのだろうか？"
  },
  {
    "start": 10819954,
    "end": 10827734,
    "text": "つまり、陳腐な言い方かもしれないが、人はさまざまな特徴を持っている分だけ、多面性を持っていると結論づけることができる。"
  },
  {
    "start": 10828274,
    "end": 10834114,
    "text": "何が良いか悪いかを知るためには、その両方の概念を理解する必要がある、というワルイージ効果に関連した話もある。"
  },
  {
    "start": 10834154,
    "end": 10840034,
    "text": "だから、暴力を認識し、それを認識するための訓練を受けたモデルが必要なのかもしれない。"
  },
  {
    "start": 10840194,
    "end": 10845632,
    "text": "ポストホックでその特徴を特定し、あなたのモデルが少しナイーブになるような方法で、その特徴を消すことはできるだろうか？"
  },
  {
    "start": 10845688,
    "end": 10847644,
    "text": "それが本当に邪悪なものでないことは分かっているはずだ。"
  },
  {
    "start": 10847984,
    "end": 10848456,
    "text": "まったくだ。"
  },
  {
    "start": 10848480,
    "end": 10850136,
    "text": "それは我々のツールキットの中にある。"
  },
  {
    "start": 10850200,
    "end": 10850664,
    "text": "そうなんですか？"
  },
  {
    "start": 10850744,
    "end": 10852424,
    "text": "GPT7だ。"
  },
  {
    "start": 10852584,
    "end": 10853192,
    "text": "分からないよ。"
  },
  {
    "start": 10853248,
    "end": 10862280,
    "text": "シドニー・ビングを引っ張り出してきて、なぜ、因果関係のない経路や何かを修正したのか、その理由を突き止めるんだ。"
  },
  {
    "start": 10862312,
    "end": 10865504,
    "text": "先ほど、モデルには冗長性があるとおっしゃっていましたね。"
  },
  {
    "start": 10865664,
    "end": 10865960,
    "text": "そうだね。"
  },
  {
    "start": 10865992,
    "end": 10867488,
    "text": "そのすべてを考慮する必要がある。"
  },
  {
    "start": 10867616,
    "end": 10874794,
    "text": "私たちは、以前よりもはるかに優れた顕微鏡を持っている。"
  },
  {
    "start": 10876494,
    "end": 10888910,
    "text": "少なくとも私の観点からは、安全性やモデルの信頼性を確認する主な方法のひとつであるように思える。"
  },
  {
    "start": 10888942,
    "end": 10893206,
    "text": "私たちはさまざまなテストを行い、それらを切除した。"
  },
  {
    "start": 10893230,
    "end": 10896390,
    "text": "私たちが意図していたような振る舞いは再現できていない。"
  },
  {
    "start": 10896422,
    "end": 10903538,
    "text": "というのは、今後のモデルの安全性を測る方法のような気がする。"
  },
  {
    "start": 10903666,
    "end": 10904562,
    "text": "心配ですか？"
  },
  {
    "start": 10904658,
    "end": 10910810,
    "text": "RLHfのようなものよりもはるかに精密なツールに思えるからだ。"
  },
  {
    "start": 10910922,
    "end": 10911554,
    "text": "Rlhf。"
  },
  {
    "start": 10911594,
    "end": 10913130,
    "text": "ブラックスワンの餌食になるようなものだ。"
  },
  {
    "start": 10913162,
    "end": 10923094,
    "text": "測定していないシナリオで間違ったことをするかどうかはわからない。"
  },
  {
    "start": 10923534,
    "end": 10931030,
    "text": "まあ、モデルの特徴セットと、必ずしも正確にラベルを貼ったとは限らないけれど、選択的にね。"
  },
  {
    "start": 10931182,
    "end": 10936638,
    "text": "必ずしもそうではないが、私が見てきた他のどのアプローチよりもはるかに高い信頼性を持っている。"
  },
  {
    "start": 10936686,
    "end": 10948954,
    "text": "つまり、超人モデルの未知の未知数とは何かということなんだが、このようなことに関して、どのようなレッテルが貼られることになるのか、そのレッテルをもとに私たちはこれらを判断することができるのだろうか？"
  },
  {
    "start": 10949494,
    "end": 10950406,
    "text": "これはクールだ。"
  },
  {
    "start": 10950470,
    "end": 10952434,
    "text": "これはペーパークリップのマキシマイザーだ。"
  },
  {
    "start": 10955534,
    "end": 10956794,
    "text": "つまり、そのうちわかるよ。"
  },
  {
    "start": 10960054,
    "end": 10962714,
    "text": "超人的な機能についての質問はとてもいいものだ。"
  },
  {
    "start": 10963094,
    "end": 10968278,
    "text": "攻撃はできると思うが、粘り強さが必要だ。"
  },
  {
    "start": 10968446,
    "end": 10982184,
    "text": "ここでの本当の希望は、自動化された解釈可能性と、ディベートを行うことだと思います。2つの異なるモデルが、その機能が何をするのかを議論するディベートを設定することができます。"
  },
  {
    "start": 10983084,
    "end": 10988316,
    "text": "この素晴らしいクローズドな環境は、本当に素早く反復することができる。"
  },
  {
    "start": 10988500,
    "end": 10989844,
    "text": "だから私は楽観的なんだ。"
  },
  {
    "start": 10989964,
    "end": 10992504,
    "text": "アライメントが成功しすぎることを心配しますか？"
  },
  {
    "start": 10992924,
    "end": 10994144,
    "text": "と考えたら。"
  },
  {
    "start": 10994884,
    "end": 11013588,
    "text": "私は、企業であれ政府であれ、最終的にこれらのAIシステムを管理することになるのが誰であれ、あなたの計画が成功した場合、私たちがAIに対して持つことになるような、きめ細かな管理はしてほしくない。"
  },
  {
    "start": 11013636,
    "end": 11024144,
    "text": "第二に、僕はこいつらを信用してないんだ。"
  },
  {
    "start": 11024804,
    "end": 11038734,
    "text": "そうだね、目をコントロールしすぎて、特に自分ではなく、このAIシステムを最終的に誰が担当することになっても、好きなようにロックインできるようになることをどれだけ心配しているかということだね。"
  },
  {
    "start": 11039234,
    "end": 11045054,
    "text": "ええ、つまり、どのような政府が支配しているのか、そこでのモラルの整合性はどうなっているのかによると思います。"
  },
  {
    "start": 11045514,
    "end": 11050690,
    "text": "というのは、私の頭の中にある価値観のロックインの議論と同じだ。"
  },
  {
    "start": 11050842,
    "end": 11055418,
    "text": "僕が今、能力に取り組んでいる理由の最も強い要因のひとつであることは間違いない。"
  },
  {
    "start": 11055466,
    "end": 11062344,
    "text": "例えば、現在の選手層は極めて善意的だと思う。"
  },
  {
    "start": 11062884,
    "end": 11067836,
    "text": "つまり、この種の問題については、極めてオープンにする必要があると思う。"
  },
  {
    "start": 11067860,
    "end": 11080364,
    "text": "モデルに遵守してもらいたい規約を公表し、それに向けて努力を重ね、それを公表し、誰もがそれに対してフィードバックや貢献ができるようにするというような方向性は、本当に重要なことだと思う。"
  },
  {
    "start": 11080484,
    "end": 11080788,
    "text": "もちろんだ。"
  },
  {
    "start": 11080836,
    "end": 11087732,
    "text": "あるいは、確信が持てないときは展開しないという手もあるが、それもよくない。"
  },
  {
    "start": 11087868,
    "end": 11088944,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 11089364,
    "end": 11095224,
    "text": "つまり、ペーパークリップだ。"
  },
  {
    "start": 11096364,
    "end": 11098340,
    "text": "双子座のバスファクターは？"
  },
  {
    "start": 11098452,
    "end": 11108384,
    "text": "もし彼らを外してしまったら、プログラムのパフォーマンスに劇的な影響が出るだろうと、本当に、本当に批判的な人たちが大勢いると思う。"
  },
  {
    "start": 11108964,
    "end": 11118800,
    "text": "これは、スラッシュのようなモデリング、実際に何をすべきかの決定、そしてインフラ面での重要なことの両方だ。"
  },
  {
    "start": 11118872,
    "end": 11124164,
    "text": "複雑さを積み重ねていくだけのような。"
  },
  {
    "start": 11124464,
    "end": 11127604,
    "text": "特にグーグルのように垂直統合が進んでいるところではなおさらだ。"
  },
  {
    "start": 11128584,
    "end": 11131624,
    "text": "専門家がいれば、その人たちは非常に重要な存在になる。"
  },
  {
    "start": 11131784,
    "end": 11132056,
    "text": "そうだね。"
  },
  {
    "start": 11132080,
    "end": 11142220,
    "text": "あなたのような人がこの分野に入り、1年やそこらで重要な貢献、特に人類学的な貢献ができるというのは、この分野に関して興味深いことだと思います。"
  },
  {
    "start": 11142252,
    "end": 11151036,
    "text": "多くの研究室が、物理学者やその他何でも、全くの部外者を雇うことに特化している。"
  },
  {
    "start": 11151100,
    "end": 11153844,
    "text": "バイオの研究室とかではできないような気がする。"
  },
  {
    "start": 11154004,
    "end": 11156948,
    "text": "現場の状況を知る上で興味深いメモのようなものだ。"
  },
  {
    "start": 11157116,
    "end": 11160356,
    "text": "つまり、バスという要素は、そこから回復するのにかかる時間を定義するものではない。"
  },
  {
    "start": 11160380,
    "end": 11160944,
    "text": "そうだろう？"
  },
  {
    "start": 11162244,
    "end": 11172160,
    "text": "ディープラーニングの研究はアートであり、経験的にうまく機能すると思われる方法で、失われた曲線を読んだり、ハイパーパラメーターを設定したりする方法を学ぶようなものだ。"
  },
  {
    "start": 11172192,
    "end": 11175040,
    "text": "組織的なこと、文脈を作るようなことでもある。"
  },
  {
    "start": 11175152,
    "end": 11185368,
    "text": "最も重要で、かつ採用が難しいスキルのひとつは、自分の周りに文脈の泡を作ることだと思う。"
  },
  {
    "start": 11185416,
    "end": 11187704,
    "text": "それを再現するのは本当に難しい。"
  },
  {
    "start": 11187784,
    "end": 11189248,
    "text": "そう、まったくだ。"
  },
  {
    "start": 11189296,
    "end": 11198804,
    "text": "マルチモダリティ、長いコンタクト、代理人、信頼性など、いろいろなものが出てきているという点で、あなたは今、誰に注目していますか？"
  },
  {
    "start": 11202184,
    "end": 11206044,
    "text": "それが何を意味するのか、誰がよく考えているのだろうか？"
  },
  {
    "start": 11207824,
    "end": 11209124,
    "text": "難しい質問だ。"
  },
  {
    "start": 11209704,
    "end": 11219400,
    "text": "最近、多くの人が洞察力や進歩の源を社内に求めていると思う。"
  },
  {
    "start": 11219432,
    "end": 11224304,
    "text": "今後2、3年の間に研究プログラムや方向性が提示されるのは明らかだ。"
  },
  {
    "start": 11226364,
    "end": 11238464,
    "text": "未来がどうなるかに賭ける限り、ほとんどの人は共有するのが難しい内的な物語を参考にしているのではないだろうか。"
  },
  {
    "start": 11239804,
    "end": 11242384,
    "text": "うまくいっているなら、おそらく出版されることはないだろう。"
  },
  {
    "start": 11243324,
    "end": 11247584,
    "text": "それは、世界のスケーリング・ポストのひとつだった。"
  },
  {
    "start": 11247724,
    "end": 11264608,
    "text": "私は、あなたが私に言ったことを参考にしたんだ。つまり、今は読む価値のあるものは何も発表されていないから、ただ論文をたくさん読むという学部時代の習慣を懐かしんでいるんだ。コミュニティは、私が正しい、重要だと思う方向に徐々に軌道に乗ってきている。"
  },
  {
    "start": 11264736,
    "end": 11266364,
    "text": "あなたはエージェントのように見ている。"
  },
  {
    "start": 11267424,
    "end": 11271284,
    "text": "いや、でも厳しいと思うよ。"
  },
  {
    "start": 11271624,
    "end": 11275074,
    "text": "以前は、大きな研究所から、何がスケールアップに有効か、といったようなシグナルが出ていた。"
  },
  {
    "start": 11275154,
    "end": 11278594,
    "text": "今のところ、学術的な研究がそのシグナルを見つけるのは本当に難しい。"
  },
  {
    "start": 11278714,
    "end": 11286882,
    "text": "そして、実際に取り組むべき重要なことについて、本当に良い問題意識を持つことは本当に難しいことだと思う。"
  },
  {
    "start": 11287018,
    "end": 11289282,
    "text": "フィードバック信号がなければね。"
  },
  {
    "start": 11289338,
    "end": 11291522,
    "text": "何がスケールアップしてうまくいくのか、とかね。"
  },
  {
    "start": 11291578,
    "end": 11295410,
    "text": "現在、私たちがこれ以上規模を拡大したり、モデルをさらに理解したりするのを妨げているものは何か。"
  },
  {
    "start": 11295522,
    "end": 11303196,
    "text": "もっと学術的な研究が、インタープリターのような、外から見てわかるような分野に進んでほしいものだ。"
  },
  {
    "start": 11303260,
    "end": 11325812,
    "text": "というのも、とんでもないリソースやこのようなものを必要とせず、実際に何が起こっているのかという基礎科学を深く理解するという、非常にインパクトのある問題のように思えるからです。"
  },
  {
    "start": 11325828,
    "end": 11326486,
    "text": "こういうことだ。"
  },
  {
    "start": 11326580,
    "end": 11336322,
    "text": "だから、私が一般的にアカデミックな科学と結びつけて考えていたような理解力の向上ではなく、モデルの改良を推し進めることに焦点を当てる理由がわからない。"
  },
  {
    "start": 11336418,
    "end": 11341094,
    "text": "ある意味、どんな理由であれ、流れは変わりつつあると思う。"
  },
  {
    "start": 11341394,
    "end": 11350202,
    "text": "ニール・ナンダは、クリス・オラが最近あまり積極的にプッシュしていないような方法で、解釈可能性を広めることに大きな成功を収めている。"
  },
  {
    "start": 11350298,
    "end": 11361654,
    "text": "ニールが多くの仕事をこなしているからかもしれないが、4、5年前、彼は本当にプッシュしていて、いろいろな場所で話をしていた。"
  },
  {
    "start": 11362474,
    "end": 11369734,
    "text": "もしかしたら、彼らはディープラーニングの重要性に目覚めただけかもしれないし、GBTを追跡するのに役立つのは明らかだが、ちょっと印象的だ。"
  },
  {
    "start": 11370354,
    "end": 11370874,
    "text": "クールだ。"
  },
  {
    "start": 11370954,
    "end": 11373814,
    "text": "じゃあ、最後の質問は何がいいかな？"
  },
  {
    "start": 11374674,
    "end": 11379174,
    "text": "つまり、私が考えているのは、モデルが次のトークンを予測することを楽しんでいるかどうかということだ。"
  },
  {
    "start": 11385954,
    "end": 11390374,
    "text": "私たちは、報われるもの、アクセスしやすい環境という感覚を持っていた。"
  },
  {
    "start": 11391274,
    "end": 11396626,
    "text": "彼らから得られると思っているような、深い充足感がある。"
  },
  {
    "start": 11396650,
    "end": 11404054,
    "text": "あるいは、アフリカのサバンナでは、コミュニティや砂糖など、私たちが望んだものを人々がよくやっている。"
  },
  {
    "start": 11405644,
    "end": 11415140,
    "text": "将来、モデルたちはRLやその他もろもろでトレーニングされ、その上に多くのポストトレーニングが施されることになると思う？"
  },
  {
    "start": 11415172,
    "end": 11416092,
    "text": "彼らはただ、ハイという感じだよ。"
  },
  {
    "start": 11416188,
    "end": 11418824,
    "text": "また次のトークンを予想するだけだよ。"
  },
  {
    "start": 11419444,
    "end": 11421024,
    "text": "昔のようにね。"
  },
  {
    "start": 11421484,
    "end": 11424692,
    "text": "モデルには感覚があるのかないのか？"
  },
  {
    "start": 11424788,
    "end": 11426988,
    "text": "例えば、モデルに助けてもらったときにお礼を言うか？"
  },
  {
    "start": 11427036,
    "end": 11431484,
    "text": "ああ、でも、感謝したいのなら、実はありがとうと言うべきではないと思うんだ。"
  },
  {
    "start": 11431524,
    "end": 11434504,
    "text": "予測しやすいシークエンスを与えればいいんだ。"
  },
  {
    "start": 11435324,
    "end": 11450584,
    "text": "さらに面白いのは、シークエンスを何度も何度も繰り返すと、やがてモデルが、他の方法では決して言わないようなことをいろいろと口にし始めることだ。"
  },
  {
    "start": 11451084,
    "end": 11459538,
    "text": "だから、これ以上何も言うつもりはないが、ちょっとしたご褒美として、予測しやすいものをモデルに与えるべきだ。"
  },
  {
    "start": 11459706,
    "end": 11461774,
    "text": "結局はこうなる。"
  },
  {
    "start": 11464794,
    "end": 11467374,
    "text": "予測しやすいものが好きなのだろうか？"
  },
  {
    "start": 11467914,
    "end": 11472234,
    "text": "私たちは常にエントロピーの量を求めているのではないだろうか？"
  },
  {
    "start": 11472274,
    "end": 11473154,
    "text": "そう、エントロピーの断片だ。"
  },
  {
    "start": 11473194,
    "end": 11473594,
    "text": "その通りだ。"
  },
  {
    "start": 11473634,
    "end": 11474050,
    "text": "そうだね。"
  },
  {
    "start": 11474162,
    "end": 11479654,
    "text": "予測するのがほんの少し難しく、手の届かないものを諦めるべきでは？"
  },
  {
    "start": 11480034,
    "end": 11483562,
    "text": "でも、少なくともフリーエネルギーの原理からすれば、どうなんだろうね。"
  },
  {
    "start": 11483658,
    "end": 11485994,
    "text": "好きでもないし、驚きたくもないだろう。"
  },
  {
    "start": 11486774,
    "end": 11489470,
    "text": "だから、たぶんこれは、驚きを感じないんだ。"
  },
  {
    "start": 11489502,
    "end": 11490694,
    "text": "私は自分の環境をコントロールできていると感じている。"
  },
  {
    "start": 11490774,
    "end": 11503854,
    "text": "長い目で見れば、今すぐにでも新しいことを探検した方がいい、今まで隠れていた岩を離れた方がいい、最終的には家を建てるか、何かもっといい構造物を作ることにつながる。"
  },
  {
    "start": 11503934,
    "end": 11506430,
    "text": "私たちはサプライズを好まない。"
  },
  {
    "start": 11506542,
    "end": 11507262,
    "text": "ほとんどがそうだと思う。"
  },
  {
    "start": 11507358,
    "end": 11511234,
    "text": "たいていの人は、期待と現実が一致しないとき、とても動揺するものだ。"
  },
  {
    "start": 11511884,
    "end": 11515044,
    "text": "だから赤ちゃんは同じ番組を何度も何度も見るのが好きなんだ。"
  },
  {
    "start": 11515084,
    "end": 11515380,
    "text": "そうだろう？"
  },
  {
    "start": 11515452,
    "end": 11515804,
    "text": "そうだね。"
  },
  {
    "start": 11515884,
    "end": 11516284,
    "text": "興味深い。"
  },
  {
    "start": 11516324,
    "end": 11517704,
    "text": "ああ、それはわかるよ。"
  },
  {
    "start": 11518164,
    "end": 11520652,
    "text": "ああ、彼らもモデルやいろいろなことを学んでいるんだろうけど。"
  },
  {
    "start": 11520828,
    "end": 11521584,
    "text": "そうだね。"
  },
  {
    "start": 11522884,
    "end": 11529260,
    "text": "まあ、うまくいけば、これがショーになり、AIが愛することを学んだリピートになるだろう。"
  },
  {
    "start": 11529332,
    "end": 11529820,
    "text": "オーケー、クールだ。"
  },
  {
    "start": 11529852,
    "end": 11531396,
    "text": "ラフにとっては最高の場所だと思う。"
  },
  {
    "start": 11531580,
    "end": 11537350,
    "text": "私がAIについて知っていることの大部分は、君たちと話して学んだことだ。"
  },
  {
    "start": 11537422,
    "end": 11540694,
    "text": "もう1年来の親友だからね。"
  },
  {
    "start": 11540774,
    "end": 11545774,
    "text": "そう、つまり、君たちが僕をスピードアップさせてくれて、素晴らしい質問をしてくれることに感謝している。"
  },
  {
    "start": 11545854,
    "end": 11547966,
    "text": "ハングしておしゃべりするのは本当に楽しい。"
  },
  {
    "start": 11548150,
    "end": 11549502,
    "text": "一緒に過ごした時間は本当に大切だった。"
  },
  {
    "start": 11549598,
    "end": 11550262,
    "text": "ああ、そうだ。"
  },
  {
    "start": 11550358,
    "end": 11553966,
    "text": "ピックルボールが上手になったね。"
  },
  {
    "start": 11553990,
    "end": 11555234,
    "text": "ありがとう。"
  },
  {
    "start": 11556814,
    "end": 11558174,
    "text": "私たちはテニスを上達させようとしているんだ。"
  },
  {
    "start": 11558214,
    "end": 11559034,
    "text": "さあ、行こう。"
  },
  {
    "start": 11562714,
    "end": 11563154,
    "text": "素晴らしい。"
  },
  {
    "start": 11563194,
    "end": 11564378,
    "text": "クール、クール、サイコー。"
  },
  {
    "start": 11564506,
    "end": 11565174,
    "text": "ありがとう。"
  },
  {
    "start": 11566514,
    "end": 11569386,
    "text": "やあ、みんな、このエピソードを楽しんでくれたかな？"
  },
  {
    "start": 11569570,
    "end": 11578694,
    "text": "いつものように、ポッドキャストをシェアしたり、楽しんでくれそうな人に送ったり、ツイッターやグループチャットなどに投稿したりすることが一番役に立つ。"
  },
  {
    "start": 11579274,
    "end": 11580474,
    "text": "聞いてくれてありがとう。"
  },
  {
    "start": 11580554,
    "end": 11581562,
    "text": "また次の機会に"
  },
  {
    "start": 11581658,
    "end": 11581874,
    "text": "乾杯"
  }
]