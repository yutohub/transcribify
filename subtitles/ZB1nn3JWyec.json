[
  {
    "start": 650,
    "end": 19040,
    "text": "前回のビデオでは、エンベッディングのコンセプトを使って、御社独自のデータをGPTモデルに送り込み、チャットGPTに質問すると、チャットGPTは、御社が持っているかもしれない、トレーニングされていない独自の情報をすべて知った上で、その質問に答えることができる、ということを説明しました。"
  },
  {
    "start": 20050,
    "end": 22766,
    "text": "その詳細が知りたければ、ビデオを見せよう。"
  },
  {
    "start": 22948,
    "end": 30386,
    "text": "これを実現するために必要なのはエンベッディング・モデルで、OpenAIにはエンベッディングAPIがある。"
  },
  {
    "start": 30498,
    "end": 39450,
    "text": "問題なのは、何百万、何千万という自社所有のドキュメントを、自分たちがほとんどコントロールできないサードパーティのサービスに送り込みたくないと考える人も、企業もあるということだ。"
  },
  {
    "start": 39520,
    "end": 49750,
    "text": "ビデオの最後に、このハグする顔のリポジトリをお見せしましたが、これはオープンソースのAIモデルを集めたものです。"
  },
  {
    "start": 49920,
    "end": 53434,
    "text": "MTEBというリーダーボードがある。"
  },
  {
    "start": 53562,
    "end": 56778,
    "text": "MTEBはMassive Text Embedding benchmarkの略。"
  },
  {
    "start": 56874,
    "end": 68130,
    "text": "このベンチマークは、エンベッディングモデルが最先端の技術に対してどのようなパフォーマンスを発揮するかを理解するために、自分自身をテストするための一般的で非常に包括的なベンチマークである。"
  },
  {
    "start": 68280,
    "end": 76170,
    "text": "もちろん、埋め込みを使う方法は、分類、クラスタリング、情報検索など、さまざまなものがある。"
  },
  {
    "start": 76270,
    "end": 82338,
    "text": "そのため、モデルによってベンチマークの異なる側面に対して良い結果を出すこともあれば、悪い結果を出すこともある。"
  },
  {
    "start": 82434,
    "end": 92170,
    "text": "とにかく、このリーダーボードを作成するために、彼らはこれらのデータセットとタスクのすべてに対してテストを行い、平均点を出してランキングした。"
  },
  {
    "start": 92240,
    "end": 98460,
    "text": "6番のテキスト埋め込み、エイダ2を見ると、これはOpenAIの埋め込みモデルだ。"
  },
  {
    "start": 99070,
    "end": 102078,
    "text": "ここにアップされているのは、本当に素晴らしいパフォーマンスをしているものばかりだ。"
  },
  {
    "start": 102244,
    "end": 104000,
    "text": "E、5、ラージ、B 2"
  },
  {
    "start": 104450,
    "end": 110106,
    "text": "OpenAIのAPIを使うのは簡単なのか？"
  },
  {
    "start": 110298,
    "end": 113438,
    "text": "このようなモデルを自分で展開するのは、どれくらいの労力が必要なのでしょうか？"
  },
  {
    "start": 113524,
    "end": 116066,
    "text": "素晴らしいニュースは、それは本当に難しいことではないということだ。"
  },
  {
    "start": 116168,
    "end": 120740,
    "text": "それにはいくつかのステップがあるが、今日はそれぞれのステップについて説明しよう。"
  },
  {
    "start": 121750,
    "end": 125398,
    "text": "例えば、ランキング上位のモデルが欲しいとしよう。"
  },
  {
    "start": 125484,
    "end": 127122,
    "text": "どうすればこれを手に入れられるのか？"
  },
  {
    "start": 127266,
    "end": 136902,
    "text": "クリックすると詳細が表示され、埋め込みサイズが1、0、24であることがわかる。"
  },
  {
    "start": 136956,
    "end": 143340,
    "text": "送信したテキスト1ビットにつき、出力されるベクトルには1024個の数字が含まれる。"
  },
  {
    "start": 143950,
    "end": 148380,
    "text": "OpenAIの方は1536だ。"
  },
  {
    "start": 148910,
    "end": 158286,
    "text": "もうひとつの大きな違いは、OpenAIのモデル特有のものだと言わざるを得ないが、どれだけのデータを入れることができるかということだ。"
  },
  {
    "start": 158468,
    "end": 163220,
    "text": "こちらは最大512まで。"
  },
  {
    "start": 164070,
    "end": 165154,
    "text": "見てみよう。"
  },
  {
    "start": 165352,
    "end": 167454,
    "text": "それが言葉なのかトークンなのかはわからない。"
  },
  {
    "start": 167502,
    "end": 180534,
    "text": "それに対してOpenAIのものは数千ページと、桁が違う。"
  },
  {
    "start": 180732,
    "end": 185218,
    "text": "とにかく、この入力の長さで問題ないとしよう。"
  },
  {
    "start": 185314,
    "end": 186534,
    "text": "どうやって配備するのか？"
  },
  {
    "start": 186572,
    "end": 188738,
    "text": "ここにデプロイというボタンがあります。"
  },
  {
    "start": 188914,
    "end": 195980,
    "text": "Sagemakerをクリックすると、コピー＆ペーストできるコードが表示されます。"
  },
  {
    "start": 196670,
    "end": 200330,
    "text": "あなたの文章をここに書いて、試してみてください。"
  },
  {
    "start": 200480,
    "end": 219362,
    "text": "この方法とこのコードの両方から得られるデータが、正しい形をしていないということです。例えば、5つの文章を入れた場合、1024の5倍の数字は得られません。"
  },
  {
    "start": 219496,
    "end": 226482,
    "text": "そのため、その最後に追加のステップを加える必要があり、少し複雑になるが、それでも十分に可能だ。"
  },
  {
    "start": 226546,
    "end": 227720,
    "text": "さあ、行くぞ"
  },
  {
    "start": 228970,
    "end": 242394,
    "text": "ブログをフォローするのがお好きなら、このブログが圧倒的にわかりやすいので、フォローできるように一番下にリンクを貼っておく。"
  },
  {
    "start": 242512,
    "end": 246150,
    "text": "私が選んだモデルとは違うものを使っている。"
  },
  {
    "start": 246310,
    "end": 247900,
    "text": "見てみよう。"
  },
  {
    "start": 255100,
    "end": 261064,
    "text": "そうそう、ここにあるのはオールミニのLL6 V 2というのが選ばれている。"
  },
  {
    "start": 261182,
    "end": 267100,
    "text": "このモデルには、私が選んだモデルと同じ問題があり、それは最後に何らかの追加処理が必要だということだ。"
  },
  {
    "start": 267170,
    "end": 270670,
    "text": "これを参考にすれば間違いない。"
  },
  {
    "start": 271760,
    "end": 274108,
    "text": "では始めよう。"
  },
  {
    "start": 274274,
    "end": 279440,
    "text": "最初にすべきことは、AWSのsagemakerに入ることだ。"
  },
  {
    "start": 279780,
    "end": 286128,
    "text": "sagemakerに入ったら、自分の資産を置いておきたい地域を選択したことを確認する。"
  },
  {
    "start": 286214,
    "end": 289250,
    "text": "私は西を選んだ。"
  },
  {
    "start": 289640,
    "end": 292416,
    "text": "ノートブックのインスタンスに入る。"
  },
  {
    "start": 292528,
    "end": 299024,
    "text": "ここでやりたいことは、Jupyterノートブックを実行できるインスタンスを作成することだ。"
  },
  {
    "start": 299072,
    "end": 304088,
    "text": "私はすでにここでそれを実行しているが、その方法を紹介しよう。"
  },
  {
    "start": 304174,
    "end": 308728,
    "text": "ノートブック・インスタンスの作成をクリックし、任意の名前を付けることができる。"
  },
  {
    "start": 308814,
    "end": 311720,
    "text": "テスト埋め込みノート"
  },
  {
    "start": 312460,
    "end": 314472,
    "text": "ノートブック・インスタンス・タイプ"
  },
  {
    "start": 314606,
    "end": 319470,
    "text": "私たちが使っているようなモデルなら、MLTの3ラージにすることをお勧めする。"
  },
  {
    "start": 320160,
    "end": 323532,
    "text": "Jupyterラボの3つのボリュームサイズを選択します。"
  },
  {
    "start": 323586,
    "end": 325404,
    "text": "これを10に変えた方がいい。"
  },
  {
    "start": 325522,
    "end": 330080,
    "text": "5本だとクラッシュすることがあるんだ。"
  },
  {
    "start": 331380,
    "end": 336492,
    "text": "そして、パーミッションと暗号化のために、Amazon Sagemakerの実行ロールを選択します。"
  },
  {
    "start": 336556,
    "end": 340390,
    "text": "もし社内に技術部門があれば、きっと助けてくれるはずだ。"
  },
  {
    "start": 341000,
    "end": 342452,
    "text": "次に暗号化キー。"
  },
  {
    "start": 342506,
    "end": 358920,
    "text": "このデモでは暗号化を選択していないが、もしあなたが非常に機密性の高いデータを扱っているのであれば、このKMS暗号化をお勧めする。"
  },
  {
    "start": 359500,
    "end": 361528,
    "text": "では、見てみよう。"
  },
  {
    "start": 361614,
    "end": 362520,
    "text": "ネットワーク"
  },
  {
    "start": 364300,
    "end": 365916,
    "text": "よし、もう大丈夫だろう。"
  },
  {
    "start": 365938,
    "end": 374924,
    "text": "ノートブック・インスタンスの作成をクリックすると、このようなものが表示されます。"
  },
  {
    "start": 375042,
    "end": 380320,
    "text": "このようなものを手に入れたら、サービスが開始されるまで数分かかるかもしれない。"
  },
  {
    "start": 380470,
    "end": 383024,
    "text": "Jupyterラボを開くをクリックする。"
  },
  {
    "start": 383222,
    "end": 386530,
    "text": "ただ、このインターフェイスに比べると少し新しい。"
  },
  {
    "start": 387060,
    "end": 393060,
    "text": "Jupyterラボに入ったら、Pytorchを選んでください。"
  },
  {
    "start": 393800,
    "end": 395430,
    "text": "それをクリックすると"
  },
  {
    "start": 395880,
    "end": 396564,
    "text": "これでよし。"
  },
  {
    "start": 396602,
    "end": 404970,
    "text": "ノートブックはすでにお持ちでしょうから、私が以前作った、すべてのコードが入ったものをお見せしましょう。"
  },
  {
    "start": 405500,
    "end": 407128,
    "text": "これで終わりにしよう。"
  },
  {
    "start": 407294,
    "end": 408200,
    "text": "捨てる。"
  },
  {
    "start": 410460,
    "end": 411864,
    "text": "それでは、どうぞ。"
  },
  {
    "start": 411982,
    "end": 430540,
    "text": "このノートブックでは、正しい認証情報さえあればインターネットからアクセスできるAWS APIに、ここでのランキング上位であるe five large v two embeddingモデルをデプロイする。"
  },
  {
    "start": 431040,
    "end": 434880,
    "text": "ステップ1では、いくつかのパッケージをインストールする必要がある。"
  },
  {
    "start": 435540,
    "end": 437852,
    "text": "トランスフォーマーというパッケージを使っている。"
  },
  {
    "start": 437996,
    "end": 447860,
    "text": "ステップ2では、Pytorchとトランスフォーマー・ライブラリーという、これから使う必要のあるライブラリーをインポートしなければならない。"
  },
  {
    "start": 448440,
    "end": 453956,
    "text": "ステップ3では、AWSのロールを取得または設定する必要がある。"
  },
  {
    "start": 454068,
    "end": 463776,
    "text": "これは、Sagemakerの中で動いている私たちのノートブックが、wsの他の部分にアセットを入れる権限を持っているためです。"
  },
  {
    "start": 463828,
    "end": 470204,
    "text": "例えば、後でモデルをAWSの3つのファイルに保存する必要があることがわかるだろう。"
  },
  {
    "start": 470322,
    "end": 478460,
    "text": "その場合、AWSの別の場所にインターネットにオープンなエンドポイントを作成する必要がある。"
  },
  {
    "start": 478540,
    "end": 481250,
    "text": "そのためのパーミッションが必要なのだ。"
  },
  {
    "start": 482100,
    "end": 484050,
    "text": "ちょっと走らせてくれ。"
  },
  {
    "start": 485300,
    "end": 487650,
    "text": "これらはあまり長い時間を要することはない。"
  },
  {
    "start": 491960,
    "end": 495140,
    "text": "小さな再生ボタンがないのがわかるだろう。"
  },
  {
    "start": 495210,
    "end": 498916,
    "text": "グーグルコラボと違って、コントロールリターンだけで実行できる。"
  },
  {
    "start": 499018,
    "end": 505512,
    "text": "ステップ3を見てもらえばわかると思うが、僕がやっているのは、ハグする顔からモデルを取ってくることだ。"
  },
  {
    "start": 505646,
    "end": 509850,
    "text": "これはこれに相当する。"
  },
  {
    "start": 510780,
    "end": 516628,
    "text": "ハギング・フェイスのプリ・トレーニング・モデルを手に入れろ、と言っているのだ。"
  },
  {
    "start": 516814,
    "end": 520972,
    "text": "そうすると、それをやり遂げるのに少し時間がかかるかもしれない。"
  },
  {
    "start": 521106,
    "end": 527740,
    "text": "ここにある次のコードの塊は、デプロイメント・プロセスに不可欠なものではない。"
  },
  {
    "start": 527810,
    "end": 530832,
    "text": "私はただ、このモデルが実際に機能することをお見せしたいだけです。"
  },
  {
    "start": 530886,
    "end": 531056,
    "text": "そうだね。"
  },
  {
    "start": 531078,
    "end": 536690,
    "text": "モデルを引き下ろしたので、ここでやることはテキストを入れることだ。"
  },
  {
    "start": 537380,
    "end": 540032,
    "text": "ここに文章のリストがある。"
  },
  {
    "start": 540176,
    "end": 542032,
    "text": "2つの異なるクエリーがある。"
  },
  {
    "start": 542096,
    "end": 546048,
    "text": "女性はどれくらいのタンパク質を摂るべきですか？"
  },
  {
    "start": 546144,
    "end": 547396,
    "text": "という一節がある。"
  },
  {
    "start": 547418,
    "end": 547556,
    "text": "E."
  },
  {
    "start": 547578,
    "end": 549220,
    "text": "文書の塊。"
  },
  {
    "start": 550200,
    "end": 555284,
    "text": "最初のクエリは最初のクエリに関連するもので、2番目のクエリは2番目のクエリに関連するものだ。"
  },
  {
    "start": 555332,
    "end": 560664,
    "text": "埋め込みの違いについては、後で実際に動いているところを見ることができる。"
  },
  {
    "start": 560862,
    "end": 567884,
    "text": "それから、この部分でやっているのは、入力テキストを受け取ってトークン化することだ。"
  },
  {
    "start": 567922,
    "end": 568172,
    "text": "E."
  },
  {
    "start": 568226,
    "end": 582960,
    "text": "その結果をモデルに渡して、その結果をoutputsという変数に保存します。"
  },
  {
    "start": 583620,
    "end": 586604,
    "text": "さて、出力からデータを取り出す必要がある。"
  },
  {
    "start": 586732,
    "end": 594788,
    "text": "最後に隠された状態を出力するのだが、実際にはデータはいらない。"
  },
  {
    "start": 594874,
    "end": 597590,
    "text": "えーと、これ、さっきやったっけ？"
  },
  {
    "start": 600760,
    "end": 604360,
    "text": "それを実行して、出力を見てみよう。"
  },
  {
    "start": 605420,
    "end": 614890,
    "text": "4×75×124のテンソルになっていることがわかるだろう。"
  },
  {
    "start": 615260,
    "end": 617880,
    "text": "私たちは4つのセンテンスを理解している。"
  },
  {
    "start": 617960,
    "end": 620796,
    "text": "4つのベクトルが戻ってくると予想される。"
  },
  {
    "start": 620898,
    "end": 625516,
    "text": "この埋め込みモデルのベクトルサイズは1024である。"
  },
  {
    "start": 625618,
    "end": 627184,
    "text": "これも理にかなっている。"
  },
  {
    "start": 627222,
    "end": 633280,
    "text": "私たちが期待しているのはこの4つだが、75では違う。"
  },
  {
    "start": 633350,
    "end": 634672,
    "text": "75歳って何？"
  },
  {
    "start": 634806,
    "end": 643472,
    "text": "それは何かというと、トークン化された文の長さである。"
  },
  {
    "start": 643616,
    "end": 645172,
    "text": "私たちはこれを本当に望んでいるわけではない。"
  },
  {
    "start": 645226,
    "end": 659076,
    "text": "これは、モデルの実際の出力が我々が望む形になっておらず、いくつかの追加コードを実行する必要がある、という意味である。したがって、プーリング操作と呼ばれる追加関数を定義する必要がある。"
  },
  {
    "start": 659188,
    "end": 666108,
    "text": "私たちはこのデータを取り込み、プーリングを使って私たちが望む形に整形する。"
  },
  {
    "start": 666194,
    "end": 677680,
    "text": "ここでは関数を定義し、その関数を使って出力を渡し、その出力をembeddingsという変数に保存しています。"
  },
  {
    "start": 679940,
    "end": 691876,
    "text": "コサイン類似度を使えば、ベクトルの長さにはあまり関心がなく、ベクトル間の角度にしか関心がないので、正規化することができる。"
  },
  {
    "start": 691978,
    "end": 698150,
    "text": "さて、これを実行すると、埋め込みサイズは確かに我々が望む形になっていることがわかる。"
  },
  {
    "start": 698840,
    "end": 703380,
    "text": "この話は、ここでする時間よりももっと込み入った話になる。"
  },
  {
    "start": 703450,
    "end": 709492,
    "text": "平均的なプーリングとはいったい何なのか？"
  },
  {
    "start": 709636,
    "end": 714728,
    "text": "アベレージプーリングは基本的に、モデルの出力を実際に望む形に再形成する方法である。"
  },
  {
    "start": 714814,
    "end": 719624,
    "text": "この中で、プーリングのやり方はいろいろあるが、ここでは4×4のマトリックスを使っている。"
  },
  {
    "start": 719672,
    "end": 723272,
    "text": "例えば、2×2の行列が必要だとしよう。"
  },
  {
    "start": 723336,
    "end": 728368,
    "text": "基本的には、これを引っ張り、平均を取り、これを引っ張り、平均を取り、これを引っ張り、平均を取り、これを引っ張る。"
  },
  {
    "start": 728374,
    "end": 729532,
    "text": "これが出力だ。"
  },
  {
    "start": 729596,
    "end": 732080,
    "text": "寸法を絞るようなものだ。"
  },
  {
    "start": 732230,
    "end": 735490,
    "text": "同じように、僕たちもそうしてきた。"
  },
  {
    "start": 736180,
    "end": 739424,
    "text": "私たちは75人を1人に絞った。"
  },
  {
    "start": 739622,
    "end": 746404,
    "text": "というわけで、それぞれ1024個の数値からなる4つのベクトルが得られる。"
  },
  {
    "start": 746522,
    "end": 755816,
    "text": "これは基本的に、私たちが入力したものの余弦距離を比較するもので、実際に機能するかどうかを見ることができる。"
  },
  {
    "start": 755918,
    "end": 762440,
    "text": "最初のクエリでは、最初のパッセージのスコアが90点であることがわかる。"
  },
  {
    "start": 762510,
    "end": 764344,
    "text": "2つ目のパッセージは69点。"
  },
  {
    "start": 764462,
    "end": 769276,
    "text": "このクエリには、このクエリの方がこのクエリよりもずっと関連性が高いので、その通りです。"
  },
  {
    "start": 769378,
    "end": 777932,
    "text": "これは2つ目のクエリに対するもので、2つ目のパッセージが1つ目のパッセージよりも高いスコアを得るはずであることがわかる。"
  },
  {
    "start": 778066,
    "end": 781010,
    "text": "さて、展開プロセスに戻ろう。"
  },
  {
    "start": 781380,
    "end": 786112,
    "text": "これでモデルを手に入れ、それにいくつかのデータを入れ、機能するようになった。"
  },
  {
    "start": 786246,
    "end": 797332,
    "text": "さて、このモデルを先ほどお見せしたスクリプトと一緒にtarファイルに入れて保存する必要がある。"
  },
  {
    "start": 797386,
    "end": 802496,
    "text": "そして、そのすべてをAWS S threeにファイルとして保存する。"
  },
  {
    "start": 802538,
    "end": 806600,
    "text": "もしS3を使ったことがなければ、ファイルを置く場所のようなものだと思えばいい。"
  },
  {
    "start": 807820,
    "end": 815836,
    "text": "ここでやっているのは、このノートブックが走っているローカル空間内にいくつかのディレクトリを作ることだ。"
  },
  {
    "start": 815938,
    "end": 821544,
    "text": "そして、トークナイザーとモデルをこれらのディレクトリに保存する。"
  },
  {
    "start": 821672,
    "end": 825550,
    "text": "それほど時間はかからないと思うので、実行しよう。"
  },
  {
    "start": 826260,
    "end": 835120,
    "text": "これが終わると、このディレクトリが作成され、その中にたくさんのファイルがあることがわかるだろう。"
  },
  {
    "start": 835190,
    "end": 840630,
    "text": "特にこのように、pytorchmodel binがモデルである。"
  },
  {
    "start": 841000,
    "end": 847840,
    "text": "このディレクトリには、基本的に、モデルの大きな柱となる成果物をすべて置くことになる。"
  },
  {
    "start": 848000,
    "end": 855288,
    "text": "前にも言ったように、平均プーリングステップが必要なので、このモデルのバニラバージョンをただ走らせるわけにはいかない。"
  },
  {
    "start": 855454,
    "end": 864644,
    "text": "さらに、このフォルダにinference Pyというファイルを追加する必要がある。"
  },
  {
    "start": 864772,
    "end": 871624,
    "text": "ここで、このコード・ディレクトリの中のinference Pyというファイルに、これらすべてを書き込もうとしている。"
  },
  {
    "start": 871752,
    "end": 878960,
    "text": "これは、誰かがエンドポイントを呼び出すたびに実行されるコードです。"
  },
  {
    "start": 879540,
    "end": 885536,
    "text": "必要なプーリング関数を入れているのがわかるだろう。"
  },
  {
    "start": 885638,
    "end": 888972,
    "text": "私たちはモデルにファイルの入手先を指示している。"
  },
  {
    "start": 889116,
    "end": 904260,
    "text": "そして、モデルを実行し、出力を取得し、平均プーリングを行い、埋め込みを正規化し、APIは埋め込みベクトルと呼ばれるキーを持つ辞書を返します。"
  },
  {
    "start": 904340,
    "end": 909476,
    "text": "そうすれば、それらすべてがレスポンスとしてユーザーに出力される。"
  },
  {
    "start": 909588,
    "end": 914116,
    "text": "もしすでに実行済みなら、基本的にはこのファイルにすべてを書き込むことになる。"
  },
  {
    "start": 914148,
    "end": 918350,
    "text": "ここをダブルクリックすると、そのすべてが表示される。"
  },
  {
    "start": 918800,
    "end": 932556,
    "text": "ステップ5では、10分ほどかかるので実行はしないが、ここで紹介したものをすべてtarファイルにパッケージする。"
  },
  {
    "start": 932668,
    "end": 936290,
    "text": "ここではtarファイルに名前をつけている。"
  },
  {
    "start": 937060,
    "end": 938048,
    "text": "これは何でもあり得る。"
  },
  {
    "start": 938134,
    "end": 939780,
    "text": "好きなように変更できる。"
  },
  {
    "start": 939930,
    "end": 948996,
    "text": "そして、このディレクトリ内のすべてのファイルをこのアーカイブに追加し、これを作成する。"
  },
  {
    "start": 949098,
    "end": 952792,
    "text": "これを実行すると、基本的にはこうなる。"
  },
  {
    "start": 952926,
    "end": 959530,
    "text": "ここまでできたら、次はこれをS3に送る。"
  },
  {
    "start": 959980,
    "end": 965996,
    "text": "つまり、この部分は、ファイルがどこに行くべきかという情報をコードに与えているだけなのだ。"
  },
  {
    "start": 966098,
    "end": 968264,
    "text": "インサイド・スリーにはバケツというものがある。"
  },
  {
    "start": 968312,
    "end": 971896,
    "text": "私はバケツを作ったが、自分でバケツを作ることもできる。"
  },
  {
    "start": 972088,
    "end": 977040,
    "text": "では、モデル名を見てみよう。"
  },
  {
    "start": 977190,
    "end": 981440,
    "text": "というわけで、基本的には3つの場所へのURLを取得したことになる。"
  },
  {
    "start": 982180,
    "end": 994336,
    "text": "そして、基本的にはAWSコマンドラインインターフェイスを使って、このローカルファイルをs threeバケットにコピーする。"
  },
  {
    "start": 994528,
    "end": 996724,
    "text": "少し時間がかかるので、実行はしない。"
  },
  {
    "start": 996842,
    "end": 1001420,
    "text": "それがすべてできたら、デプロイメントができる。"
  },
  {
    "start": 1001600,
    "end": 1006680,
    "text": "ここでは、ハグする顔のモデル・クラスを作る。"
  },
  {
    "start": 1006830,
    "end": 1014712,
    "text": "このモデルのURLは、基本的にtarファイルへのパスである。"
  },
  {
    "start": 1014856,
    "end": 1021660,
    "text": "すべてのコードとモデルをどこに持ってくるか指示し、役割も与えた。"
  },
  {
    "start": 1022080,
    "end": 1028540,
    "text": "エンドポイントをマシンにデプロイする。"
  },
  {
    "start": 1029600,
    "end": 1035360,
    "text": "これを実行したら、基本的にマシンをスピンアップしたことになり、その代金を支払う必要が出てくる。"
  },
  {
    "start": 1035430,
    "end": 1040692,
    "text": "もし本当に使うつもりがなく、ただふざけているのであれば、その後に削除してきれいにするべきだ。"
  },
  {
    "start": 1040826,
    "end": 1043910,
    "text": "これを実行すると、こうなる。"
  },
  {
    "start": 1045000,
    "end": 1065710,
    "text": "このステップ7を実行した後、セージメーカーに戻り、推論に進むと、モデルが表示されます。"
  },
  {
    "start": 1066160,
    "end": 1076476,
    "text": "クリックすると、どこでモデルを取得しているかがわかります。"
  },
  {
    "start": 1076578,
    "end": 1078940,
    "text": "ここにtarファイルを保存する。"
  },
  {
    "start": 1079100,
    "end": 1083212,
    "text": "モデルがあって、エンドポイントもある。"
  },
  {
    "start": 1083276,
    "end": 1087824,
    "text": "推論エンドポイントをクリックすると、それがサービス中であることがわかる。"
  },
  {
    "start": 1087942,
    "end": 1093908,
    "text": "このセルを作動させた後、このセルが使えるようになるまで数分かかることがある。"
  },
  {
    "start": 1093994,
    "end": 1097520,
    "text": "クリックするとURLが表示されます。"
  },
  {
    "start": 1097680,
    "end": 1100608,
    "text": "これはURLのエンドポイントである。"
  },
  {
    "start": 1100784,
    "end": 1105044,
    "text": "それをコピーして、Postmanを使ってテストしてみよう。"
  },
  {
    "start": 1105172,
    "end": 1117196,
    "text": "Postmanを使ったことがなければ、postman.comのproductからtoolsに行き、ここにAPIクライアントがあるので、それをダウンロードしてコンピューターにインストールすればいい。"
  },
  {
    "start": 1117298,
    "end": 1120328,
    "text": "APIをテストするのにとても便利なツールだ。"
  },
  {
    "start": 1120504,
    "end": 1128380,
    "text": "Postmanに入ったら、ここに来て、新しいコレクションを作り、新しいリクエストを作ることができる。"
  },
  {
    "start": 1128540,
    "end": 1137970,
    "text": "リクエストを追加した後、URLを貼り付け、投稿に設定する必要があります。"
  },
  {
    "start": 1138340,
    "end": 1151312,
    "text": "AWSリージョンへのアクセスキーとシークレットキーを入力し、サービス名をsagemakerと入力する必要がある。"
  },
  {
    "start": 1151456,
    "end": 1156330,
    "text": "アクセス・キーとシークレット・キーの入手方法を説明した記事へのリンクを下に貼っておく。"
  },
  {
    "start": 1156700,
    "end": 1163050,
    "text": "それでは、すでにすべての情報を入力したこのファイルに戻ります。"
  },
  {
    "start": 1163500,
    "end": 1170220,
    "text": "そこで、body rawでJsonを選択し、次のように入力する。"
  },
  {
    "start": 1170290,
    "end": 1174460,
    "text": "これは辞書の形式である。"
  },
  {
    "start": 1174880,
    "end": 1180988,
    "text": "この2つのかぎ括弧の間に、入力は常にinputsというキーを持っている。"
  },
  {
    "start": 1181084,
    "end": 1188348,
    "text": "入力の下には、この角括弧で示された文章またはパッセージのリストがある。"
  },
  {
    "start": 1188444,
    "end": 1195572,
    "text": "そしてこの中に、埋め込みを取得したい文をいくつでも入れることができる。"
  },
  {
    "start": 1195626,
    "end": 1201452,
    "text": "トークンの長さは512個までである。"
  },
  {
    "start": 1201616,
    "end": 1212570,
    "text": "例えば、送信を押すと、1024の数字からなる3つのベクトルが返ってくるはずだ。"
  },
  {
    "start": 1215290,
    "end": 1216586,
    "text": "さあ、行くぞ"
  },
  {
    "start": 1216688,
    "end": 1223322,
    "text": "これが1つのベクターで、これがだいたい適切なサイズであることがわかるだろう。"
  },
  {
    "start": 1223456,
    "end": 1226410,
    "text": "これが2つ目のエンベッディングで、これが3つ目のエンベッディングだ。"
  },
  {
    "start": 1226750,
    "end": 1230506,
    "text": "これが、ハグする顔を埋め込む方法だ。"
  },
  {
    "start": 1230538,
    "end": 1247122,
    "text": "AWSエンドポイントへのモデル 最後に、AWSの使い方にあまり詳しくない方は、ノートブックを実行するためにスピンアップしたインスタンスを停止することを忘れないでください。"
  },
  {
    "start": 1247176,
    "end": 1250674,
    "text": "ノートブックのインスタンスを選択し、停止をクリックするだけです。"
  },
  {
    "start": 1250792,
    "end": 1258854,
    "text": "また、推論セクションで、実行したくないモデルやエンドポイントが実行されていないか再確認することもできる。"
  },
  {
    "start": 1258972,
    "end": 1279838,
    "text": "もしそうであれば、それらを選択してクリーンアップし、削除すればいい。最後に、来週か再来週には、独自のベンチマークを設計・作成する方法について、さらに数本のビデオを予定している。"
  },
  {
    "start": 1279924,
    "end": 1290462,
    "text": "また、いくつかの学術論文にも目を通し、モデルを埋め込むための様々なアーキテクチャを理解することで、あなたに最適なモデルを選択できるようになる。"
  },
  {
    "start": 1290596,
    "end": 1296334,
    "text": "をクリックして、見逃さないようにしてください。"
  },
  {
    "start": 1296532,
    "end": 1297838,
    "text": "それではまた次回。"
  },
  {
    "start": 1298004,
    "end": 1298250,
    "text": "さようなら。"
  }
]