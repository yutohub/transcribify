[
  {
    "start": 280,
    "end": 9374,
    "text": "10年以上にわたってAIの最前線をハックし、教育してきた伝説的な人物を紹介しよう。"
  },
  {
    "start": 9542,
    "end": 20886,
    "text": "ニューラルネットワークからコンピュータ・ビジョンまで、文学的処理から強化学習まで、彼は限界を押し広げ、世界中の何百万人もの人々にインスピレーションを与えてきた。"
  },
  {
    "start": 20918,
    "end": 41260,
    "text": "オープンAIの創設メンバーであり、イマジネットのリファレンス・ヒューマンであり、元グーグルの頭脳であり、元ディープマインドであり、元テスラであり、ミスター・オートパイロットである。"
  },
  {
    "start": 41600,
    "end": 43220,
    "text": "彼は本当にすべてを見てきた。"
  },
  {
    "start": 44360,
    "end": 60150,
    "text": "数ヶ月前、記念すべき日に、この特別な人はCudaモードのディスコードに参加し、LLM Cで他の人とハッキングを始めました。"
  },
  {
    "start": 61010,
    "end": 64410,
    "text": "彼自身が語るのが一番だと思う。"
  },
  {
    "start": 64570,
    "end": 70830,
    "text": "アンドレ・カルパティの登場を歓迎しよう。"
  },
  {
    "start": 85500,
    "end": 86932,
    "text": "ここに来られてとても興奮している。"
  },
  {
    "start": 86956,
    "end": 88956,
    "text": "これは私が一番好きな発表の場だ。"
  },
  {
    "start": 88988,
    "end": 92852,
    "text": "そう、招待してくれてありがとう、そしてクダ・モードを走らせてくれて、これをつけてくれてありがとう。"
  },
  {
    "start": 92916,
    "end": 94400,
    "text": "これは素晴らしいイベントだ。"
  },
  {
    "start": 94740,
    "end": 97316,
    "text": "では、LLM Cについて少しお話ししましょう。"
  },
  {
    "start": 97428,
    "end": 98284,
    "text": "我々は何をしているのか？"
  },
  {
    "start": 98332,
    "end": 101520,
    "text": "トランスフォーマーはCとピンチでトレーニングしているんだ。"
  },
  {
    "start": 102020,
    "end": 103760,
    "text": "次はどうすればいい？"
  },
  {
    "start": 105780,
    "end": 111044,
    "text": "では、このプロジェクトがどのようにして生まれたのか、私の視点から見てどのようなものだったのかを少しお話したいと思います。"
  },
  {
    "start": 111132,
    "end": 118156,
    "text": "およそ1年前、私はYouTubeのシリーズにビデオを追加しようとしていて、LLMトレーニングやGPトレーニングなどを人々に教えようとしていた。"
  },
  {
    "start": 118228,
    "end": 120876,
    "text": "私は基本的にGPDをハックして、仕事をしようとしていた。"
  },
  {
    "start": 121028,
    "end": 122588,
    "text": "それは私だった。"
  },
  {
    "start": 122764,
    "end": 125772,
    "text": "では、皆さんはもちろんパイトーチと仕事をしたことがありますよね？"
  },
  {
    "start": 125796,
    "end": 129252,
    "text": "しかし、このような場合、あなたが書いたモデルを使うことになる。"
  },
  {
    "start": 129316,
    "end": 130068,
    "text": "それは理にかなっている。"
  },
  {
    "start": 130164,
    "end": 134036,
    "text": "今、あなたはここでいくつもの抽象的なものを同時に把握しなければならない。"
  },
  {
    "start": 134108,
    "end": 138048,
    "text": "それをデバイスに入れ、コンパイルし、DDPでラピッドにしたい。"
  },
  {
    "start": 138184,
    "end": 143544,
    "text": "というのも、どういう順番でやればいいのかさえわからないからだ。"
  },
  {
    "start": 143592,
    "end": 144552,
    "text": "具体的に何が起こるのか？"
  },
  {
    "start": 144576,
    "end": 145480,
    "text": "抽象的な表現とは何か？"
  },
  {
    "start": 145520,
    "end": 146712,
    "text": "彼らはあなたのモデルに何をするのか？"
  },
  {
    "start": 146816,
    "end": 148992,
    "text": "どのような仕組みになっているのか、完全には理解していない。"
  },
  {
    "start": 149096,
    "end": 156288,
    "text": "そうなると、モデルを評価、トレーニング、モデル推論など、さまざまな方法で使いたいことになる。"
  },
  {
    "start": 156464,
    "end": 163504,
    "text": "モデルをトレーニングすることはできたのですが、なぜか評価と推論がうまくいきませんでした。"
  },
  {
    "start": 163592,
    "end": 179176,
    "text": "これはトーチのコンパイル・エラーの一例で、他のものでした。覚えていませんし、キャプチャもしませんでしたが、推論とevalの両方でエラーが出て、別のエラーも出て、何が起こっているのかさっぱりわかりませんでした。"
  },
  {
    "start": 179328,
    "end": 180544,
    "text": "私は誰にでもできることをした。"
  },
  {
    "start": 180552,
    "end": 192490,
    "text": "その後、私は教会に行き、私の問題を解決するためにPTR BLTKを探していた。"
  },
  {
    "start": 193030,
    "end": 197486,
    "text": "残念なことに、PTR BLTKにはこのエラーに関するガイダンスはなかった。"
  },
  {
    "start": 197598,
    "end": 198886,
    "text": "正直、行き詰まっていたんだ。"
  },
  {
    "start": 198918,
    "end": 206170,
    "text": "2時間後、トーチのコンパイルと格闘し、一体何が起こっているのか理解しようとした。"
  },
  {
    "start": 206630,
    "end": 211950,
    "text": "だから、最初の頃は否定されたような気分だった。"
  },
  {
    "start": 211990,
    "end": 213342,
    "text": "こんなことが私に起こるはずがないと思った。"
  },
  {
    "start": 213366,
    "end": 217514,
    "text": "クレイジーなことは何もしていない。GPTを少しトレーニングしているだけだ。"
  },
  {
    "start": 217602,
    "end": 220114,
    "text": "これは本当に簡単なことのように思える。"
  },
  {
    "start": 220242,
    "end": 226954,
    "text": "そして、やがて怒りの境地に入り、よし、もちろん全部書くぞ、という気持ちになった。"
  },
  {
    "start": 227122,
    "end": 229842,
    "text": "自分のやろうとしていることは頭では理解している。"
  },
  {
    "start": 229906,
    "end": 236426,
    "text": "トーチ・コンパイラーは、なぜかそれを使ったり、実行したりすることを許してくれない。"
  },
  {
    "start": 236458,
    "end": 238074,
    "text": "少し無力感を感じた。"
  },
  {
    "start": 238122,
    "end": 242242,
    "text": "人生を自分の手で切り開き、自分の運命をコントロールするんだ。"
  },
  {
    "start": 242266,
    "end": 243696,
    "text": "cで書くよ。"
  },
  {
    "start": 243848,
    "end": 245220,
    "text": "どこまで悪いんだ？"
  },
  {
    "start": 246080,
    "end": 249728,
    "text": "ピートーチがあなたに何を提供しているのか、考えてみよう。"
  },
  {
    "start": 249824,
    "end": 252480,
    "text": "いろいろなことがあるけれど、多分、ここに関係することのいくつかだろう。"
  },
  {
    "start": 252640,
    "end": 258656,
    "text": "なぜ箇条書きになっているのかわかりませんが、私のスライドではまったく問題ありません。"
  },
  {
    "start": 258688,
    "end": 259500,
    "text": "分からないよ。"
  },
  {
    "start": 260640,
    "end": 263336,
    "text": "オーケー、でも1つ目は、配列を取得しているんだよね？"
  },
  {
    "start": 263368,
    "end": 266648,
    "text": "演算を操作できる非常に便利なn次元配列です。"
  },
  {
    "start": 266784,
    "end": 273210,
    "text": "もしこれを放棄するのであれば、多くのパンクチャー演算を行う必要がある。"
  },
  {
    "start": 273370,
    "end": 274954,
    "text": "二つ目は、サインをタダでもらえることだ。"
  },
  {
    "start": 275002,
    "end": 279230,
    "text": "オートグラフがなければ、すべてのレイヤーでフォワードパスとバックワードパスをする必要がある。"
  },
  {
    "start": 279570,
    "end": 286762,
    "text": "私たちにはデバイスがないので、メモリがホスト上にあるかデバイス上にあるか、CPUとGPUの間で異なるデバイスにメモリを振り分けるかどうかを心配しなければならない。"
  },
  {
    "start": 286786,
    "end": 287498,
    "text": "そうだ。"
  },
  {
    "start": 287634,
    "end": 294650,
    "text": "私たちには単純なDTAP変換がないので、どのテンソルがどのような精度で保存されているかに細心の注意を払い、それらの間で明示的に変換しなければならない。"
  },
  {
    "start": 294770,
    "end": 296072,
    "text": "コンパイルする必要はない。"
  },
  {
    "start": 296186,
    "end": 302116,
    "text": "私たちが望むカーネル機能はすべて手動で行わなければならないし、時空間パフォーマンスの最適化も手動で行わなければならない。"
  },
  {
    "start": 302308,
    "end": 308764,
    "text": "そのため、すべてのプロセスを手動で立ち上げ、互いを見つけ、ニッケルと通信できるようにしなければならない。"
  },
  {
    "start": 308892,
    "end": 312460,
    "text": "Pytorchは本当に本当に素晴らしく、これはPytorchが提供するもののほんの一部だ。"
  },
  {
    "start": 312540,
    "end": 314708,
    "text": "ピートーチがいなければ、僕らは世界で裸同然だろう？"
  },
  {
    "start": 314764,
    "end": 316476,
    "text": "多分、大丈夫だと思う。"
  },
  {
    "start": 316668,
    "end": 319340,
    "text": "ああ、どこまで悪いんだ？"
  },
  {
    "start": 319380,
    "end": 324108,
    "text": "ステップ1では、pytorchのコードを持っている。"
  },
  {
    "start": 324124,
    "end": 327694,
    "text": "それは、私たちが正しさをチェックするための参照でしかない。"
  },
  {
    "start": 327822,
    "end": 328990,
    "text": "私たちはパイプロシュの土地にいる。"
  },
  {
    "start": 329030,
    "end": 329990,
    "text": "すべてが素晴らしく、清潔だ。"
  },
  {
    "start": 330030,
    "end": 332638,
    "text": "小さな変圧器といくつかのモジュールがあって、それを呼んでいるだけだ。"
  },
  {
    "start": 332654,
    "end": 333534,
    "text": "すべてが素晴らしい。"
  },
  {
    "start": 333622,
    "end": 336010,
    "text": "ピケロッホでのリファレンスとなる。"
  },
  {
    "start": 336630,
    "end": 338918,
    "text": "レイヤーの一例をお見せしよう。"
  },
  {
    "start": 338974,
    "end": 344862,
    "text": "例えば、ここにあるレイヤー・ノームはピクロアチームのレイヤーのようなもので、基本的にはこれをcに移植したい。"
  },
  {
    "start": 344966,
    "end": 346534,
    "text": "どのようなプロセスを経るのか？"
  },
  {
    "start": 346622,
    "end": 348110,
    "text": "では、すべてのレイヤーを反復することにしよう。"
  },
  {
    "start": 348190,
    "end": 350310,
    "text": "第一に、前方へのパスが必要だ。"
  },
  {
    "start": 350430,
    "end": 361220,
    "text": "というのも、Pytorchはレイヤーノルムの実装をPytorchだけで実装しているわけではなく、ブロックのようなもので、最終的にはいくつかのcudaカーネルに入るからです。"
  },
  {
    "start": 361380,
    "end": 365980,
    "text": "レイヤーノルムのフォワードパスを書いて、それがPytorchのレイヤーノルムと同等であることを確認しなければならなかった。"
  },
  {
    "start": 366140,
    "end": 369116,
    "text": "そしてもちろん、レイヤーノルムのバックワードパスを書かなければならなかった。"
  },
  {
    "start": 369228,
    "end": 372316,
    "text": "ここでペンと紙を取り出し、背景を描く。"
  },
  {
    "start": 372468,
    "end": 375356,
    "text": "これはバッチノルムの場合だが、レイヤーノルムも同様だろう。"
  },
  {
    "start": 375548,
    "end": 377500,
    "text": "ああ、バックワードパスを書かなければならなかった。"
  },
  {
    "start": 377620,
    "end": 380538,
    "text": "繰り返しますが、これはまだすべてピトーチの中です。"
  },
  {
    "start": 380604,
    "end": 391022,
    "text": "Pytorchの前方および後方のレイヤーノルムが、この代表的な、基本的に手動のテンソルベースの実装と一致していることを確認するだけだ。"
  },
  {
    "start": 391166,
    "end": 393686,
    "text": "これでPytorchのコードは前方後方になった。"
  },
  {
    "start": 393878,
    "end": 398846,
    "text": "次にすることは、それをcに移植することだ。これは実は、多くの場合、皆さんが思っているよりずっと簡単なことなんだ。"
  },
  {
    "start": 398918,
    "end": 403410,
    "text": "左側がPytorchのコードで、右側が基本的にC言語で書かれた同等のレイヤー・ノード・フォワードだ。"
  },
  {
    "start": 403790,
    "end": 405930,
    "text": "そんなにクレイジーじゃないだろ？"
  },
  {
    "start": 406730,
    "end": 410554,
    "text": "Pytorchの時とは違って、フロートスターの配列がたくさんある。"
  },
  {
    "start": 410722,
    "end": 412178,
    "text": "フロートスターが出た。"
  },
  {
    "start": 412234,
    "end": 417298,
    "text": "Floatstarの入力、出力、平均、標準偏差、重み、バイアス、そしていくつかのハイパーハンマー。"
  },
  {
    "start": 417434,
    "end": 421394,
    "text": "僕がLLCでやりたいことのひとつは、物事をシンプルにすることなんだ。"
  },
  {
    "start": 421482,
    "end": 425402,
    "text": "テンソルを抽象化するのではなく、どんな抽象化もしたくないんだ。"
  },
  {
    "start": 425506,
    "end": 428530,
    "text": "単なる浮動小数点配列と浮動小数点配列に対する演算だ。"
  },
  {
    "start": 428610,
    "end": 430546,
    "text": "なぜ、もっと複雑であるべきなのか。"
  },
  {
    "start": 430658,
    "end": 433698,
    "text": "すべてが単なる浮動小数点配列で、すべてが完全に自己完結している。"
  },
  {
    "start": 433754,
    "end": 437884,
    "text": "根底にある表現、インポートと呼ばれる抽象化などがない。"
  },
  {
    "start": 437972,
    "end": 439972,
    "text": "これは、フロート・アレイの前進である。"
  },
  {
    "start": 440036,
    "end": 440988,
    "text": "それだけだ。"
  },
  {
    "start": 441084,
    "end": 442160,
    "text": "それがフォワードだ。"
  },
  {
    "start": 442780,
    "end": 445468,
    "text": "次に、すべてのレイヤーに対して後戻りをする。"
  },
  {
    "start": 445644,
    "end": 453120,
    "text": "すべてのレイヤーでこの作業を行い、すべてをcに変換して、リファレンス実装と一致していることを確認したら、それをひも付けしていく。"
  },
  {
    "start": 453820,
    "end": 461598,
    "text": "メインでCのコードに入り、LLM Cで使用するすべてのメモリを割り当てなければならない。"
  },
  {
    "start": 461694,
    "end": 464614,
    "text": "すべての割り当ては最初に一度だけ行われる。"
  },
  {
    "start": 464702,
    "end": 467486,
    "text": "私たちは、これから使うすべてのメモリをあらかじめ計画している。"
  },
  {
    "start": 467638,
    "end": 472982,
    "text": "そうすれば固定され、それ以降はただデータを送り込んでモデルをトレーニングするだけのダイナミクスになる。"
  },
  {
    "start": 473086,
    "end": 483662,
    "text": "すべてのテンソル、そのサイズ、そしてパラメータを事前に計画する必要がある。"
  },
  {
    "start": 483686,
    "end": 485596,
    "text": "データもグラッドもスペースが必要だ。"
  },
  {
    "start": 485758,
    "end": 490712,
    "text": "だから、すべてのメモリを事前に計画し、それをすべて割り当ててから、それをつなぎ合わせる必要がある。"
  },
  {
    "start": 490816,
    "end": 496288,
    "text": "これらのレイヤーはすべて、バックプロパゲーションのフォワードパスとバックワードパスを持っている。"
  },
  {
    "start": 496304,
    "end": 509632,
    "text": "フォワード・パスは、テスターをすべて割り当て、細心の注意を払ってインデックスを作成し、すべてが正しく流れるようにします。"
  },
  {
    "start": 509736,
    "end": 512632,
    "text": "それをつなぎ合わせるのが2つ目の仕事だ。"
  },
  {
    "start": 512776,
    "end": 516832,
    "text": "そうすれば、コンパイルして走らせるだけでいいものができる。"
  },
  {
    "start": 516936,
    "end": 520304,
    "text": "左上にあるのが、必要なものすべてだ。"
  },
  {
    "start": 520432,
    "end": 525584,
    "text": "私たちはスターターパックをダウンロードします。これはGPT-2のウェイトを1つのバイナリファイルにしただけのもので、とてもシンプルです。"
  },
  {
    "start": 525752,
    "end": 530536,
    "text": "また、この場合は小さなシェイクスピアのデータセットとトークナイザーも必要だ。"
  },
  {
    "start": 530648,
    "end": 533824,
    "text": "そして、この小さなCコード・ファイルをコンパイルして実行するだけだ。"
  },
  {
    "start": 533872,
    "end": 536424,
    "text": "この時点ではcのシングルファイルだ。"
  },
  {
    "start": 536592,
    "end": 540036,
    "text": "私の記憶が正しければ、2000行とかそんな感じだったと思う。"
  },
  {
    "start": 540168,
    "end": 548892,
    "text": "パイプライン・コードがCコードを識別していることを確認することができる。"
  },
  {
    "start": 548956,
    "end": 551052,
    "text": "Cで走っているだけですべてが素晴らしい。"
  },
  {
    "start": 551196,
    "end": 555900,
    "text": "この時点で、私はとても素晴らしい気分になっている。"
  },
  {
    "start": 556060,
    "end": 559508,
    "text": "ファイルcが1つあるだけで、何の依存関係もない。"
  },
  {
    "start": 559684,
    "end": 565252,
    "text": "即座にコンパイルされ、即座に実行され、すべてのメモリは単一のブロブに割り当てられる。"
  },
  {
    "start": 565356,
    "end": 568002,
    "text": "ステップを踏み始めると、後でブームになることはない。"
  },
  {
    "start": 568116,
    "end": 570622,
    "text": "すべて事前に計画されており、完全に決定論的だ。"
  },
  {
    "start": 570766,
    "end": 575846,
    "text": "原理的にはGPT-2をトレーニングすることができる。"
  },
  {
    "start": 576038,
    "end": 578502,
    "text": "ジャガイモの上でも、どんなものの上でも動く。"
  },
  {
    "start": 578526,
    "end": 580646,
    "text": "これは、依存関係のない単一のCファイルだ。"
  },
  {
    "start": 580758,
    "end": 591550,
    "text": "原理的には、これは探査機で動かすのに最適な候補だろう。宇宙では、もう少し固めれば、記念碑的な探査機に高いトーチコードを搭載することはないだろうから。"
  },
  {
    "start": 591630,
    "end": 593250,
    "text": "LMCは素晴らしいと思う。"
  },
  {
    "start": 596320,
    "end": 598128,
    "text": "この時点では最高の気分だった。"
  },
  {
    "start": 598304,
    "end": 605368,
    "text": "余談だが、モルディブで時差ぼけになっていたとき、これまで説明したような仕事をした。"
  },
  {
    "start": 605544,
    "end": 609192,
    "text": "基本的に午前1時に目覚めるので完璧だ。"
  },
  {
    "start": 609296,
    "end": 610540,
    "text": "何もすることがない。"
  },
  {
    "start": 610840,
    "end": 615192,
    "text": "Cローンのようなものを書いて、日の出にはすべての天候アクティビティをしに行くんだ。"
  },
  {
    "start": 615296,
    "end": 618780,
    "text": "そこは、ローワンCのほとんどがトレーニングを受けていた別荘だ。"
  },
  {
    "start": 619080,
    "end": 620056,
    "text": "完璧だった。"
  },
  {
    "start": 620128,
    "end": 621522,
    "text": "これもその写真だ。"
  },
  {
    "start": 621656,
    "end": 623370,
    "text": "これは"
  },
  {
    "start": 623790,
    "end": 626534,
    "text": "月が沈み、日の出が起きようとしていると思う。"
  },
  {
    "start": 626622,
    "end": 629170,
    "text": "これは、ソフトウェア開発を行う上で推奨される方法である。"
  },
  {
    "start": 632190,
    "end": 635494,
    "text": "さて、Cのコードができたが、効率が悪いのでもっと速く実行したい。"
  },
  {
    "start": 635582,
    "end": 637054,
    "text": "そのためには4つのGPUが必要だ。"
  },
  {
    "start": 637102,
    "end": 639166,
    "text": "すべてのCコードをGPUに変換する必要がある。"
  },
  {
    "start": 639318,
    "end": 643718,
    "text": "ここでリコの開発クーダのパートに行き、すべてのカーネルを開発し始める。"
  },
  {
    "start": 643814,
    "end": 645950,
    "text": "先ほどのレイヤリング・フォワード・パスだ。"
  },
  {
    "start": 646030,
    "end": 651442,
    "text": "今、私たちは、同じ機能を持ちながらGPU上で動作し、より高速なカーネルをいくつか開発するつもりだ。"
  },
  {
    "start": 651606,
    "end": 656514,
    "text": "通常、バージョン123456などがあり、それらはすべて異なるカーネル実装だ。"
  },
  {
    "start": 656562,
    "end": 662370,
    "text": "通常、時間が経つにつれて少し速くなるが、仕様にぴったり合っており、まったく同じ数値が出る。"
  },
  {
    "start": 662530,
    "end": 665150,
    "text": "私たちはそれらのレイヤーをすべて開発し、CuDAに持ち込んだ。"
  },
  {
    "start": 665570,
    "end": 671146,
    "text": "これが何なのか分からないが、基本的にはカーネルの一つだ。"
  },
  {
    "start": 671178,
    "end": 684396,
    "text": "ここで重要なのは、最初のカーネルは、バッチとタイで並列化するため、通常は些細なことで、その後、基本的にCコードをcudaカーネルにコピーペーストし、bashのタイムトークンを麻痺させるため、すでにスピードアップを得ているということです。"
  },
  {
    "start": 684428,
    "end": 686820,
    "text": "各スレッドは単一の出力要素を処理するだけである。"
  },
  {
    "start": 686860,
    "end": 691732,
    "text": "最初のカーネルは通常些細なことだが、その後、最適化はかなり精巧になる。"
  },
  {
    "start": 691836,
    "end": 694460,
    "text": "最後にはカーネル6になる。"
  },
  {
    "start": 694540,
    "end": 696300,
    "text": "我々はもう少し複雑なことをたくさんやっている。"
  },
  {
    "start": 696340,
    "end": 700404,
    "text": "もっと生産的な仕事もある。"
  },
  {
    "start": 700532,
    "end": 703556,
    "text": "また、共有メモリーやユーバーメモリーを通じてコミュニケーションをとることもある。"
  },
  {
    "start": 703588,
    "end": 711250,
    "text": "私たちはそれを正しく編成し、策略的なヒントをキャッシュし、すべてに対処するための小さなヒントやトリックをたくさん用意している。"
  },
  {
    "start": 711950,
    "end": 715934,
    "text": "後でもう少し詳しく説明するつもりだが、ここでは任意に複雑にすることができる。"
  },
  {
    "start": 715982,
    "end": 717570,
    "text": "Cudaのコードを書く。"
  },
  {
    "start": 717910,
    "end": 725490,
    "text": "このプロジェクトでわかったことのひとつは、残念ながらCudAを学ぶのは簡単ではないということだ。"
  },
  {
    "start": 726070,
    "end": 729574,
    "text": "CudAも使っているが、もっとうまくなるのは簡単なことではないと思う。"
  },
  {
    "start": 729662,
    "end": 733066,
    "text": "これらの本の中には、残念ながらどれも少し古くなってしまったものもあると思う。"
  },
  {
    "start": 733178,
    "end": 745730,
    "text": "というのも、LMCプロジェクト期間中に開発したCUDAコードの多くは、この本には載っていないからです。"
  },
  {
    "start": 745850,
    "end": 750802,
    "text": "結局、追加したカーネルの多くはカバーしきれなかった。"
  },
  {
    "start": 750906,
    "end": 759036,
    "text": "その上、このCUDA Cプログラミング・ガイドがあるが、正直なところ、CUDAの初心者には読みにくい。"
  },
  {
    "start": 759218,
    "end": 764712,
    "text": "そして、サイモン・ゼフィン・トロピックのこの素晴らしいブログ記事がある。"
  },
  {
    "start": 764736,
    "end": 766088,
    "text": "インターネットで適当に。"
  },
  {
    "start": 766184,
    "end": 767152,
    "text": "信じられないよ。"
  },
  {
    "start": 767216,
    "end": 769200,
    "text": "それがもっとあれば、とても素晴らしいことだ。"
  },
  {
    "start": 769240,
    "end": 772660,
    "text": "そう、だからちょっと難しいと思ったんだ。"
  },
  {
    "start": 773360,
    "end": 781720,
    "text": "つまり、クーダ・モードのようなものが、クーダを書くことの可能性を間違いなく速めてくれることを期待しているんだ。"
  },
  {
    "start": 781880,
    "end": 788028,
    "text": "さて、次に何が起こったかというと、僕は基本的にCudaのコードと少し格闘していた。"
  },
  {
    "start": 788084,
    "end": 794524,
    "text": "この本を読みながらクーダのカーネルを実装していたんだけど、クーダのカーネルはいいんだけど、イマイチなんだよね。"
  },
  {
    "start": 794652,
    "end": 799852,
    "text": "そこで、ナジを見たアベンジャーズのチームがインターネットから集結し、寄稿を始めた。"
  },
  {
    "start": 799876,
    "end": 807044,
    "text": "特に、エリック・アルン・アレクサールは、アルムナージの中心的な開発者であり、LMCに多大な貢献をしてくれた。"
  },
  {
    "start": 807172,
    "end": 810492,
    "text": "彼らは本当に最適化し、すべてのカーネルを書き始めた。"
  },
  {
    "start": 810516,
    "end": 812956,
    "text": "これはね、法律を学ぶためのものなんだ。"
  },
  {
    "start": 813068,
    "end": 817156,
    "text": "ロス・ウィーラーやチン・ティズル、他にもたくさんいる。"
  },
  {
    "start": 817348,
    "end": 820604,
    "text": "時を経て、OMNCプロジェクトへの貢献者は60人になった。"
  },
  {
    "start": 820732,
    "end": 823140,
    "text": "オルムダージのスポンサーとなったラムダにエールを送りたい。"
  },
  {
    "start": 823260,
    "end": 826900,
    "text": "これらのカーネルをすべて走らせ、最適化できるように、彼らは計算に貢献している。"
  },
  {
    "start": 827020,
    "end": 830252,
    "text": "インターネットから人々が集まってきて、プロジェクトに協力してくれたことは、私にとって驚きだった。"
  },
  {
    "start": 830316,
    "end": 832836,
    "text": "そしてね、これは起こりうることの中で最も好きなことの一つなんだ。"
  },
  {
    "start": 833028,
    "end": 836356,
    "text": "オープンソースのMITライセンスデポで起こりうる私のお気に入りのこと。"
  },
  {
    "start": 836428,
    "end": 839108,
    "text": "みんなインターネットからやってきて、貢献している。"
  },
  {
    "start": 839164,
    "end": 840120,
    "text": "素晴らしいよ。"
  },
  {
    "start": 840700,
    "end": 843532,
    "text": "さて、すべてのレイヤーをクダに変換した。"
  },
  {
    "start": 843596,
    "end": 848348,
    "text": "これですべてのカーネルが揃い、これまでのFE32ではシングルGPUでトレーニングできるようになった。"
  },
  {
    "start": 848444,
    "end": 849400,
    "text": "それは素晴らしいことだ。"
  },
  {
    "start": 849820,
    "end": 852476,
    "text": "それ以降、私たちはどんどん最適化を進めていく。"
  },
  {
    "start": 852508,
    "end": 857040,
    "text": "第一に、あなた自身のコードをロールバックするときに、マップMolson FPE 32を持ちたくない。"
  },
  {
    "start": 857340,
    "end": 862804,
    "text": "私たちは実際にクブラのステップ2に切り替えた。"
  },
  {
    "start": 862892,
    "end": 864164,
    "text": "それはかなり複雑だと思う。"
  },
  {
    "start": 864252,
    "end": 867136,
    "text": "クッキー・ナンドには、非常に優れたフラッシュ・テンションの実装があることがわかった。"
  },
  {
    "start": 867248,
    "end": 868740,
    "text": "我々はそれに切り替える。"
  },
  {
    "start": 870640,
    "end": 876160,
    "text": "次に、コードをスピードアップするために、ベース精度に手を伸ばしたい。"
  },
  {
    "start": 876240,
    "end": 880944,
    "text": "パラメータやアクティベーションなど、すべてのテンソルを調べたい。"
  },
  {
    "start": 880992,
    "end": 886472,
    "text": "どれがfloat32で、どれがbflow16で、どれがどれだけの割合を占めているのかを考えなければならない。"
  },
  {
    "start": 886496,
    "end": 888688,
    "text": "そうすれば、すべての変換を自動的に行います。"
  },
  {
    "start": 888784,
    "end": 891318,
    "text": "そのために手を伸ばし、実行する。"
  },
  {
    "start": 891464,
    "end": 894418,
    "text": "他にも、時間をかけて実装した最適化はたくさんある。"
  },
  {
    "start": 894514,
    "end": 901190,
    "text": "例として、すべてのカーネルフュージョンを異なる再計算設定で行い、バックワード中にフォワードパスの一部を再計算した。"
  },
  {
    "start": 902450,
    "end": 907950,
    "text": "エリックからは、特に後方パス時に必要なメモリ量の最小化について、多くの最適化がなされている。"
  },
  {
    "start": 908810,
    "end": 920660,
    "text": "私たちの経験では、基本的に128ビットのロード命令とストア命令をコンパイラに使わせるのだが、どういうわけかコンパイラは多くの場合使いたがらない。"
  },
  {
    "start": 920850,
    "end": 939256,
    "text": "SASを見て、アセンブリのSASを見て、ループに使われている命令を見て、これは128ビットのロードストアであるべきだが、MCCコンパイラの何かがうまくいっていないために、たまたま32ビットかそれ以外になってしまったのだ。"
  },
  {
    "start": 939288,
    "end": 943340,
    "text": "このデータ構造は、コンパイラの手を少し強引に動かすようなものだ。"
  },
  {
    "start": 943800,
    "end": 950270,
    "text": "私たちは、計算の一部をオーバーラップさせるために、あらゆる種類のCUDAストリームを実装しましたが、これは大失敗に終わりました。"
  },
  {
    "start": 950930,
    "end": 957850,
    "text": "アルンが言うように、僕は基本的に軌道上から核攻撃を仕掛けたんだ。"
  },
  {
    "start": 957970,
    "end": 962970,
    "text": "私は今、ストリームに関するすべての言及をコントロールFで検索し、削除、削除、削除したところだ。"
  },
  {
    "start": 963090,
    "end": 969098,
    "text": "基本的には、すべてのストリームを削除し、すべてをシングルスレッドにした。"
  },
  {
    "start": 969114,
    "end": 970098,
    "text": "ただ、それに関わりたくなかったんだ。"
  },
  {
    "start": 970114,
    "end": 977506,
    "text": "だから、エレンCは実際には重なり合うことはないのだが、ただ、現時点では十分な利益のために複雑すぎるという感じだ。"
  },
  {
    "start": 977538,
    "end": 978110,
    "text": "だから"
  },
  {
    "start": 978450,
    "end": 981530,
    "text": "その一部をゆっくりと再導入できるかもしれない。"
  },
  {
    "start": 981650,
    "end": 983714,
    "text": "私たちには確率的な根拠があり、完全な決定論がある。"
  },
  {
    "start": 983802,
    "end": 988954,
    "text": "完全な決定論はかなり難しいことがわかった。アトミックが使えないため、カーネルのいくつかはかなり複雑化するからだ。"
  },
  {
    "start": 989042,
    "end": 996202,
    "text": "エンコーダーバックワードは特にクレイジーだった。エンコーダーバックワードはアトミックがあれば些細なことだが、アトミックがなければ些細なことではない。"
  },
  {
    "start": 996346,
    "end": 1005700,
    "text": "とにかく、多くの最適化は、効率性と決定論、そしてストキャスティックやランダムなどの精度を念頭に置いて行われた。"
  },
  {
    "start": 1006080,
    "end": 1008632,
    "text": "次に、単一のGPUだけでなく、複数のGPUを使いたい。"
  },
  {
    "start": 1008696,
    "end": 1014912,
    "text": "そこでニッケルを導入し、すべての異なる労働者の間で概要を把握するのだ。"
  },
  {
    "start": 1015096,
    "end": 1031480,
    "text": "これは基本的に、オプティマイザーのステートをfloatにするもので、aとwのための本当に大きなバッファです。"
  },
  {
    "start": 1031560,
    "end": 1033816,
    "text": "そのために手を差し伸べるのはとても役に立つ。"
  },
  {
    "start": 1033928,
    "end": 1037640,
    "text": "現在、omnipはゼロワンを使用している。これは、シャードされたオプティマイザの状態である。"
  },
  {
    "start": 1037720,
    "end": 1044744,
    "text": "PR402があるが、少し面倒なのでまだマージしていないと思うが、いずれマージされるかもしれない。"
  },
  {
    "start": 1044872,
    "end": 1052604,
    "text": "LMCの多くは、スピードの向上と実際に導入するものの複雑さとのバランスを取るようなものなんだ。"
  },
  {
    "start": 1052652,
    "end": 1059800,
    "text": "コードがクレイジーになり始めると、負担をかけられる人数が減ってしまうからだ。"
  },
  {
    "start": 1061460,
    "end": 1063884,
    "text": "マルチGBの次はマルチノードだ。"
  },
  {
    "start": 1063932,
    "end": 1069556,
    "text": "複数のマシンにまたがって実行する場合、すべてのマシンを同期させ、互いを見つけられるようにしなければならない。"
  },
  {
    "start": 1069588,
    "end": 1077146,
    "text": "その結果、qPT2を実際に回すことができるようになり、すべての作業の後に実際に再現できるようになった。"
  },
  {
    "start": 1077268,
    "end": 1078726,
    "text": "ディスカッションに投稿がある。"
  },
  {
    "start": 1078758,
    "end": 1091638,
    "text": "Lom Cは、2019年くらいの時点で最先端のLLMであった16億GPT-2を、h100台のシングルノードで約24時間で訓練することができ、そのコストはおよそ600ドルです。"
  },
  {
    "start": 1091814,
    "end": 1094190,
    "text": "そうすることで、依存性が非常になくなる。"
  },
  {
    "start": 1094230,
    "end": 1100270,
    "text": "pythonもpytorchも必要ないので、最も重い依存関係であるCudnnが必要だ。"
  },
  {
    "start": 1100390,
    "end": 1101686,
    "text": "カドンはオプション。"
  },
  {
    "start": 1101758,
    "end": 1109182,
    "text": "しかし、Cubianは最も面倒な依存関係のようなもので、それ以降はただのcコードの束だ。"
  },
  {
    "start": 1109206,
    "end": 1110230,
    "text": "それをコンパイルして実行する。"
  },
  {
    "start": 1110270,
    "end": 1112142,
    "text": "本当に何も必要ない。"
  },
  {
    "start": 1112286,
    "end": 1116582,
    "text": "コンダ環境もピットインストールも必要ない。"
  },
  {
    "start": 1116766,
    "end": 1119750,
    "text": "そしてコードをコンパイルして実行すると、ステップを踏み始める。"
  },
  {
    "start": 1119790,
    "end": 1123374,
    "text": "24時間待って、それで終わりだ。"
  },
  {
    "start": 1123542,
    "end": 1124734,
    "text": "診断結果を印刷する。"
  },
  {
    "start": 1124822,
    "end": 1134128,
    "text": "ここでは1つのノードでmfuが50％近くあり、とても良い。"
  },
  {
    "start": 1134264,
    "end": 1137216,
    "text": "基本的に、これは最適化がうまくいったことを示している。"
  },
  {
    "start": 1137328,
    "end": 1141080,
    "text": "このサイズでは、おかしな数値の問題やパイプの紛失などはない。"
  },
  {
    "start": 1141240,
    "end": 1152720,
    "text": "そう、LMSのGBPは、まだPytorchと比較することができる。"
  },
  {
    "start": 1152840,
    "end": 1158754,
    "text": "そのため、Pytorchでほぼ同等のトレーニングを実行することができ、2つの実装を並べて比較することができる。"
  },
  {
    "start": 1158922,
    "end": 1165954,
    "text": "というのも、Pytorchチームは時間をかけて最適化を続けているからだ。"
  },
  {
    "start": 1166042,
    "end": 1169018,
    "text": "この投稿の時点では、私たちはNLMを使っていました。"
  },
  {
    "start": 1169034,
    "end": 1173402,
    "text": "メモリは30％減り、トレーニングは20％速くなった。"
  },
  {
    "start": 1173546,
    "end": 1176698,
    "text": "pytorchの実装を完全に超最適化したかどうかはわからない。"
  },
  {
    "start": 1176754,
    "end": 1184408,
    "text": "自己ベストを更新することができたが、具体的にはGPT-2のエレンがブンブン振っていた。"
  },
  {
    "start": 1184544,
    "end": 1187020,
    "text": "それ以外のトレーニングをしようと思ったら、大変なことになる。"
  },
  {
    "start": 1188200,
    "end": 1191440,
    "text": "コードを何度も変更しなければならない。"
  },
  {
    "start": 1191520,
    "end": 1194900,
    "text": "GPTのトレーニングのために、あれだけの仕事をしたんだ。"
  },
  {
    "start": 1195520,
    "end": 1198032,
    "text": "また、コンパイルや動作も格段に速くなった。"
  },
  {
    "start": 1198096,
    "end": 1200680,
    "text": "トーチのコンパイルには1分とかかなり時間がかかる。"
  },
  {
    "start": 1200720,
    "end": 1201552,
    "text": "ただ待っているだけだ。"
  },
  {
    "start": 1201696,
    "end": 1205088,
    "text": "というのも、個人的にはあまりやりたくないことなんだ。"
  },
  {
    "start": 1205264,
    "end": 1209536,
    "text": "さて、ループして戻ってみると、それほど単純なことではなかった。"
  },
  {
    "start": 1209728,
    "end": 1216202,
    "text": "いろいろなことがあり、何人かで数ヶ月かかったが、楽しかった。"
  },
  {
    "start": 1216346,
    "end": 1218830,
    "text": "多くのことを学んだし、その過程で友人もできた。"
  },
  {
    "start": 1222490,
    "end": 1225746,
    "text": "現在進行形の素晴らしい仕事だった。"
  },
  {
    "start": 1225898,
    "end": 1227394,
    "text": "ラムダ・スリーのサポートを追加します。"
  },
  {
    "start": 1227482,
    "end": 1233666,
    "text": "本当は今日までに完成させるつもりだったんだけど、もう少し、もう少し仕事が残っているんだ。"
  },
  {
    "start": 1233778,
    "end": 1237670,
    "text": "もうすぐラマCでラマ3.1のトレーニングがあります。"
  },
  {
    "start": 1238130,
    "end": 1240172,
    "text": "FP8人のサポートがある。"
  },
  {
    "start": 1240236,
    "end": 1246960,
    "text": "アルンはこの件に取り組んでおり、FP 8のサポートについても少しPRしている。"
  },
  {
    "start": 1247780,
    "end": 1250084,
    "text": "あのシートには注目すべきフォークがたくさんある。"
  },
  {
    "start": 1250132,
    "end": 1251760,
    "text": "GitHubのレポにもある。"
  },
  {
    "start": 1252060,
    "end": 1256692,
    "text": "私が理解する限り、AMDのフォークは非常に活発で、かなり優れていると思う。"
  },
  {
    "start": 1256716,
    "end": 1260044,
    "text": "また、クーダのフォークもなかなかいい。"
  },
  {
    "start": 1260172,
    "end": 1261840,
    "text": "だからフォークが多い。"
  },
  {
    "start": 1262780,
    "end": 1265356,
    "text": "ヘレン・Cの分もよろしく。"
  },
  {
    "start": 1265388,
    "end": 1266452,
    "text": "かなり読みやすいと思う。"
  },
  {
    "start": 1266476,
    "end": 1268316,
    "text": "私はそれを清潔に保ち、十分に文書化するよう心がけている。"
  },
  {
    "start": 1268348,
    "end": 1270354,
    "text": "中身はよく理解されていると思う。"
  },
  {
    "start": 1270452,
    "end": 1274610,
    "text": "基本的にスチームがほとんどで、3000行くらいのコードしかないと思う。"
  },
  {
    "start": 1275790,
    "end": 1282006,
    "text": "もうひとつ、私が伝えたかったのは、このプロジェクトを始めるにあたって、すべてが行き当たりばったりだったわけではないということだ。"
  },
  {
    "start": 1282118,
    "end": 1288830,
    "text": "LNCとは何なのか？"
  },
  {
    "start": 1288910,
    "end": 1293022,
    "text": "Pytorchが特にそうだとすれば、torchはソフトウェア2.0用のGCCのように少しコンパイルする。"
  },
  {
    "start": 1293086,
    "end": 1298210,
    "text": "LMCはコンパイラなんだから、アセンブリを書くようなものだ。"
  },
  {
    "start": 1298670,
    "end": 1310010,
    "text": "GPT-2のトレーニングという特殊な環境において、LLMCを3カ月かけて複数人で書き、Pytorchよりも速いものを得たのだと思う。"
  },
  {
    "start": 1310350,
    "end": 1313566,
    "text": "だから、この練習は基本的に、それが可能であることを証明している。"
  },
  {
    "start": 1313718,
    "end": 1325308,
    "text": "しかし、もしLLMが時間の経過とともにコーディングがもっと上手になるのであれば、LLNは時間の経過とともにどんなカスタム・アプリケーションにも対応できるようになるだろう。"
  },
  {
    "start": 1325454,
    "end": 1330296,
    "text": "だからLLMは、あなたが興味を持っているカスタム・アプリケーションのコンパイラのような役割を果たすことができる。"
  },
  {
    "start": 1330328,
    "end": 1336192,
    "text": "彼らはすべてのLLMスキームを実行し、あなたが特定のアプリケーション用にコンパイルして実行できるバイナリを出力する。"
  },
  {
    "start": 1336336,
    "end": 1344952,
    "text": "パイソンやピトーチを使うのが好きかどうかはわからないし、それ以外のものは、人間は有限で、知識も知性も注意力も有限だから、ただの松葉杖にすぎない。"
  },
  {
    "start": 1345136,
    "end": 1349568,
    "text": "実際、カスタムcudaカーネルなどですべてのコードを書きたいのではないですか？"
  },
  {
    "start": 1349664,
    "end": 1350390,
    "text": "たぶんね。"
  },
  {
    "start": 1350560,
    "end": 1360834,
    "text": "というのも、LLMの初期段階や彼らの知能では、ゼロからこのコードを書くことはできないかもしれないからだ。"
  },
  {
    "start": 1360882,
    "end": 1362858,
    "text": "あなたはGPT-2 LCの書き込みを促しただけだ。"
  },
  {
    "start": 1362954,
    "end": 1369522,
    "text": "おそらくLMLcは取得できないだろうが、LNcをセッションLLMの文脈で考えれば、取得できる可能性はかなり高くなる。"
  },
  {
    "start": 1369626,
    "end": 1373994,
    "text": "LLMにとって、基本的にサンプルコードを与えるための数発学習は非常に役に立つと予想できる。"
  },
  {
    "start": 1374082,
    "end": 1379964,
    "text": "だから、LMDHCはこのサンプルコードに非常に役立つと思う。"
  },
  {
    "start": 1380132,
    "end": 1382560,
    "text": "だから、この可能性は決して低くないと思う。"
  },
  {
    "start": 1383300,
    "end": 1384780,
    "text": "ああ、これは起こりそうなことだ。"
  },
  {
    "start": 1384820,
    "end": 1387372,
    "text": "おそらく、ソフトウェア開発全般が大きく変わっていくと思う。"
  },
  {
    "start": 1387396,
    "end": 1393324,
    "text": "というのも、もしそれが可能なら、もしかしたらこれが起こるかもしれないからだ。"
  },
  {
    "start": 1393372,
    "end": 1395268,
    "text": "そう、それだけだ。"
  },
  {
    "start": 1395284,
    "end": 1396000,
    "text": "ありがとう。"
  },
  {
    "start": 1405660,
    "end": 1406164,
    "text": "分かった。"
  },
  {
    "start": 1406212,
    "end": 1408180,
    "text": "まあ、午前のセッションのトークのようにね。"
  }
]