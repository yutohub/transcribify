[
  {
    "start": 250,
    "end": 1710,
    "text": "神経スケーリングの法則。"
  },
  {
    "start": 3730,
    "end": 7470,
    "text": "グレッグを追いかけるのは素晴らしいことだ。"
  },
  {
    "start": 8930,
    "end": 15306,
    "text": "じゃあ、哲学か物理学の話から始めようか。"
  },
  {
    "start": 15418,
    "end": 18080,
    "text": "データは理論と深層学習のダークマターである。"
  },
  {
    "start": 19090,
    "end": 24950,
    "text": "ディープラーニングに何を求めているのかを理解していなければ、ディープラーニングが何をしているのかを理解することは望めない。"
  },
  {
    "start": 25060,
    "end": 30066,
    "text": "私たちがディープラーニングに求めていることは、基本的にデータに埋め込まれている。"
  },
  {
    "start": 30098,
    "end": 35042,
    "text": "だから、他の領域と同じように、生物学でも進化を考慮しなければ意味がない。"
  },
  {
    "start": 35106,
    "end": 37538,
    "text": "神経科学では、行動に照らし合わせなければ意味をなさない。"
  },
  {
    "start": 37634,
    "end": 39334,
    "text": "これらは他人の有名な名言である。"
  },
  {
    "start": 39452,
    "end": 43130,
    "text": "いつか有名になりたいと思っているから、何か付け加えたいと思ったんだ。"
  },
  {
    "start": 43280,
    "end": 45894,
    "text": "これは私の引用であって、ジェットGPTの引用ではない。"
  },
  {
    "start": 46022,
    "end": 49242,
    "text": "ディープラーニングでは、データの構造に照らし合わせなければ意味をなさない。"
  },
  {
    "start": 49296,
    "end": 53820,
    "text": "ビッフィーほどではないし、おそらく有名にはならないだろうが、とにかく、私はまだ真実だと思う。"
  },
  {
    "start": 54430,
    "end": 56302,
    "text": "これは問題だろう？"
  },
  {
    "start": 56356,
    "end": 58670,
    "text": "私たちがデータを理解していないからだ。"
  },
  {
    "start": 58820,
    "end": 59694,
    "text": "光と言えるか？"
  },
  {
    "start": 59732,
    "end": 61150,
    "text": "レンズを通してということですか？"
  },
  {
    "start": 62370,
    "end": 63118,
    "text": "ああ、申し訳ない。"
  },
  {
    "start": 63204,
    "end": 64254,
    "text": "電源が入っていなかった。"
  },
  {
    "start": 64292,
    "end": 64880,
    "text": "オーケー。"
  },
  {
    "start": 66210,
    "end": 69010,
    "text": "データに対する理解不足が根本的な問題になりつつある。"
  },
  {
    "start": 69080,
    "end": 73346,
    "text": "例えば、GPT4ではトレーニングデータがどのようなものなのかさえわからないケースもある。"
  },
  {
    "start": 73528,
    "end": 77758,
    "text": "とはいえ、例えば試験を解くなど、目覚ましい新能力を目の当たりにすることもある。"
  },
  {
    "start": 77854,
    "end": 87826,
    "text": "これを見たとき、あなたがすぐに抱いた疑問は、これらの試験の問題集はどこまですでにウェブに載っているのか、そしてこれらの問題はウェブ全体で訓練されているのか、ということだったと思う。"
  },
  {
    "start": 87948,
    "end": 88620,
    "text": "そうだろう？"
  },
  {
    "start": 89150,
    "end": 96620,
    "text": "例えば、テキストやコードのインターネット全体を事前学習セットとした場合、このような新機能にどれほど驚かなければならないだろうか？"
  },
  {
    "start": 98990,
    "end": 101354,
    "text": "ただコピーしているだけということはないと思う。"
  },
  {
    "start": 101472,
    "end": 104942,
    "text": "興味深い質問に答えるために、実に興味深い方法で物事を組み合わせている。"
  },
  {
    "start": 105076,
    "end": 113674,
    "text": "仮に学習前のデータセットがどのようなものかがわかっていたとしても、例えば意識学習タスクのように、テスト時に実行されるタスクは実際どの程度違うのだろうか？"
  },
  {
    "start": 113802,
    "end": 117646,
    "text": "事前トレーニングで見たものと、果たしてどれだけ違うのか？"
  },
  {
    "start": 117838,
    "end": 120194,
    "text": "私たちはそのことをよく理解していない。"
  },
  {
    "start": 120392,
    "end": 126546,
    "text": "特に事前トレーニングセットの多様性について、2つの質問をするつもりだ。"
  },
  {
    "start": 126728,
    "end": 134290,
    "text": "例えば、新しいタスクの文脈学習のような新しい能力を可能にするために、事前学習セットはどの程度多様である必要があるのだろうか？"
  },
  {
    "start": 134370,
    "end": 137618,
    "text": "新しいタスクはどのように違って見えるのか？"
  },
  {
    "start": 137804,
    "end": 142460,
    "text": "新しいタスクはトレーニング前のデータとどの程度違うのか？"
  },
  {
    "start": 142990,
    "end": 145206,
    "text": "ニューラル・スケーリングの法則も？"
  },
  {
    "start": 145238,
    "end": 147180,
    "text": "それについては、ここで何度か話してきた。"
  },
  {
    "start": 148430,
    "end": 150634,
    "text": "性能はデータ量に応じてスケールする。"
  },
  {
    "start": 150752,
    "end": 154158,
    "text": "データの質が問題なのか、データの多様性が問題なのか。"
  },
  {
    "start": 154244,
    "end": 158890,
    "text": "より多様なデータを作ることができれば、ニューラル・スケーリングの法則に打ち勝つことができるのだろうか？"
  },
  {
    "start": 158970,
    "end": 160654,
    "text": "それが第2部になる。"
  },
  {
    "start": 160692,
    "end": 163850,
    "text": "基本的に、この話は2部構成になっている。"
  },
  {
    "start": 164010,
    "end": 167378,
    "text": "最初の部分は、グレッグが話していたことを実際に構築したものだ。"
  },
  {
    "start": 167544,
    "end": 170766,
    "text": "私たちは、回帰の文脈学習に焦点を当てるつもりだ。"
  },
  {
    "start": 170798,
    "end": 177870,
    "text": "なぜこのようなことをするかというと、管理された環境でこの問題に取り組むためだ。"
  },
  {
    "start": 177950,
    "end": 178638,
    "text": "そうだね。"
  },
  {
    "start": 178824,
    "end": 182210,
    "text": "回帰に焦点を当てることで、ひとつには、タスクの空間を定義することができる。"
  },
  {
    "start": 182290,
    "end": 190854,
    "text": "2つ目は、新しいタスクが訓練前のタスク集合とどれだけ違うかを定量的に評価できるような、タスク空間上のメトリックを定義できることだ。"
  },
  {
    "start": 190982,
    "end": 198550,
    "text": "訓練前データやタスクの多様性を制御された方法でパラメトリックに変化させることができる。"
  },
  {
    "start": 198710,
    "end": 208202,
    "text": "様々な事前分布の下での最適なベイズ学習器を導き出すことができ、これらの様々なベイズ学習器との関連において変換器の性能を定量的に理解することができる。"
  },
  {
    "start": 208266,
    "end": 210462,
    "text": "何が起こっているのかを理解することができる。"
  },
  {
    "start": 210596,
    "end": 220130,
    "text": "つまり、事前学習セットのタスクの多様性が閾値に達すると、文脈学習が突然現れるという相転移が見られるのだ。"
  },
  {
    "start": 220280,
    "end": 226430,
    "text": "この創発的な能力は、事前訓練課題分布を用いたベイズ学習では説明できない。"
  },
  {
    "start": 226510,
    "end": 233174,
    "text": "文脈学習を単なるベイジアン推論として説明しようとする様々なアプローチがあったが、そうではないことがわかった。"
  },
  {
    "start": 233212,
    "end": 238994,
    "text": "ベイズ推論がうまくいかないからこそ、新しいタスクの文脈学習がうまくいくのだ。"
  },
  {
    "start": 239122,
    "end": 247302,
    "text": "そして第2部では、データセットのサイズに対する性能の緩やかなパワーロスのスケーリングが、データが実際には高度に冗長であることを示していることを示すつもりだ。"
  },
  {
    "start": 247446,
    "end": 253820,
    "text": "冗長でない、より多様なデータセットを見つけることで、これらの既存のニューラル・スケーリングを大幅に上回ることができる。"
  },
  {
    "start": 254510,
    "end": 256286,
    "text": "よし、では始めよう。"
  },
  {
    "start": 256388,
    "end": 261354,
    "text": "というわけで、これらの作品はどちらも最近、少なくともアーカイブに登録されたり、出版されたりしている。"
  },
  {
    "start": 261402,
    "end": 267966,
    "text": "1つ目はこの論文で、回帰のための事前訓練タスクの多様性と非ベイズ型不連続学習の出現である。"
  },
  {
    "start": 268078,
    "end": 271918,
    "text": "アラン・マンチェイという実に優秀な3人の大学院生によるものだ。"
  },
  {
    "start": 271934,
    "end": 279926,
    "text": "だから、グレッグが話したのと同じセットアップをするつもりだ。"
  },
  {
    "start": 279948,
    "end": 282600,
    "text": "見覚えはあるだろうが、表記はもちろんすべて違う。"
  },
  {
    "start": 283690,
    "end": 286870,
    "text": "分配金を少しひねってみよう。"
  },
  {
    "start": 287770,
    "end": 291158,
    "text": "リグレッションのためのシングルタスクとは何か？"
  },
  {
    "start": 291254,
    "end": 296620,
    "text": "我々は、1つのタスクをd次元空間の未知の回帰ベクトルと定義している。"
  },
  {
    "start": 297230,
    "end": 299254,
    "text": "k組の入力出力が得られる。"
  },
  {
    "start": 299302,
    "end": 301814,
    "text": "xは入力、yは出力である。"
  },
  {
    "start": 301862,
    "end": 303630,
    "text": "Yは単なるスカラーかもしれない。"
  },
  {
    "start": 304850,
    "end": 310350,
    "text": "我々は、等方ガウスとd次元空間から1つの未知の回帰ベクトルを描画するつもりである。"
  },
  {
    "start": 310420,
    "end": 317662,
    "text": "入力も等方性ガウスで、出力は真の回帰ベクトル＋ノイズでラベル付けされる。"
  },
  {
    "start": 317726,
    "end": 320110,
    "text": "我々はノイズの多い回帰の環境で仕事をするつもりだ。"
  },
  {
    "start": 320190,
    "end": 323140,
    "text": "つまり、これはdイコール1次元の例に過ぎない。"
  },
  {
    "start": 325030,
    "end": 329806,
    "text": "さて、変圧器の文脈学習問題をどのように定義すればいいのだろうか？"
  },
  {
    "start": 329838,
    "end": 333154,
    "text": "同じように自己回帰的にやるんだ。"
  },
  {
    "start": 333202,
    "end": 335110,
    "text": "ここに変圧器がある。"
  },
  {
    "start": 335260,
    "end": 341446,
    "text": "ここでは、あるタスクから引き出されたインプット・アウトプット、インプット・アウトプットのシーケンスとしてコンテキストを送り込むことにする。"
  },
  {
    "start": 341478,
    "end": 345754,
    "text": "ここには、yとxを関係づける未知の回帰ベクトルwがある。"
  },
  {
    "start": 345952,
    "end": 346700,
    "text": "いいかい？"
  },
  {
    "start": 347310,
    "end": 350054,
    "text": "今、私たちは一連のコンテクストを持つことになる。"
  },
  {
    "start": 350102,
    "end": 360394,
    "text": "各コンテキスト、例えばk番目のコンテキストに対して、最初のkから1を引いた入力出力ペアを見た後、新しいKfの入力を見る。"
  },
  {
    "start": 360522,
    "end": 368030,
    "text": "Kfの入力に対して、前のkからマイナス1の入力と出力のペアの文脈の知識に基づいて、正しい出力を得なければならない。"
  },
  {
    "start": 368110,
    "end": 370334,
    "text": "例えば、こういうことだ。"
  },
  {
    "start": 370382,
    "end": 371266,
    "text": "Kは2に等しい。"
  },
  {
    "start": 371368,
    "end": 375538,
    "text": "入力1、出力1、入力2だ。"
  },
  {
    "start": 375704,
    "end": 379190,
    "text": "そのタスクは、Y2の予想を出すことである。"
  },
  {
    "start": 379260,
    "end": 380646,
    "text": "まだY2を見ていない。"
  },
  {
    "start": 380668,
    "end": 382258,
    "text": "それは次の文脈で出てくる。"
  },
  {
    "start": 382354,
    "end": 384390,
    "text": "だから、すべてオートマチックに行われる。"
  },
  {
    "start": 385690,
    "end": 389690,
    "text": "この損失関数は、単に出力を順番に二乗したものである。"
  },
  {
    "start": 390750,
    "end": 393414,
    "text": "オーケー、それはコンテクストでやることだ。"
  },
  {
    "start": 393462,
    "end": 395626,
    "text": "このトランスはどこから入手できるのか？"
  },
  {
    "start": 395728,
    "end": 399866,
    "text": "タスクの分配を事前に訓練するんだ。"
  },
  {
    "start": 399968,
    "end": 401946,
    "text": "これがトレーニング前のプロセスだ。"
  },
  {
    "start": 402128,
    "end": 404362,
    "text": "ここからが出発点だ。"
  },
  {
    "start": 404426,
    "end": 409098,
    "text": "ここで、訓練前のデータ分布におけるタスクの多様性をパラメトリックに制御する。"
  },
  {
    "start": 409194,
    "end": 422770,
    "text": "未知のタスクが固定数m個あり、それらは等方性ガウスから一度だけ描かれるが、その後固定される、というような事前学習データ分布があるとする。"
  },
  {
    "start": 423270,
    "end": 429270,
    "text": "mは訓練前のタスク多様性パラメータである。"
  },
  {
    "start": 429850,
    "end": 436120,
    "text": "トランスフォーマー波を導き出すために使うプレトレーニングの損失関数は、まさにこの損失関数だ。"
  },
  {
    "start": 436570,
    "end": 443058,
    "text": "基本的には、m個の離散的なタスク・ベクトルに対して一様分布からwを選ぶわけですね。"
  },
  {
    "start": 443164,
    "end": 447542,
    "text": "そして、ランダムな入力、ランダムなノイズを引き、もちろんラベルを得る。"
  },
  {
    "start": 447686,
    "end": 451630,
    "text": "であれば、すべての異なるコンテキストの長さについて、二乗損失を最小化する。"
  },
  {
    "start": 453890,
    "end": 473266,
    "text": "そして、実際の事前学習では、機械学習で通常行うようにこの期待値を推定し、ミニバッチを構築して、この方法でいくつかの例をサンプリングし、そのミニバッチで損失関数に関して勾配降下ステップを取り、何度も何度も反復する。"
  },
  {
    "start": 473448,
    "end": 483778,
    "text": "このプレトレーニング・プロセス全体では、たくさんの異なる入力と出力を見ることになるが、それらはすべて有限のタスク・ベクトル・セットから導き出される。"
  },
  {
    "start": 483954,
    "end": 488600,
    "text": "それは、内容的にあまり豊かでないデータセットのようなものだ。"
  },
  {
    "start": 489210,
    "end": 496998,
    "text": "理想的には、事前学習で見たどのタスクとも異なる、根本的に新しいタスクの文脈学習を行いたい。"
  },
  {
    "start": 497094,
    "end": 498310,
    "text": "それが私たちの目標だ。"
  },
  {
    "start": 498470,
    "end": 500910,
    "text": "では、コンテキスト・ラーニングでそれをどう評価するのか？"
  },
  {
    "start": 500980,
    "end": 509722,
    "text": "今、私たちがしていることは、等方的なガウス分布から描かれた新しいタスクベクトルを持っているということです。"
  },
  {
    "start": 509786,
    "end": 511790,
    "text": "それは高次元の球体のようなものだ。"
  },
  {
    "start": 512690,
    "end": 521810,
    "text": "全く新しいタスクでの損失は、事前学習タスクの分布を我々のタスクの真の分布に置き換える以外は同じことである。"
  },
  {
    "start": 523110,
    "end": 527410,
    "text": "この損失関数は、基本的に新しいタスクのパフォーマンスを測定する。"
  },
  {
    "start": 528950,
    "end": 536614,
    "text": "では、この変圧器と比較するのに興味深い理論的限界は何だろう？"
  },
  {
    "start": 536732,
    "end": 541002,
    "text": "1つはベイズ・アプローチですね？"
  },
  {
    "start": 541056,
    "end": 558480,
    "text": "つまり、先行する所得性学習の理論と同じように、事前学習データのタスクの分布を学習するベイジアン学習器を考えてみよう、ということだ。"
  },
  {
    "start": 559250,
    "end": 567566,
    "text": "長い間、変圧器をトレーニングしているのだから、変圧器は可能だろう、いや、そんな仮定をする必要もないだろう、と考えることにする。"
  },
  {
    "start": 567598,
    "end": 580120,
    "text": "このアルゴリズムを動機づけるために、我々は、変換器が得たすべての入力出力例に隠されていたm個の有限回帰ベクトルを暗黙的に学習していると考えることができる。"
  },
  {
    "start": 580570,
    "end": 593574,
    "text": "もしそれがわかっているとしたら、理想的なベイズ的オブザーバーやベイズ的推定器は、m個の訓練前のタスク・ベクトルを知っていて、ある新しい入力に対する出力を予測する必要があるとしたら、どうするだろうか？"
  },
  {
    "start": 593702,
    "end": 604058,
    "text": "では、どうすればいいかというと、コンテキストとm個のタスクベクトルから出力の事後平均を計算すればいい。"
  },
  {
    "start": 604154,
    "end": 606938,
    "text": "これは非常に簡単に計算できる事後平均だ。"
  },
  {
    "start": 607034,
    "end": 610750,
    "text": "これを計算すると、事実上回帰計算をしているように見える。"
  },
  {
    "start": 612530,
    "end": 627106,
    "text": "推定回帰ベクトルは、プリ・トレーニング分布の回帰ベクトルの加重平均であり、それらが観察された予測を行う尤度によって加重されます。"
  },
  {
    "start": 627298,
    "end": 641058,
    "text": "大雑把に言えば、ベイズ推定器のようなもので、これらのm個のベクトルを記憶しており、それらを最適な方法で、平均二乗誤差を最小にする意味で、任意のコンテキストのシーケンスに対する出力を予測するために使用する。"
  },
  {
    "start": 641154,
    "end": 646630,
    "text": "そもそもデータがない場合は、すべての回帰ベクトルの平均をとればよい。"
  },
  {
    "start": 646710,
    "end": 649594,
    "text": "あなた方なら、この計算を数行でできるだろう？"
  },
  {
    "start": 649632,
    "end": 650054,
    "text": "もちろんだ。"
  },
  {
    "start": 650112,
    "end": 657310,
    "text": "MMSc推定量なので、これを離散最小平均2乗推定量と呼びます。"
  },
  {
    "start": 659010,
    "end": 672660,
    "text": "この離散的なタスクの集合に対する事前分布がわかっている場合、各タスクを一度しか見ていない場合。"
  },
  {
    "start": 674230,
    "end": 675806,
    "text": "ええ、私たちはそのような環境では仕事をしていません。"
  },
  {
    "start": 675838,
    "end": 678502,
    "text": "それも、あなたたちのやり方との大きな違いだ。"
  },
  {
    "start": 678636,
    "end": 680920,
    "text": "一人一人を何度も何度も見ることになる。"
  },
  {
    "start": 681930,
    "end": 686790,
    "text": "次のスライドで数字をお見せします。"
  },
  {
    "start": 686940,
    "end": 694262,
    "text": "基本的に、あなたにはいくつかのタスクがある。"
  },
  {
    "start": 694316,
    "end": 694498,
    "text": "そうだね。"
  },
  {
    "start": 694524,
    "end": 706750,
    "text": "ミニバッチの各メンバーについてミニバッチを構成する場合、mwsのセットからwの1つを選び、入力と出力の新しいセットを選ぶ。"
  },
  {
    "start": 707330,
    "end": 709626,
    "text": "多くの異なる入出力を見ていることになる。"
  },
  {
    "start": 709658,
    "end": 711038,
    "text": "そこには繰り返しはない。"
  },
  {
    "start": 711124,
    "end": 716838,
    "text": "入力と出力では1エポックだが、未知の回帰ベクトルやタスクでは複数エポックになる。"
  },
  {
    "start": 717034,
    "end": 727014,
    "text": "ウィキペディアの記事をできるだけたくさん見本にするつもりだけど、それはいつもウィキペディアの記事であって、決してシェイクスピアの記事にはならない、と言っているようなものだろう？"
  },
  {
    "start": 727212,
    "end": 727718,
    "text": "いや。"
  },
  {
    "start": 727804,
    "end": 743046,
    "text": "ベイズの最適推定量という考え方は、ある意味理にかなっていると思う。"
  },
  {
    "start": 743158,
    "end": 771422,
    "text": "しかし、もしこれらのタスクのいずれかを実際に行うかどうかが少し不確実であると仮定するならば、私たちは別の理論的近似を試みました。"
  },
  {
    "start": 771566,
    "end": 775678,
    "text": "このノイズとリッジの間を補間するノイズを増加させる。"
  },
  {
    "start": 775774,
    "end": 778294,
    "text": "トランスフォーマーが何をするのか、まったく説明されていない。"
  },
  {
    "start": 778412,
    "end": 784210,
    "text": "興味深いことに、これからお見せする2つのことは、トランスが2つの異なるセッティングで何をするかを説明している。"
  },
  {
    "start": 784290,
    "end": 785974,
    "text": "それについてはすぐに説明する。"
  },
  {
    "start": 786172,
    "end": 800394,
    "text": "では、もう1つのオプションは、タスクの真の分布が等方的なガウス分布で、ガウスノイズやその他もろもろがあるとしたら、MMSc推定量はどうなるでしょうか？"
  },
  {
    "start": 800432,
    "end": 807130,
    "text": "我々は、それがリッジ回帰であり、リッジパラメーターが出力のノイズによって設定されることを知っている。"
  },
  {
    "start": 807210,
    "end": 807840,
    "text": "そうだね。"
  },
  {
    "start": 808370,
    "end": 814890,
    "text": "さて、これがリッジ推定量である。"
  },
  {
    "start": 815050,
    "end": 820850,
    "text": "DMMSeは、トレーニング前のタスク配分では非常にうまくいくが、新しいタスクではうまくいかない。"
  },
  {
    "start": 821590,
    "end": 829382,
    "text": "では、トランスフォーマーは何をするのか、そして何を学習するのかが、タスクの多様性パラメータmにどのように依存するのか、というのが自然な疑問である。"
  },
  {
    "start": 829516,
    "end": 832086,
    "text": "訓練前のタスク多様性パラメータm。"
  },
  {
    "start": 832268,
    "end": 836102,
    "text": "よし、トランスが何をやっているのか、もうひとつだけ測ってみよう。"
  },
  {
    "start": 836236,
    "end": 844854,
    "text": "また、変換器によって学習された関数と、これら2つの興味深い関数との予測空間における距離を計算することもできる。"
  },
  {
    "start": 844902,
    "end": 846806,
    "text": "右、リッジかDmMSe。"
  },
  {
    "start": 846918,
    "end": 863290,
    "text": "そこで、変圧器の出力、例えばリッジかDMMCのどちらか、今使っている方の予測との差の2乗を取り、それを真のタスク分布と、もちろんランダムな入力と出力の分布で平均する。"
  },
  {
    "start": 863370,
    "end": 872210,
    "text": "だからこれは、リッジとDmMMSCのどちらからトランスフォーマーが学習した関数がどの程度離れているかを示しているだけで、今後の図にプロットする。"
  },
  {
    "start": 873430,
    "end": 875218,
    "text": "さて、それでは最初の結果を見てみよう。"
  },
  {
    "start": 875304,
    "end": 877478,
    "text": "ここには解き明かさなければならないことが山ほどある。"
  },
  {
    "start": 877564,
    "end": 883894,
    "text": "さて、この横軸はトレーニング前のタスクの多様性ですね。"
  },
  {
    "start": 883932,
    "end": 885398,
    "text": "これがパラメータmである。"
  },
  {
    "start": 885564,
    "end": 888700,
    "text": "2回から20回くらいまで。"
  },
  {
    "start": 889230,
    "end": 889980,
    "text": "オーケー。"
  },
  {
    "start": 890510,
    "end": 894378,
    "text": "縦軸は最終例の誤差。"
  },
  {
    "start": 894544,
    "end": 905966,
    "text": "グレッグが見せていたカーブの直筆サインをお見せすることもできるが、例として最終的なエラーをお見せするだけだ。"
  },
  {
    "start": 906068,
    "end": 910240,
    "text": "最終的な誤差はノイズがあるため、ゼロではない可能性がある。"
  },
  {
    "start": 911170,
    "end": 911630,
    "text": "オーケー。"
  },
  {
    "start": 911700,
    "end": 915306,
    "text": "DmMMScとリッジのパフォーマンスを見てみよう。"
  },
  {
    "start": 915338,
    "end": 918034,
    "text": "DMMSeは緑色のやつだよね？"
  },
  {
    "start": 918232,
    "end": 927174,
    "text": "トレーニング前のタスク分布の誤差を評価するのであれば、DMMScがベストです。"
  },
  {
    "start": 927212,
    "end": 929430,
    "text": "緑色のカーブが常に最も低い。"
  },
  {
    "start": 929770,
    "end": 933666,
    "text": "もちろん、タスクが増えれば増えるほど、絶対誤差は大きくなる。"
  },
  {
    "start": 933778,
    "end": 942082,
    "text": "そう、リッジはDMMSeに比べ、トレーニング前のタスク分布が悪いからだ。"
  },
  {
    "start": 942146,
    "end": 948294,
    "text": "DMMMseは訓練前の分布にあった正確なm個のタスクベクトルを知っているが、Ridgeは知らないからだ。"
  },
  {
    "start": 948342,
    "end": 950730,
    "text": "等方性を知っているだけだ。"
  },
  {
    "start": 951230,
    "end": 951846,
    "text": "そうだね。"
  },
  {
    "start": 951968,
    "end": 953962,
    "text": "リッジはもっと悪くなるだろう。"
  },
  {
    "start": 954106,
    "end": 961822,
    "text": "もちろん、訓練前のタスク分布の数が本当に大きくなると、DMMScとRidgeは互いに近づくはずである。"
  },
  {
    "start": 961956,
    "end": 963430,
    "text": "それが期待されていることだ。"
  },
  {
    "start": 963610,
    "end": 965266,
    "text": "トランスの役割は？"
  },
  {
    "start": 965368,
    "end": 966914,
    "text": "それがこのオレンジ色の線だ。"
  },
  {
    "start": 967112,
    "end": 972930,
    "text": "負荷タスクの多様性では、DMMScとまったく同じように振る舞うんだろう？"
  },
  {
    "start": 973000,
    "end": 977846,
    "text": "まるでトランスフォーマーが、事前トレーニングセットの限られた多様性を記憶しているかのようだ。"
  },
  {
    "start": 978028,
    "end": 985414,
    "text": "トレーニング前の多様性がある閾値を超えたら、もはやそれはできない。"
  },
  {
    "start": 985532,
    "end": 996010,
    "text": "トランスフォーマーがリッジにスナップする時点では、それほどタスクの多様性がないにもかかわらず。"
  },
  {
    "start": 996910,
    "end": 1001350,
    "text": "つまり、興味深いことに、トランスフォーマーはトレーニング前のロスを最小限に抑えることに失敗しているのだ。"
  },
  {
    "start": 1001430,
    "end": 1003406,
    "text": "失敗したときは、面白い方法で失敗する。"
  },
  {
    "start": 1003428,
    "end": 1006650,
    "text": "リッジになり、新しい仕事もうまくこなせるようになる。"
  },
  {
    "start": 1006730,
    "end": 1008490,
    "text": "よし、では評価しよう。"
  },
  {
    "start": 1008570,
    "end": 1012314,
    "text": "つまり、これはすべてトレーニング前の課題配分でのパフォーマンスを評価したものだ。"
  },
  {
    "start": 1012442,
    "end": 1015198,
    "text": "同じパフォーマンスを真のタスク分布で見てみよう。"
  },
  {
    "start": 1015294,
    "end": 1022340,
    "text": "これは、各アルゴリズムが、訓練前のデータセットにない新しいタスクをどの程度解決できるかというようなことだ。"
  },
  {
    "start": 1023270,
    "end": 1026082,
    "text": "リッジ、今できる最善のことだ。"
  },
  {
    "start": 1026216,
    "end": 1028180,
    "text": "だから、リッジは本当によくやっている。"
  },
  {
    "start": 1029270,
    "end": 1033970,
    "text": "DMMMSCは、タスクの多様性が低いと本当に不利だ。"
  },
  {
    "start": 1034130,
    "end": 1039958,
    "text": "その後、最終的にリッジに近づくと、同じようにトランスの挙動が変化する。"
  },
  {
    "start": 1040054,
    "end": 1046538,
    "text": "新しいタスクではDMMSCのような振る舞いをするので、新しいタスクをうまく解決できない。"
  },
  {
    "start": 1046624,
    "end": 1052890,
    "text": "そして、やがてリッジにスナップし、新しいタスクをうまく解決できるようになる。"
  },
  {
    "start": 1052960,
    "end": 1055282,
    "text": "GPt-2アーキテクチャーだ。"
  },
  {
    "start": 1055366,
    "end": 1057040,
    "text": "入力次元は8だった。"
  },
  {
    "start": 1057890,
    "end": 1060858,
    "text": "バッチサイズは256、トレーニングステップは500kである。"
  },
  {
    "start": 1060874,
    "end": 1064670,
    "text": "それは128,000,000の例のようなものだ。"
  },
  {
    "start": 1064830,
    "end": 1069762,
    "text": ""
  },
  {
    "start": 1069816,
    "end": 1078778,
    "text": "128,000,000のグラデーション・ステップを踏んでいるため、128,000,000のタスク例を見ることができる。"
  },
  {
    "start": 1078974,
    "end": 1083814,
    "text": "では、もっと長い時間トレーニングするとしたらどうだろう？"
  },
  {
    "start": 1083932,
    "end": 1084502,
    "text": "ああ、申し訳ない。"
  },
  {
    "start": 1084556,
    "end": 1085030,
    "text": "どうぞ。"
  },
  {
    "start": 1085100,
    "end": 1088898,
    "text": "変圧器の大きさは舗装の継続時間に影響しますか？"
  },
  {
    "start": 1088994,
    "end": 1091510,
    "text": "それについては、今後のスライドで話そう。"
  },
  {
    "start": 1092010,
    "end": 1095234,
    "text": "擬似ランダム生成器との関係は？"
  },
  {
    "start": 1095282,
    "end": 1104030,
    "text": "そうですね、もしアイテムの部分空間があったとして、それをより大きな均一な部分空間と区別するのはちょっと難しいですね。"
  },
  {
    "start": 1105650,
    "end": 1111066,
    "text": "真の回帰ベクトルに対するもっと面白い分布で遊べるだろう。"
  },
  {
    "start": 1111098,
    "end": 1114240,
    "text": "そのアイデアはまだ試していない。"
  },
  {
    "start": 1116390,
    "end": 1117566,
    "text": "赤いカーブである。"
  },
  {
    "start": 1117598,
    "end": 1139066,
    "text": "このようなタスクの集合があり、各タスクの例を見ることはないが、0.1というわずかな確率はある、というような分布のベイズ最適推定量と考えることはできるだろうか。"
  },
  {
    "start": 1139168,
    "end": 1144090,
    "text": "私たちが試したのは、各タスクの見積もりがうるさいということだ。"
  },
  {
    "start": 1145710,
    "end": 1148134,
    "text": "それは、滑らかでバラバラのMMSvのようなものだ。"
  },
  {
    "start": 1148262,
    "end": 1155066,
    "text": "そのアルゴリズムの学習曲線は、たとえノイズを最適化したとしても、このオレンジ色の曲線とは一致しない。"
  },
  {
    "start": 1155178,
    "end": 1161674,
    "text": "少なくとも性能の点で、トランスフォーマーが何をしているのかを、その発見的推定で近似することはできない。"
  },
  {
    "start": 1161802,
    "end": 1162480,
    "text": "もちろんだ。"
  },
  {
    "start": 1169110,
    "end": 1175966,
    "text": "もし、その可能性が高ければ、リグレッションを行い、そうでなければ昼寝をする。"
  },
  {
    "start": 1175998,
    "end": 1176974,
    "text": "こういう仕事もある。"
  },
  {
    "start": 1177022,
    "end": 1177860,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 1178390,
    "end": 1182514,
    "text": "それでも、タスクの多様性が低いうちは似たようなものかもしれない。"
  },
  {
    "start": 1182562,
    "end": 1185190,
    "text": "トランスフォーマーで何が起こっているのかを説明しているようなものだ。"
  },
  {
    "start": 1186170,
    "end": 1193402,
    "text": "だから、少なくともこの少数のタスクについては、トランスフォーマーはそれぞれのタスクが何であるかを知っているかのように振る舞うことができる。"
  },
  {
    "start": 1193536,
    "end": 1194220,
    "text": "そうだね。"
  },
  {
    "start": 1198830,
    "end": 1210926,
    "text": "十分なステップ数をトレーニングすれば、変圧器は緑色の線量に適合するはずだから、トレーニングを続ける、というようなことだ。"
  },
  {
    "start": 1211028,
    "end": 1212062,
    "text": "なるほど、いい質問だ。"
  },
  {
    "start": 1212116,
    "end": 1214000,
    "text": "それこそが、私たちが次に尋ねようとしていることだ。"
  },
  {
    "start": 1214450,
    "end": 1216126,
    "text": "それは真実ではないことがわかった。"
  },
  {
    "start": 1216308,
    "end": 1225566,
    "text": "グリーンからイエローへのシフトは、早めのストップをしているように見えるので、リッジのような挙動になる。"
  },
  {
    "start": 1225758,
    "end": 1228478,
    "text": "それが正しい理解かどうかは分からない。"
  },
  {
    "start": 1228654,
    "end": 1231140,
    "text": "アーリーストップはしない。"
  },
  {
    "start": 1232090,
    "end": 1235910,
    "text": "トレーニングスタッフの数は決まっているが、タスクの数は決まっている。"
  },
  {
    "start": 1236730,
    "end": 1237142,
    "text": "その通りだ。"
  },
  {
    "start": 1237196,
    "end": 1238454,
    "text": "我々はそれを変化させるつもりだ。"
  },
  {
    "start": 1238572,
    "end": 1239286,
    "text": "そうだね。"
  },
  {
    "start": 1239468,
    "end": 1241682,
    "text": "それを変えるとどうなるかをお見せしよう。"
  },
  {
    "start": 1241756,
    "end": 1244380,
    "text": "質問の答えにならなければ、また出直そう。"
  },
  {
    "start": 1245310,
    "end": 1247754,
    "text": "よし、そこでこの赤い矢印の出番だ。"
  },
  {
    "start": 1247792,
    "end": 1247994,
    "text": "そうだね。"
  },
  {
    "start": 1248032,
    "end": 1250822,
    "text": "私たちは500k歩のトレーニングをした。"
  },
  {
    "start": 1250886,
    "end": 1251450,
    "text": "そうだね。"
  },
  {
    "start": 1251600,
    "end": 1253754,
    "text": "もっと長くトレーニングしたらどうなるだろう？"
  },
  {
    "start": 1253952,
    "end": 1254700,
    "text": "そうだね。"
  },
  {
    "start": 1255150,
    "end": 1256186,
    "text": "どうなるんだろう？"
  },
  {
    "start": 1256288,
    "end": 1259054,
    "text": "もちろん、DMMScとリッジは変わらない。"
  },
  {
    "start": 1259092,
    "end": 1260880,
    "text": "トレーニングは必要ない。"
  },
  {
    "start": 1261970,
    "end": 1263970,
    "text": "トランスはどうなるのか？"
  },
  {
    "start": 1264950,
    "end": 1279682,
    "text": "その結果、タスクの多様性が高ければリッジに近くなり、タスクの多様性が低ければDMMSeに近くなることがわかった。"
  },
  {
    "start": 1279736,
    "end": 1281318,
    "text": "その証拠をお見せしよう。"
  },
  {
    "start": 1281404,
    "end": 1283782,
    "text": "より長くトレーニングするためのさまざまな方法とは？"
  },
  {
    "start": 1283916,
    "end": 1284358,
    "text": "そうだね。"
  },
  {
    "start": 1284444,
    "end": 1288360,
    "text": "トレーニングのハイパーパラメータはすべて同じにして、バッチサイズを大きくすることもできる。"
  },
  {
    "start": 1289290,
    "end": 1294286,
    "text": "ここではバッチサイズが256だったので、512、1024と増やしていった。"
  },
  {
    "start": 1294288,
    "end": 1296922,
    "text": "私たちが見つけたもの"
  },
  {
    "start": 1296976,
    "end": 1299002,
    "text": "この青は最小のバッチサイズである。"
  },
  {
    "start": 1299056,
    "end": 1300378,
    "text": "それは以前にも見たことがあるものだ。"
  },
  {
    "start": 1300544,
    "end": 1305406,
    "text": "この軸は、予測空間における事前学習されたトランスフォーマーからリッジまでの距離である。"
  },
  {
    "start": 1305508,
    "end": 1309840,
    "text": "これは、事前に訓練されたトランスフォーマーがどれだけリッジに近いかを関数で表したものだ。"
  },
  {
    "start": 1311090,
    "end": 1313682,
    "text": "それはこっちの話だ。"
  },
  {
    "start": 1313816,
    "end": 1323054,
    "text": "同じ一定のタスク多様性で、より長く訓練したり、より多くのデータで訓練したりすると、ある閾値でタスク多様性が生じる。"
  },
  {
    "start": 1323102,
    "end": 1329270,
    "text": "タスクの多様性が高いと、尾根のようになる。"
  },
  {
    "start": 1329610,
    "end": 1330310,
    "text": "そうだね。"
  },
  {
    "start": 1330460,
    "end": 1337758,
    "text": "より多くのデータと決まった数のタスクでトレーニングしても、DMMSeに近づくのではなく、リッチに近づくのだ。"
  },
  {
    "start": 1337954,
    "end": 1347930,
    "text": "しかし、タスクの多様性が低い場合、データ量を増やすとリッジから遠ざかり、DMMSeに近づくことがわかった。"
  },
  {
    "start": 1350430,
    "end": 1358522,
    "text": "訓練量を増やすもう一つの方法は、バッチサイズはそのままで、訓練ステップ数を増やすことだ。"
  },
  {
    "start": 1358666,
    "end": 1361882,
    "text": "例えば、50万のトレーニングステップから100万のトレーニングステップになったとしよう。"
  },
  {
    "start": 1361946,
    "end": 1365950,
    "text": "同じような閾値で同じようなパターンが得られる。"
  },
  {
    "start": 1366110,
    "end": 1366722,
    "text": "そうだろう？"
  },
  {
    "start": 1366856,
    "end": 1367202,
    "text": "もう一度言う。"
  },
  {
    "start": 1367256,
    "end": 1373006,
    "text": "タスクの多様性が高い場合、より多くのトレーニングがPTをリッジに近づける。"
  },
  {
    "start": 1373198,
    "end": 1374846,
    "text": "新しい仕事でもうまくいくだろう。"
  },
  {
    "start": 1374958,
    "end": 1380550,
    "text": "タスクの多様性が低い場合、事前に学習された変換器Ptは、新しいタスクでは稜線にならなくなる。"
  },
  {
    "start": 1382170,
    "end": 1386082,
    "text": "これは、タスクの多様性の閾値を定義するために使用するものである。"
  },
  {
    "start": 1386226,
    "end": 1391894,
    "text": "この2つの段階を分けるのが閾値で、もっとトレーニングすれば、もっとリッジらしくなる。"
  },
  {
    "start": 1392022,
    "end": 1393014,
    "text": "それがこの段階だ。"
  },
  {
    "start": 1393062,
    "end": 1395850,
    "text": "もっとトレーニングすれば、リッジのようにはならない。"
  },
  {
    "start": 1397790,
    "end": 1400810,
    "text": "これは相転移のようなものだろう？"
  },
  {
    "start": 1400880,
    "end": 1403098,
    "text": "この横軸はタスクの多様性である。"
  },
  {
    "start": 1403194,
    "end": 1405274,
    "text": "これがこのタスクの多様性の閾値だ。"
  },
  {
    "start": 1405402,
    "end": 1408142,
    "text": "もっと長くトレーニングすれば、もっとリッジらしくなる。"
  },
  {
    "start": 1408196,
    "end": 1410560,
    "text": "もっと長くトレーニングすれば、尾根のようにはならない。"
  },
  {
    "start": 1412530,
    "end": 1423682,
    "text": "このタスクの多様性のしきい値では、事前学習されたトランスフォーマーにアルゴリズム的な相転移があり、長く訓練すると、dmmmsyのようなものからridgeのようなものへと変化する。"
  },
  {
    "start": 1423736,
    "end": 1426210,
    "text": "それが移籍の定義だ。"
  },
  {
    "start": 1426630,
    "end": 1431186,
    "text": "さて、ここで新しいタスクに対する文脈学習の出現を直接的に示してみよう。"
  },
  {
    "start": 1431298,
    "end": 1436626,
    "text": "トレーニング前の分布から始めて、有限のタスクセットがあるとしよう。"
  },
  {
    "start": 1436738,
    "end": 1439178,
    "text": "これがd次元の入力空間である。"
  },
  {
    "start": 1439264,
    "end": 1443638,
    "text": "これらは、m個の真の回帰ベクトルに対応するm個のベクトルである。"
  },
  {
    "start": 1443734,
    "end": 1452862,
    "text": "2つのトレーニング前タスクベクトルの間を補間すれば、3つのアルゴリズムすべてのパフォーマンスを追跡できるよね？"
  },
  {
    "start": 1452916,
    "end": 1463806,
    "text": "プリ・トレーニング分布にある2つの回帰ベクトルの間で回帰ベクトルを補間する新しい問題インスタンスを生成します。"
  },
  {
    "start": 1463918,
    "end": 1465954,
    "text": "新しいタスクはその真ん中にある。"
  },
  {
    "start": 1466072,
    "end": 1472766,
    "text": "アルファは補間パラメータであり、トレーニング前のタスクの多様性が低い場合に見られる。"
  },
  {
    "start": 1472958,
    "end": 1476046,
    "text": "オレンジは訓練前のトランスフォーマー。"
  },
  {
    "start": 1476158,
    "end": 1484358,
    "text": "すでに見たことのある2つのタスクではとてもうまくいくが、見たことのない新しいタスクではひどい結果になる。"
  },
  {
    "start": 1484524,
    "end": 1493914,
    "text": "もちろん、リッジは常に好成績を収めているが、DMMScやプリ・トレイン・トランスフォーマーよりも、両者が以前に経験したことのあるタスクでは成績が悪かった。"
  },
  {
    "start": 1494032,
    "end": 1494746,
    "text": "そうだね。"
  },
  {
    "start": 1494928,
    "end": 1495562,
    "text": "オーケー。"
  },
  {
    "start": 1495696,
    "end": 1505546,
    "text": "タスクの多様性を高めると、訓練前のトランスフォーマーがDMMScからリッジに切り替わるのがわかる。"
  },
  {
    "start": 1505658,
    "end": 1508298,
    "text": "すると、リッジのような動きをすることがわかる。"
  },
  {
    "start": 1508394,
    "end": 1513920,
    "text": "現在、リッジは新しいタスクによく取り組み、DMMMScは新しいタスクにあまり取り組んでいない。"
  },
  {
    "start": 1517170,
    "end": 1526470,
    "text": "これは、タスクの多様性のしきい値を超えて、新しいタスクをどのように学習できるかを直接的に視覚化したようなものだ。"
  },
  {
    "start": 1526890,
    "end": 1533106,
    "text": "では、タスクの多様性の閾値は、入力の次元によってどのように変化するのだろうか？"
  },
  {
    "start": 1533218,
    "end": 1533734,
    "text": "そうだね。"
  },
  {
    "start": 1533852,
    "end": 1538850,
    "text": "タスクの量は、入力やタスクの次元に指数関数的に比例しますよね。"
  },
  {
    "start": 1538940,
    "end": 1544038,
    "text": "これを考えるには、高次元空間の等方性ガウスは球に集中する。"
  },
  {
    "start": 1544134,
    "end": 1547530,
    "text": "その球体の表面積は、次元の指数関数になる。"
  },
  {
    "start": 1548830,
    "end": 1560394,
    "text": "DMMSeがこの空間のすべてを本当にサンプリングするには、指数関数的に多くのタスクベクトルが必要になる。"
  },
  {
    "start": 1560442,
    "end": 1561040,
    "text": "そうだね。"
  },
  {
    "start": 1561490,
    "end": 1565522,
    "text": "では、タスクの多様性の閾値はdによってどのように変化するのだろうか？"
  },
  {
    "start": 1565656,
    "end": 1570894,
    "text": "PTも新しい課題を解くために、事前トレーニングで指数関数的に多くの課題を見る必要があるのだろうか？"
  },
  {
    "start": 1570942,
    "end": 1574450,
    "text": "まあ、意外にもそうではないことがわかった。"
  },
  {
    "start": 1574870,
    "end": 1580210,
    "text": "つまり、ここでは次元の数をスケーリングし、常に一定である問題のSN比をスケーリングした。"
  },
  {
    "start": 1582790,
    "end": 1588658,
    "text": "そこで、バッチサイズを大きくして同じ実験を行った。"
  },
  {
    "start": 1588754,
    "end": 1591794,
    "text": "その遷移がタスク多様性の閾値を決定する。"
  },
  {
    "start": 1591922,
    "end": 1603386,
    "text": "8次元から16次元、32次元と進むにつれて、タスクの多様性のしきい値が2つ上の14番目から2つ上の16番目へと変化していることがわかる。"
  },
  {
    "start": 1603418,
    "end": 1609230,
    "text": "つまり、大まかなスケーリングだが、寸法を大きくするにつれて、このようなトレーニング走行をするのは難しくなる。"
  },
  {
    "start": 1609570,
    "end": 1618286,
    "text": "おおよそ、少なくともこの限られた範囲では、タスクの多様性の閾値の次元に対するスケーリングは好ましいことがわかる。"
  },
  {
    "start": 1618318,
    "end": 1621154,
    "text": "その意味ではリニアと言えるかもしれない。"
  },
  {
    "start": 1621352,
    "end": 1624366,
    "text": "DMMSeについてはどうなのか？"
  },
  {
    "start": 1624558,
    "end": 1631638,
    "text": "タスクの数を指数関数的に拡張することはできないので、少し違う質問をした。"
  },
  {
    "start": 1631804,
    "end": 1641926,
    "text": "最大のタスク数である20タスクに対して、DMMseとridgeの距離を次元の関数として計算した。"
  },
  {
    "start": 1642038,
    "end": 1648090,
    "text": "寸法が大きくなるにつれて、DmMMscはリッジからどんどん離れていく。"
  },
  {
    "start": 1648160,
    "end": 1648442,
    "text": "そうだね。"
  },
  {
    "start": 1648496,
    "end": 1652810,
    "text": "タスクのセットは有限だが、球体の体積を増やしているのだ。"
  },
  {
    "start": 1653150,
    "end": 1655466,
    "text": "DMMseはリッジのように振る舞わない。"
  },
  {
    "start": 1655498,
    "end": 1657802,
    "text": "次元が上がるにつれてどんどん悪くなる。"
  },
  {
    "start": 1657946,
    "end": 1663774,
    "text": "この次元の範囲では、事前訓練された変圧器では、尾根までの距離がこのように伸びることはない。"
  },
  {
    "start": 1663902,
    "end": 1669620,
    "text": "タスクの多様性の閾値がこのあたりだからだ。"
  },
  {
    "start": 1670790,
    "end": 1684018,
    "text": "事前学習された変換器の性能の次元に対するスケーリングは、この設定でベイズ型文脈学習者が行うよりもはるかに優れている。"
  },
  {
    "start": 1684114,
    "end": 1699580,
    "text": "繰り返しになるが、文脈学習の出現は、訓練前の課題分布に関するベイズ理論では説明できない。"
  },
  {
    "start": 1700130,
    "end": 1707546,
    "text": "トランスフォーマーを覚えたい？"
  },
  {
    "start": 1707578,
    "end": 1708206,
    "text": "これでよし。"
  },
  {
    "start": 1708308,
    "end": 1709274,
    "text": "次のスライドのタイトル"
  },
  {
    "start": 1709322,
    "end": 1710800,
    "text": "ああ、いい質問だ。"
  },
  {
    "start": 1712050,
    "end": 1718980,
    "text": "私はまだ、これが先行者にとって最適な位相だと主張している。"
  },
  {
    "start": 1719590,
    "end": 1728920,
    "text": "あなたの事前分布に関しては、それはベイズ最適ではないが、最適な事前分布があり、その2つの事前分布を区別することはできない。"
  },
  {
    "start": 1731770,
    "end": 1733926,
    "text": "それについては後で話そう。"
  },
  {
    "start": 1734108,
    "end": 1737666,
    "text": "真の事前分布を考慮したベイズ最適ではない。"
  },
  {
    "start": 1737858,
    "end": 1739734,
    "text": "リジッドのベイズ最適解は真に迫っている。"
  },
  {
    "start": 1739852,
    "end": 1747500,
    "text": "いやいや、しかし、事前分布がある分布に関しては、何に関してですか？"
  },
  {
    "start": 1748510,
    "end": 1750170,
    "text": "それは例と一致している。"
  },
  {
    "start": 1750320,
    "end": 1753710,
    "text": "ああ、でも、その事前情報が存在するとしても、この話にはまだ書かれていない。"
  },
  {
    "start": 1753780,
    "end": 1755070,
    "text": "その前の段階が何なのかは分からない。"
  },
  {
    "start": 1755140,
    "end": 1762550,
    "text": "ああ、ただ、どの風呂にも入っていないような本当の仕事があるんだ。"
  },
  {
    "start": 1762570,
    "end": 1765460,
    "text": "私たちのセッティングではあり得ないことでしょう？"
  },
  {
    "start": 1765990,
    "end": 1783990,
    "text": "いや、君の設定だと、このモデルだけなら、そう、君は有限の数のタスクを見るわけだが、この事前準備では、ゼロ回見るタスクもあるかもしれないし、100万回見るタスクもあるかもしれない。"
  },
  {
    "start": 1784060,
    "end": 1785522,
    "text": "それは有効な事前提だ。"
  },
  {
    "start": 1785666,
    "end": 1786710,
    "text": "それは一貫している。"
  },
  {
    "start": 1786780,
    "end": 1789910,
    "text": "ああ、でも、それが訓練前の変圧器の挙動を説明していることを証明しなければならない。"
  },
  {
    "start": 1789990,
    "end": 1792060,
    "text": "その通りだが、おそらくそうではないだろう。"
  },
  {
    "start": 1794750,
    "end": 1796374,
    "text": "私の直感は正反対だ。"
  },
  {
    "start": 1796422,
    "end": 1800346,
    "text": "私は、その可能性は極めて低いと思う。"
  },
  {
    "start": 1800448,
    "end": 1806506,
    "text": "なぜなら、128,000,000の例を示しているのに、10個のタスクに対して2個しかないからだ。"
  },
  {
    "start": 1806618,
    "end": 1807086,
    "text": "そうだね。"
  },
  {
    "start": 1807188,
    "end": 1810778,
    "text": "一つのタスクの例を見たことがない、ということはまずないだろう。"
  },
  {
    "start": 1810874,
    "end": 1812058,
    "text": "可能性は極めて低い。"
  },
  {
    "start": 1812154,
    "end": 1819540,
    "text": "もし、トレーニング前のプロセスでは起こりそうもない出来事が、あなたの事前トレーニングでは起こりそうだとしたら、それは何が起こっているのかをどのように説明できるだろうか？"
  },
  {
    "start": 1820390,
    "end": 1821730,
    "text": "その後で話そう。"
  },
  {
    "start": 1830330,
    "end": 1831298,
    "text": "ああ、成長しているよ。"
  },
  {
    "start": 1831314,
    "end": 1835126,
    "text": "例えば、バッチサイズを2つ増やせば、基本的にトレーニングの総量は2つ増える。"
  },
  {
    "start": 1835228,
    "end": 1841340,
    "text": "トランジションをよりシャープにするのは、より長い時間トレーニングすることだ。"
  },
  {
    "start": 1841710,
    "end": 1843162,
    "text": "トレーニングデータの量。"
  },
  {
    "start": 1843216,
    "end": 1848246,
    "text": "mは固定されている。"
  },
  {
    "start": 1848278,
    "end": 1848426,
    "text": "そうだね。"
  },
  {
    "start": 1848448,
    "end": 1849926,
    "text": "これらのプロットで。"
  },
  {
    "start": 1850038,
    "end": 1852954,
    "text": "最も考えやすいのは、トレーニング前のデータだ。"
  },
  {
    "start": 1852992,
    "end": 1853302,
    "text": "そうだね。"
  },
  {
    "start": 1853376,
    "end": 1855486,
    "text": "横軸はその量である。"
  },
  {
    "start": 1855508,
    "end": 1856554,
    "text": "課題は多様性か。"
  },
  {
    "start": 1856602,
    "end": 1857326,
    "text": "それはMだ。"
  },
  {
    "start": 1857428,
    "end": 1857790,
    "text": "そうだろう？"
  },
  {
    "start": 1857860,
    "end": 1858906,
    "text": "それは固定されている。"
  },
  {
    "start": 1858938,
    "end": 1866462,
    "text": "実際、バッチサイズを大きくしている以外はすべて固定されている。"
  },
  {
    "start": 1866606,
    "end": 1870142,
    "text": "では、リッジのようになるか、リッチのようにならないか？"
  },
  {
    "start": 1870286,
    "end": 1874530,
    "text": "ここで私はリッジのようになり、ここで私はリッチでなくなる。"
  },
  {
    "start": 1875430,
    "end": 1885960,
    "text": "もっと実用的なセッティングを考えるなら、データの総量を固定した方がいいかもしれない。"
  },
  {
    "start": 1886970,
    "end": 1888218,
    "text": "私は増やす。"
  },
  {
    "start": 1888304,
    "end": 1893420,
    "text": "とすると、タスクごとの例数は"
  },
  {
    "start": 1894110,
    "end": 1895340,
    "text": "どうなんだ。"
  },
  {
    "start": 1896110,
    "end": 1899590,
    "text": "ええ、そのような特別な実験はしていないと思います。"
  },
  {
    "start": 1899750,
    "end": 1905040,
    "text": "このカーブに沿って歩けば、mの変化を見ることができるだろう？"
  },
  {
    "start": 1906690,
    "end": 1912080,
    "text": "これはmを増やし、mあたりの例数を減らしているのだろう。"
  },
  {
    "start": 1912850,
    "end": 1914510,
    "text": "それがこのカーブの存在だ。"
  },
  {
    "start": 1915730,
    "end": 1918110,
    "text": "デリック・オブジェを試したことはありますか？"
  },
  {
    "start": 1919750,
    "end": 1920526,
    "text": "いや、していない。"
  },
  {
    "start": 1920558,
    "end": 1922350,
    "text": "私たちはラプラス法を試してみた。"
  },
  {
    "start": 1922510,
    "end": 1930966,
    "text": "タスクの多様性が高い場合、事前学習された変換器は空間全体にわたってラプラス事前学習に対して北京的な振る舞いをする。"
  },
  {
    "start": 1931068,
    "end": 1942706,
    "text": "タスクの多様性が低い場合は、再びDMMCのように振る舞うので、ラプラス事前分布を一般化する以外は、同じ振る舞いになる。"
  },
  {
    "start": 1942738,
    "end": 1944700,
    "text": "このプリトレイン・トランスフォーマーは本当にいい。"
  },
  {
    "start": 1945230,
    "end": 1948140,
    "text": "ここで驚くのは、彼らが本当にうまいということだ。"
  },
  {
    "start": 1948830,
    "end": 1953120,
    "text": "驚きの内容は後でまとめるか、後で強調することにしよう。"
  },
  {
    "start": 1955250,
    "end": 1956942,
    "text": "さて、キャパシティの質問だ。"
  },
  {
    "start": 1957076,
    "end": 1966062,
    "text": "例えば、正則化の場合、これらのプロットが示しているのは、重みの減衰がタスクの多様性の閾値を下げるということだ。"
  },
  {
    "start": 1966206,
    "end": 1972818,
    "text": "ウェイトの減衰が何らかの形で正則化されるのは、もちろんトポロジー的にトレーニングが正則化されるからだ。"
  },
  {
    "start": 1972984,
    "end": 1985702,
    "text": "直感的には、事前訓練されたトランスフォーマーが限られた数のタスクを記憶するのを防ぐため、タスクの多様性のしきい値が低くなると、新しいタスクをよりうまく解けるようになると思うかもしれない。"
  },
  {
    "start": 1985756,
    "end": 1986920,
    "text": "そういうことだ。"
  },
  {
    "start": 1987370,
    "end": 1992118,
    "text": "モデルの容量を増やしても、タスクの多様性のしきい値に大きな変化はない。"
  },
  {
    "start": 1992214,
    "end": 1994780,
    "text": "我々はすでにかなり大きなモデルからスタートしている。"
  },
  {
    "start": 1995390,
    "end": 2002574,
    "text": "モデルの容量を減らすと、タスクの多様性の閾値が上がることがわかった。"
  },
  {
    "start": 2002612,
    "end": 2004510,
    "text": "タスクの多様性のしきい値を下げる。"
  },
  {
    "start": 2005410,
    "end": 2005774,
    "text": "申し訳ない。"
  },
  {
    "start": 2005812,
    "end": 2009386,
    "text": "ウェイト・ディケイとは、ロスにwの2乗の項を加えることを意味する。"
  },
  {
    "start": 2009498,
    "end": 2013970,
    "text": "勾配はマイナスwなので、すべてのウェイトを減衰させることになる。"
  },
  {
    "start": 2017670,
    "end": 2023954,
    "text": "では、このアルゴリズムによる相転移はどこから来るのだろうか？"
  },
  {
    "start": 2023992,
    "end": 2026210,
    "text": "それをメカニズム的に説明するとしたら？"
  },
  {
    "start": 2026280,
    "end": 2027558,
    "text": "短い答えは、わからないということだ。"
  },
  {
    "start": 2027644,
    "end": 2030360,
    "text": "現時点での最善の推測をお伝えしよう。"
  },
  {
    "start": 2030970,
    "end": 2035830,
    "text": "私たちはフードの下を覗いて、トレーニング前の学習ダイナミクスを見てみることができる。"
  },
  {
    "start": 2036810,
    "end": 2038202,
    "text": "それはまだ見たことがない。"
  },
  {
    "start": 2038256,
    "end": 2038474,
    "text": "そうだね。"
  },
  {
    "start": 2038512,
    "end": 2046230,
    "text": "この軸は500kステップまでの事前トレーニングステップ数である。"
  },
  {
    "start": 2046390,
    "end": 2050578,
    "text": "これらの色の違いは、トレーニング前のタスクの多様性の違いである。"
  },
  {
    "start": 2050694,
    "end": 2051360,
    "text": "そうだね。"
  },
  {
    "start": 2052050,
    "end": 2061994,
    "text": "青はタスクの多様性が低い、ピンクはタスクの多様性が高い、といった具合だ。"
  },
  {
    "start": 2062042,
    "end": 2062494,
    "text": "そうだね。"
  },
  {
    "start": 2062612,
    "end": 2065618,
    "text": "これはプリ間の距離である。"
  },
  {
    "start": 2065704,
    "end": 2068990,
    "text": "これはエラー学習曲線ではなく、距離学習曲線だ。"
  },
  {
    "start": 2069150,
    "end": 2079362,
    "text": "タスクの真の分布から引き出されたタスクのランダム分布で評価された、関数空間または予測空間における事前学習された変換器からリッジまでの距離。"
  },
  {
    "start": 2079426,
    "end": 2086680,
    "text": "これは、等方的なガウシアン分布のタスクだけで、あるいは可能な限り一般的な設定で、どれだけリッジに近いかを測定している。"
  },
  {
    "start": 2087610,
    "end": 2100870,
    "text": "タスクの多様性が低いときに起こることは、最初は事前訓練された変換器がリッジに近づくが、その後逃げてリッジから遠ざかり、そうなるとDMMSeに近づくということである。"
  },
  {
    "start": 2100950,
    "end": 2105790,
    "text": "タスクの多様性が多少高くても同じ効果があることがわかった。"
  },
  {
    "start": 2106530,
    "end": 2109102,
    "text": "タスクの多様性を下げたら、申し訳ない。"
  },
  {
    "start": 2109236,
    "end": 2116020,
    "text": "タスクの多様性をさらに増やすと、カーブが単調減少するような急激な変化が起こる。"
  },
  {
    "start": 2117590,
    "end": 2121726,
    "text": "今起きていることは、DMMSCのソリューションに気づいていないということだ。"
  },
  {
    "start": 2121838,
    "end": 2124590,
    "text": "どんどん尾根に近づいていく。"
  },
  {
    "start": 2124750,
    "end": 2127270,
    "text": "DMMMScのソリューションに引っかかることはない。"
  },
  {
    "start": 2128090,
    "end": 2131334,
    "text": "と聞かれるかもしれない。"
  },
  {
    "start": 2131532,
    "end": 2132182,
    "text": "そうだね。"
  },
  {
    "start": 2132316,
    "end": 2139222,
    "text": "トレーニングのステップ数を4倍にするとこうなる。"
  },
  {
    "start": 2139356,
    "end": 2146326,
    "text": "この2種類の学習曲線の二分化は、同じタスク多様性の閾値付近でほぼ維持される。"
  },
  {
    "start": 2146438,
    "end": 2150050,
    "text": "これは、私たちが10個のタスクに対して大まかに2つ話すのと同じ閾値だ。"
  },
  {
    "start": 2150150,
    "end": 2153840,
    "text": "ああ、もっと変わるよ。"
  },
  {
    "start": 2154610,
    "end": 2157834,
    "text": "さらにタスクの多様性が増していると言えるだろう。"
  },
  {
    "start": 2157882,
    "end": 2159440,
    "text": "まだ逃げますか？"
  },
  {
    "start": 2162290,
    "end": 2164714,
    "text": "可能性はあるが、その可能性は非常に低いと思う。"
  },
  {
    "start": 2164762,
    "end": 2171410,
    "text": "この緑のカーブはちょうど境界線にあたるので、かなり敏感で、紫のカーブはもっと安定していると思う。"
  },
  {
    "start": 2171910,
    "end": 2175334,
    "text": "もっと長くトレーニングしても、結局は上がらない。"
  },
  {
    "start": 2175372,
    "end": 2178200,
    "text": "今すぐ、その理由を説明しよう。"
  },
  {
    "start": 2179530,
    "end": 2181170,
    "text": "これがその証拠の一部である。"
  },
  {
    "start": 2181330,
    "end": 2186630,
    "text": "トレーニング時間はタスクの複雑さによってどのように変化するのか？"
  },
  {
    "start": 2187530,
    "end": 2194502,
    "text": "つまり、尾根に最も近づいたときに、最適な早めの停止時間と考えられるような、便利な指標があればいいのだ。"
  },
  {
    "start": 2194646,
    "end": 2197926,
    "text": "ところで、リッジに近づいても、リッジにはかなわない。"
  },
  {
    "start": 2197958,
    "end": 2205530,
    "text": "最適な早期停止時間を使用しても、早期停止を行うだけでは、新しいタスクの文脈学習ができる優れたプリトリン・トランスフォーマーを得ることはできない。"
  },
  {
    "start": 2205690,
    "end": 2214180,
    "text": "どのような場合でも、この回転時間を計算することができる。"
  },
  {
    "start": 2215750,
    "end": 2234486,
    "text": "このタスクの多様性閾値の相転移に到達するまでは、およそmに対してべき乗則で、平方根でスケーリングすることがわかった。"
  },
  {
    "start": 2234668,
    "end": 2235400,
    "text": "そうだね。"
  },
  {
    "start": 2235930,
    "end": 2256826,
    "text": "さて、もし取引時間を突然増やすとしたら、もしこれが安定した画像でなかったとしたら、このスケーリングの平方根に一致させるために、あるいはスケーリングの法則の一部を変更するために、突然この製品がここまで落ち込まなければならなくなるだろう。"
  },
  {
    "start": 2256938,
    "end": 2257550,
    "text": "そうだろう？"
  },
  {
    "start": 2257700,
    "end": 2259546,
    "text": "他の実験もした。"
  },
  {
    "start": 2259658,
    "end": 2266030,
    "text": "トレーニング時間を長くしても、タスクの多様性の閾値に大きな違いは見られない。"
  },
  {
    "start": 2267570,
    "end": 2271634,
    "text": "さて、ここからが重要なメッセージだ。"
  },
  {
    "start": 2271832,
    "end": 2281030,
    "text": "タスクの多様性mを大きくすると、訓練前のトランスフォーマーがリッジに向かうのを止め、最終的にDMMScに向きを変えるのに時間がかかる。"
  },
  {
    "start": 2281930,
    "end": 2285350,
    "text": "タスクの多様性のしきい値を超えるまでは、dmmmsを見つけることはない。"
  },
  {
    "start": 2287850,
    "end": 2288902,
    "text": "こういうことだ。"
  },
  {
    "start": 2288956,
    "end": 2291926,
    "text": "DmMMSCはトレーニング前のロスを最小限に抑えるものだ。"
  },
  {
    "start": 2291958,
    "end": 2293546,
    "text": "それが私たちが慣れ親しんできたことだ。"
  },
  {
    "start": 2293728,
    "end": 2296598,
    "text": "トレーニング前のロスを最小にするものを見つけたい。"
  },
  {
    "start": 2296774,
    "end": 2302634,
    "text": "さて、トレーニング前のロスを最小限に抑えることができない場合、潜在的にフィット不足になる可能性は無限にある。"
  },
  {
    "start": 2302762,
    "end": 2305166,
    "text": "失敗する方法はたくさんあるよね？"
  },
  {
    "start": 2305268,
    "end": 2308846,
    "text": "失敗した機械学習モデルはすべて違う意味で違うようなものだ。"
  },
  {
    "start": 2308948,
    "end": 2311040,
    "text": "幸せな人はみんな同じでしょう？"
  },
  {
    "start": 2312850,
    "end": 2323250,
    "text": "事前訓練されたトランスフォーマーが、DMMMSCを見つけることに失敗して事前訓練の損失を最小化できなかった場合、ある意味で、興味深いことに、それは可能な限り最善の方法で失敗する。"
  },
  {
    "start": 2323400,
    "end": 2326238,
    "text": "リッジを見つけたのは意外だった。"
  },
  {
    "start": 2326414,
    "end": 2332898,
    "text": "このような事前トレーニングの失敗があるからこそ、新しいタスクの文脈学習が生まれるのだ。"
  },
  {
    "start": 2332914,
    "end": 2336550,
    "text": "リッジは基本的に新しいタスクをこなすアルゴリズムだからだ。"
  },
  {
    "start": 2337470,
    "end": 2339830,
    "text": "これはトレーニングのロスを最小限に抑えるために失敗した。"
  },
  {
    "start": 2339910,
    "end": 2340940,
    "text": "そうだね。"
  },
  {
    "start": 2341470,
    "end": 2342506,
    "text": "それがあなたの目に映るものだ。"
  },
  {
    "start": 2342608,
    "end": 2344730,
    "text": "まあ、少なくともDMMMseとの比較ではね。"
  },
  {
    "start": 2347310,
    "end": 2350060,
    "text": "それが最初に見せたものだよね？"
  },
  {
    "start": 2351330,
    "end": 2357520,
    "text": "タスクの多様性が高い場合、事前に訓練された変換器の誤差は、変換器の誤差よりも大きくなる。"
  },
  {
    "start": 2360850,
    "end": 2365460,
    "text": "少なくとも、これまでのデータと一致すると思われる写真をお見せしよう。"
  },
  {
    "start": 2366070,
    "end": 2371730,
    "text": "次のスライドで、これは重要なヒントですよね？"
  },
  {
    "start": 2371880,
    "end": 2378838,
    "text": "DMMCを見つけることができなければ、リッチを見つける。"
  },
  {
    "start": 2378924,
    "end": 2380630,
    "text": "どんなケースだろう？"
  },
  {
    "start": 2380700,
    "end": 2391366,
    "text": "機械学習が、訓練前の損失（この特定のケースではDMMSe）に対する可能な限り最良の解を見つけることに失敗するときはいつでも、失敗には2つの理由が考えられる。"
  },
  {
    "start": 2391478,
    "end": 2393210,
    "text": "ひとつは表現力の問題だ。"
  },
  {
    "start": 2393360,
    "end": 2393914,
    "text": "そうだね。"
  },
  {
    "start": 2394032,
    "end": 2398646,
    "text": "DMMseを実現できるトランスのウェイト構成はないかもしれない。"
  },
  {
    "start": 2398758,
    "end": 2399900,
    "text": "それはそうかもしれない。"
  },
  {
    "start": 2400590,
    "end": 2402954,
    "text": "もうひとつの可能性は、トレーニングの失敗かもしれない。"
  },
  {
    "start": 2403002,
    "end": 2408480,
    "text": "そのような構成はあるかもしれないが、その吸引力の流域は非常に小さく、SGDはそれを見つけることができない。"
  },
  {
    "start": 2409570,
    "end": 2411690,
    "text": "仮に2番目の可能性を考えてみよう。"
  },
  {
    "start": 2411850,
    "end": 2415150,
    "text": "この相転移は、ロスの状況という点ではどのようなものになるのだろうか？"
  },
  {
    "start": 2415230,
    "end": 2417874,
    "text": "これが現時点での最善の推測だ。"
  },
  {
    "start": 2417992,
    "end": 2425650,
    "text": "訓練前のタスクの多様性が低い場合、これは漫画の変換パラメータの関数としての訓練前の損失である。"
  },
  {
    "start": 2425990,
    "end": 2430754,
    "text": "DmMMScポイントとリッジポイントがあり、グローバルミニマムがある。"
  },
  {
    "start": 2430802,
    "end": 2434200,
    "text": "SGDが見つけられるほど広い尾根で。"
  },
  {
    "start": 2434570,
    "end": 2436054,
    "text": "それが私たちが見ているものだ。"
  },
  {
    "start": 2436092,
    "end": 2439030,
    "text": "タスクの多様性が低い場合、トランスはリッジのように振る舞う。"
  },
  {
    "start": 2440970,
    "end": 2453946,
    "text": "タスクの多様性が高い場合、DmMMScが変圧器によって表現可能な機能のセットの一部であると仮定すると、DmMMSCにおける取引前の損失は最小でなければならない。"
  },
  {
    "start": 2454058,
    "end": 2460750,
    "text": "鋭かったり、SGDが見つけられないほど小さな吸盤があったりするかもしれない。"
  },
  {
    "start": 2460900,
    "end": 2471646,
    "text": "興味深いことに、十分な幅があり、尾根に最小値を持つ流域が常に見つかっているが、その誤差はDMMScよりも大きい。"
  },
  {
    "start": 2471758,
    "end": 2485590,
    "text": "物理学の世界と同じように、タスクの多様性を高めると、その幅が広がり、最小値を示すような一次の相転移があると想像できる。"
  },
  {
    "start": 2485930,
    "end": 2489510,
    "text": "それが落ちてきて、ますます鋭くなる。"
  },
  {
    "start": 2489670,
    "end": 2491642,
    "text": "それが、何が起こるかについての私の最善の推測だ。"
  },
  {
    "start": 2491776,
    "end": 2498730,
    "text": "このような概念的な理論が、この仮説をさらに検証するためのさまざまな実験を示唆していることは、すでに想像がつくだろう。"
  },
  {
    "start": 2499810,
    "end": 2502830,
    "text": "これが宇宙移行で起きていることだと思う。"
  },
  {
    "start": 2507730,
    "end": 2509662,
    "text": "これが第1部の最後のスライドだ。"
  },
  {
    "start": 2509716,
    "end": 2511120,
    "text": "何か質問はありますか？"
  },
  {
    "start": 2511570,
    "end": 2513742,
    "text": "実は、3つ目のケースがあると思う。"
  },
  {
    "start": 2513876,
    "end": 2520830,
    "text": "多様性という課題を無限大にすれば、EMMseは後悔を回復するはずだ。"
  },
  {
    "start": 2521590,
    "end": 2522306,
    "text": "そう、その通りだ。"
  },
  {
    "start": 2522328,
    "end": 2524402,
    "text": "それは本当に大きなMで起こることだ。"
  },
  {
    "start": 2524456,
    "end": 2528662,
    "text": "そう、だから、今考えているMを超えるサーキットが起こるはずなんだ。"
  },
  {
    "start": 2528796,
    "end": 2534658,
    "text": "突然、その障壁は消えるはずだ。"
  },
  {
    "start": 2534754,
    "end": 2536598,
    "text": "ああ、そうだね。"
  },
  {
    "start": 2536684,
    "end": 2538040,
    "text": "それは本当にいい指摘だ。"
  },
  {
    "start": 2538810,
    "end": 2545498,
    "text": "本当に大きなmでは、最小値が1つあるはずで、それはDmMSeと怒りがある場所にある。"
  },
  {
    "start": 2545584,
    "end": 2546394,
    "text": "まったくその通りだ。"
  },
  {
    "start": 2546432,
    "end": 2554346,
    "text": "ここで見ている体制を見ると、DMMMSCとリッジの間にはまだ隔たりがある。"
  },
  {
    "start": 2554378,
    "end": 2556346,
    "text": "わずかなギャップだが、それでもギャップはある。"
  },
  {
    "start": 2556458,
    "end": 2557662,
    "text": "その通りだ。"
  },
  {
    "start": 2557796,
    "end": 2561166,
    "text": "本当に大きなタスクの多様性では、すべてがシンプルだ。"
  },
  {
    "start": 2561348,
    "end": 2572110,
    "text": "本当に興味深いのは、DMMSeとリッジの間に大きな隔たりがあるような、タスクの多様性が本当に低い場合、事前に訓練されたトランスフォーマーは依然としてリッジを好むということだ。"
  },
  {
    "start": 2572270,
    "end": 2573860,
    "text": "それが驚きだ。"
  },
  {
    "start": 2576070,
    "end": 2578194,
    "text": "DMMScのソリューションが見つからない。"
  },
  {
    "start": 2578322,
    "end": 2581830,
    "text": "リッジとDMMCが離れていても、リッジを見つける。"
  },
  {
    "start": 2582410,
    "end": 2591266,
    "text": "DMMCとリッジは離れているが、なぜかトランスフォーマーはリッジを気に入っている。"
  },
  {
    "start": 2591378,
    "end": 2596330,
    "text": "繰り返しになるが、この写真はすべて憶測にすぎない。"
  },
  {
    "start": 2596400,
    "end": 2600650,
    "text": "もし私たちがこの作業を続けるとしたら、この写真を使った実験の指針になるだろう。"
  },
  {
    "start": 2605230,
    "end": 2605690,
    "text": "そうだね。"
  },
  {
    "start": 2605760,
    "end": 2608698,
    "text": "あなたのカーブのいくつかは、記憶がないように見える。"
  },
  {
    "start": 2608794,
    "end": 2616546,
    "text": "これではないのか、ちょっと気になる。"
  },
  {
    "start": 2616568,
    "end": 2622740,
    "text": "幾何学的な、あるいは、どちらかを参考にしているわけではない。"
  },
  {
    "start": 2624550,
    "end": 2627480,
    "text": "その特徴を把握しようとしているんだ。"
  },
  {
    "start": 2633290,
    "end": 2634022,
    "text": "分からないよ。"
  },
  {
    "start": 2634076,
    "end": 2635240,
    "text": "ああ、よくわからない。"
  },
  {
    "start": 2637630,
    "end": 2638380,
    "text": "オーケー。"
  },
  {
    "start": 2639630,
    "end": 2641930,
    "text": "私は別のセッティングについて話したかった。"
  },
  {
    "start": 2643070,
    "end": 2645660,
    "text": "このハイライトはすぐに終わると思う。"
  },
  {
    "start": 2646590,
    "end": 2647626,
    "text": "スタートは遅かったよね？"
  },
  {
    "start": 2647648,
    "end": 2648890,
    "text": "10分くらい遅れた"
  },
  {
    "start": 2650450,
    "end": 2651102,
    "text": "よし、完璧だ。"
  },
  {
    "start": 2651156,
    "end": 2651326,
    "text": "そうだね。"
  },
  {
    "start": 2651348,
    "end": 2652174,
    "text": "約15分。"
  },
  {
    "start": 2652212,
    "end": 2658506,
    "text": "では、データの多様性が重要なもう1つの設定を紹介しよう。"
  },
  {
    "start": 2658538,
    "end": 2662990,
    "text": "実際に私たちが観察しているスケーリングの法則を変えることができるのだ。"
  },
  {
    "start": 2663970,
    "end": 2667954,
    "text": "これは非常に才能あるチームによる仕事だ。"
  },
  {
    "start": 2668152,
    "end": 2670500,
    "text": "ここには3つの論文がある。"
  },
  {
    "start": 2670870,
    "end": 2675300,
    "text": "本稿では主にこの論文に焦点を当てるつもりだが、この論文が本稿の動機付けとなっている。"
  },
  {
    "start": 2675910,
    "end": 2677942,
    "text": "これが基本的な考え方だ。"
  },
  {
    "start": 2677996,
    "end": 2683618,
    "text": "このワークショップの他のいくつかの講演では、神経のスケーリング法則について見てきた。"
  },
  {
    "start": 2683794,
    "end": 2690010,
    "text": "誤差は、パラメータの数、データポイントの数、計算量のいずれかに応じてべき乗則で減少する傾向がある。"
  },
  {
    "start": 2691230,
    "end": 2694010,
    "text": "指数はかなり小さいことが多い。"
  },
  {
    "start": 2694160,
    "end": 2694474,
    "text": "そうだね。"
  },
  {
    "start": 2694512,
    "end": 2699542,
    "text": "個人的には、スケーリングだけでAIを進化させるのはかなり高価だと思う。"
  },
  {
    "start": 2699606,
    "end": 2700806,
    "text": "確かに高い。"
  },
  {
    "start": 2700918,
    "end": 2703710,
    "text": "持続可能かどうかという疑問がある。"
  },
  {
    "start": 2705890,
    "end": 2714402,
    "text": "例えば、大きな変換器を使った言語モデリングを行う場合、クロスエントロピーを3.4ナッツから2.8ナッツに落とすには、10倍以上のトレーニングデータが必要になる。"
  },
  {
    "start": 2714456,
    "end": 2714722,
    "text": "そうだね。"
  },
  {
    "start": 2714776,
    "end": 2717154,
    "text": "スケーリング指数はマイナスゼロの9。"
  },
  {
    "start": 2717272,
    "end": 2718900,
    "text": "ゼロに近い。"
  },
  {
    "start": 2722950,
    "end": 2725780,
    "text": "大型ビジョントランスも同様だ。"
  },
  {
    "start": 2726310,
    "end": 2733698,
    "text": "10億データポイントから20億データポイントになれば、イメージネットのパフォーマンスは2％から3％向上する。"
  },
  {
    "start": 2733794,
    "end": 2734294,
    "text": "そうだろう？"
  },
  {
    "start": 2734412,
    "end": 2739190,
    "text": "つまり、10億のデータポイントを足して、2％ポイント改善したことになる。"
  },
  {
    "start": 2739690,
    "end": 2742810,
    "text": "遅くて持続不可能というのはこういうことだ。"
  },
  {
    "start": 2743790,
    "end": 2747418,
    "text": "それでは、第2部の重要なアイデアと持ち帰りメッセージをお伝えしよう。"
  },
  {
    "start": 2747584,
    "end": 2756510,
    "text": "重要な考え方は、データセットサイズに対する誤差のパワーロスのスケーリングが遅いということは、訓練例が非常に冗長であることを示している可能性が高いということである。"
  },
  {
    "start": 2756930,
    "end": 2757962,
    "text": "ほとんど同語反復だ。"
  },
  {
    "start": 2758026,
    "end": 2761150,
    "text": "これ以上例を増やしても何の役にも立たない。"
  },
  {
    "start": 2761970,
    "end": 2768130,
    "text": "したがって、データセットを刈り込んで、冗長でない例の疎な部分集合を特定することができるはずである。"
  },
  {
    "start": 2769990,
    "end": 2772866,
    "text": "冗長性がない分、ある意味で多様性がある。"
  },
  {
    "start": 2772968,
    "end": 2780310,
    "text": "冗長でないデータセットのサイズの関数として誤差をプロットすれば、このパワーロスのスケーリングに勝てるかもしれない。"
  },
  {
    "start": 2782010,
    "end": 2788590,
    "text": "そこで、パーセプトロン学習が生徒の教師設定でも可能であることを分析的に示しました。"
  },
  {
    "start": 2788690,
    "end": 2797622,
    "text": "少なくとも、理論的にも実践的にも指数関数的なスケーリングを達成することができる。"
  },
  {
    "start": 2797686,
    "end": 2805242,
    "text": "例えば、ベンチマークテストで訓練されたレスネットや、事前訓練された画像と微調整で訓練された視覚変換器などである。"
  },
  {
    "start": 2805386,
    "end": 2809550,
    "text": "我々は、これらの類似のアルゴリズムを使用して、電力損失スケーリングを打ち負かす方法を示す。"
  },
  {
    "start": 2810290,
    "end": 2812874,
    "text": "データの刈り込み方が重要であることがわかるだろう。"
  },
  {
    "start": 2812922,
    "end": 2816126,
    "text": "我々は、多くの異なる刈り込みメトリクスのベンチマーク研究を行う。"
  },
  {
    "start": 2816238,
    "end": 2819090,
    "text": "私たちは、安価でスケーラブルな新しい指標を開発します。"
  },
  {
    "start": 2819990,
    "end": 2821838,
    "text": "計算するのにラベルも必要ない。"
  },
  {
    "start": 2821854,
    "end": 2828498,
    "text": "そうすれば、精度を落とすことなく、イメージネットの75%までプルーニングすることができる。"
  },
  {
    "start": 2828594,
    "end": 2836440,
    "text": "その後、この論文では、言語モデルやより大規模なインターネット・スケールのデータセットにこれを適用する方法を示した。"
  },
  {
    "start": 2839050,
    "end": 2840540,
    "text": "じゃあ、どうすればいいんだ？"
  },
  {
    "start": 2841550,
    "end": 2844540,
    "text": "データセットを刈り込む面白い戦略とは？"
  },
  {
    "start": 2845150,
    "end": 2850410,
    "text": "さて、マンチェイとカロリナとともにこの論文で探求したシンプルな発見的手法がある。"
  },
  {
    "start": 2852290,
    "end": 2864500,
    "text": "私たちが行ったのは、あるデータセット（この場合はtfar 10）を使って、非常に短期間のトレーニングを行うことだった。"
  },
  {
    "start": 2865910,
    "end": 2870850,
    "text": "次に、個々の例について、決定境界までの距離を計算する。"
  },
  {
    "start": 2871910,
    "end": 2877806,
    "text": "正しい側の決定境界線から遠いものは、ある意味で簡単な例である。"
  },
  {
    "start": 2877838,
    "end": 2888250,
    "text": "意思決定境界線に近いもの、あるいはもっと悪いことに、意思決定境界線の反対側で遠いものなど、短時間の訓練で素早く正しく学習することができる。"
  },
  {
    "start": 2888400,
    "end": 2890166,
    "text": "これらは難しい例だ。"
  },
  {
    "start": 2890278,
    "end": 2895740,
    "text": "短期間のトレーニングでは、自信をもって習得できないか、あるいは間違っている。"
  },
  {
    "start": 2896270,
    "end": 2897020,
    "text": "そうだろう？"
  },
  {
    "start": 2897470,
    "end": 2907470,
    "text": "このようにして定義された難易度によって例をランク付けし、これを数回繰り返してスコアを平均化することができる。"
  },
  {
    "start": 2908130,
    "end": 2913390,
    "text": "私たちにできることは、最も困難な例の一部fだけを保持することによってデータを刈り込むことである。"
  },
  {
    "start": 2914370,
    "end": 2919050,
    "text": "となると、問題は、損失を被る前にいくつの例を剪定できるかということだ。"
  },
  {
    "start": 2919210,
    "end": 2922606,
    "text": "CFR10では、例の約50％を削除できることがわかった。"
  },
  {
    "start": 2922638,
    "end": 2924146,
    "text": "データセットの半分を捨てることができる。"
  },
  {
    "start": 2924248,
    "end": 2928274,
    "text": "その半分のデータセットで訓練すれば、データセット全体で訓練した場合と同じようにうまくいく。"
  },
  {
    "start": 2928392,
    "end": 2932678,
    "text": "CFAR100の場合、データセットの約25％を捨てることができる。"
  },
  {
    "start": 2932844,
    "end": 2935906,
    "text": "なるほど、これは合理的なヒューリスティック刈り込みアルゴリズムだ。"
  },
  {
    "start": 2935938,
    "end": 2937560,
    "text": "それは多くの疑問を投げかけるものだ。"
  },
  {
    "start": 2938010,
    "end": 2940600,
    "text": "なぜこのような方法でデータの刈り込みが行われるのか？"
  },
  {
    "start": 2941050,
    "end": 2944326,
    "text": "なぜ、最も難しいことを続けることが、正しいアプローチの最も難しい例なのか？"
  },
  {
    "start": 2944358,
    "end": 2948518,
    "text": "それとも、データ刈り込みの数学的理論を開発できるかということだろうか？"
  },
  {
    "start": 2948694,
    "end": 2952400,
    "text": "プルーニングされたデータセットのサイズによって、パフォーマンスはどのように変化するのか？"
  },
  {
    "start": 2953810,
    "end": 2954814,
    "text": "規模を拡大できるか？"
  },
  {
    "start": 2954852,
    "end": 2956426,
    "text": "imagenetでも使えますか？"
  },
  {
    "start": 2956618,
    "end": 2959470,
    "text": "それとも、イメージネットのために新しい刈り込み方法が必要なのでしょうか？"
  },
  {
    "start": 2961810,
    "end": 2966370,
    "text": "さて、では私たちのアイデアを修正するために、実はいくつかの理論から始めた。"
  },
  {
    "start": 2966440,
    "end": 2974210,
    "text": "最も単純な設定で、枝刈り後のテスト誤差を解析的に導けるか？"
  },
  {
    "start": 2974970,
    "end": 2977270,
    "text": "私たちはパーセプトロンから始めた。"
  },
  {
    "start": 2979050,
    "end": 2982882,
    "text": "基本的に、データ分布のモデルは以下の通りである。"
  },
  {
    "start": 2983026,
    "end": 2986070,
    "text": "PIIDランダムなガウス入力を選ぶ。"
  },
  {
    "start": 2987770,
    "end": 2991754,
    "text": "重みベクトルtを持つランダムな教師パーセプトロンを選ぶ。"
  },
  {
    "start": 2991792,
    "end": 2993126,
    "text": "これが先生だ。"
  },
  {
    "start": 2993238,
    "end": 2996982,
    "text": "ウェイト・ベクトルに垂直な判定境界を持つ。"
  },
  {
    "start": 2997126,
    "end": 3001894,
    "text": "のように、各例と教師のドット積の正弦だけでラベルを付ける。"
  },
  {
    "start": 3002032,
    "end": 3006170,
    "text": "これらの例はプラスの例であり、これらの例はマイナスの例である。"
  },
  {
    "start": 3006250,
    "end": 3007838,
    "text": "これは2ウェイ分類の問題だ。"
  },
  {
    "start": 3007924,
    "end": 3013098,
    "text": "これがトレーニングデータのモデルであり、データの刈り込み戦略だ。"
  },
  {
    "start": 3013194,
    "end": 3017202,
    "text": "さて、これからやることは、ディープラーニングとデータガイドの論文でやったことを踏襲するだけだ。"
  },
  {
    "start": 3017336,
    "end": 3026610,
    "text": "プローブの生徒を短期間訓練し、プローブの生徒が教師のゼロでないドット積をいくつか習得するようにする。"
  },
  {
    "start": 3027350,
    "end": 3033990,
    "text": "そして、プローブ学生の決定境界を計算し、プローブ学生に対する各例のマージンを計算します。"
  },
  {
    "start": 3034060,
    "end": 3036130,
    "text": "覚えておいてほしいのは、先生と直接接触する必要はないということだ。"
  },
  {
    "start": 3036210,
    "end": 3037878,
    "text": "我々はトレーニングデータにしかアクセスできない。"
  },
  {
    "start": 3037964,
    "end": 3042380,
    "text": "プローブ学生の決定境界に対するトレーニングデータのマージンを計算する。"
  },
  {
    "start": 3043310,
    "end": 3048966,
    "text": "そして、この決定境界線に関して、最もマージンの少ないハードなデータをキープすることになる。"
  },
  {
    "start": 3049158,
    "end": 3052080,
    "text": "例えば、この例とこの例を残しておこう。"
  },
  {
    "start": 3053890,
    "end": 3059760,
    "text": "そうしたら、プローブを捨てて、前と同じようにゼロからトレーニングを始めるんだ。"
  },
  {
    "start": 3060210,
    "end": 3066820,
    "text": "次に、非ガウス刈り込みデータに対する最大マージン学習器のテスト誤差を解析的に計算する。"
  },
  {
    "start": 3067510,
    "end": 3075890,
    "text": "これが、問題の次元が無限大になる高次元統計の極限で取り組む戦略だ。"
  },
  {
    "start": 3076230,
    "end": 3080150,
    "text": "刈り込みを始める前の例数は無限大になる。"
  },
  {
    "start": 3080810,
    "end": 3087542,
    "text": "密度、次元に対する例数の比率、データ密度をアルファ・トータル（alpha total）と呼ぶことにする。"
  },
  {
    "start": 3087596,
    "end": 3089320,
    "text": "それは今後も変わらないだろう。"
  },
  {
    "start": 3090170,
    "end": 3094620,
    "text": "このとき、fは重要なパラメータであり、保持する例の割合fである。"
  },
  {
    "start": 3095310,
    "end": 3099980,
    "text": "したがって、刈り込まれたデータセットのサイズは、定義上、アルファの合計のf倍になる。"
  },
  {
    "start": 3100690,
    "end": 3103870,
    "text": "これがプルーンのデータセットのサイズだ。"
  },
  {
    "start": 3103940,
    "end": 3109710,
    "text": "アルファ・プルーンによって、パフォーマンスやテストの誤差がどのように変化するかが気になるところだ。"
  },
  {
    "start": 3111970,
    "end": 3122110,
    "text": "さて、この問題の重要なパラメータは、θ、教師とプローブの間の角度、プローブへのデータの投影、マージン、そしてこの比率である。"
  },
  {
    "start": 3122270,
    "end": 3130514,
    "text": "さて、この高次元統計的限界に集中し、訓練データの詳細な実現などに依存しない特定の量がある。"
  },
  {
    "start": 3130642,
    "end": 3134514,
    "text": "一つは、生徒とプローブの間の余弦角である。"
  },
  {
    "start": 3134642,
    "end": 3138242,
    "text": "生徒がパーセプトロンであり、そのパーセプトロンを完成まで訓練する。"
  },
  {
    "start": 3138306,
    "end": 3142054,
    "text": "剪定した後、プローブと角度をつけることになる。"
  },
  {
    "start": 3142102,
    "end": 3145974,
    "text": "これを \"Ρ \"と呼ぶことにする。"
  },
  {
    "start": 3146022,
    "end": 3147114,
    "text": "これをrと呼ぶことにする。"
  },
  {
    "start": 3147232,
    "end": 3152186,
    "text": "テストの誤差は、生徒と教師の逆コサイン角でしかない。"
  },
  {
    "start": 3152218,
    "end": 3155440,
    "text": "生徒と教師の距離が近ければ、テストの誤差は小さくなる。"
  },
  {
    "start": 3157010,
    "end": 3173134,
    "text": "無秩序系の統計力学、特にレプリカ法の考え方を使えば、これらの量について自己無撞着な方程式を計算することができる。"
  },
  {
    "start": 3173262,
    "end": 3175738,
    "text": "これらの式からテスターを抽出することができる。"
  },
  {
    "start": 3175934,
    "end": 3177858,
    "text": "方程式についてはあまり心配する必要はない。"
  },
  {
    "start": 3177954,
    "end": 3180870,
    "text": "その結果をお伝えしよう。"
  },
  {
    "start": 3181690,
    "end": 3184600,
    "text": "これが結果の一例である。"
  },
  {
    "start": 3186410,
    "end": 3189254,
    "text": "これは、プローブと教師がイコールである場合の例である。"
  },
  {
    "start": 3189302,
    "end": 3191098,
    "text": "θはゼロだろ？"
  },
  {
    "start": 3191184,
    "end": 3193734,
    "text": "私たちは時に、可能な限り最良の刈り込み指標を持っている。"
  },
  {
    "start": 3193782,
    "end": 3197930,
    "text": "私たちは先生の決定塚に従って剪定している。"
  },
  {
    "start": 3200110,
    "end": 3202394,
    "text": "この横軸はアルファ・プルーンである。"
  },
  {
    "start": 3202442,
    "end": 3207790,
    "text": "この縦軸を刈り込んだ後のデータ量がテストミスなのだ。"
  },
  {
    "start": 3208530,
    "end": 3215700,
    "text": "これらの異なる曲線、あるいはそれに対応する異なる色は、異なるアルファの合計から始まるデータの異なる割合に対応している。"
  },
  {
    "start": 3217430,
    "end": 3226354,
    "text": "例えば、100％のデータを維持する場合、それは全く刈り込みをしないのと同じことで、データセットの大きさに応じてテスト誤差がべき乗則でスケーリングされることになる。"
  },
  {
    "start": 3226472,
    "end": 3229430,
    "text": "これは古典的なパーセプトロン理論でよく知られている。"
  },
  {
    "start": 3230570,
    "end": 3237302,
    "text": "さて、ではアルファ・プルーンとアルファ・トータルおよびfのレベルを変えて、パフォーマンスをプロットしたらどうなるだろうか？"
  },
  {
    "start": 3237436,
    "end": 3238120,
    "text": "そうだろう？"
  },
  {
    "start": 3238970,
    "end": 3245338,
    "text": "アルファ・プルーンFとアルファ・トータルの関係を思い出してほしい。"
  },
  {
    "start": 3245424,
    "end": 3248586,
    "text": "特定のプルーンのデータセットサイズを得るには、多くの方法がある。"
  },
  {
    "start": 3248688,
    "end": 3253034,
    "text": "私は、たくさんのデータ、大きなアルファの合計、小さなFから始めることができた。"
  },
  {
    "start": 3253152,
    "end": 3257920,
    "text": "あるいは、より少ないデータ、たとえばアルファ値の合計を小さくして、F値を大きくすることから始めることもできる。"
  },
  {
    "start": 3258450,
    "end": 3263170,
    "text": "だから、どのアルファ・プルーンでも複数のカーブが存在する。"
  },
  {
    "start": 3264470,
    "end": 3269860,
    "text": "各曲線は最終的にべき乗則に落ち着くので、一定の刈り込み比率fに対応する。"
  },
  {
    "start": 3270790,
    "end": 3275934,
    "text": "この曲線族のパレート包絡線は指数関数的に減少する。"
  },
  {
    "start": 3276062,
    "end": 3282470,
    "text": "このパレート包絡線をトレースする方法は、より大きなデータセットから始めて、より積極的な刈り込みを行うことだ。"
  },
  {
    "start": 3287550,
    "end": 3298326,
    "text": "あなたは、超平面のアルファのように、距離内にあることを条件に点の束を言っているだけだ。"
  },
  {
    "start": 3298438,
    "end": 3299770,
    "text": "最大マージンは？"
  },
  {
    "start": 3301790,
    "end": 3310510,
    "text": "例数の割合の関数として、そのデータ分布に対する最大マージン分類器のテスターは？"
  },
  {
    "start": 3310580,
    "end": 3312602,
    "text": "私はどんどん狭くなっているのだろうか？"
  },
  {
    "start": 3312666,
    "end": 3313440,
    "text": "ああ、その通りだ。"
  },
  {
    "start": 3314930,
    "end": 3318754,
    "text": "ところで、こちらでは、剪定をまったくしないよりも、もっと悪いことをするんだ。"
  },
  {
    "start": 3318792,
    "end": 3320530,
    "text": "それは興味深い見解だ。"
  },
  {
    "start": 3321270,
    "end": 3328502,
    "text": "いずれにせよ、スケーリング則をべき乗から指数に変える方法はある。"
  },
  {
    "start": 3328636,
    "end": 3335426,
    "text": "それは、より大きなデータセットから始めて、より積極的な刈り込みを行うことである。"
  },
  {
    "start": 3335538,
    "end": 3335766,
    "text": "そうだね。"
  },
  {
    "start": 3335788,
    "end": 3338470,
    "text": "そうすれば、この期間最適フロンティアをなぞることになる。"
  },
  {
    "start": 3339050,
    "end": 3342154,
    "text": "さて、ここで最悪のケースに戻る。"
  },
  {
    "start": 3342192,
    "end": 3343340,
    "text": "これがその例だ。"
  },
  {
    "start": 3343950,
    "end": 3349098,
    "text": "そもそもデータがあまりないのでは？"
  },
  {
    "start": 3349184,
    "end": 3352342,
    "text": "それは、スモールアルファープルーンのような少量のデータがある場合だ。"
  },
  {
    "start": 3352486,
    "end": 3355882,
    "text": "一番難しい例を残しておくのは良い考えではないことがわかった。"
  },
  {
    "start": 3356026,
    "end": 3359146,
    "text": "簡単な例は残しておいた方がいいということがわかった。"
  },
  {
    "start": 3359178,
    "end": 3364346,
    "text": "つまり、「難しい例を残す」と「簡単な例を残す」という2つの戦略の違いはここにある。"
  },
  {
    "start": 3364458,
    "end": 3368974,
    "text": "そもそもデータがたくさんあるのなら、難しい例を残しておく方が良い戦略だ。"
  },
  {
    "start": 3369102,
    "end": 3374830,
    "text": "そもそもデータが少ないのであれば、簡単な例を残しておく方が良い戦略である。"
  },
  {
    "start": 3374910,
    "end": 3377720,
    "text": "これは面白い予想だろう？"
  },
  {
    "start": 3378250,
    "end": 3382578,
    "text": "これと同じ予測は、ベンチマークデータセットで訓練されたディープニューラルネットワークでも成り立つのだろうか？"
  },
  {
    "start": 3382674,
    "end": 3384230,
    "text": "驚くことに、そうなのだ。"
  },
  {
    "start": 3384380,
    "end": 3384886,
    "text": "そうだろう？"
  },
  {
    "start": 3384988,
    "end": 3395210,
    "text": "シンプルなモデルで何かを解明し、それがうまくいけば、シンプルなモデルの妥当性の範囲をはるかに超えた予測を可能にする。"
  },
  {
    "start": 3395280,
    "end": 3398858,
    "text": "レスネット18のCファー10でもまったく同じことがわかった。"
  },
  {
    "start": 3398944,
    "end": 3400662,
    "text": "この予想は実際に当たっている。"
  },
  {
    "start": 3400806,
    "end": 3403046,
    "text": "誰も誰も見ていない。"
  },
  {
    "start": 3403078,
    "end": 3407230,
    "text": "というのは、私たちは常にたくさんの例から始めているからだ。"
  },
  {
    "start": 3407300,
    "end": 3413594,
    "text": "人為的にデータセットを減らし、その後に刈り込みを行うのであれば、確かにこの方が良い戦略であることがわかる。"
  },
  {
    "start": 3413722,
    "end": 3418142,
    "text": "このパーセプトロンによる予測は、驚くべきことに、より一般的な設定でも成り立つ。"
  },
  {
    "start": 3418286,
    "end": 3420770,
    "text": "さて、もう一度、これが漫画の絵だ。"
  },
  {
    "start": 3421190,
    "end": 3424734,
    "text": "そもそもデータが少ない場合は、マージンが大きい例を残しておく。"
  },
  {
    "start": 3424782,
    "end": 3426046,
    "text": "電柱の近くに物を置く。"
  },
  {
    "start": 3426158,
    "end": 3431682,
    "text": "もし最初からたくさんのデータがあるのなら、赤道付近のものを保持し、ここでtは真の回帰ベクトルである。"
  },
  {
    "start": 3431826,
    "end": 3433650,
    "text": "すみません、tはパーセプトロンです。"
  },
  {
    "start": 3433810,
    "end": 3434520,
    "text": "オーケー。"
  },
  {
    "start": 3436250,
    "end": 3439500,
    "text": "データがあまりないのなら、全部残しておけばいいじゃないか。"
  },
  {
    "start": 3442030,
    "end": 3450640,
    "text": "私たちは、与えられたサイズの最適なデータセットに関するパフォーマンスのスケーリングを理解しようとしているんですね？"
  },
  {
    "start": 3451170,
    "end": 3453034,
    "text": "これらは非ガウスのデータセットである。"
  },
  {
    "start": 3453082,
    "end": 3454094,
    "text": "どうやって手に入れたんだ？"
  },
  {
    "start": 3454212,
    "end": 3458000,
    "text": "私たちは常に、プルーンのデータセットサイズに関するパフォーマンスを見ている。"
  },
  {
    "start": 3462450,
    "end": 3467200,
    "text": "少ないデータセットでトレーニングすることで、長時間トレーニングする必要がなくなるので、効率は上がる。"
  },
  {
    "start": 3468550,
    "end": 3475518,
    "text": "ここでは、非ガウシアンデータのテスターを分析・計算し、正則化における最適な損失を実際に見つけることができる別の論文についての宣伝です。"
  },
  {
    "start": 3475534,
    "end": 3476642,
    "text": "それについては触れない。"
  },
  {
    "start": 3476776,
    "end": 3477460,
    "text": "オーケー。"
  },
  {
    "start": 3477990,
    "end": 3482150,
    "text": "プローブの角度が変わると面白い変化が起こる。"
  },
  {
    "start": 3482570,
    "end": 3485014,
    "text": "えーと、2分で何が言えるかな？"
  },
  {
    "start": 3485052,
    "end": 3486054,
    "text": "超楽しいね。"
  },
  {
    "start": 3486172,
    "end": 3488346,
    "text": "じゃあ、練習だけでいいんだね？"
  },
  {
    "start": 3488528,
    "end": 3497020,
    "text": "この刈り込み手順をさまざまな問題で試してみたところ、ブラック・スケーリングの法則に打ち勝つことができたんだ。"
  },
  {
    "start": 3498190,
    "end": 3505230,
    "text": "もし不完全な刈り込み指標があれば、指数関数的な結果が予測されるだろう。"
  },
  {
    "start": 3505810,
    "end": 3512650,
    "text": "ある方法でデータを刈り込めば、間違いなくスケーリング法則をかなり打ち破ることができる。"
  },
  {
    "start": 3512740,
    "end": 3513426,
    "text": "そうだろう？"
  },
  {
    "start": 3513608,
    "end": 3516194,
    "text": "また、視覚トランスフォーマーにも有効だ。"
  },
  {
    "start": 3516312,
    "end": 3516980,
    "text": "オーケー。"
  },
  {
    "start": 3521670,
    "end": 3522034,
    "text": "そうだね。"
  },
  {
    "start": 3522072,
    "end": 3524418,
    "text": "面白いことを教えてあげよう。"
  },
  {
    "start": 3524504,
    "end": 3526094,
    "text": "我々はそれをimagenetに拡大した。"
  },
  {
    "start": 3526142,
    "end": 3529634,
    "text": "ラベルを必要としない面白いアルゴリズムがあるんだ。"
  },
  {
    "start": 3529762,
    "end": 3536274,
    "text": "そのアルゴリズムを使えば、直感的に、簡単な例は何か？"
  },
  {
    "start": 3536322,
    "end": 3537234,
    "text": "なぜ冗長なのか？"
  },
  {
    "start": 3537282,
    "end": 3538354,
    "text": "難しい例とは？"
  },
  {
    "start": 3538402,
    "end": 3542186,
    "text": "そもそも、多くの例があるのに、なぜそれを維持することが有益なのでしょうか？"
  },
  {
    "start": 3542288,
    "end": 3545046,
    "text": "これはimagenetでうまく機能する我々の新しい刈り込みアルゴリズムである。"
  },
  {
    "start": 3545078,
    "end": 3549190,
    "text": "パフォーマンスを落とすことなく、イメージネットの25％を捨てることができる。"
  },
  {
    "start": 3549350,
    "end": 3551450,
    "text": "これはただのランダムクラスだ。"
  },
  {
    "start": 3551520,
    "end": 3553782,
    "text": "クラス100はブラックスワンだ。"
  },
  {
    "start": 3553926,
    "end": 3556014,
    "text": "これらは最も簡単な例だろう？"
  },
  {
    "start": 3556052,
    "end": 3557600,
    "text": "すぐに覚えられるものだ。"
  },
  {
    "start": 3557970,
    "end": 3560574,
    "text": "を見れば、お互いにかなり冗長であることがわかるだろう。"
  },
  {
    "start": 3560612,
    "end": 3563150,
    "text": "ブラックスワンの定番ポーズだ。"
  },
  {
    "start": 3564210,
    "end": 3570114,
    "text": "難しい例はどれも特異なもので、それなりに特異なものだ。"
  },
  {
    "start": 3570232,
    "end": 3575540,
    "text": "イメージネットで成功したいのなら、これらの多くを捨てても構わない。"
  },
  {
    "start": 3576790,
    "end": 3580440,
    "text": "もう1つの例は、ランダムな200クラスだろう？"
  },
  {
    "start": 3581290,
    "end": 3582754,
    "text": "チベタンテリア。"
  },
  {
    "start": 3582802,
    "end": 3583986,
    "text": "これらは簡単な例だ。"
  },
  {
    "start": 3584018,
    "end": 3585618,
    "text": "どれも定型的で冗長だ。"
  },
  {
    "start": 3585714,
    "end": 3586866,
    "text": "これらは難しい例だ。"
  },
  {
    "start": 3586898,
    "end": 3590860,
    "text": "ここには奇妙なカラーマップもある。"
  },
  {
    "start": 3591550,
    "end": 3593686,
    "text": "そしてお楽しみのトラカミキリ。"
  },
  {
    "start": 3593718,
    "end": 3595500,
    "text": "ここでも簡単な例を挙げる。"
  },
  {
    "start": 3596350,
    "end": 3599450,
    "text": "これは難しい例で、トラカミキリの漫画である。"
  },
  {
    "start": 3600690,
    "end": 3602654,
    "text": "これはすべてアルゴリズムが選んだものだ。"
  },
  {
    "start": 3602692,
    "end": 3613690,
    "text": "これは、データセットを探索する素晴らしい方法だ。"
  },
  {
    "start": 3613770,
    "end": 3616258,
    "text": "つまり、お互いによく似ているとも言える。"
  },
  {
    "start": 3616424,
    "end": 3617780,
    "text": "もっとたくさんいる。"
  },
  {
    "start": 3618630,
    "end": 3620260,
    "text": "カブトムシが増えただけだ。"
  },
  {
    "start": 3623590,
    "end": 3630280,
    "text": "なぜ似ていると言ったかというと、これを得るために使ったアルゴリズムは、これらの画像をすべて基礎モデルの埋め込み空間に置くというものだったからだ。"
  },
  {
    "start": 3630970,
    "end": 3636594,
    "text": "それらをクラスターに分類し、クラスターの中心から最も遠い例を選ぶ。"
  },
  {
    "start": 3636722,
    "end": 3640914,
    "text": "これらの画像はすべて、それぞれのクラスター重心に最も近い。"
  },
  {
    "start": 3641042,
    "end": 3647002,
    "text": "基礎モデルの埋め込み空間におけるユークリッド距離で測定すると、それらはすべて互いによく似ている。"
  },
  {
    "start": 3647136,
    "end": 3650230,
    "text": "確かに、どれもある程度似ていると、カブトムシが多くなる。"
  },
  {
    "start": 3650320,
    "end": 3652720,
    "text": "似ていることの方が重要だと思う。"
  },
  {
    "start": 3654930,
    "end": 3658160,
    "text": "似ているからこそ、これを選ぶことができた。"
  },
  {
    "start": 3661010,
    "end": 3665746,
    "text": "私たちは病的なものに対する数学的概念を持ち合わせていない。"
  },
  {
    "start": 3665928,
    "end": 3670242,
    "text": "オーケー、もう一度言うが、我々はこのライオンのデータセットも把握した。"
  },
  {
    "start": 3670296,
    "end": 3672770,
    "text": "440,000,000の画像。"
  },
  {
    "start": 3673350,
    "end": 3675202,
    "text": "半分の大きさに剪定することもできる。"
  },
  {
    "start": 3675256,
    "end": 3678414,
    "text": "パフォーマンスを落とすことなく、2億2000万ドルを獲得した。"
  },
  {
    "start": 3678462,
    "end": 3679974,
    "text": "そうすれば、トレーニングのスピードは2倍になる。"
  },
  {
    "start": 3680092,
    "end": 3685000,
    "text": "基礎モデルを2倍の速さでトレーニングできるようになれば、もちろん時間もお金も節約できる。"
  },
  {
    "start": 3686490,
    "end": 3690250,
    "text": "言語モデルの効率も15％ほど向上する。"
  },
  {
    "start": 3690670,
    "end": 3701370,
    "text": "とにかく、その詳細はここにある。"
  },
  {
    "start": 3707490,
    "end": 3708400,
    "text": "ありがとう。"
  },
  {
    "start": 3709010,
    "end": 3716610,
    "text": "プローブの状態に基づいてデータを刈り込んだ場合、それはトレーニングのかなり初期の段階だ。"
  },
  {
    "start": 3716680,
    "end": 3723042,
    "text": "そうすると、最終的なトレーニング結果がプローブ状態に近いものに偏ってしまうのではないか？"
  },
  {
    "start": 3723176,
    "end": 3729800,
    "text": "このようにデータの刈り込みを行うことで、モデルトレーニングの効率が上がるという点を考慮しましたか？"
  },
  {
    "start": 3730250,
    "end": 3742410,
    "text": "そう、これがモデルデータの刈り込みがどのように役立つかという哲学のようなものだ。"
  },
  {
    "start": 3748110,
    "end": 3754814,
    "text": "我々は、プルーンのデータセットのimagenet分類器の訓練に偏りがないかを調べた。"
  },
  {
    "start": 3754852,
    "end": 3759150,
    "text": "特定のクラスで他のクラスより成績が悪いのか？"
  },
  {
    "start": 3759300,
    "end": 3761662,
    "text": "クラスバランスを考えなければ、そうなる。"
  },
  {
    "start": 3761796,
    "end": 3762190,
    "text": "そうだろう？"
  },
  {
    "start": 3762260,
    "end": 3764720,
    "text": "クラス・バランスを取るのであれば、それは排除される。"
  },
  {
    "start": 3765490,
    "end": 3775258,
    "text": "さて、ラベルがなく、キャプションがあるライオン・データセットを訓練する場合だが、枝刈りの際にキャプションは無視した。"
  },
  {
    "start": 3775454,
    "end": 3778950,
    "text": "次にimagenetの分類器を見たが、バイアスは見られなかった。"
  },
  {
    "start": 3781930,
    "end": 3784290,
    "text": "ライオンのクリップモデルを訓練した。"
  },
  {
    "start": 3784450,
    "end": 3796570,
    "text": "私たちは、ライオンの埋め込み空間の上でイメージネット分類器を訓練するために線形読み出しを行い、その画像分類器のバイアスを調べました。"
  },
  {
    "start": 3798350,
    "end": 3799206,
    "text": "それ次第だと思う。"
  },
  {
    "start": 3799238,
    "end": 3808000,
    "text": "トレーニングと同じデータ分布で刈り込みをするのであれば、バイアスの心配をしなければならないかもしれないが、そうでない場合は、少なくともこのような限定的な精算条件では心配する必要はない。"
  },
  {
    "start": 3817250,
    "end": 3818158,
    "text": "ありがとう。"
  },
  {
    "start": 3818324,
    "end": 3819566,
    "text": "このことについては少し触れたと思う。"
  },
  {
    "start": 3819598,
    "end": 3828054,
    "text": "パレート包絡線について話したが、もっと聞き逃していたら申し訳ないが、その曲線はデータセットのサイズに応じて最適なカリキュラムを推測することもできるのではないだろうか？"
  },
  {
    "start": 3828252,
    "end": 3832982,
    "text": "可能性としては、そうだね、一発で刈り込みをする戦略を考えていたんだ。"
  },
  {
    "start": 3833116,
    "end": 3840390,
    "text": "少し鍛えては剪定し、少し鍛えては剪定し......といった具合に、いろいろな修正が考えられるだろう。"
  },
  {
    "start": 3841050,
    "end": 3845762,
    "text": "データポイントの難易度に応じて順番に並べることも想像できるだろう。"
  },
  {
    "start": 3845826,
    "end": 3847686,
    "text": "そのようなことは一切探っていない。"
  },
  {
    "start": 3847868,
    "end": 3852702,
    "text": "一発刈りは、基礎データセットという概念につながるからいいよね。"
  },
  {
    "start": 3852756,
    "end": 3856046,
    "text": "この巨大なライオンのデータセットがあり、大勢の人がそれを使ってトレーニングしているようなものだ。"
  },
  {
    "start": 3856148,
    "end": 3863840,
    "text": "もし、データセット全体と同程度に優れたサブセットを1つ見つけることができれば、それを基礎データセットとして配布し、代わりにみんながそれを使ってトレーニングすればいい。"
  },
  {
    "start": 3864230,
    "end": 3870660,
    "text": "カリキュラム学習や能動学習などのハイパーパラメーターを最適化する必要はない。"
  },
  {
    "start": 3873110,
    "end": 3881522,
    "text": "私にとって少し不明なのは、この刈り込みテクニックが本当にタスクの識別性に基づいているのかということだ。"
  },
  {
    "start": 3881586,
    "end": 3888600,
    "text": "もしジェネレーティブなタスクがあったとしても、このようなデータの投げ捨てが節約になるかどうかはわからない。"
  },
  {
    "start": 3890330,
    "end": 3894310,
    "text": "最適化の仕事の一部をやっているようなものだと感じている。"
  },
  {
    "start": 3894390,
    "end": 3900566,
    "text": "モデルをある方向に向かわせるために混乱させるのではなく、基本的には、モデルがある方向に速く向かえるようにデータを刈り込むのだ。"
  },
  {
    "start": 3900598,
    "end": 3907386,
    "text": "最適化の際、このテクニックは、分布を複製したい生成タスクに転用できると思いますか？"
  },
  {
    "start": 3907498,
    "end": 3909440,
    "text": "基本的にはそうだ。"
  },
  {
    "start": 3910370,
    "end": 3911566,
    "text": "本当にいい質問だね。"
  },
  {
    "start": 3911668,
    "end": 3916450,
    "text": "生成モデルをトレーニングするためのデータ刈り込みについては、まだ調べていない。"
  },
  {
    "start": 3916870,
    "end": 3918290,
    "text": "私たちはそれを見ていない。"
  },
  {
    "start": 3918360,
    "end": 3919330,
    "text": "分からないよ。"
  },
  {
    "start": 3919480,
    "end": 3921300,
    "text": "オープンな、経験的な質問だ。"
  },
  {
    "start": 3923270,
    "end": 3933080,
    "text": "生成モデルの最終的な入力出力マップを損なわないような、分布に関する特定のデータフィッティング手順を想像することもできるだろう。"
  },
  {
    "start": 3933450,
    "end": 3935254,
    "text": "うまくいく可能性はある。"
  },
  {
    "start": 3935292,
    "end": 3937560,
    "text": "そうなるかどうかは経験的な問題だ。"
  },
  {
    "start": 3938970,
    "end": 3943000,
    "text": "スーリヤにもう一度お礼を言い、直行しよう。"
  },
  {
    "start": 3947770,
    "end": 3950540,
    "text": "15分後にまたここで会おう。"
  }
]