[
  {
    "start": 170,
    "end": 5470,
    "text": "さて、このビデオでは引き続きマルチドック・レトリバーについて見ていこう。"
  },
  {
    "start": 5810,
    "end": 11150,
    "text": "ベクター・ストアのデータベースには、Chromadbを使うつもりだ。"
  },
  {
    "start": 11300,
    "end": 17802,
    "text": "今回追加する大きなポイントは、実際にローカルで動作するエンベッディングを追加することだ。"
  },
  {
    "start": 17946,
    "end": 22910,
    "text": "これを行うには、まずGPUが必要か、GPUが動いているのが理想的だ。"
  },
  {
    "start": 22980,
    "end": 28994,
    "text": "超強力なGPUを使わなくても、CPUでこれを動かすことができる。"
  },
  {
    "start": 29042,
    "end": 32998,
    "text": "ただ、これにはもう少し時間がかかりそうだ。"
  },
  {
    "start": 33164,
    "end": 36038,
    "text": "私が同じものを持ち込んでいることがわかるだろう。"
  },
  {
    "start": 36124,
    "end": 39774,
    "text": "実はもう必要ないんだ。"
  },
  {
    "start": 39922,
    "end": 41162,
    "text": "新しい2人のようなものだ。"
  },
  {
    "start": 41216,
    "end": 49914,
    "text": "インストラクターのエンベッディング（埋め込み）については後で説明する。"
  },
  {
    "start": 50032,
    "end": 55946,
    "text": "もうひとつの違いは、多くの人がPDfファイルや複数のPDfファイルについて質問していることだ。"
  },
  {
    "start": 56058,
    "end": 61918,
    "text": "ここで複数のPDFファイルを扱うためにテキストファイルを入れ替えた。"
  },
  {
    "start": 62084,
    "end": 68770,
    "text": "実際、ここを見てもらえばわかると思うが、私がやったのはいくつかの書類を入れただけだ。"
  },
  {
    "start": 69190,
    "end": 81954,
    "text": "これらは、リアクト・ツールに関するアーカイブからのいくつかの論文で、かつてのフラッシュ・アテンション・アリビと呼ばれるものです。"
  },
  {
    "start": 82082,
    "end": 84358,
    "text": "分割とかは全部同じ。"
  },
  {
    "start": 84444,
    "end": 92362,
    "text": "この場合、シンプルなpy PDFローダーを使っています。"
  },
  {
    "start": 92496,
    "end": 96214,
    "text": "次に重要なのは、エンベッディングにたどり着くことだ。"
  },
  {
    "start": 96262,
    "end": 98650,
    "text": "埋め込みには2つの方法がある。"
  },
  {
    "start": 99150,
    "end": 102634,
    "text": "通常の抱きつき顔の埋め込みだけでいい。"
  },
  {
    "start": 102762,
    "end": 109662,
    "text": "これはセンテンス・トランスのようなものを使ったもので、その周辺にはさまざまなモデルがある。"
  },
  {
    "start": 109796,
    "end": 111758,
    "text": "その品質はさまざまだ。"
  },
  {
    "start": 111924,
    "end": 116900,
    "text": "どれがこれにマッチするかは、あなたのデータにもよる。"
  },
  {
    "start": 117270,
    "end": 122034,
    "text": "標準的なセンテンス・トランスを使用する例としては、このようなものがある。"
  },
  {
    "start": 122152,
    "end": 126498,
    "text": "これは、以前はトップモデルのひとつだった。"
  },
  {
    "start": 126584,
    "end": 131174,
    "text": "私のテストでは、より良い結果を出していると思われる新しいモデルに出会った。"
  },
  {
    "start": 131292,
    "end": 132950,
    "text": "それで行こうと決めたんだ。"
  },
  {
    "start": 133020,
    "end": 136722,
    "text": "私が使っている新しいモデルは、インストラクターのエンベッディングだ。"
  },
  {
    "start": 136866,
    "end": 144346,
    "text": "私は、このような人たちは、論文やそのようなものを説明するために、1本のビデオに値すると思う。"
  },
  {
    "start": 144448,
    "end": 151454,
    "text": "この考え方は、あなたが何に使うかによって、これらはカスタム埋め込みであるということです。"
  },
  {
    "start": 151572,
    "end": 158142,
    "text": "この場合は、インストラクションのエンベッディングを使うだけで、これのエクセル版を使う。"
  },
  {
    "start": 158196,
    "end": 161230,
    "text": "これらを基本的にラングチェーンに持ち込む。"
  },
  {
    "start": 162210,
    "end": 164746,
    "text": "ローカルで実行しようとしているのがわかるだろう。"
  },
  {
    "start": 164778,
    "end": 168546,
    "text": "モデルをダウンロードし、このためのすべてのファイルをダウンロードしている。"
  },
  {
    "start": 168648,
    "end": 172430,
    "text": "ここでは実際に、GPUに搭載することを伝えている。"
  },
  {
    "start": 172510,
    "end": 175314,
    "text": "これがCuDaという装置である。"
  },
  {
    "start": 175432,
    "end": 179506,
    "text": "ローカルで走らせたいなら、そのためのデバイスCPUを搭載すればいい。"
  },
  {
    "start": 179528,
    "end": 181330,
    "text": "間違いなく、もっと遅くなるだろうね。"
  },
  {
    "start": 181490,
    "end": 184950,
    "text": "基本的には、これを積んで持ち込むんだ。"
  },
  {
    "start": 185020,
    "end": 193094,
    "text": "デフォルトでは、これらは512のシーケンス長で動作している。"
  },
  {
    "start": 193142,
    "end": 195340,
    "text": "この場合はそれでいいだろう。"
  },
  {
    "start": 195950,
    "end": 201850,
    "text": "エンベッディングをセットアップしたら、次はベクターストアを作る必要がある。"
  },
  {
    "start": 201920,
    "end": 204622,
    "text": "これはすべて、前回のビデオとまったく同じだ。"
  },
  {
    "start": 204676,
    "end": 208094,
    "text": "ここでは基本的に、新しいエンベッディングを渡すだけだ。"
  },
  {
    "start": 208212,
    "end": 211114,
    "text": "OpenAIのエンベッディングはもう使わない。"
  },
  {
    "start": 211242,
    "end": 217570,
    "text": "さて、エンベッディングの設定ができたら、あとは基本的に今までと同じようにやっていこう。"
  },
  {
    "start": 217640,
    "end": 219554,
    "text": "ベクターストアをセットアップする必要がある。"
  },
  {
    "start": 219672,
    "end": 223266,
    "text": "ここでは、ベクターストアの設定にchromodbを使っている。"
  },
  {
    "start": 223448,
    "end": 225358,
    "text": "我々はディレクトリを保持する。"
  },
  {
    "start": 225534,
    "end": 228306,
    "text": "ドキュメントから作成する必要がありそうだ。"
  },
  {
    "start": 228418,
    "end": 236806,
    "text": "インストラクターのエンベッディングを渡し、そこからすでに取り出したドキュメント・テキストを渡す。"
  },
  {
    "start": 236908,
    "end": 239302,
    "text": "これは前のビデオとまったく同じだ。"
  },
  {
    "start": 239356,
    "end": 240394,
    "text": "私たちは何も変えていない。"
  },
  {
    "start": 240432,
    "end": 245146,
    "text": "今やっているのは、このインストラクターの埋め込みを使うことだけだ。"
  },
  {
    "start": 245248,
    "end": 250118,
    "text": "レトリーバーを作るのと同じようなことが基本的にできるようになった。"
  },
  {
    "start": 250294,
    "end": 255630,
    "text": "今、このレトリーバーは、明らかに私たちの新しいエンベッディングを使っている。"
  },
  {
    "start": 255700,
    "end": 265118,
    "text": "今、レトリーバーは新しい埋め込み、つまりインストラクターの埋め込みを使って、ここにあるクエリに基づいて実際にマッチするさまざまなコンテキストを見つけようとしている。"
  },
  {
    "start": 265204,
    "end": 267166,
    "text": "次は、基本的にチェーンを作る必要がある。"
  },
  {
    "start": 267278,
    "end": 269538,
    "text": "これもまた以前と同じである。"
  },
  {
    "start": 269624,
    "end": 271042,
    "text": "特に変わったところはない。"
  },
  {
    "start": 271096,
    "end": 285046,
    "text": "ベクターストアやエンベッディングを処理するリトリーバーを渡している。"
  },
  {
    "start": 285228,
    "end": 291126,
    "text": "フラッシュ・アテンションとは何か？"
  },
  {
    "start": 291238,
    "end": 294342,
    "text": "3つのトップ文書を取りに行くんだ。"
  },
  {
    "start": 294406,
    "end": 308654,
    "text": "この場合、驚くことではないが、エンベッディングが私たちが知りたいことに最も近い類似文書として選んだのは、このフラッシュ・アテンション・ペーパーか、このPDFになる。"
  },
  {
    "start": 308772,
    "end": 312074,
    "text": "つまり、基本的にフラッシュ・アテンションの定義を返してくれるのだ。"
  },
  {
    "start": 312202,
    "end": 314586,
    "text": "そして、そのさまざまな部分について尋ねることができる。"
  },
  {
    "start": 314628,
    "end": 316558,
    "text": "ここにIOのことが書かれている。"
  },
  {
    "start": 316654,
    "end": 318914,
    "text": "それは何ですか？"
  },
  {
    "start": 319032,
    "end": 328546,
    "text": "基本的には、同じ論文に記載されているタイリングを調べて、その答えを見つけることができる。"
  },
  {
    "start": 328648,
    "end": 334134,
    "text": "じゃあ、他の質問もしてみよう。"
  },
  {
    "start": 334332,
    "end": 341754,
    "text": "前者のツールとは何かを問うことで、基本的に同じものを返せるかどうかを見極めることができる。"
  },
  {
    "start": 341792,
    "end": 342762,
    "text": "どうなるんだ？"
  },
  {
    "start": 342896,
    "end": 349242,
    "text": "案の定、自己教師ありの方法で学習する言語モデルというツールを手に入れた。"
  },
  {
    "start": 349376,
    "end": 358570,
    "text": "つまり、これは基本的に、ツールフォームから出力された3つの例、つまり3つの異なるコンテキストからの出力の書き換えを示しているだけなのだ。"
  },
  {
    "start": 358730,
    "end": 361614,
    "text": "私たちは基本的に、それについてもう少し質問することができる。"
  },
  {
    "start": 361652,
    "end": 363722,
    "text": "toolformaで使えるツールは？"
  },
  {
    "start": 363786,
    "end": 372354,
    "text": "検索エンジン、計算機、翻訳システムを簡単なAPIコールで使用することができ、さらにさまざまな例やものを求めることもできる。"
  },
  {
    "start": 372392,
    "end": 381686,
    "text": "論文をざっと読んで、具体的な質問をしたい場合、この方法からいくつかのことを得ることができる。"
  },
  {
    "start": 381868,
    "end": 390562,
    "text": "この質問をすると、LLMSの補強論文からその答えを得ているのが興味深い。"
  },
  {
    "start": 390626,
    "end": 397354,
    "text": "また、これは実は調査論文なので、ツール元に関することも含まれている。"
  },
  {
    "start": 397472,
    "end": 410410,
    "text": "基本的には、調査論文、ツール元論文、そしてもうひとつは調査論文にあったもので、検索補強に関する質問をすると、上位3つのコンテキストを決定する。"
  },
  {
    "start": 410570,
    "end": 415870,
    "text": "さて、この件に関連する論文は、LLM調査の補強版にしかない。"
  },
  {
    "start": 416030,
    "end": 418322,
    "text": "案の定、そのいくつかを手に入れることができた。"
  },
  {
    "start": 418376,
    "end": 426738,
    "text": "レアルモデルとボロモデルの違いについて具体的に尋ねると、このようなことを教えてくれる。"
  },
  {
    "start": 426904,
    "end": 440422,
    "text": "ここでのアイデアは、実際の言語モデル部分にはまだOpenAIを使用しているということです。次回のビデオでは、OpenAIを取り除き、完全にローカルですべてを実行する方法を試して見ます。"
  },
  {
    "start": 440566,
    "end": 447782,
    "text": "現在、エンベッダーを実際に使用するために、エンベッダーシステムを使用しています。"
  },
  {
    "start": 447846,
    "end": 449482,
    "text": "このためにOpenAIを使っているわけではない。"
  },
  {
    "start": 449536,
    "end": 458554,
    "text": "この大きな利点は、データがOpenAIの大規模言語モデルまで行く必要がないことだ。"
  },
  {
    "start": 458682,
    "end": 464138,
    "text": "今、明らかに出てくるコンテクストはまだOpenAIに上がっている。"
  },
  {
    "start": 464314,
    "end": 472514,
    "text": "しかし、エンベッディングを行うために、一度にすべてのデータをアップする必要がある。"
  },
  {
    "start": 472632,
    "end": 479234,
    "text": "重要なのは、エンベッディングを一発で行うため、すべてのデータをアップするだけではないということだ。"
  },
  {
    "start": 479282,
    "end": 483222,
    "text": "こうすることでプライバシーが少し守られる。"
  },
  {
    "start": 483356,
    "end": 489526,
    "text": "もちろん、基本的にデータをサーバーに触れないようにしたいのであれば、これはまだ理想的ではない。"
  },
  {
    "start": 489638,
    "end": 500378,
    "text": "次のビデオでは、実際の言語モデルを使って、返信の部分と埋め込み部分を見てみましょう。"
  },
  {
    "start": 500544,
    "end": 507966,
    "text": "あとは、Chroma DBのデータベースを削除して、また戻すだけです。"
  },
  {
    "start": 508068,
    "end": 509662,
    "text": "以前見たのと同じだ。"
  },
  {
    "start": 509716,
    "end": 516094,
    "text": "OpenAI GPT 3.5ターボだけを試したい場合は、こちらをご覧ください。"
  },
  {
    "start": 516292,
    "end": 518186,
    "text": "このノートはこれで終わり。"
  },
  {
    "start": 518378,
    "end": 522862,
    "text": "いつものように、質問があれば下のコメント欄に書き込んでください。"
  },
  {
    "start": 522996,
    "end": 525938,
    "text": "この記事がお役に立ちましたら、「いいね！」をクリックしてください。"
  },
  {
    "start": 526114,
    "end": 532920,
    "text": "次回のビデオでは、このためにあらゆるものにカスタムモデルを使うことについて見ていく。"
  },
  {
    "start": 533290,
    "end": 535190,
    "text": "オーケー、次のビデオで話そう。"
  },
  {
    "start": 535260,
    "end": 535860,
    "text": "とりあえず、さようなら。"
  }
]