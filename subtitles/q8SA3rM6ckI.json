[
  {
    "start": 90,
    "end": 798,
    "text": "皆さん、こんにちは。"
  },
  {
    "start": 964,
    "end": 4906,
    "text": "今日、我々は再びメイクモアの導入を継続する。"
  },
  {
    "start": 5098,
    "end": 13178,
    "text": "さて、ここまではマルチリオセプトロンで、ニューラルネットはこんな感じでした。"
  },
  {
    "start": 13354,
    "end": 22510,
    "text": "さて、皆さんはニューラル・ネットワークやその亜種、そしてそれらがどのように機能するのか、そしてその図はクールで、とてもエキサイティングで興味深く、より良い結果を得ることができるのではないかと、とてもワクワクしていることだろう。"
  },
  {
    "start": 22660,
    "end": 25986,
    "text": "残念ながら、もう1回だけここで講義を受けなければならないと思う。"
  },
  {
    "start": 26178,
    "end": 36326,
    "text": "その理由は、我々はすでにこのモタリオ・パーセプトロンを訓練しており、かなり良い損失が得られているからだ。"
  },
  {
    "start": 36508,
    "end": 41222,
    "text": "私が問題にしているのは、このコードの行が後方に失われていることだ。"
  },
  {
    "start": 41366,
    "end": 47626,
    "text": "つまり、我々はPytorch autogradを使い、その過程ですべてのグラデーションを計算しているのだ。"
  },
  {
    "start": 47728,
    "end": 54466,
    "text": "ロスト・バックワードの使用はやめて、テンソルのレベルでバックワードパスを手動で書いてほしい。"
  },
  {
    "start": 54598,
    "end": 58538,
    "text": "私は、この練習は次のような理由から非常に有効だと思う。"
  },
  {
    "start": 58714,
    "end": 65258,
    "text": "実はこのトピックについてはブログ記事全体を持っているのだが、私はバックプロパゲーションをリーキー・アブストラクションと呼びたい。"
  },
  {
    "start": 65434,
    "end": 71086,
    "text": "つまり、バックプロパゲーションは、ニューラルネットワークを魔法のように機能させるだけではないということだ。"
  },
  {
    "start": 71198,
    "end": 78260,
    "text": "微分可能な関数の任意のレゴブロックを積み上げて、指をくわえて逆伝播すればすべてがうまくいく、というわけではない。"
  },
  {
    "start": 78810,
    "end": 80642,
    "text": "物事は自動的に動くものではない。"
  },
  {
    "start": 80786,
    "end": 97020,
    "text": "その内部を理解していないと、魔法のように機能しなかったり、最適に機能しなかったりする。デバッグを望むのであれば、またニューラルネットでそれに対処しようと望むのであれば、その内部でどのように機能するかを理解する必要がある。"
  },
  {
    "start": 97630,
    "end": 101990,
    "text": "少し前のブログ記事だが、そのような例をいくつか紹介している。"
  },
  {
    "start": 102070,
    "end": 104926,
    "text": "例えば、すでに取材したものもある。"
  },
  {
    "start": 105028,
    "end": 113098,
    "text": "例えば、これらの関数の平坦なテールや、グラデーションが死んでしまうので飽和させすぎないようにする方法などだ。"
  },
  {
    "start": 113194,
    "end": 122180,
    "text": "死んだニューロンのケースはすでに説明したとおりだし、リカレント・ニューラル・ネットワークの場合は、勾配が爆発したり消えたりするケースだ。"
  },
  {
    "start": 122870,
    "end": 127326,
    "text": "そして、野生の例にもしばしば出くわすだろう。"
  },
  {
    "start": 127518,
    "end": 136146,
    "text": "これは、私がインターネット上のランダムなコードベースで見つけたスニペットで、彼らの実装には非常に微妙だがかなり大きなバグがある。"
  },
  {
    "start": 136258,
    "end": 141586,
    "text": "このバグは、このコードの作者がバックプロパゲーションを理解していないことを示している。"
  },
  {
    "start": 141698,
    "end": 153102,
    "text": "ここで彼らがやろうとしていることは、損失をある最大値で切り取ろうとしていることだが、実際には、損失を最大値で切り取るのではなく、グラデーションが最大値を持つように切り取ろうとしているのだ。"
  },
  {
    "start": 153236,
    "end": 164654,
    "text": "というのも、外れ値の損失をクリップすると、その勾配をゼロに設定することになるからだ。"
  },
  {
    "start": 164852,
    "end": 168106,
    "text": "だから、これに目を通して読んでみてほしい。"
  },
  {
    "start": 168228,
    "end": 172306,
    "text": "基本的に、自分が何をしているのか分かっていれば避けられる微妙な問題がたくさんある。"
  },
  {
    "start": 172408,
    "end": 179800,
    "text": "だから、Pytorchや他のフレームワークがautogradを提供しているから、その仕組みを無視してもいいということにはならないと思う。"
  },
  {
    "start": 180570,
    "end": 189122,
    "text": "さて、オートグラッドについてはすでに説明したし、マイクログラッドについても書いたが、マイクログラッドは個々のスカラーのレベルでのみのオートグラッド・エンジンだった。"
  },
  {
    "start": 189186,
    "end": 191734,
    "text": "原子は単一の個体数である。"
  },
  {
    "start": 191932,
    "end": 193914,
    "text": "十分だとは思わない。"
  },
  {
    "start": 193952,
    "end": 197674,
    "text": "基本的にはテンソルのレベルでのバックプロパゲーションも考えてほしい。"
  },
  {
    "start": 197792,
    "end": 200214,
    "text": "まとめると、いい練習になったと思う。"
  },
  {
    "start": 200342,
    "end": 202550,
    "text": "とても貴重なものだと思う。"
  },
  {
    "start": 202630,
    "end": 207934,
    "text": "ニューラルネットワークのデバッグがうまくなり、自分のやっていることを理解できるようになる。"
  },
  {
    "start": 208052,
    "end": 212734,
    "text": "すべてを完全に明示してくれるので、何が隠されているのか神経質になることはない。"
  },
  {
    "start": 212852,
    "end": 215802,
    "text": "基本的に、我々はより強くなる。"
  },
  {
    "start": 215946,
    "end": 217666,
    "text": "では、本題に入ろう。"
  },
  {
    "start": 217768,
    "end": 226622,
    "text": "ちょっと面白い歴史的メモとして、今日、手書きでバックワードパスを書くことは推奨されておらず、練習目的以外では誰もやらない。"
  },
  {
    "start": 226766,
    "end": 231234,
    "text": "10年ほど前、ディープラーニングの分野では、これはかなり標準的なことであり、実際に普及していた。"
  },
  {
    "start": 231362,
    "end": 237702,
    "text": "当時は、私を含め、誰もが自分のバックワードパスを手作業で書いていた。"
  },
  {
    "start": 237836,
    "end": 242310,
    "text": "以前はバックワードパスを手書きしていたが、今はみんなロフタをバックワードと呼んでいる。"
  },
  {
    "start": 242470,
    "end": 243738,
    "text": "私たちは何かを失った。"
  },
  {
    "start": 243904,
    "end": 246634,
    "text": "その例をいくつか挙げたい。"
  },
  {
    "start": 246752,
    "end": 254654,
    "text": "これは2006年にジェフ・ヒントンとラッセル・スラクステンドフが科学誌に発表した論文で、当時大きな反響を呼んだ。"
  },
  {
    "start": 254772,
    "end": 259338,
    "text": "これは、制限付きボルトマン・マシンと呼ばれるいくつかのアーキテクチャーを訓練するものだった。"
  },
  {
    "start": 259434,
    "end": 265486,
    "text": "基本的にはオートエンコーダーで、これは2010年のものだ。"
  },
  {
    "start": 265588,
    "end": 271086,
    "text": "私は制限付きボルトマン・マシンをトレーニングするためのライブラリを持っていて、これは当時Matlabで書かれていた。"
  },
  {
    "start": 271118,
    "end": 272962,
    "text": "Pythonはディープラーニングには使われなかった。"
  },
  {
    "start": 273016,
    "end": 274830,
    "text": "浸透しているのは、すべてMatlabだった。"
  },
  {
    "start": 274910,
    "end": 279734,
    "text": "MatLabは誰もが使う科学計算パッケージだった。"
  },
  {
    "start": 279852,
    "end": 288434,
    "text": "Matlabはかろうじてプログラミング言語と言えるが、とても便利なテンソルクラスがあり、この計算環境だった。"
  },
  {
    "start": 288482,
    "end": 295658,
    "text": "もちろん、すべてCPU上で動作するが、それに付随して非常に優れたプロットが用意され、デバッガーも内蔵されている。"
  },
  {
    "start": 295824,
    "end": 306094,
    "text": "さて、2010年に私が書いたこのパッケージのコードは、制限マシンのフィッティングのために書いたもので、ある程度は認識できるが、どのようにフィッティングするのかをお見せしたかった。"
  },
  {
    "start": 306212,
    "end": 308810,
    "text": "私はxyバッチでデータを作成しています。"
  },
  {
    "start": 308890,
    "end": 313646,
    "text": "ニューラルネットを初期化しているので、重みとバイアスがある。"
  },
  {
    "start": 313748,
    "end": 317522,
    "text": "これがトレーニングループで、実際にフォワードパスを行う。"
  },
  {
    "start": 317656,
    "end": 322430,
    "text": "当時は、ニューラルネットワークの訓練にバックプロパゲーションを使う必要はなかった。"
  },
  {
    "start": 322510,
    "end": 328274,
    "text": "これは特に、勾配を推定するコントラスト発散を実装している。"
  },
  {
    "start": 328402,
    "end": 333720,
    "text": "そしてここでは、そのグラデーションを用いて、パラメータを更新する。"
  },
  {
    "start": 336570,
    "end": 341418,
    "text": "基本的に、人々はこれらのグラデーションを直接、インラインで、そして自分自身でいじくりまわしていたことがわかるだろう。"
  },
  {
    "start": 341584,
    "end": 343802,
    "text": "オートグラッド・エンジンを使うのはそれほど一般的ではなかった。"
  },
  {
    "start": 343936,
    "end": 349670,
    "text": "2014年の私の論文から、フラグメント埋め込みと呼ばれる例をもう一つ紹介しよう。"
  },
  {
    "start": 349830,
    "end": 352940,
    "text": "ここで私がやっていたのは、画像とテキストの位置合わせだ。"
  },
  {
    "start": 353470,
    "end": 356110,
    "text": "クリップのようなものだ。"
  },
  {
    "start": 356180,
    "end": 362986,
    "text": "画像全体や文章全体というレベルではなく、個々のオブジェクトや文章の断片というレベルで作業していたのだ。"
  },
  {
    "start": 363098,
    "end": 366974,
    "text": "私はそれらを埋め込んで、クリップのような損失を計算していた。"
  },
  {
    "start": 367102,
    "end": 374050,
    "text": "私は2014年にこれを実装したコードを掘り起こしたが、それはすでにnumpyとPythonで書かれていた。"
  },
  {
    "start": 374470,
    "end": 381698,
    "text": "ここではコスト関数を実装しているが、コストだけでなくバックワードパスも手動で実装するのが標準だった。"
  },
  {
    "start": 381874,
    "end": 386840,
    "text": "ここでは、画像埋め込み、文埋め込み、損失関数を計算している。"
  },
  {
    "start": 387530,
    "end": 388930,
    "text": "私は得点を計算する。"
  },
  {
    "start": 389010,
    "end": 390358,
    "text": "これが損失関数である。"
  },
  {
    "start": 390524,
    "end": 393706,
    "text": "損失関数ができたら、ここでバックワードパスを行う。"
  },
  {
    "start": 393808,
    "end": 399050,
    "text": "損失関数とニューラルネットを通して後方へ進み、正則化を加える。"
  },
  {
    "start": 399870,
    "end": 401974,
    "text": "すべて手作業で行われた。"
  },
  {
    "start": 402022,
    "end": 403658,
    "text": "後方へのパスを書き出すだけだ。"
  },
  {
    "start": 403744,
    "end": 410682,
    "text": "その場合、勾配チェッカーを使って、バックプロパゲーション中に計算した勾配の数値推定値と一致することを確認することになる。"
  },
  {
    "start": 410826,
    "end": 415920,
    "text": "しかし今日では、もちろんオートグラッド・エンジンを使うのが普通だ。"
  },
  {
    "start": 416850,
    "end": 421906,
    "text": "ニューラルネットワークがどのように機能するかは、非常に直感的なレベルで理解できたと思う。"
  },
  {
    "start": 422008,
    "end": 425266,
    "text": "だから、これはまたいい練習になると思う。"
  },
  {
    "start": 425368,
    "end": 433478,
    "text": "さて、前回の講義を思い出してほしいのだが、これは当時私たちが実装したJupyterノートブックであり、すべてそのままにするつもりだ。"
  },
  {
    "start": 433564,
    "end": 437698,
    "text": "バッチ正規化層を持つ2層のマルチライン・パーセプトロンを使うことになる。"
  },
  {
    "start": 437794,
    "end": 440770,
    "text": "フォワードパスは基本的にこの講義と同じになる。"
  },
  {
    "start": 440850,
    "end": 445530,
    "text": "ここでは、後方へのロストをなくし、代わりに後方へのパスを手動で書くことにする。"
  },
  {
    "start": 446030,
    "end": 448134,
    "text": "さて、これがこの講義のスターター・コードだ。"
  },
  {
    "start": 448262,
    "end": 451050,
    "text": "私たちはこのノートでバックドロップ忍者になりつつある。"
  },
  {
    "start": 451550,
    "end": 455470,
    "text": "ここでの最初の数セルは、我々が慣れ親しんでいるものと同じだ。"
  },
  {
    "start": 455540,
    "end": 459710,
    "text": "インポートを行い、データセットをロードし、データセットを処理する。"
  },
  {
    "start": 459780,
    "end": 460990,
    "text": "どれも変わらなかった。"
  },
  {
    "start": 461490,
    "end": 465994,
    "text": "ここで、後でグラデーションを比較するために使うユーティリティ関数を紹介する。"
  },
  {
    "start": 466122,
    "end": 477140,
    "text": "もちろん、Pytorchが正しいと仮定してのことだが。"
  },
  {
    "start": 478730,
    "end": 481638,
    "text": "そして、ここで私たちが慣れ親しんでいる初期化を行う。"
  },
  {
    "start": 481724,
    "end": 488118,
    "text": "文字用の埋め込みテーブル、第一レイヤー、第二レイヤー、そしてその間のbash正規化がある。"
  },
  {
    "start": 488284,
    "end": 490498,
    "text": "ここですべてのパラメーターを作成する。"
  },
  {
    "start": 490674,
    "end": 495194,
    "text": "さて、初期化を少し変えて小さな数字にしたことにお気づきだろうか。"
  },
  {
    "start": 495312,
    "end": 497898,
    "text": "通常、バイアスはすべてゼロに設定される。"
  },
  {
    "start": 497984,
    "end": 500522,
    "text": "ここでは小さな乱数に設定している。"
  },
  {
    "start": 500656,
    "end": 516738,
    "text": "というのも、変数が正確にゼロに初期化されると、グラデーションの実装が正しくなくなることがあるからだ。"
  },
  {
    "start": 516824,
    "end": 522610,
    "text": "だから、小さな数字にすることで、この計算における潜在的なエラーを覆い隠そうとしているんだ。"
  },
  {
    "start": 523110,
    "end": 526926,
    "text": "また、最初のレイヤーにB1を使っていることにもお気づきだろう。"
  },
  {
    "start": 526958,
    "end": 530390,
    "text": "バッチ正規化の直後にもかかわらず、バイアスをかけている。"
  },
  {
    "start": 530890,
    "end": 535378,
    "text": "というのも、バイアスは必要ないという話をしたからだ。"
  },
  {
    "start": 535474,
    "end": 544330,
    "text": "このバイアスがスプリアスであっても、正しく計算されていることを確認することができる。"
  },
  {
    "start": 545070,
    "end": 549500,
    "text": "ここでは1つのバッチを計算し、ここではフォワードパスを計算している。"
  },
  {
    "start": 550270,
    "end": 554654,
    "text": "さて、フォワードパスは、我々がここで慣れ親しんでいるものよりも大幅に拡大されていることにお気づきだろう。"
  },
  {
    "start": 554692,
    "end": 557360,
    "text": "前方へのパスはちょうどここにあった。"
  },
  {
    "start": 557890,
    "end": 561466,
    "text": "さて、フォワードパスが長い理由は2つある。"
  },
  {
    "start": 561578,
    "end": 568114,
    "text": "その1、ここではfドットクロスエントロピーを使ったが、ここでは損失関数の明示的な実装を持ち帰った。"
  },
  {
    "start": 568312,
    "end": 573502,
    "text": "その2は、実装を扱いやすい塊に分けたことだ。"
  },
  {
    "start": 573646,
    "end": 578038,
    "text": "フォワードパスでは、途中により多くの中間テンソルがある。"
  },
  {
    "start": 578124,
    "end": 585526,
    "text": "というのも、この逆伝播の勾配を下から上へ計算しようとしているからだ。"
  },
  {
    "start": 585708,
    "end": 597574,
    "text": "例えば、前方パスでロック・プロップス・テンソルがあるように、後方パスでは、ロック・プロップス・テンソルに対するロスの微分を保存するdロック・プロップスがある。"
  },
  {
    "start": 597702,
    "end": 604510,
    "text": "したがって、これらのテンソルのひとつひとつにdを付加し、バックプロパゲーションの過程でそれを計算することになる。"
  },
  {
    "start": 605250,
    "end": 607306,
    "text": "を例にとると、a、b、rawがある。"
  },
  {
    "start": 607338,
    "end": 609978,
    "text": "ここではdbとrawを計算する。"
  },
  {
    "start": 610154,
    "end": 619538,
    "text": "ここでPyTorchに、練習1ではバックワードパスを計算するので、これらの中間値のgradを保持したいと伝えている。"
  },
  {
    "start": 619624,
    "end": 629154,
    "text": "これらのd変数をすべて計算し、上で紹介したCMp関数を使って、Pytorchが教えてくれていることに関して正しいかどうかをチェックする。"
  },
  {
    "start": 629352,
    "end": 634150,
    "text": "これは、このグラフ全体をバックプロパゲートするエクササイズになる。"
  },
  {
    "start": 634650,
    "end": 647642,
    "text": "さて、練習2以下で何が起こるかを手短に予習してもらうために、ここでは損失を完全に分割し、それを構成するすべての小さなアトミックピースを手動で逆伝播した。"
  },
  {
    "start": 647776,
    "end": 660170,
    "text": "その代わりに、数学と紙と鉛筆を使って、ロジットに対するロスの勾配を解析的に導き出す。"
  },
  {
    "start": 660250,
    "end": 670514,
    "text": "一度にすべての小さなチャンクを逆伝播するのではなく、勾配が何であるかを解析的に導き出し、それを実装する。"
  },
  {
    "start": 670712,
    "end": 673774,
    "text": "次に、bashの正規化についてもまったく同じことを行う。"
  },
  {
    "start": 673902,
    "end": 684866,
    "text": "バッシュ・ノルムを小さな構成要素に分割する代わりに、ペンと紙と数学と微積分を使って、バッシュ・ノルム・レイヤーを通してグラデーションを導き出そう。"
  },
  {
    "start": 684978,
    "end": 693130,
    "text": "bashのノーム・レイヤーを経由する後方パスの計算を、すべての小片を個別に後方伝搬するのではなく、より効率的な表現で行おうとしているのだ。"
  },
  {
    "start": 693470,
    "end": 702214,
    "text": "そして演習4では、この2層MLPをトレーニングする完全なコードをまとめます。"
  },
  {
    "start": 702342,
    "end": 707434,
    "text": "基本的には手動でバックドロップを挿入し、後方へのロストを取り除く。"
  },
  {
    "start": 707562,
    "end": 713822,
    "text": "を読めば、基本的に、完全に自分のコードを使っても同じ結果が得られることがわかるだろう。"
  },
  {
    "start": 713956,
    "end": 720318,
    "text": "Pytorchから使っているのは、計算を効率化するためのトーチテンソルだけだ。"
  },
  {
    "start": 720414,
    "end": 725250,
    "text": "そうでなければ、ニューラルネットを前進させたり後退させたりして訓練することの意味を十分に理解できないだろう。"
  },
  {
    "start": 725320,
    "end": 726546,
    "text": "それは素晴らしいことだと思う。"
  },
  {
    "start": 726648,
    "end": 727938,
    "text": "さあ、始めよう。"
  },
  {
    "start": 728104,
    "end": 737986,
    "text": "さて、このノートブックのすべてのセルをここまで走らせたので、これを消去して、dlock probsから始まるバックワードパスの実装を開始します。"
  },
  {
    "start": 738098,
    "end": 744966,
    "text": "ロック・プロップス・テンソルの全要素に対するロスの勾配を計算するために、ここで何をすべきかを理解したい。"
  },
  {
    "start": 745158,
    "end": 757050,
    "text": "さて、ここで答えを明かしてしまうが、教育的に最も役立つと思うことを簡単に書いておくと、実際にこのビデオの説明に入って、このJupyterノートブックへのリンクを見つけてほしい。"
  },
  {
    "start": 757130,
    "end": 760286,
    "text": "どちらもGitHubで見ることができるが、Google Colabでも見ることができる。"
  },
  {
    "start": 760308,
    "end": 761422,
    "text": "何もインストールする必要はない。"
  },
  {
    "start": 761476,
    "end": 768100,
    "text": "Google Colabのウェブサイトにアクセスし、これらの派生物やグラデーションを自分で実装してみることができる。"
  },
  {
    "start": 768470,
    "end": 777362,
    "text": "もし、私のビデオに来て、私がそれをするのを見ることができないのであれば、連動して、まず自分でやってみて、それから私が答えを教えるのを見ることができる。"
  },
  {
    "start": 777496,
    "end": 779078,
    "text": "それがあなたにとって最も価値のあることだと思う。"
  },
  {
    "start": 779084,
    "end": 781170,
    "text": "というのが、この講義の進め方だ。"
  },
  {
    "start": 781330,
    "end": 783602,
    "text": "私たちはDlogの小道具から始めています。"
  },
  {
    "start": 783746,
    "end": 790710,
    "text": "さて、Dlog propsはlog propsのすべての要素に関する損失の導関数を保持する。"
  },
  {
    "start": 791370,
    "end": 796394,
    "text": "丸太の中はどうなっているかというと、これは32×27の形をしている。"
  },
  {
    "start": 796592,
    "end": 805162,
    "text": "Dlog propsも32×27のサイズの配列であるべきなのは、驚くことではないだろう。"
  },
  {
    "start": 805306,
    "end": 808350,
    "text": "これらのサイズは常に等しくなる。"
  },
  {
    "start": 809570,
    "end": 813610,
    "text": "さて、ロックプローブはロスにどう影響するのか？"
  },
  {
    "start": 813770,
    "end": 821650,
    "text": "さて、損失はnとybの範囲とその平均値でインデックスされた負のロックプロブレムである。"
  },
  {
    "start": 821800,
    "end": 830070,
    "text": "念のために言っておくが、YBは基本的にすべての正しいインデックスの配列である。"
  },
  {
    "start": 831610,
    "end": 838040,
    "text": "ここでやっているのは、サイズ32×27のログ・プロップスの配列を取り出すことだ。"
  },
  {
    "start": 839210,
    "end": 847226,
    "text": "そして、各行ごとに8番、14番、15番......とインデックスを抜いていく。"
  },
  {
    "start": 847248,
    "end": 850554,
    "text": "行を下っていくので、nのイテレーター範囲になる。"
  },
  {
    "start": 850672,
    "end": 856106,
    "text": "ということは、このテンソルYBで指定された列のインデックスを常に抜き取ることになる。"
  },
  {
    "start": 856218,
    "end": 859466,
    "text": "0列目では8列目を取っている。"
  },
  {
    "start": 859578,
    "end": 862854,
    "text": "最初の行では、14列目を取っている。"
  },
  {
    "start": 863002,
    "end": 872210,
    "text": "つまり、ロック・プロップスは、シーケンスの正しい次の文字のロック確率をすべて抜き出す。"
  },
  {
    "start": 872630,
    "end": 874114,
    "text": "それがそうだ。"
  },
  {
    "start": 874152,
    "end": 879400,
    "text": "バッチサイズが32なので、この形、つまりサイズはもちろん32だ。"
  },
  {
    "start": 880410,
    "end": 886710,
    "text": "これらの要素が取り除かれ、その平均値とマイナスが損失になる。"
  },
  {
    "start": 887210,
    "end": 894150,
    "text": "微分の数値形式を理解するために、私はいつも簡単な例題を扱うのが好きだ。"
  },
  {
    "start": 894310,
    "end": 900950,
    "text": "ここで起こっているのは、これらの例を抜き出した後、平均を取り、そしてマイナスを取るということだ。"
  },
  {
    "start": 901030,
    "end": 907200,
    "text": "損失は、基本的には、こう書くこともできるが、a＋b＋cのマイナスである。"
  },
  {
    "start": 907810,
    "end": 911342,
    "text": "この3つの数字の平均は、例えばマイナスを3で割ったようなものになる。"
  },
  {
    "start": 911396,
    "end": 913730,
    "text": "これが、3つの数字の平均を求める方法だ。"
  },
  {
    "start": 913800,
    "end": 916754,
    "text": "ABCだが、実際には32の数字がある。"
  },
  {
    "start": 916952,
    "end": 922100,
    "text": "ということは、基本的にはダのようなロスは何なんだ？"
  },
  {
    "start": 922470,
    "end": 933014,
    "text": "この式を数学的に単純化すると、aの3倍をマイナス1、bの3倍をマイナス1＋cの3倍をマイナス1となる。"
  },
  {
    "start": 933132,
    "end": 934802,
    "text": "では、ダの損失とは何か？"
  },
  {
    "start": 934866,
    "end": 936486,
    "text": "マイナス1オーバーだ。"
  },
  {
    "start": 936668,
    "end": 943340,
    "text": "ということは、a、b、cだけでなく、32個の数字があれば、dがdだけ損をすることがわかる。"
  },
  {
    "start": 944270,
    "end": 946618,
    "text": "これらの数字はすべてnを1つ上回ることになる。"
  },
  {
    "start": 946704,
    "end": 952640,
    "text": "より一般的には、nはこの場合のバッチ32のサイズである。"
  },
  {
    "start": 953010,
    "end": 961710,
    "text": "dロックの損失は、これらのすべての場所でn以上の負の1である。"
  },
  {
    "start": 962130,
    "end": 966570,
    "text": "ロック・プロップスは大きな配列だからだ。"
  },
  {
    "start": 966650,
    "end": 974110,
    "text": "ロックのプロップの形は32×27だが、ロスの計算に参加するのは32だけであることがわかる。"
  },
  {
    "start": 974270,
    "end": 980054,
    "text": "ここで摘出されない他のほとんどの要素の派生物は何だろう？"
  },
  {
    "start": 980252,
    "end": 982086,
    "text": "まあ、直感的には彼らの損失はゼロだ。"
  },
  {
    "start": 982188,
    "end": 982694,
    "text": "何だと？"
  },
  {
    "start": 982812,
    "end": 987218,
    "text": "その勾配は直感的にゼロであり、それは彼らが損失に関与していないからである。"
  },
  {
    "start": 987394,
    "end": 991778,
    "text": "このテンソルの中にある数字のほとんどは、損失には影響しない。"
  },
  {
    "start": 991874,
    "end": 1000618,
    "text": "つまり、これらの数字を変えても損失は変わらない。"
  },
  {
    "start": 1000704,
    "end": 1002220,
    "text": "影響はない。"
  },
  {
    "start": 1003250,
    "end": 1005994,
    "text": "このデリバティブを実装する方法がここにある。"
  },
  {
    "start": 1006042,
    "end": 1010238,
    "text": "そして、32×27のトーチゼロから始める。"
  },
  {
    "start": 1010324,
    "end": 1017958,
    "text": "あるいは、数字をハードコードしたくないからこうするのではなく、ロックの小道具のようにトーチゼロにしよう。"
  },
  {
    "start": 1018074,
    "end": 1022130,
    "text": "基本的に、これはまさにロック・プローブの形をしたゼロの配列を作ることになる。"
  },
  {
    "start": 1022550,
    "end": 1028238,
    "text": "とすれば、まさにこれらの位置で、nにわたって負の微分を設定する必要がある。"
  },
  {
    "start": 1028414,
    "end": 1030130,
    "text": "これが私たちにできることだ。"
  },
  {
    "start": 1030280,
    "end": 1041820,
    "text": "同じようにインデックスされたロック・プローブは、ここで導き出されたように、ゼロの上にマイナス1がセットされ、nを割る。"
  },
  {
    "start": 1042430,
    "end": 1049494,
    "text": "さて、これらの推論をすべて消去して、これがデロック・プロップスの派生候補である。"
  },
  {
    "start": 1049622,
    "end": 1052720,
    "text": "最初の行のコメントを解除して、これが正しいかチェックしてみよう。"
  },
  {
    "start": 1054130,
    "end": 1057242,
    "text": "よし、cmpが動いた。"
  },
  {
    "start": 1057306,
    "end": 1059310,
    "text": "CMPに戻ろう。"
  },
  {
    "start": 1059650,
    "end": 1069390,
    "text": "これは、我々が計算した値（dT）が、ピトーチが計算したtグラッドと正確に等しいかどうかを計算しているのだ。"
  },
  {
    "start": 1069550,
    "end": 1073582,
    "text": "であれば、これはすべての要素が正確に等しいことを確認していることになる。"
  },
  {
    "start": 1073726,
    "end": 1079480,
    "text": "というのも、我々はブーリアンテンソルが欲しいのではなく、ブーリアン値が欲しいだけだからだ。"
  },
  {
    "start": 1080010,
    "end": 1088600,
    "text": "もし正確に等しくなくても、浮動小数点の問題でほぼ等しいかもしれないが、非常に近いことを確認する。"
  },
  {
    "start": 1088970,
    "end": 1096300,
    "text": "ここではトーチ・オール・クローズを使っているが、これはちょっと小回りが利く。"
  },
  {
    "start": 1096750,
    "end": 1103630,
    "text": "浮動小数点演算のため、わずかに異なる計算を使えば、わずかに異なる結果を得ることができる。"
  },
  {
    "start": 1103780,
    "end": 1107086,
    "text": "これは、ほぼ近い結果が得られるかどうかをチェックしている。"
  },
  {
    "start": 1107268,
    "end": 1112766,
    "text": "この場合、ここでは最大値、基本的には差が最も大きい値をチェックしている。"
  },
  {
    "start": 1112948,
    "end": 1117154,
    "text": "この2つの絶対値の差は何なのか？"
  },
  {
    "start": 1117272,
    "end": 1123780,
    "text": "というわけで、正確な等式か、近似的な等式か、そして最大の差は何なのかをプリントしている。"
  },
  {
    "start": 1124950,
    "end": 1128930,
    "text": "つまり、ここでは実際に正確な等式が成立していることがわかる。"
  },
  {
    "start": 1129010,
    "end": 1134662,
    "text": "従って、もちろん近似等式も成り立ち、最大差はちょうどゼロとなる。"
  },
  {
    "start": 1134796,
    "end": 1143526,
    "text": "基本的に、我々のdlock propsは、Pytorchがバックプロパゲーションで計算したlockprobs gradと全く同じである。"
  },
  {
    "start": 1143718,
    "end": 1145962,
    "text": "だから、今のところうまくいっているよ。"
  },
  {
    "start": 1146096,
    "end": 1148438,
    "text": "それではバックプロパゲーションを続けよう。"
  },
  {
    "start": 1148614,
    "end": 1152238,
    "text": "logprobsはログを通してprobsに依存している。"
  },
  {
    "start": 1152404,
    "end": 1156800,
    "text": "probsのすべての要素は、要素ごとに対数2が適用されている。"
  },
  {
    "start": 1157570,
    "end": 1161680,
    "text": "ディープ・プローブが必要なら、顕微鏡写真のトレーニングを思い出してほしい。"
  },
  {
    "start": 1162130,
    "end": 1163802,
    "text": "我々はログノードのようなものを持っている。"
  },
  {
    "start": 1163866,
    "end": 1166618,
    "text": "問題を取り込み、ログのプロップを作成する。"
  },
  {
    "start": 1166794,
    "end": 1171150,
    "text": "ディープ・プローブは、その個々の操作の局所微分となる。"
  },
  {
    "start": 1171230,
    "end": 1177310,
    "text": "出力に対する微分損失の対数倍であり、この場合はd log propsである。"
  },
  {
    "start": 1177470,
    "end": 1180094,
    "text": "この操作の局所微分は？"
  },
  {
    "start": 1180222,
    "end": 1188520,
    "text": "さて、私たちは対数を要素ごとに取っているが、ここに来て、アルファがあなたの友達であることから、xの対数のd×dxは、xに対して単純に1であることがよくわかる。"
  },
  {
    "start": 1188890,
    "end": 1191774,
    "text": "したがって、この場合、xは問題である。"
  },
  {
    "start": 1191842,
    "end": 1196134,
    "text": "d×dxはxに対して1であり、これはprobsに対して1である。"
  },
  {
    "start": 1196262,
    "end": 1197718,
    "text": "であれば、これは局所微分である。"
  },
  {
    "start": 1197814,
    "end": 1199962,
    "text": "そのときはチェーンで繋ぐ。"
  },
  {
    "start": 1200096,
    "end": 1203070,
    "text": "これはチェーンルール×dログプロップスである。"
  },
  {
    "start": 1203490,
    "end": 1207134,
    "text": "では、このコメントを外して、セルをそのまま走らせてみよう。"
  },
  {
    "start": 1207252,
    "end": 1212080,
    "text": "ここで計算したpropsの導関数が正確に正しいことがわかる。"
  },
  {
    "start": 1212770,
    "end": 1214740,
    "text": "そこで、この仕組みに注目してほしい。"
  },
  {
    "start": 1215510,
    "end": 1218254,
    "text": "プロップが反転するんだ。"
  },
  {
    "start": 1218302,
    "end": 1220514,
    "text": "そしてここで要素ごとに掛け合わされる。"
  },
  {
    "start": 1220712,
    "end": 1226926,
    "text": "もしあなたの確率が1に非常に近いなら、それはあなたのネットワークが現在キャラクターを正しく予測していることを意味する。"
  },
  {
    "start": 1227038,
    "end": 1231334,
    "text": "そうなると1対1になってしまい、ヴログはスルーされてしまう。"
  },
  {
    "start": 1231532,
    "end": 1234082,
    "text": "確率が誤って割り当てられた場合。"
  },
  {
    "start": 1234146,
    "end": 1245214,
    "text": "もしここで正しいキャラクターが非常に低い確率を得ているのであれば、1.0、それで割ることでこれを押し上げ、さらにドロックの確率を掛ける。"
  },
  {
    "start": 1245282,
    "end": 1253710,
    "text": "基本的に、この線が直感的にやっていることは、現在割り当てられている確率が非常に低い例を取り出して、その勾配を高めているということだ。"
  },
  {
    "start": 1254370,
    "end": 1255918,
    "text": "そういう見方もできる。"
  },
  {
    "start": 1256084,
    "end": 1258670,
    "text": "次はカウントサム・イムFだ。"
  },
  {
    "start": 1259250,
    "end": 1261982,
    "text": "我々はこの派生物を求めている。"
  },
  {
    "start": 1262116,
    "end": 1268206,
    "text": "ちょっと混乱するかもしれないので、ここでちょっと間を置いて、一般的に何が起こっているのかを紹介しよう。"
  },
  {
    "start": 1268318,
    "end": 1270994,
    "text": "ここにはニューラルネットから出てくるロジットがある。"
  },
  {
    "start": 1271032,
    "end": 1277326,
    "text": "私がやっているのは、各行の最大値を求め、数値的な安定性のためにそれを引いているんだ。"
  },
  {
    "start": 1277438,
    "end": 1286134,
    "text": "このようにしないと、ロジットの値が大きすぎる場合、指数化してしまうため、数値的な問題にぶつかるという話をした。"
  },
  {
    "start": 1286332,
    "end": 1288434,
    "text": "これは安全のためだ。"
  },
  {
    "start": 1288562,
    "end": 1294950,
    "text": "数値的には、ここですべての対数のようなものを指数化してカウントを作成する。"
  },
  {
    "start": 1295110,
    "end": 1301434,
    "text": "そして、これらのカウントの合計を取り、すべての確率の合計が1になるように正規化したい。"
  },
  {
    "start": 1301632,
    "end": 1306590,
    "text": "ここで、カウントの合計に1をかける代わりに、負の1のべき乗をかける。"
  },
  {
    "start": 1306660,
    "end": 1308138,
    "text": "数学的には両者は同一である。"
  },
  {
    "start": 1308234,
    "end": 1315610,
    "text": "除算の後方パスのPytorchの実装が何か間違っていて、奇妙な結果を出していることがわかったんだ。"
  },
  {
    "start": 1315700,
    "end": 1318498,
    "text": "スター、スター・ネガティブ・ワンではそうはならない。"
  },
  {
    "start": 1318584,
    "end": 1320386,
    "text": "私は代わりにこの公式を使っている。"
  },
  {
    "start": 1320568,
    "end": 1328834,
    "text": "基本的にここで起こっていることは、ロジットが得られたので、それらをすべて指数化し、カウントを正規化して確率を作成することである。"
  },
  {
    "start": 1328962,
    "end": 1331750,
    "text": "ただ、それは複数のラインで起きていることだ。"
  },
  {
    "start": 1332490,
    "end": 1344250,
    "text": "ここで、バックプロパゲート（逆伝播）をカウント・スミフに、そしてカウントにも行いたい。"
  },
  {
    "start": 1344400,
    "end": 1347850,
    "text": "カウントサムinfは何であるべきか。"
  },
  {
    "start": 1348000,
    "end": 1353114,
    "text": "さて、ここで注意しなければならないのは、形状を精査し、注意しなければならないということだ。"
  },
  {
    "start": 1353242,
    "end": 1360254,
    "text": "カウントの形と、カウントの合計の形は異なる。"
  },
  {
    "start": 1360452,
    "end": 1362990,
    "text": "特に、カウントは32×27である。"
  },
  {
    "start": 1363060,
    "end": 1365938,
    "text": "このカウントサムintは32×1である。"
  },
  {
    "start": 1366104,
    "end": 1381346,
    "text": "つまり、この乗算では、32個の数値からなる列テンソルを水平方向に27回複製して2つのテンソルを整列させ、要素の2倍乗算を行う必要がある。"
  },
  {
    "start": 1381538,
    "end": 1389506,
    "text": "おもちゃの例で言えば、ここでも小道具に過ぎず、消費的な回数がカウントされている。"
  },
  {
    "start": 1389538,
    "end": 1396358,
    "text": "cはaにbを掛けたものだが、aは3×3でbは3×1の列テンソルである。"
  },
  {
    "start": 1396454,
    "end": 1402454,
    "text": "そのため、Pytorchは内部的にbのこの要素を複製し、すべての列にわたってそれを行った。"
  },
  {
    "start": 1402502,
    "end": 1408750,
    "text": "例えば、bの最初の要素であるb,oneは、この掛け算のすべての列にわたってここに複製されることになる。"
  },
  {
    "start": 1409250,
    "end": 1413600,
    "text": "現在、この操作をバックプロパゲートして、いくつかのイムをカウントしようとしている。"
  },
  {
    "start": 1414150,
    "end": 1425022,
    "text": "この導関数を計算するときに重要なのは、これは1つの操作のように見えるが、実際には2つの操作を順番に適用しているということだ。"
  },
  {
    "start": 1425166,
    "end": 1434566,
    "text": "Pytorchが最初に行った処理は、この列テンソルを取り出し、すべての列にわたって基本的に27回複製するというものだ。"
  },
  {
    "start": 1434668,
    "end": 1436706,
    "text": "これが最初のオペレーションで、レプリケーションだ。"
  },
  {
    "start": 1436818,
    "end": 1439234,
    "text": "であれば、2番目の演算は乗算である。"
  },
  {
    "start": 1439362,
    "end": 1442090,
    "text": "まず、掛け算をバックブラウズしてみよう。"
  },
  {
    "start": 1442670,
    "end": 1452870,
    "text": "もしこの2つの配列が同じサイズで、aとbがあり、どちらも3×3だとしたら、掛け算でどのように逆伝播するのだろうか？"
  },
  {
    "start": 1453030,
    "end": 1461230,
    "text": "もしテンソルではなくスカラーだけだとしたら、cがa×bに等しいとすると、bに対するCの微分は何だろう？"
  },
  {
    "start": 1461300,
    "end": 1464346,
    "text": "まあ、それはただの、つまり局所的な派生物だ。"
  },
  {
    "start": 1464538,
    "end": 1479460,
    "text": "この場合、乗算を元に戻し、乗算そのものを逆伝播することで、局所微分となる。"
  },
  {
    "start": 1480150,
    "end": 1484710,
    "text": "これは局所微分であり、連鎖法則dの小道具である。"
  },
  {
    "start": 1486090,
    "end": 1491420,
    "text": "これは微分または勾配であるが、複製されたbに関するものである。"
  },
  {
    "start": 1492030,
    "end": 1495494,
    "text": "レプリケートされたbはなく、bカラムが1つあるだけだ。"
  },
  {
    "start": 1495622,
    "end": 1498810,
    "text": "レプリケーションをどのようにバックプロパゲートするか？"
  },
  {
    "start": 1499310,
    "end": 1504686,
    "text": "直感的には、このbは同じ変数であり、何度も再利用されているだけである。"
  },
  {
    "start": 1504868,
    "end": 1510778,
    "text": "だから、マイクログラッドで遭遇したケースと同等と見ることができる。"
  },
  {
    "start": 1510954,
    "end": 1514366,
    "text": "というわけで、マイクログラッドで使ったグラフを適当に抜き出してみた。"
  },
  {
    "start": 1514478,
    "end": 1523378,
    "text": "ひとつのノードの出力が、最後の関数まで、基本的にグラフの2つの分岐に供給される例があった。"
  },
  {
    "start": 1523544,
    "end": 1530594,
    "text": "バックワードパスで行うべき正しいことは、どのノードに到着したグラジエントも合計する必要があるという話だ。"
  },
  {
    "start": 1530722,
    "end": 1534070,
    "text": "これらの異なる枝にまたがって、勾配は合計される。"
  },
  {
    "start": 1534650,
    "end": 1540970,
    "text": "ノードが複数回使用される場合、バックプロパゲーションの間に、そのノードのすべての使用に対する勾配が合計される。"
  },
  {
    "start": 1541390,
    "end": 1544662,
    "text": "ここでは、これらの列のすべてでb oneが複数回使われている。"
  },
  {
    "start": 1544726,
    "end": 1550886,
    "text": "したがって、ここで行うべき正しいことは、すべての行を横方向に合計することである。"
  },
  {
    "start": 1550998,
    "end": 1561610,
    "text": "次元で合計したいが、カウント、合計、intとその勾配がまったく同じ形になるように、この次元を保持したい。"
  },
  {
    "start": 1561690,
    "end": 1566382,
    "text": "私たちは、この次元を失わないために、それらを真実として維持することを確認したい。"
  },
  {
    "start": 1566526,
    "end": 1570740,
    "text": "これにより、カウントの合計が1つずつ正確に32の形になる。"
  },
  {
    "start": 1571430,
    "end": 1577880,
    "text": "この比較も明らかにして実行すると、完全に一致することがわかる。"
  },
  {
    "start": 1578250,
    "end": 1580840,
    "text": "このデリバティブはまさに正しい。"
  },
  {
    "start": 1582090,
    "end": 1585110,
    "text": "これを消させてください。"
  },
  {
    "start": 1585260,
    "end": 1592634,
    "text": "ここで、countsにもバックプロパゲートしてみよう。countsは、propsを作成するためのもうひとつの変数である。"
  },
  {
    "start": 1592672,
    "end": 1593354,
    "text": "それをやっただけだ。"
  },
  {
    "start": 1593392,
    "end": 1595114,
    "text": "カウントにも入ってみよう。"
  },
  {
    "start": 1595312,
    "end": 1603902,
    "text": "decountsはdecouncesがaなので、DC by DAはbに過ぎない。"
  },
  {
    "start": 1604036,
    "end": 1606110,
    "text": "従って、それはカウント・サミフである。"
  },
  {
    "start": 1607490,
    "end": 1610510,
    "text": "回チェーンルールdprbs。"
  },
  {
    "start": 1611250,
    "end": 1613938,
    "text": "さて、Sumivのカウントは1つ増えて32。"
  },
  {
    "start": 1614104,
    "end": 1617220,
    "text": "DPRbsは32×27。"
  },
  {
    "start": 1617910,
    "end": 1623518,
    "text": "これらの放送は問題なく放送されるし、カウントを減らしてくれるだろう。"
  },
  {
    "start": 1623614,
    "end": 1626260,
    "text": "ここでの補足説明は必要ない。"
  },
  {
    "start": 1626970,
    "end": 1636002,
    "text": "dpropsを正しく乗算するためには、カウントSumimpを再び複製する必要があるからだ。"
  },
  {
    "start": 1636146,
    "end": 1638040,
    "text": "それが正しい結果をもたらすだろう。"
  },
  {
    "start": 1638570,
    "end": 1641538,
    "text": "この単独作戦に関する限り。"
  },
  {
    "start": 1641714,
    "end": 1648502,
    "text": "プロップスからカウントにバックプロップしたが、実際にはカウントの微分をチェックすることはできない。"
  },
  {
    "start": 1648646,
    "end": 1650138,
    "text": "私はもっと後に持っている。"
  },
  {
    "start": 1650224,
    "end": 1654506,
    "text": "その理由は、count sum intがカウント数に依存するからである。"
  },
  {
    "start": 1654618,
    "end": 1659930,
    "text": "カウント・サムintがカウント・サムに逆伝播するので、ここで2つ目の分岐を終わらせなければならない。"
  },
  {
    "start": 1660010,
    "end": 1662218,
    "text": "count sumはcountsにバックプロパゲートする。"
  },
  {
    "start": 1662314,
    "end": 1665338,
    "text": "だから、カウントは2回使われているノードである。"
  },
  {
    "start": 1665434,
    "end": 1667134,
    "text": "ここで小道具に使われているんだ。"
  },
  {
    "start": 1667182,
    "end": 1669970,
    "text": "それはスミフ伯爵を経由して、この別の支店を経由する。"
  },
  {
    "start": 1670310,
    "end": 1676580,
    "text": "最初の貢献度を計算したとしても、2番目の貢献度は後で計算しなければならない。"
  },
  {
    "start": 1676950,
    "end": 1679026,
    "text": "オーケー、ではこのブランチを続けることにしよう。"
  },
  {
    "start": 1679138,
    "end": 1681010,
    "text": "私たちは、カウント・スミフの導関数を持っている。"
  },
  {
    "start": 1681090,
    "end": 1683202,
    "text": "今度は、その和の微分を求める。"
  },
  {
    "start": 1683346,
    "end": 1687554,
    "text": "dカウントの合計は、この操作の局所導関数に等しい。"
  },
  {
    "start": 1687682,
    "end": 1691666,
    "text": "これは基本的に、要素ごとに1つの総和を数えるものである。"
  },
  {
    "start": 1691858,
    "end": 1696230,
    "text": "カウントの合計を負の1乗することは、カウントの合計を1乗することと同じである。"
  },
  {
    "start": 1696310,
    "end": 1704862,
    "text": "ウルフラム・アルファを見ると、xのマイナス1d×d×dxは、基本的にマイナスxのマイナス2ですよね？"
  },
  {
    "start": 1704916,
    "end": 1708720,
    "text": "sの2乗に対して負の1乗は、負の2乗に対して負のxと同じである。"
  },
  {
    "start": 1709170,
    "end": 1719026,
    "text": "ここでのdカウントの合計は局所微分となり、負カウントの合計は負2になる。"
  },
  {
    "start": 1719128,
    "end": 1724820,
    "text": "これは局所微分×連鎖法則であり、dカウント和intである。"
  },
  {
    "start": 1726630,
    "end": 1728550,
    "text": "それがDカウントの合計だ。"
  },
  {
    "start": 1729210,
    "end": 1732118,
    "text": "コメントアウトを解除して、私が正しいことを確認しよう。"
  },
  {
    "start": 1732284,
    "end": 1740326,
    "text": "さて、これで完全に等しくなり、どの形にも大雑把さはなくなった。"
  },
  {
    "start": 1740438,
    "end": 1743450,
    "text": "さて、次はこのラインをバックプロパゲートしたい。"
  },
  {
    "start": 1743520,
    "end": 1747158,
    "text": "カウント・サムは行に沿ったカウントの合計である。"
  },
  {
    "start": 1747334,
    "end": 1750634,
    "text": "ここにヘルプを書いた。"
  },
  {
    "start": 1750832,
    "end": 1756398,
    "text": "もちろん、カウントは32×27であり、カウントの合計は32×1であることに留意しなければならない。"
  },
  {
    "start": 1756564,
    "end": 1766030,
    "text": "この逆伝播では、この導関数の列を、導関数の配列、2次元の配列に変換する必要がある。"
  },
  {
    "start": 1766610,
    "end": 1768754,
    "text": "この作戦は何をしているのか？"
  },
  {
    "start": 1768792,
    "end": 1778050,
    "text": "ある種の入力、たとえば3×3の行列aを受け取り、行を合計して列テンソルb b 1 b 2 b 3にする。"
  },
  {
    "start": 1778120,
    "end": 1779606,
    "text": "それは基本的にこうだ。"
  },
  {
    "start": 1779788,
    "end": 1789426,
    "text": "今、我々はbに関する損失の導関数、bのすべての要素を持っている。"
  },
  {
    "start": 1789618,
    "end": 1793562,
    "text": "BがAにどのように依存するのか。"
  },
  {
    "start": 1793616,
    "end": 1796038,
    "text": "この操作の局所微分は？"
  },
  {
    "start": 1796214,
    "end": 1801082,
    "text": "さて、ここでわかるのは、B1はこれらの要素にのみ依存しているということだ。"
  },
  {
    "start": 1801216,
    "end": 1805486,
    "text": "この下にあるすべての要素に関するb 1の導関数はゼロである。"
  },
  {
    "start": 1805668,
    "end": 1811022,
    "text": "これらの要素、例えば1、1、1、2などは、局所微分は1ですよね？"
  },
  {
    "start": 1811076,
    "end": 1815326,
    "text": "db、one by d、a elevenなどはoneである。"
  },
  {
    "start": 1815428,
    "end": 1817300,
    "text": "ひとつ、ひとつ、ひとつ。"
  },
  {
    "start": 1817990,
    "end": 1827494,
    "text": "ロスの微分値がbに対して1であるとき、bの局所微分値は、これらの入力に対して1であり、ここではゼロだが、これらの入力では1である。"
  },
  {
    "start": 1827692,
    "end": 1834950,
    "text": "つまり、連鎖法則では、bの微分のような局所的な微分時間がある。"
  },
  {
    "start": 1835100,
    "end": 1844890,
    "text": "したがって、これらの3つの要素では局所導関数が1であるため、局所導関数にb 1の導関数を掛けたものは、単にb 1の導関数となる。"
  },
  {
    "start": 1845040,
    "end": 1846982,
    "text": "ルーターとして見ることができる。"
  },
  {
    "start": 1847046,
    "end": 1850390,
    "text": "基本的に、加算はグラデーションのルーターである。"
  },
  {
    "start": 1850470,
    "end": 1855818,
    "text": "上からのグラデーションがどのようなものであれ、その加算に参加するすべての要素に均等にルーティングされるだけだ。"
  },
  {
    "start": 1855994,
    "end": 1863066,
    "text": "この場合、b 1の導関数はa 11、a 1 2、a 13の導関数と等しく流れる。"
  },
  {
    "start": 1863258,
    "end": 1880818,
    "text": "この列テンソルのbの全要素を微分するとdとなり、先ほど計算した総和となる。基本的には、これらの要素はすべてaの全要素に流れ、水平方向に流れていることがわかる。"
  },
  {
    "start": 1880994,
    "end": 1892038,
    "text": "つまり、基本的には、32×1サイズのデカウントの合計を取り、それを水平方向に27回複製して32×27の配列を作りたいのだ。"
  },
  {
    "start": 1892214,
    "end": 1894134,
    "text": "この作戦を実行する方法はたくさんある。"
  },
  {
    "start": 1894182,
    "end": 1902960,
    "text": "もちろん、テンソルを複製するだけでもいいんだけど、1つだけクリーンなのは、デカウントを単純にトーチドット1回にすることかな。"
  },
  {
    "start": 1903570,
    "end": 1907834,
    "text": "を2次元に配列したものである。"
  },
  {
    "start": 1907882,
    "end": 1912682,
    "text": "32×27のディカウントサム。"
  },
  {
    "start": 1912826,
    "end": 1917614,
    "text": "この方法では、基本的に放送にレプリケーションを実行させることになる。"
  },
  {
    "start": 1917662,
    "end": 1918980,
    "text": "そういう見方もできる。"
  },
  {
    "start": 1919670,
    "end": 1925070,
    "text": "というのも、すでにカウント数が計算されているからだ。"
  },
  {
    "start": 1925150,
    "end": 1928834,
    "text": "先ほど計算したのは、最初の分岐点だけだ。"
  },
  {
    "start": 1928882,
    "end": 1930610,
    "text": "私たちは今、第2ブランチを終えている。"
  },
  {
    "start": 1930690,
    "end": 1934498,
    "text": "これらのグラデーションがプラス・イコールになるようにする必要がある。"
  },
  {
    "start": 1934674,
    "end": 1939986,
    "text": "では、ここで比較をコメントアウトしてみよう。"
  },
  {
    "start": 1940098,
    "end": 1944314,
    "text": "正しい結果が出るよう、指をくわえて確かめよう。"
  },
  {
    "start": 1944432,
    "end": 1947818,
    "text": "ピトーチもこの勾配については同意見だ。"
  },
  {
    "start": 1947984,
    "end": 1949866,
    "text": "よし、コツをつかめたかな？"
  },
  {
    "start": 1949888,
    "end": 1953754,
    "text": "今、countsはノルムロジットの要素y, xである。"
  },
  {
    "start": 1953882,
    "end": 1955950,
    "text": "今度はデノルム・ロジットが欲しい。"
  },
  {
    "start": 1956610,
    "end": 1959454,
    "text": "要素演算だから、すべてが非常にシンプルなんだ。"
  },
  {
    "start": 1959572,
    "end": 1961694,
    "text": "xに対するeの局所微分は？"
  },
  {
    "start": 1961812,
    "end": 1963802,
    "text": "有名な話だが、eからxまでしかない。"
  },
  {
    "start": 1963956,
    "end": 1966210,
    "text": "これが局所微分である。"
  },
  {
    "start": 1968470,
    "end": 1969678,
    "text": "これが局所微分である。"
  },
  {
    "start": 1969774,
    "end": 1974766,
    "text": "今、すでに計算したし、それはカウントの中だから、カウントを再利用することもできるだろう。"
  },
  {
    "start": 1974798,
    "end": 1986050,
    "text": "これは局所微分であり、回数に見えるのはおかしいが、回数微分は通常のロジットの微分である。"
  },
  {
    "start": 1986210,
    "end": 1989142,
    "text": "では、これを消して検証してみよう。"
  },
  {
    "start": 1989286,
    "end": 1990700,
    "text": "それは良さそうだ。"
  },
  {
    "start": 1992350,
    "end": 1994410,
    "text": "それが通常のロジットだ。"
  },
  {
    "start": 1994750,
    "end": 1996874,
    "text": "さて、私たちはこのラインにいる。"
  },
  {
    "start": 1996912,
    "end": 2002850,
    "text": "さて、デノルム・ロジットができたので、デロイトとデロイト・マックスを計算しようとしている。"
  },
  {
    "start": 2002950,
    "end": 2004960,
    "text": "このラインを通じてのバックプロパゲーション。"
  },
  {
    "start": 2005330,
    "end": 2008654,
    "text": "ここで注意しなければならないのは、またしても形が同じではないということだ。"
  },
  {
    "start": 2008692,
    "end": 2011822,
    "text": "つまり、ここでは暗黙の放送が行われているのだ。"
  },
  {
    "start": 2011956,
    "end": 2016270,
    "text": "通常のロジットはこの形をしており、32×27のロジットも同様である。"
  },
  {
    "start": 2016340,
    "end": 2019042,
    "text": "logitの最大値は32×1だけである。"
  },
  {
    "start": 2019176,
    "end": 2022290,
    "text": "このマイナスに放送がある。"
  },
  {
    "start": 2022870,
    "end": 2026834,
    "text": "さて、ここでもう一度、おもちゃの例を書き出してみた。"
  },
  {
    "start": 2026952,
    "end": 2030566,
    "text": "私たちは基本的に、これはcイコールaマイナスBだと考えている。"
  },
  {
    "start": 2030748,
    "end": 2034978,
    "text": "形から、これらは3×3であることがわかるが、これは単なる列である。"
  },
  {
    "start": 2035154,
    "end": 2039986,
    "text": "だから、たとえばcのすべての要素について、それがどのようにしてbになったかを調べなければならない。"
  },
  {
    "start": 2040108,
    "end": 2047180,
    "text": "cの各要素は、aの対応する要素からbを引いたものである。"
  },
  {
    "start": 2048110,
    "end": 2061680,
    "text": "これらのCの入力に対する導関数が、対応するaに対しては1であり、対応するbに対しては負の1であることは明白だ。"
  },
  {
    "start": 2062130,
    "end": 2072686,
    "text": "したがって、Cの微分は対応するAに等しく流れ、さらに対応するBにも等しく流れる。"
  },
  {
    "start": 2072798,
    "end": 2075534,
    "text": "それに加えて、Bの放送がある。"
  },
  {
    "start": 2075582,
    "end": 2079094,
    "text": "以前と同じように、追加で合計を出さなければならない。"
  },
  {
    "start": 2079292,
    "end": 2086006,
    "text": "もちろん、Bの微分はマイナスになる。なぜなら、ここでの局所微分はマイナス1だからだ。"
  },
  {
    "start": 2086188,
    "end": 2090154,
    "text": "DC32×DB3はマイナス1。"
  },
  {
    "start": 2090352,
    "end": 2091818,
    "text": "それを実行に移そう"
  },
  {
    "start": 2091904,
    "end": 2104634,
    "text": "基本的に、delojitsはノーマルロジットの微分を正確にコピーすることになるので、delojitsはdenorm logitsと等しくなる。"
  },
  {
    "start": 2104682,
    "end": 2115474,
    "text": "デロジット・マキシスはデノーム・ロジットの負になる。"
  },
  {
    "start": 2115672,
    "end": 2120638,
    "text": "というのは、logit maxisは列だからである。"
  },
  {
    "start": 2120814,
    "end": 2136066,
    "text": "つまり、前に見たように、すべての列にわたって同じ要素を複製し続けるので、バックワードパスでは、これを再利用し続けるので、これらはすべて、1つの変数を使用する別々の分岐のようなものだ。"
  },
  {
    "start": 2136178,
    "end": 2143158,
    "text": "したがって、この次元を破壊しないように、1つの和をとって、それらを等しくしておく必要がある。"
  },
  {
    "start": 2143334,
    "end": 2146214,
    "text": "となると、デロジット・マキシも同じ形になる。"
  },
  {
    "start": 2146342,
    "end": 2150134,
    "text": "ここで注意しなければならないのは、このデロジッツは最終的なデロジッツではないということだ。"
  },
  {
    "start": 2150262,
    "end": 2160234,
    "text": "というのも、ここからロジットへの勾配信号が得られるだけでなく、ロジット・マキシはロジットの関数であり、これはロジットへの2つ目の分岐だからだ。"
  },
  {
    "start": 2160362,
    "end": 2162874,
    "text": "これはまだロジットの最終的な導関数ではない。"
  },
  {
    "start": 2162922,
    "end": 2165402,
    "text": "2つ目のブランチはまた後日。"
  },
  {
    "start": 2165546,
    "end": 2168046,
    "text": "今のところ、デロジット・マキシスが最終的なデリバティブだ。"
  },
  {
    "start": 2168158,
    "end": 2176370,
    "text": "このCMPのコメントを解除して、これを実行し、Pytorchが同意するかどうかlogit maxisしてみよう。"
  },
  {
    "start": 2176520,
    "end": 2180360,
    "text": "このラインを通じて派生したものだ。"
  },
  {
    "start": 2181050,
    "end": 2186870,
    "text": "さて、次に進む前に、ここで少し立ち止まって、これらのロジットマックスと特にそのグラデーションを見てみたい。"
  },
  {
    "start": 2187210,
    "end": 2195242,
    "text": "このようなことをする唯一の理由は、ここで実装しているソフト・マックスの数値的な安定性のためであることは、以前のルート講義でお話ししました。"
  },
  {
    "start": 2195376,
    "end": 2209306,
    "text": "このロジットテンソルの1行を例にとり、すべての要素に等しく値を足したり引いたりした場合、プロブの値は変化しないことを説明した。"
  },
  {
    "start": 2209338,
    "end": 2210746,
    "text": "ソフトマックスは変えない。"
  },
  {
    "start": 2210858,
    "end": 2214922,
    "text": "これがやっているのは、xがオーバーフローしないようにすることだけだ。"
  },
  {
    "start": 2215066,
    "end": 2223250,
    "text": "最大値を使うのは、各行のロジットの最高値がゼロであることが保証されるからである。"
  },
  {
    "start": 2223670,
    "end": 2238406,
    "text": "ロジットの最大値を変えても問題は変わらず、したがって損失も変わらないのであれば、ロジットの最大値の勾配はゼロになるはずである。"
  },
  {
    "start": 2238588,
    "end": 2238934,
    "text": "そうだろう？"
  },
  {
    "start": 2238972,
    "end": 2241180,
    "text": "この2つのことを言うのは同じだからだ。"
  },
  {
    "start": 2241790,
    "end": 2244202,
    "text": "しかし、この数字がごく少数であることを願っている。"
  },
  {
    "start": 2244256,
    "end": 2245786,
    "text": "確かに、私たちはこれがゼロであることを願っている。"
  },
  {
    "start": 2245968,
    "end": 2256750,
    "text": "さて、浮動小数点のある種の不器用さのせいで、これは正確にゼロにはならない。"
  },
  {
    "start": 2256900,
    "end": 2262750,
    "text": "これは、ロードされたマックスの値が、本来あるべきロスに影響していないことを物語っている。"
  },
  {
    "start": 2263090,
    "end": 2281080,
    "text": "Pytorchのfドットクロスエントロピーのような実装で、これらの要素をすべてブロック化し、逆伝播を1つ1つ行っていないのであれば、おそらくここを通って微分されるものは正確にゼロだと仮定するだろうから。"
  },
  {
    "start": 2281450,
    "end": 2289010,
    "text": "というのも、このブランチは数値的な安定のためだけに行われるものだからだ。"
  },
  {
    "start": 2289170,
    "end": 2307578,
    "text": "すべての原子を分割し、数値的な安定性を保つために計算を行ったとしても、補正が起こり、最終的な損失に関してこれらの値が重要でないという事実を基本的に反映し、非常に小さな勾配が得られることがわかります。"
  },
  {
    "start": 2307754,
    "end": 2310926,
    "text": "では、このラインを通して逆伝播を続けよう。"
  },
  {
    "start": 2311028,
    "end": 2316426,
    "text": "ロジットの最大値を計算したところで、この2番目のブランチを通してロジットにバックプロップしたい。"
  },
  {
    "start": 2316618,
    "end": 2323170,
    "text": "もちろん、ここでは対数をとり、すべての行で最大値をとり、その値をここで見ている。"
  },
  {
    "start": 2323320,
    "end": 2335400,
    "text": "さて、この仕組みはPytorchでは、このmaxが両方の値を返し、それらの値が最大値をカウントするインデックスを返すというものだ。"
  },
  {
    "start": 2335850,
    "end": 2339654,
    "text": "さて、フォワード・パスでは、必要なのは数値だけだった。"
  },
  {
    "start": 2339772,
    "end": 2347718,
    "text": "バックワードパスで、最大値がどこで発生したかを知ることは非常に有益であり、我々はその発生したインデックスを持っている。"
  },
  {
    "start": 2347814,
    "end": 2352954,
    "text": "これはもちろん、バックプロパゲーションに役立つ。"
  },
  {
    "start": 2352992,
    "end": 2353146,
    "text": "ここで？"
  },
  {
    "start": 2353168,
    "end": 2362422,
    "text": "この場合、32×27のlogistテンソルがあり、各行で最大値を見つけ、その値をlogit maxisに抜き出す。"
  },
  {
    "start": 2362586,
    "end": 2380642,
    "text": "だから、直感的には、基本的に、ここに流れるデリバティブは、抜き出された適切なエントリーのローカルデリバティブを1倍し、デロイト・マクシスのグローバルデリバティブを1倍したものになるはずだ。"
  },
  {
    "start": 2380786,
    "end": 2393100,
    "text": "私たちがここでやっていることは、よく考えてみれば、デロジットの最大値を取って、その最大値が来たロジット内の正しい位置にばらまくことなのだ。"
  },
  {
    "start": 2393470,
    "end": 2398762,
    "text": "というわけで、それを実現するコードを1行だけ考えてみた。"
  },
  {
    "start": 2398816,
    "end": 2408666,
    "text": "ゼロを作成し、正しい要素を入力する。"
  },
  {
    "start": 2408858,
    "end": 2414900,
    "text": "ここではインデックスを1つにしているが、1つのホットを使うこともできる。"
  },
  {
    "start": 2415590,
    "end": 2417170,
    "text": "fドット、1ホット。"
  },
  {
    "start": 2417320,
    "end": 2430902,
    "text": "そして、最初の次元のインデックスの最大対数をとり、Pytorchにこれらのテンソルの次元は27であるべきだと伝えている。"
  },
  {
    "start": 2431036,
    "end": 2436694,
    "text": "だから、これで何ができるかというと、申し訳ないが、これはクレイジーなことなんだ。"
  },
  {
    "start": 2436892,
    "end": 2438406,
    "text": "そのシブさ。"
  },
  {
    "start": 2438428,
    "end": 2446890,
    "text": "これは実際には、各行の最大値がどこから来たかを示す配列に過ぎず、その要素は1であり、他の要素はすべて0である。"
  },
  {
    "start": 2446960,
    "end": 2454174,
    "text": "それは各行で1つのホットなベクトルであり、これらのインデックスは現在、適切な場所に単一のものを入力している。"
  },
  {
    "start": 2454372,
    "end": 2457946,
    "text": "ということは、私がここでやっているのは、デロジット・マクシスを掛けるということだ。"
  },
  {
    "start": 2458058,
    "end": 2462830,
    "text": "これは32×1の列であることに留意してほしい。"
  },
  {
    "start": 2462980,
    "end": 2471454,
    "text": "だから、delojit maxisを使う時は、delojit Maxisがブロードキャストして、そのカラムがレプリケートされる。"
  },
  {
    "start": 2471502,
    "end": 2479030,
    "text": "その場合、エレメント単位の乗算によって、これらのビットのどれがオンになっているかにルーティングされる。"
  },
  {
    "start": 2479180,
    "end": 2484514,
    "text": "というわけで、これもこの種の作戦を実行する方法のひとつだ。"
  },
  {
    "start": 2484642,
    "end": 2486742,
    "text": "どちらも使える。"
  },
  {
    "start": 2486796,
    "end": 2489414,
    "text": "ただ、それと同等の方法を示そうと思っただけだ。"
  },
  {
    "start": 2489532,
    "end": 2494950,
    "text": "プラス・イコールを使っているのは、すでにここでロジットを計算したからで、今は2番目のブランチになっている。"
  },
  {
    "start": 2495110,
    "end": 2503440,
    "text": "ロジットを見て、これが正しいことを確認しよう。"
  },
  {
    "start": 2504530,
    "end": 2507406,
    "text": "次はロジットの続きだ。"
  },
  {
    "start": 2507508,
    "end": 2512750,
    "text": "これは、このリニアレイヤにおけるマトリックス乗算とバイアスオフセットの結果である。"
  },
  {
    "start": 2513090,
    "end": 2517886,
    "text": "これらすべての中間テンソルの形状をプリントアウトした。"
  },
  {
    "start": 2517998,
    "end": 2521794,
    "text": "先ほど見たように、ロジットはもちろん32×27であることがわかる。"
  },
  {
    "start": 2521992,
    "end": 2525170,
    "text": "すると、ここでのhは32×64となる。"
  },
  {
    "start": 2525240,
    "end": 2527526,
    "text": "これらは64次元の隠された状態である。"
  },
  {
    "start": 2527708,
    "end": 2532946,
    "text": "とすると、このw行列は64次元のベクトルを27次元に投影する。"
  },
  {
    "start": 2533058,
    "end": 2537830,
    "text": "となると、27次元のオフセットがあり、これは1次元のベクトルである。"
  },
  {
    "start": 2538410,
    "end": 2546778,
    "text": "hにwを2つ掛けると32×27になるので、このプラスが実際に放送されることに注意しなければならない。"
  },
  {
    "start": 2546944,
    "end": 2552026,
    "text": "ということは、これにb2を足した27次元のベクトルがここにある。"
  },
  {
    "start": 2552208,
    "end": 2564814,
    "text": "さて、放送のルールでは、このバイアス・ベクトルで何が起こるかというと、この27の1次元ベクトルは、左に1つパディングされた次元に整列され、基本的には行ベクトルになる。"
  },
  {
    "start": 2564942,
    "end": 2569842,
    "text": "であれば、縦に32回複製され、32×27になる。"
  },
  {
    "start": 2569896,
    "end": 2571970,
    "text": "であれば、2倍する要素がある。"
  },
  {
    "start": 2572950,
    "end": 2581926,
    "text": "さて、問題は、ロジットから隠れ状態、重み行列w 2、バイアスb 2への逆伝播をどのように行うかである。"
  },
  {
    "start": 2582108,
    "end": 2590594,
    "text": "行列の掛け算の微分を調べなければならないと思うかもしれない。"
  },
  {
    "start": 2590722,
    "end": 2596266,
    "text": "しかし、そんなことをする必要はなく、第一原理に立ち返って、自分で紙に書いて導き出すことができる。"
  },
  {
    "start": 2596448,
    "end": 2604366,
    "text": "具体的には、具体的な小さな例を見つけ、それを完全に書き出すのだ。"
  },
  {
    "start": 2604468,
    "end": 2617650,
    "text": "そして、その個々の小さな例がどのように機能するかを分析する過程で、より広いパターンを理解し、これらの導関数がこのような式でどのように流れるかを一般化し、完全な一般式を書き出すことができるようになる。"
  },
  {
    "start": 2617720,
    "end": 2619058,
    "text": "試してみよう。"
  },
  {
    "start": 2619224,
    "end": 2624642,
    "text": "低予算で作ったことを許してほしい。"
  },
  {
    "start": 2624776,
    "end": 2634070,
    "text": "私たちの興味は、aにbとcを掛け合わせ、adを作り、dに関して損失を微分することだ。"
  },
  {
    "start": 2634140,
    "end": 2637560,
    "text": "損失がabとcに対してどのように微分されるかを知りたい。"
  },
  {
    "start": 2637930,
    "end": 2642214,
    "text": "さて、これらは行列の掛け算の小さな2次元の例である。"
  },
  {
    "start": 2642342,
    "end": 2646298,
    "text": "2×2の2×2プラス2。"
  },
  {
    "start": 2646464,
    "end": 2650666,
    "text": "c oneとc twoの2つの要素だけのベクトルでは、2×2が得られる。"
  },
  {
    "start": 2650848,
    "end": 2658126,
    "text": "ここで、cというバイアス・ベクトルがあり、バイアス・ベクトルはc1とc2であることに注目してほしい。"
  },
  {
    "start": 2658228,
    "end": 2664234,
    "text": "ここで説明したように、バイアス・ベクトルは放送の行ベクトルとなり、垂直方向に複製される。"
  },
  {
    "start": 2664362,
    "end": 2665822,
    "text": "ここでも同じことが起きている。"
  },
  {
    "start": 2665876,
    "end": 2672180,
    "text": "C 1, C 2が縦に複製され、結果としてC 1, C 2が2列になっているのがわかる。"
  },
  {
    "start": 2673030,
    "end": 2681970,
    "text": "つまり、この行列の掛け算を、ボンネットの中で実際に起こっていることに分解するのだ。"
  },
  {
    "start": 2682130,
    "end": 2691242,
    "text": "行列の掛け算とその仕組みの結果として、dの11はaの最初の行とbの最初の列の間のドット積の結果である。"
  },
  {
    "start": 2691376,
    "end": 2700970,
    "text": "aが11、bが12、aが12、bが21＋cが1、......という具合に、Dの他のすべての要素についても同様である。"
  },
  {
    "start": 2701120,
    "end": 2707146,
    "text": "実際に書き出してみると、これは単なる掛け算と足し算の集まりであることがわかる。"
  },
  {
    "start": 2707258,
    "end": 2711082,
    "text": "マイクログラッドでは、掛け算と足し算を区別する方法を知っている。"
  },
  {
    "start": 2711226,
    "end": 2712586,
    "text": "だからもう怖くない。"
  },
  {
    "start": 2712618,
    "end": 2714266,
    "text": "行列の掛け算だけではない。"
  },
  {
    "start": 2714378,
    "end": 2716526,
    "text": "残念ながら、退屈なだけだ。"
  },
  {
    "start": 2716638,
    "end": 2718382,
    "text": "これは完全に扱いやすい。"
  },
  {
    "start": 2718526,
    "end": 2724878,
    "text": "我々はこれらすべてについてDによるDLを持っており、これらすべての小さな他の変数によるDLを望んでいる。"
  },
  {
    "start": 2724974,
    "end": 2726034,
    "text": "どうやってそれを達成するのか？"
  },
  {
    "start": 2726072,
    "end": 2727730,
    "text": "実際にグラデーションを得るには？"
  },
  {
    "start": 2727890,
    "end": 2730566,
    "text": "なるほど、低予算での製作はここでも続いている。"
  },
  {
    "start": 2730748,
    "end": 2735430,
    "text": "例えば、イレブンに対する損失の微分を導出しよう。"
  },
  {
    "start": 2736010,
    "end": 2742940,
    "text": "ここでは、a elevenが単純な表現で2回出てくることがわかる。"
  },
  {
    "start": 2743870,
    "end": 2746726,
    "text": "D・A・イレブンのDLとは？"
  },
  {
    "start": 2746918,
    "end": 2757360,
    "text": "つまり、Dイレブンの局所微分のdイレブン倍がDLとなり、この場合はbイレブンとなる。"
  },
  {
    "start": 2758930,
    "end": 2763790,
    "text": "ここでも同様に、a 11に対するD 12の局所導関数はb 12だけである。"
  },
  {
    "start": 2763940,
    "end": 2768340,
    "text": "ということは、bの12は連鎖法則ではDLにdの12を掛けることになる。"
  },
  {
    "start": 2768790,
    "end": 2780178,
    "text": "ということは、aイレブンはdイレブンとdトゥエルブの両方の生産に使われるので、並行して走っているこれらの連鎖の両方の寄与を合計する必要がある。"
  },
  {
    "start": 2780274,
    "end": 2785682,
    "text": "だから、この2つの貢献度を足すだけでプラスになるんだ。"
  },
  {
    "start": 2785746,
    "end": 2788258,
    "text": "ということは、DL by d a elevenとなる。"
  },
  {
    "start": 2788434,
    "end": 2793578,
    "text": "aの他の要素についても、まったく同じ分析ができる。"
  },
  {
    "start": 2793744,
    "end": 2807822,
    "text": "単純に書き出すと、このような式で勾配を取るだけの超シンプルなものだ。"
  },
  {
    "start": 2807876,
    "end": 2811870,
    "text": "それらをすべてテイクと同じ形に並べればいい。"
  },
  {
    "start": 2811940,
    "end": 2813646,
    "text": "aは単なる2×2の行列である。"
  },
  {
    "start": 2813758,
    "end": 2822398,
    "text": "ここでのdaによるDLもまた、導関数を持つ同じ形状のテンソルとなる。"
  },
  {
    "start": 2822414,
    "end": 2824942,
    "text": "では、ダイレブンでDLしよう。"
  },
  {
    "start": 2825086,
    "end": 2830546,
    "text": "ここに書き出したものは、実は行列の乗算として表現できることがわかる。"
  },
  {
    "start": 2830738,
    "end": 2839894,
    "text": "というわけで、勾配を取ることで導き出したこれらの数式は、実はすべて行列の掛け算として表現できるのだ。"
  },
  {
    "start": 2840022,
    "end": 2845318,
    "text": "特に、この2つの行列の掛け算であることがわかる。"
  },
  {
    "start": 2845494,
    "end": 2863070,
    "text": "DLをDで表し、bにbを掛ける行列を転置する。"
  },
  {
    "start": 2863220,
    "end": 2867010,
    "text": "を見ると、この別の行列Bが転置されていることがわかる。"
  },
  {
    "start": 2867350,
    "end": 2884070,
    "text": "というわけで、要するに、非常に単純な例を挙げれば、式を分解して非常に単純な推論を行うだけで、DL by da、つまりDL by ddの行列にbの転置行列を掛けたものに等しい、ということになる。"
  },
  {
    "start": 2885850,
    "end": 2887634,
    "text": "それが今のところあるものだ。"
  },
  {
    "start": 2887772,
    "end": 2892058,
    "text": "ここで、bとcに関する導関数も求める。"
  },
  {
    "start": 2892224,
    "end": 2898870,
    "text": "Bについては、正直言って深くないので、完全な導出はしていない。"
  },
  {
    "start": 2898950,
    "end": 2900406,
    "text": "迷惑なだけだ。"
  },
  {
    "start": 2900438,
    "end": 2901366,
    "text": "疲れるよ。"
  },
  {
    "start": 2901478,
    "end": 2903354,
    "text": "この分析は実際に自分でできる。"
  },
  {
    "start": 2903472,
    "end": 2912778,
    "text": "また、これらの式をaではなくbに関して微分すると、DL by Dbも行列の乗算であることがわかる。"
  },
  {
    "start": 2912874,
    "end": 2918930,
    "text": "この場合、行列aを取って転置し、DLとDDを行列乗算しなければならない。"
  },
  {
    "start": 2919670,
    "end": 2921810,
    "text": "それがDBによるDLだ。"
  },
  {
    "start": 2922470,
    "end": 2934886,
    "text": "ここでオフセットc1とc2について、再びc1に関して微分すれば、次のような式が得られ、c2は次のような式が得られる。"
  },
  {
    "start": 2935068,
    "end": 2940822,
    "text": "基本的にDCによるDLは、単にこれらの表現を相殺しているだけだとわかるだろう。"
  },
  {
    "start": 2940966,
    "end": 2952960,
    "text": "Dの導関数のDL×dd行列を取り、列をまたいで合計すれば、cの導関数が得られる。"
  },
  {
    "start": 2953410,
    "end": 2959818,
    "text": "手短に言えば、行列乗算の後方経路は行列乗算である。"
  },
  {
    "start": 2959994,
    "end": 2963694,
    "text": "Dはaにbとcを足したものに等しい。"
  },
  {
    "start": 2963892,
    "end": 2967778,
    "text": "スカラーの場合は、非常によく似た結果になる。"
  },
  {
    "start": 2967864,
    "end": 2972210,
    "text": "をスカラー倍算ではなく行列倍算に変更した。"
  },
  {
    "start": 2972550,
    "end": 2981394,
    "text": "aに関するDの導関数は、dd、行列乗算b転置によってDLされる。"
  },
  {
    "start": 2981522,
    "end": 2985042,
    "text": "ここでは、DLとDDを掛け合わせたトランスポーズである。"
  },
  {
    "start": 2985106,
    "end": 2995370,
    "text": "どちらの場合も、微分と他の項を掛け合わせた行列の掛け算であり、cの場合は和となる。"
  },
  {
    "start": 2995790,
    "end": 2997430,
    "text": "秘密を教えてあげよう。"
  },
  {
    "start": 2997590,
    "end": 3002518,
    "text": "行列の掛け算によってバックプロパゲートするために導き出した公式を、私は決して思い出せない。"
  },
  {
    "start": 3002614,
    "end": 3005310,
    "text": "これらの式でバックプロパゲートは問題なくできる。"
  },
  {
    "start": 3005460,
    "end": 3009054,
    "text": "これがうまくいくのは、寸法がうまくいく必要があるからだ。"
  },
  {
    "start": 3009252,
    "end": 3010878,
    "text": "例を挙げよう。"
  },
  {
    "start": 3011044,
    "end": 3013070,
    "text": "dHを作りたいとする。"
  },
  {
    "start": 3013730,
    "end": 3015918,
    "text": "では、DHはどうあるべきか？"
  },
  {
    "start": 3016004,
    "end": 3023634,
    "text": "第一に、DHの形はHの形と同じでなければならず、Hの形は32×64であることを知らなければならない。"
  },
  {
    "start": 3023752,
    "end": 3038550,
    "text": "私が知っているもう一つの情報は、DHはデロジットとw 2、dロジットは32×27、w 2は64×27のある種の行列の掛け算に違いないということだ。"
  },
  {
    "start": 3038700,
    "end": 3045482,
    "text": "この場合、形がうまくいく方法はひとつしかなく、それは確かに正しい結果である。"
  },
  {
    "start": 3045616,
    "end": 3048906,
    "text": "特にここでは、hは32×64にする必要がある。"
  },
  {
    "start": 3049008,
    "end": 3055006,
    "text": "それを達成する唯一の方法は、デロギッツを取って行列乗算することだ。"
  },
  {
    "start": 3055188,
    "end": 3059600,
    "text": "Wを2つ取らなければならないのはわかると思うが、寸法がうまくいくようにするには、それを転置しなければならない。"
  },
  {
    "start": 3060210,
    "end": 3066722,
    "text": "この2つのピースをマトリックス状に掛け合わせることで、形が整うのだ。"
  },
  {
    "start": 3066776,
    "end": 3068670,
    "text": "これが正しい公式であることが判明した。"
  },
  {
    "start": 3068750,
    "end": 3081398,
    "text": "ここでdHを求めるとdaとなり、daはDL×Dd行列乗算b転置行列であることがわかる。"
  },
  {
    "start": 3081484,
    "end": 3084790,
    "text": "wの2つの転置は、まさにここにあるものだ。"
  },
  {
    "start": 3084940,
    "end": 3088562,
    "text": "これらの公式を同様に覚える必要はない。"
  },
  {
    "start": 3088706,
    "end": 3097226,
    "text": "さて、DW 2が欲しい場合、デロジットとHの行列乗算でなければならないことは分かっている。"
  },
  {
    "start": 3097408,
    "end": 3102106,
    "text": "多分、いくつかの移籍があるんだろうけど、1つだけ移籍もあって、それがどっちなのか分からないんだ。"
  },
  {
    "start": 3102128,
    "end": 3110720,
    "text": "その形状は64×27であり、この2つの行列の掛け算に由来している。"
  },
  {
    "start": 3111090,
    "end": 3123762,
    "text": "ということは、64×27を得るには、hを取り、それを転置し、行列乗算する必要があるので、64×32になる。"
  },
  {
    "start": 3123816,
    "end": 3128726,
    "text": "となると、32に27を行列掛けして、64に27を行列掛けする必要がある。"
  },
  {
    "start": 3128828,
    "end": 3132374,
    "text": "デロジシェイプとマトリックス掛けする必要がある。"
  },
  {
    "start": 3132492,
    "end": 3137074,
    "text": "次元がうまくいくようにするには、行列の掛け算を使うしかない。"
  },
  {
    "start": 3137202,
    "end": 3140314,
    "text": "ここに来れば、それがまさにここにあることがわかる。"
  },
  {
    "start": 3140352,
    "end": 3145210,
    "text": "hの転置aは、hにlogisを掛けたものである。"
  },
  {
    "start": 3145950,
    "end": 3154598,
    "text": "これがw 2で、db 2は単なる縦の合計だ。"
  },
  {
    "start": 3154694,
    "end": 3158110,
    "text": "実際、同じように、形をうまく作る方法は一つしかない。"
  },
  {
    "start": 3158180,
    "end": 3165650,
    "text": "ゼロ軸に沿った垂直方向の合計であることを思い出す必要はない。"
  },
  {
    "start": 3165800,
    "end": 3172418,
    "text": "ここでデロジッツを獲得するには、32×27となる。"
  },
  {
    "start": 3172584,
    "end": 3177030,
    "text": "それは、ある方向でデロージッツを超えるだけの和だと知っているからだ。"
  },
  {
    "start": 3179850,
    "end": 3183510,
    "text": "その方向はゼロでなければならない。"
  },
  {
    "start": 3184010,
    "end": 3188994,
    "text": "これこそ、ある意味、ハチャメチャなやり方だ。"
  },
  {
    "start": 3189052,
    "end": 3192762,
    "text": "コピペして消して、こっちに振らせてくれ。"
  },
  {
    "start": 3192896,
    "end": 3196886,
    "text": "これがリニア・レイヤーの後方パスだ。"
  },
  {
    "start": 3197078,
    "end": 3206000,
    "text": "では、この3つのコメントを解除して、3つの導関数がすべて正しくなったことを確認し、実行しよう。"
  },
  {
    "start": 3206770,
    "end": 3211486,
    "text": "h、w 2、b 2はすべて正確に正しいことがわかる。"
  },
  {
    "start": 3211668,
    "end": 3214450,
    "text": "私たちは直線的なレイヤーを逆伝播した。"
  },
  {
    "start": 3215910,
    "end": 3216766,
    "text": "うっほー。"
  },
  {
    "start": 3216878,
    "end": 3223646,
    "text": "さて、次はすでにdhの導関数を持っているので、10個のhを逆伝播してhのプレアクトにする必要がある。"
  },
  {
    "start": 3223838,
    "end": 3229362,
    "text": "dhのプレアクトを導き出したいのだが、ここでは10hを逆伝播しなければならない。"
  },
  {
    "start": 3229416,
    "end": 3234466,
    "text": "これはマイクログラッドですでにやったことだし、10hが非常に単純な逆算式であることも覚えている。"
  },
  {
    "start": 3234578,
    "end": 3239654,
    "text": "さて、残念なことに、xのtan hのd×dxをボルト・プライム・アルファに入れただけでは、がっかりさせてしまう。"
  },
  {
    "start": 3239692,
    "end": 3243594,
    "text": "これは、xの双曲線セカント関数の2乗であることを示している。"
  },
  {
    "start": 3243712,
    "end": 3245174,
    "text": "参考にはならないね。"
  },
  {
    "start": 3245302,
    "end": 3250358,
    "text": "幸運なことに、グーグルの画像検索は私たちを失望させることなく、よりシンプルな公式を表示してくれる。"
  },
  {
    "start": 3250454,
    "end": 3258910,
    "text": "特に、aがzのtan hに等しいとすると、tan hを逆伝播するdzによるdaは1マイナス2乗でしかない。"
  },
  {
    "start": 3259060,
    "end": 3266338,
    "text": "ここでの1マイナス2乗aはtan hの出力であり、tan h zの入力ではないことに注意されたい。"
  },
  {
    "start": 3266504,
    "end": 3271540,
    "text": "dzによるdaは、ここでは10個のhの出力で定式化されている。"
  },
  {
    "start": 3272150,
    "end": 3282120,
    "text": "また、Googleの画像検索で、ten hの実際の定義と、Zのマイナスtan hの2乗を計算するための完全な導出も見ることができる。"
  },
  {
    "start": 3282490,
    "end": 3285986,
    "text": "1マイナス2乗が局所微分である。"
  },
  {
    "start": 3286098,
    "end": 3293306,
    "text": "この場合、tan hの2乗の出力から1を引いたものがhとなる。"
  },
  {
    "start": 3293488,
    "end": 3300010,
    "text": "これはh乗で、これが局所微分となり、連鎖法則dhをかける。"
  },
  {
    "start": 3300610,
    "end": 3303370,
    "text": "これが我々の実装候補となる。"
  },
  {
    "start": 3303450,
    "end": 3311680,
    "text": "ここに来てからコメントを解除すれば、ベストを尽くして正しい答えが出ることを祈ろう。"
  },
  {
    "start": 3312370,
    "end": 3318910,
    "text": "さて、次はdhpriactで、ゲイン、bn raw、bnb biasに逆伝播したい。"
  },
  {
    "start": 3319070,
    "end": 3329174,
    "text": "これはバッシュ・ノルムのパラメータで、バッシュ・ノルムの内部ではbnゲインとバイアスが、正確な単位ガウシアンであるbnの生データをスケーリングしてシフトしている。"
  },
  {
    "start": 3329372,
    "end": 3331606,
    "text": "これらはbashノルムのパラメーターである。"
  },
  {
    "start": 3331788,
    "end": 3334386,
    "text": "ここで掛け算がある。"
  },
  {
    "start": 3334498,
    "end": 3338354,
    "text": "この乗算は、この行列の乗算とはまったく異なるものであることは注目に値する。"
  },
  {
    "start": 3338402,
    "end": 3344054,
    "text": "ここで、行列乗算とは、これらの行列の行と列の間のドット積のことである。"
  },
  {
    "start": 3344182,
    "end": 3345766,
    "text": "これは要素ごとの乗算である。"
  },
  {
    "start": 3345798,
    "end": 3352302,
    "text": "しかし、このコード行で起こっているいくつかのブロードキャストには注意しなければならない。"
  },
  {
    "start": 3352436,
    "end": 3361280,
    "text": "bnゲインとbnバイアスは64分の1だが、hpriactとbn rawは64分の32であることがわかるだろう。"
  },
  {
    "start": 3362290,
    "end": 3368206,
    "text": "すべての形状がうまく機能し、放送が正しくバックプロパゲートされるように注意しなければならない。"
  },
  {
    "start": 3368398,
    "end": 3371086,
    "text": "特にdbとゲインから始めよう。"
  },
  {
    "start": 3371278,
    "end": 3374580,
    "text": "dbとゲインであるべきだ。"
  },
  {
    "start": 3374950,
    "end": 3377422,
    "text": "ここでもまた、エレメント単位での倍率である。"
  },
  {
    "start": 3377486,
    "end": 3386262,
    "text": "aのb乗がcに等しいとき、局所導関数はaのb乗に等しい。"
  },
  {
    "start": 3386396,
    "end": 3390970,
    "text": "局所微分はbとrawだけで、あとは連鎖法則をかける。"
  },
  {
    "start": 3391470,
    "end": 3393130,
    "text": "dhのプレアクト。"
  },
  {
    "start": 3394110,
    "end": 3398358,
    "text": "これがグラデーション候補である。"
  },
  {
    "start": 3398454,
    "end": 3407360,
    "text": "bとゲインのサイズは1×64だが、ここでは32×64になるので、ここでも注意が必要だ。"
  },
  {
    "start": 3408290,
    "end": 3415138,
    "text": "つまり、この場合、bとゲインは64個の数値からなるルール・ベクトルであることが正しい。"
  },
  {
    "start": 3415224,
    "end": 3418366,
    "text": "この作業で縦に複製される。"
  },
  {
    "start": 3418558,
    "end": 3423410,
    "text": "だから、正しいのは、それが複製されているから合計することだ。"
  },
  {
    "start": 3423990,
    "end": 3432162,
    "text": "したがって、現在逆流している各行のすべての勾配は、同じテンソルのdbとゲインに合計する必要がある。"
  },
  {
    "start": 3432306,
    "end": 3440198,
    "text": "基本的には、すべてのゼロ、すべての例を合計しなければならない。"
  },
  {
    "start": 3440374,
    "end": 3446026,
    "text": "bnのゲインは64分の1の形をしているので、これも注意しなければならない。"
  },
  {
    "start": 3446128,
    "end": 3451694,
    "text": "そうでなければ、私は64歳になってしまう。"
  },
  {
    "start": 3451892,
    "end": 3465354,
    "text": "bとゲイン、bとバイアスは64で1つにしたが、b1とb2は1次元のベクトルにしただけだ。"
  },
  {
    "start": 3465402,
    "end": 3467102,
    "text": "それらは2次元のテンソルではない。"
  },
  {
    "start": 3467166,
    "end": 3472750,
    "text": "なぜゲインとバイアスを2次元のままにしたのか、正確には思い出せない。"
  },
  {
    "start": 3472830,
    "end": 3476366,
    "text": "あなたが一貫性を保ち、それを同じに保っている限り、それは本当に問題ではない。"
  },
  {
    "start": 3476488,
    "end": 3480040,
    "text": "この場合、テンソル形状が機能するように次元を保ちたい。"
  },
  {
    "start": 3481370,
    "end": 3492870,
    "text": "次にbとrawがあるので、dbとrawはbnゲインにdhのプレアクトを掛けたものになる。"
  },
  {
    "start": 3493030,
    "end": 3494630,
    "text": "それが我々のチェーンルールだ。"
  },
  {
    "start": 3494790,
    "end": 3499306,
    "text": "さて、この寸法はどうだろう？"
  },
  {
    "start": 3499408,
    "end": 3500426,
    "text": "気をつけないといけないよね。"
  },
  {
    "start": 3500448,
    "end": 3503786,
    "text": "dhのプリアクトは32×64。"
  },
  {
    "start": 3503888,
    "end": 3506398,
    "text": "Bnゲインは64分の1。"
  },
  {
    "start": 3506484,
    "end": 3507946,
    "text": "それは複製されるだけだ。"
  },
  {
    "start": 3508058,
    "end": 3515602,
    "text": "なぜなら、フォワードパスでも同じように複製されるからだ。"
  },
  {
    "start": 3515736,
    "end": 3520626,
    "text": "実際、ここでは括弧は必要ない。"
  },
  {
    "start": 3520808,
    "end": 3524498,
    "text": "最後に、バイアスについては、非常によく似ている。"
  },
  {
    "start": 3524664,
    "end": 3528818,
    "text": "このバイアスは、リニアで見られたバイアスと非常によく似ている。"
  },
  {
    "start": 3528914,
    "end": 3536770,
    "text": "というのも、これらは単なるオフセットだからだ。"
  },
  {
    "start": 3536930,
    "end": 3542902,
    "text": "つまり、基本的にはdHのプレアクトにしたいのだが、正しい次元に沿って合計する必要がある。"
  },
  {
    "start": 3543046,
    "end": 3551210,
    "text": "この場合、ゲインと同様に、バイアスが垂直方向に複製されるため、0番目の次元である例を横断して合計する必要がある。"
  },
  {
    "start": 3551710,
    "end": 3554960,
    "text": "私たちはまた、それらを真実として持ち続けたい。"
  },
  {
    "start": 3555330,
    "end": 3560000,
    "text": "だから、これは基本的にこれを要約し、64分の1にしてくれる。"
  },
  {
    "start": 3560610,
    "end": 3562986,
    "text": "これが実装候補である。"
  },
  {
    "start": 3563018,
    "end": 3564820,
    "text": "そのおかげですべての形が機能する。"
  },
  {
    "start": 3565350,
    "end": 3575854,
    "text": "そして、この3行のコメントを解除して、3つのテンソルすべてについて正しい結果が得られていることを確認しよう。"
  },
  {
    "start": 3575982,
    "end": 3579554,
    "text": "確かに、そのすべてが正しくバックプロパゲートされていることがわかる。"
  },
  {
    "start": 3579682,
    "end": 3581698,
    "text": "これでバッチノルムのレイヤーにたどり着いた。"
  },
  {
    "start": 3581874,
    "end": 3584930,
    "text": "ここではbn gainとbnbasがパラメーターであることがわかる。"
  },
  {
    "start": 3585010,
    "end": 3586610,
    "text": "バックプロパゲーションが終了する。"
  },
  {
    "start": 3586690,
    "end": 3590870,
    "text": "bnの生が標準化の出力である。"
  },
  {
    "start": 3591630,
    "end": 3598054,
    "text": "ここで私がやっていることは、もちろん、バッチノルムを管理しやすい断片に分割して、各行を個別にバックプロパゲートできるようにすることだ。"
  },
  {
    "start": 3598182,
    "end": 3603230,
    "text": "基本的に何が起こっているかというと、bnはIを意味する。"
  },
  {
    "start": 3603890,
    "end": 3606078,
    "text": "これが \"B \"であり、\"I \"である。"
  },
  {
    "start": 3606164,
    "end": 3608378,
    "text": "変数の命名については申し訳ない。"
  },
  {
    "start": 3608554,
    "end": 3611040,
    "text": "Bとdiffはxからmuを引いたものである。"
  },
  {
    "start": 3611490,
    "end": 3614602,
    "text": "Bと差分2は、xからミューの2乗を引いたものである。"
  },
  {
    "start": 3614666,
    "end": 3618990,
    "text": "ここで分散内、bnvrは分散である。"
  },
  {
    "start": 3619070,
    "end": 3625006,
    "text": "シグマスクエア、これはbとVARで、基本的には二乗の合計である。"
  },
  {
    "start": 3625198,
    "end": 3629410,
    "text": "これはxからミューの2乗を引いたもので、その和である。"
  },
  {
    "start": 3629570,
    "end": 3631894,
    "text": "さて、ここで1つの出発点に気づくだろう。"
  },
  {
    "start": 3632092,
    "end": 3637218,
    "text": "ここでは例数であるmを1として正規化している。"
  },
  {
    "start": 3637314,
    "end": 3640822,
    "text": "ここでは、nの代わりにnから1を引いたものを1として正規化している。"
  },
  {
    "start": 3640876,
    "end": 3643194,
    "text": "これは意図的なものだ。"
  },
  {
    "start": 3643232,
    "end": 3649162,
    "text": "このラインにいるときは、ベッセルの補正と呼ばれるものだが、私はこうしたい。"
  },
  {
    "start": 3649216,
    "end": 3655750,
    "text": "この場合、bnvar invは基本的にbnvプラスεになる。"
  },
  {
    "start": 3655830,
    "end": 3668622,
    "text": "イプシロンはyマイナス5であり、その1乗平方根はマイナスゼロ5の累乗と同じである。"
  },
  {
    "start": 3668766,
    "end": 3673410,
    "text": "bとVAR infは、ここではこの分母を1オーバーしている。"
  },
  {
    "start": 3673560,
    "end": 3678918,
    "text": "とすると、Bn raw（ここではxハット）はbn diffと等しいことがわかる。"
  },
  {
    "start": 3679004,
    "end": 3684360,
    "text": "分子にBnvar infを乗じたもの。"
  },
  {
    "start": 3684810,
    "end": 3688454,
    "text": "プリプリアクトを生み出すこのラインが最後のピースだった。"
  },
  {
    "start": 3688492,
    "end": 3690520,
    "text": "すでにバックプロパゲートしている。"
  },
  {
    "start": 3691450,
    "end": 3700060,
    "text": "さて、ここでやりたいことは、bとrawを持っていて、まずbとdiffとbnvar imにバックプロパゲートすることだ。"
  },
  {
    "start": 3700670,
    "end": 3706000,
    "text": "dbとrawがあるので、この行をバックプロパゲートする必要がある。"
  },
  {
    "start": 3706770,
    "end": 3712718,
    "text": "さて、ここにシェイプを書き出してみたが、確かにbnvar Imは64分の1のシェイプである。"
  },
  {
    "start": 3712804,
    "end": 3719422,
    "text": "ここで注意しなければならないのは、放送が行われていることだ。"
  },
  {
    "start": 3719486,
    "end": 3721474,
    "text": "今までに、私たちはそれにかなり慣れているはずだ。"
  },
  {
    "start": 3721592,
    "end": 3729670,
    "text": "dbとdiffを得るには、bnvar infにdbとrawを掛けただけであることがわかる。"
  },
  {
    "start": 3731530,
    "end": 3740170,
    "text": "逆に、dbとvarinfを得るには、bn diffを取り、それにdbとrawを掛ける必要がある。"
  },
  {
    "start": 3742350,
    "end": 3743798,
    "text": "これが候補者だ。"
  },
  {
    "start": 3743894,
    "end": 3747558,
    "text": "もちろん、放送が守られるようにしなければならない。"
  },
  {
    "start": 3747654,
    "end": 3756240,
    "text": "特にbnvar infは、dbとrawを掛け合わせても問題なく、期待通りの32×64が得られるだろう。"
  },
  {
    "start": 3756770,
    "end": 3764754,
    "text": "dbnvar infは、32×64を32×64で乗算することになる。"
  },
  {
    "start": 3764792,
    "end": 3766690,
    "text": "これは32×64だ。"
  },
  {
    "start": 3766840,
    "end": 3771842,
    "text": "もちろん、このbnvar intは64分の1しかない。"
  },
  {
    "start": 3771976,
    "end": 3776258,
    "text": "ここの2行目は、例全体の合計が必要だ。"
  },
  {
    "start": 3776354,
    "end": 3781320,
    "text": "というのも、ここにはこういう次元があるからだ。"
  },
  {
    "start": 3782090,
    "end": 3783670,
    "text": "これが候補者だ。"
  },
  {
    "start": 3784890,
    "end": 3790282,
    "text": "これを消して、下に振って実行しよう。"
  },
  {
    "start": 3790416,
    "end": 3795370,
    "text": "では、dbmvr infとdpndifをコメントアウトしてみよう。"
  },
  {
    "start": 3796270,
    "end": 3801610,
    "text": "ところで、dpとdiffが正しくないことに気づくだろう。"
  },
  {
    "start": 3802030,
    "end": 3808446,
    "text": "これを実行すると、bnvr infは正しいが、bn diffは正しくない。"
  },
  {
    "start": 3808628,
    "end": 3813918,
    "text": "bとdiffはまだ終わっていないのだから。"
  },
  {
    "start": 3814084,
    "end": 3818430,
    "text": "特にここをスライドすると、bとrawがbとdiffの関数であることがわかる。"
  },
  {
    "start": 3818580,
    "end": 3825174,
    "text": "実際、BnvrはbとVARの関数であり、これはBとdiffの関数である。"
  },
  {
    "start": 3825332,
    "end": 3826278,
    "text": "それはここにある。"
  },
  {
    "start": 3826364,
    "end": 3827720,
    "text": "bdn diff."
  },
  {
    "start": 3829290,
    "end": 3830582,
    "text": "この変数名はクレイジーだ。"
  },
  {
    "start": 3830636,
    "end": 3831254,
    "text": "ごめんなさい."
  },
  {
    "start": 3831372,
    "end": 3835206,
    "text": "2つに枝分かれしているが、まだ片方しかやっていない。"
  },
  {
    "start": 3835308,
    "end": 3838726,
    "text": "逆伝播を続けて、最終的にはBN差に戻ってこなければならない。"
  },
  {
    "start": 3838828,
    "end": 3842774,
    "text": "そうすれば、プラス・イコールで実際の正しいグラデーションを得ることができる。"
  },
  {
    "start": 3842902,
    "end": 3845898,
    "text": "とりあえず、CPMPも機能することを確認しておくといいだろう。"
  },
  {
    "start": 3845984,
    "end": 3849386,
    "text": "私たちに嘘をついて、すべてが常に正しいと言うのではない。"
  },
  {
    "start": 3849488,
    "end": 3852954,
    "text": "実際、グラデーションが正しくないことを検出することができる。"
  },
  {
    "start": 3853072,
    "end": 3854858,
    "text": "それも良かった。"
  },
  {
    "start": 3854944,
    "end": 3858846,
    "text": "さて、これで微分ができたので、このラインを逆伝播しようとしている。"
  },
  {
    "start": 3859028,
    "end": 3867410,
    "text": "負の0.5のべき乗になるので、べき乗則を持ち出すと、基本的にbmvは次のようになることがわかる。"
  },
  {
    "start": 3867480,
    "end": 3879080,
    "text": "指数を下げると、マイナスゼロの5倍のxとなり、マイナスゼロの5乗から1を引いたマイナス1.5乗となる。"
  },
  {
    "start": 3879690,
    "end": 3890910,
    "text": "ここで、頭の中で小さな連鎖法則を適用する必要がある。なぜなら、この括弧内の式に関して、bmvをさらに微分する必要があるからだ。"
  },
  {
    "start": 3891010,
    "end": 3895466,
    "text": "というのも、これはエレメンツ・ワイズ・オペレーションであり、すべてがかなりシンプルだからだ。"
  },
  {
    "start": 3895568,
    "end": 3897434,
    "text": "だから、そこですることは何もない。"
  },
  {
    "start": 3897632,
    "end": 3902618,
    "text": "これは局所微分であり、次に大域微分をかけて連鎖規則を作る。"
  },
  {
    "start": 3902714,
    "end": 3904750,
    "text": "これはBMVの回だけだ。"
  },
  {
    "start": 3905490,
    "end": 3907466,
    "text": "これが我々の候補者だ。"
  },
  {
    "start": 3907578,
    "end": 3916880,
    "text": "これを下ろし、チェックを外すと、正しい結果が得られることがわかる。"
  },
  {
    "start": 3917330,
    "end": 3925826,
    "text": "さて、次の行に進む前に、ここではnで割る代わりにnマイナス1で割ったベッセルス補正を使っている点について簡単に触れておきたい。"
  },
  {
    "start": 3925928,
    "end": 3929190,
    "text": "ここで正規化すると、2乗の和になる。"
  },
  {
    "start": 3929610,
    "end": 3935782,
    "text": "これは、nから1を引いた1ではなく、nに対して1を使った論文から逸脱していることにお気づきだろう。"
  },
  {
    "start": 3935916,
    "end": 3937670,
    "text": "そこにあるのはrnだ。"
  },
  {
    "start": 3939130,
    "end": 3943750,
    "text": "配列の分散を推定するには2つの方法があることがわかった。"
  },
  {
    "start": 3943910,
    "end": 3951162,
    "text": "ひとつはバイアス付き推定値で、これはnに対して1であり、もうひとつは不偏推定値で、これはnから1を引いた値である。"
  },
  {
    "start": 3951296,
    "end": 3957466,
    "text": "しかし、論文ではこのことがあまり明確に説明されていない。"
  },
  {
    "start": 3957498,
    "end": 3971250,
    "text": "トレーニングの時点ではバイアスのかかったバージョンを使っていると思いますが、後で推論について話しているときに、推論を行うときにはnから1を引いたバイアスのかかっていない推定値を使うと述べています。"
  },
  {
    "start": 3973030,
    "end": 3975246,
    "text": "基本的には推論のため。"
  },
  {
    "start": 3975438,
    "end": 3979990,
    "text": "基本的には、実行平均と実行分散を校正する。"
  },
  {
    "start": 3980140,
    "end": 3988146,
    "text": "つまり、訓練時にはバイアスのかかったバージョンを使い、テスト時にはバイアスのかかっていないバージョンを使うという、訓練とテストのミスマッチが起こるのだ。"
  },
  {
    "start": 3988258,
    "end": 3989986,
    "text": "これは非常に紛らわしいことだと思う。"
  },
  {
    "start": 3990098,
    "end": 4002714,
    "text": "ベッセルの補正や、母集団の大きさや母集団からの標本が非常に小さい場合に、なぜnから1を引いた値で割った方が分散の推定値がよくなるのかについては、こちらをご覧ください。"
  },
  {
    "start": 4002832,
    "end": 4007002,
    "text": "私たちはミニマッチを扱っているのだから。"
  },
  {
    "start": 4007066,
    "end": 4012462,
    "text": "これらのミニマッチは、トレーニングセット全体という大きな母集団の小さなサンプルである。"
  },
  {
    "start": 4012596,
    "end": 4019694,
    "text": "そのため、nに対して1を使って推定すると、実際にはほとんどの場合、分散を過小評価することになる。"
  },
  {
    "start": 4019822,
    "end": 4021390,
    "text": "これはバイアスのかかった推定量である。"
  },
  {
    "start": 4021470,
    "end": 4025250,
    "text": "を使用し、nから1を引いた値で割ることをお勧めします。"
  },
  {
    "start": 4025320,
    "end": 4031670,
    "text": "私が気に入ったこの記事には、実際に完全な理由が書かれているので、ビデオの説明にリンクしておく。"
  },
  {
    "start": 4032170,
    "end": 4040266,
    "text": "さて、トーチ分散を計算するとき、nで割るかnマイナス1で割るかにかかわらず、不偏フラグを取ることに気づくだろう。"
  },
  {
    "start": 4040448,
    "end": 4048154,
    "text": "紛らわしいことに、彼らは不偏不党のデフォルトが何であるか言及していないが、私はデフォルトで不偏不党が真実であると信じている。"
  },
  {
    "start": 4048352,
    "end": 4050940,
    "text": "なぜここのドキュメントがそのことを引用していないのかはわからない。"
  },
  {
    "start": 4051390,
    "end": 4056682,
    "text": "今、バッチノルムの1つのdでは、ドキュメントがまた間違っていて、混乱している。"
  },
  {
    "start": 4056746,
    "end": 4063134,
    "text": "標準偏差はバイアス推定量によって計算されると書いてあるが、実はこれは正確ではない。"
  },
  {
    "start": 4063172,
    "end": 4074722,
    "text": "というのも、実際にはウサギの穴はもっと深く、彼らは論文に忠実に従い、偏ったバージョンをトレーニングに使っているからだ。"
  },
  {
    "start": 4074856,
    "end": 4079618,
    "text": "標準偏差を推定する際には、不偏バージョンを使っている。"
  },
  {
    "start": 4079714,
    "end": 4081538,
    "text": "またもや列車テストのミスマッチだ。"
  },
  {
    "start": 4081634,
    "end": 4086066,
    "text": "というわけで、長くなってしまったが、私は列車テストの不一致は好きではない。"
  },
  {
    "start": 4086178,
    "end": 4093194,
    "text": "私は基本的に、バイアスのかかったバージョン、トレーニング時間、バイアスのかかっていないテスト時間を使用することを考慮しています。"
  },
  {
    "start": 4093232,
    "end": 4097340,
    "text": "私は基本的に、これはバグだと思っている。"
  },
  {
    "start": 4098110,
    "end": 4101770,
    "text": "この論文では、その理由の詳細には触れていない。"
  },
  {
    "start": 4101920,
    "end": 4106494,
    "text": "だから、私は基本的にベッセルの補正を好んで使っている。"
  },
  {
    "start": 4106612,
    "end": 4120660,
    "text": "残念なことに、bash normは、訓練とテストの両方で偏りのないバージョンと偏りのあるバージョンのどちらを使いたいかを示すキーワード引数をとらない。"
  },
  {
    "start": 4121990,
    "end": 4127566,
    "text": "ミニ・バッチのサイズがもう少し大きければ、この問題はずっと少なくなる。"
  },
  {
    "start": 4127678,
    "end": 4130530,
    "text": "それでも、ちょっと味気ない。"
  },
  {
    "start": 4130610,
    "end": 4132774,
    "text": "なぜこれでいいのか、誰か説明してくれないかな。"
  },
  {
    "start": 4132892,
    "end": 4138358,
    "text": "今のところ、トレーニング中もテスト時も、一貫して不偏バージョンを使うことを好む。"
  },
  {
    "start": 4138444,
    "end": 4141578,
    "text": "だから、ここでは1オーバー・マイナス1を使っているんだ。"
  },
  {
    "start": 4141744,
    "end": 4144460,
    "text": "では、実際にこのラインをバックプロパゲートしてみよう。"
  },
  {
    "start": 4145550,
    "end": 4150682,
    "text": "だから、いつも最初にやりたいことは、まず形を精査することなんだ。"
  },
  {
    "start": 4150816,
    "end": 4162446,
    "text": "特にここでは、関係するものの形状を見ると、bnvarの形状は64分の1なので行ベクトルであり、Bndfの2ドットの形状は64分の32である。"
  },
  {
    "start": 4162628,
    "end": 4173262,
    "text": "ここでは明らかに、0番目の軸で和をとり、和を使って図形の最初の次元をつぶしている。"
  },
  {
    "start": 4173406,
    "end": 4179590,
    "text": "これは、バックワードパスでレプリケーションやブロードキャスティングが行われることを示唆している。"
  },
  {
    "start": 4179740,
    "end": 4189862,
    "text": "このパターンにお気づきかもしれないが、基本的に、フォワードパスで合計を出すと、同じ次元に沿ってバックワードパスでレプリケーションやブロードキャストになる。"
  },
  {
    "start": 4190006,
    "end": 4197878,
    "text": "逆に、フォワードパスでレプリケーションやブロードキャストがある場合は、変数の再利用を意味する。"
  },
  {
    "start": 4197974,
    "end": 4202646,
    "text": "つまり、バックワードパスでは、まったく同じ次元の和になる。"
  },
  {
    "start": 4202838,
    "end": 4208640,
    "text": "フォワードパスとバックワードパスでは、この2つがまるで正反対であることに気づいてほしい。"
  },
  {
    "start": 4209090,
    "end": 4220850,
    "text": "さて、形状を理解したら、次に私がしたいことは、いつも頭の中でおもちゃの例を見て、数式における変数の依存関係を大まかに理解することだ。"
  },
  {
    "start": 4221350,
    "end": 4231394,
    "text": "ここでは、bとfの2次元配列があり、これを定数でスケーリングし、列を縦に合計している。"
  },
  {
    "start": 4231522,
    "end": 4248490,
    "text": "2行×2列の行列aがあり、列を合計してスケーリングすると、rhoベクトルb1、b2が得られる。b1はこのようにaに依存し、aをスケーリングした合計であり、b2はこのように2列目を合計してスケーリングしたものである。"
  },
  {
    "start": 4248910,
    "end": 4257482,
    "text": "つまり、基本的に今やりたいことは、b1とb2の微分をaに逆伝播することだ。"
  },
  {
    "start": 4257626,
    "end": 4267774,
    "text": "ということは、頭の中で微分するだけで、この局所微分は、これらのaのそれぞれについて、mから1を引いたものを1倍したものを1倍したものであることは明らかだ。"
  },
  {
    "start": 4267902,
    "end": 4276294,
    "text": "基本的に、bの導関数は、nから1を引いたaの列を1倍して流さなければならない。"
  },
  {
    "start": 4276492,
    "end": 4278438,
    "text": "ここで起きていることは、だいたいこんな感じだ。"
  },
  {
    "start": 4278604,
    "end": 4288322,
    "text": "直感的には、微分の流れは、dbとdiff 2がこの操作の局所微分になることを教えてくれる。"
  },
  {
    "start": 4288466,
    "end": 4295178,
    "text": "ちなみに、これにはいろいろなやり方があるが、私はこのトーチ・ドットのようなものをBN差2のように一度だけやるのが好きだ。"
  },
  {
    "start": 4295264,
    "end": 4300874,
    "text": "2次元の大きな配列を作り、それを拡大縮小する。"
  },
  {
    "start": 4300912,
    "end": 4303440,
    "text": "1.0÷nマイナス1。"
  },
  {
    "start": 4304530,
    "end": 4308446,
    "text": "これはnから1を引いた1の配列である。"
  },
  {
    "start": 4308548,
    "end": 4310490,
    "text": "地元の派生商品のようなものだ。"
  },
  {
    "start": 4310650,
    "end": 4316340,
    "text": "チェーンルールについては、単純にDBMバーを掛け合わせるだけだ。"
  },
  {
    "start": 4318390,
    "end": 4319954,
    "text": "これから何が起こるか、ここに注目してほしい。"
  },
  {
    "start": 4319992,
    "end": 4323634,
    "text": "これは64分の32で、これは64分の1だ。"
  },
  {
    "start": 4323752,
    "end": 4338866,
    "text": "というのも、Pytorchの内部では、基本的にDBNのバー（1×64のΡベクトル）は、この乗算で2つが同じ形になるまで縦にコピーされるからだ。"
  },
  {
    "start": 4338898,
    "end": 4344998,
    "text": "その場合、放送が基本的にレプリケーションを行うように、要素の賢明な乗算が行われる。"
  },
  {
    "start": 4345174,
    "end": 4349754,
    "text": "ここでは、DBN差分2の派生で終わることにする。"
  },
  {
    "start": 4349952,
    "end": 4351978,
    "text": "これが解答候補である。"
  },
  {
    "start": 4352074,
    "end": 4353680,
    "text": "ここで下げよう。"
  },
  {
    "start": 4354050,
    "end": 4358880,
    "text": "チェックするこの行のコメントを解除して、最善を祈ろう。"
  },
  {
    "start": 4359490,
    "end": 4362330,
    "text": "これが正しい式であることがわかる。"
  },
  {
    "start": 4362490,
    "end": 4365378,
    "text": "次に、ここでbとdiffに区別してみよう。"
  },
  {
    "start": 4365544,
    "end": 4370770,
    "text": "ここでは、bとdiffを要素ごとに2乗して、bとdiffを2つにした。"
  },
  {
    "start": 4370920,
    "end": 4375374,
    "text": "これは、単純なエレメント単位の操作なので、比較的単純な派生物である。"
  },
  {
    "start": 4375422,
    "end": 4377074,
    "text": "スカラーの場合と同じようなものだ。"
  },
  {
    "start": 4377192,
    "end": 4383894,
    "text": "Dbとdiffは、これがxの2乗だとすると、その導関数はxの2乗ということになる。"
  },
  {
    "start": 4383932,
    "end": 4386694,
    "text": "単純にbとdiffの2倍である。"
  },
  {
    "start": 4386812,
    "end": 4388310,
    "text": "それが地元の派生商品だ。"
  },
  {
    "start": 4388890,
    "end": 4390482,
    "text": "倍のチェーンルール。"
  },
  {
    "start": 4390546,
    "end": 4392250,
    "text": "これらの形状は同じである。"
  },
  {
    "start": 4392320,
    "end": 4393702,
    "text": "同じ形をしている。"
  },
  {
    "start": 4393846,
    "end": 4395626,
    "text": "倍だ。"
  },
  {
    "start": 4395808,
    "end": 4398070,
    "text": "これがこの変数のバックワードパスだ。"
  },
  {
    "start": 4398150,
    "end": 4399820,
    "text": "それをここに持ってこよう。"
  },
  {
    "start": 4400510,
    "end": 4404094,
    "text": "というのも、DBMの差分はすでに計算済みだからだ。"
  },
  {
    "start": 4404212,
    "end": 4416154,
    "text": "なぜなら、bとdiffはすでにbとrawからこちらにバックプロパゲートされていたからだ。"
  },
  {
    "start": 4416282,
    "end": 4418558,
    "text": "これで2つ目のブランチが完成した。"
  },
  {
    "start": 4418654,
    "end": 4420910,
    "text": "だから、プラス・イコールにしなければならないんだ。"
  },
  {
    "start": 4421070,
    "end": 4424754,
    "text": "思い起こせば、以前はbとdiffの微分が間違っていた。"
  },
  {
    "start": 4424872,
    "end": 4430258,
    "text": "この最後の欠けている部分を付け加えれば、正確な正しさが得られると期待している。"
  },
  {
    "start": 4430434,
    "end": 4431798,
    "text": "走ろう"
  },
  {
    "start": 4431964,
    "end": 4436630,
    "text": "bとdiffは正確に正しい微分を表示するようになった。"
  },
  {
    "start": 4437530,
    "end": 4439330,
    "text": "それは慰めになる。"
  },
  {
    "start": 4439410,
    "end": 4442040,
    "text": "では、この行を逆伝播してみよう。"
  },
  {
    "start": 4443310,
    "end": 4447338,
    "text": "もちろん、最初にやることはシェイプのチェックだ。"
  },
  {
    "start": 4447424,
    "end": 4449994,
    "text": "基本的に、この形状は32×64である。"
  },
  {
    "start": 4450112,
    "end": 4456046,
    "text": "HPBNは同じ形だが、bnの平均Iは64分の1のΡベクトルである。"
  },
  {
    "start": 4456148,
    "end": 4458698,
    "text": "このマイナスは実際に放送をすることになる。"
  },
  {
    "start": 4458794,
    "end": 4460462,
    "text": "だから、その点には注意しなければならない。"
  },
  {
    "start": 4460596,
    "end": 4466926,
    "text": "をヒントに、やはり二元性のため、フォワードパスでの放送は変数の再利用を意味する。"
  },
  {
    "start": 4466958,
    "end": 4469746,
    "text": "したがって、バックワードパスには合計がある。"
  },
  {
    "start": 4469928,
    "end": 4471586,
    "text": "ここでバックワードパスを書き出してみよう。"
  },
  {
    "start": 4471608,
    "end": 4479250,
    "text": "HPBNに逆伝播する。"
  },
  {
    "start": 4479330,
    "end": 4485014,
    "text": "そうすると、ここにある各要素の局所導関数は、ここにある対応する要素の導関数のみとなる。"
  },
  {
    "start": 4485212,
    "end": 4489926,
    "text": "基本的にこれは、グラデーションが単にコピーされることを意味する。"
  },
  {
    "start": 4490038,
    "end": 4491286,
    "text": "単なる変数の割り当てだ。"
  },
  {
    "start": 4491318,
    "end": 4492166,
    "text": "それは平等だ。"
  },
  {
    "start": 4492278,
    "end": 4499290,
    "text": "dbndifの正確なコピーを作るために、念のためこのテンソルをクローンしておこう。"
  },
  {
    "start": 4500130,
    "end": 4502382,
    "text": "その後、ここに逆伝播される。"
  },
  {
    "start": 4502516,
    "end": 4511866,
    "text": "ここで私がやりたいと思っているのは、DBNミニは基本的に、局所微分は何か？"
  },
  {
    "start": 4511978,
    "end": 4520100,
    "text": "まあ、bとdiffの形のようなネガトーチですよね。"
  },
  {
    "start": 4522150,
    "end": 4530040,
    "text": "そして、ここで微分したものをdbとdiffにかける。"
  },
  {
    "start": 4532890,
    "end": 4536742,
    "text": "これは複製されたbと平均の逆伝播である。"
  },
  {
    "start": 4536796,
    "end": 4542558,
    "text": "だから、ブロードキャスティングのレプリケーションでバックプロパゲートしなければならない。"
  },
  {
    "start": 4542594,
    "end": 4544214,
    "text": "私はそれを和算で行う。"
  },
  {
    "start": 4544342,
    "end": 4550650,
    "text": "この全体を、レプリケーションであるゼロ次元で合計するんだ。"
  },
  {
    "start": 4553550,
    "end": 4558478,
    "text": "ところで、これをよく見ると、これと同じ形をしていることに気づくだろう。"
  },
  {
    "start": 4558564,
    "end": 4566098,
    "text": "つまり、ここでやっていることは、dbとdiffを掛け合わせたoneの配列に過ぎないので、実はあまり意味がない。"
  },
  {
    "start": 4566184,
    "end": 4571410,
    "text": "実際、私はこれをするだけで、それは同等なのだ。"
  },
  {
    "start": 4572070,
    "end": 4574958,
    "text": "これが後方パス候補だ。"
  },
  {
    "start": 4575144,
    "end": 4581400,
    "text": "ここにコピーして、これとこれをコメントアウトさせてください。"
  },
  {
    "start": 4582570,
    "end": 4583320,
    "text": "入る。"
  },
  {
    "start": 4584090,
    "end": 4585560,
    "text": "それは間違っている。"
  },
  {
    "start": 4587290,
    "end": 4588150,
    "text": "くそっ。"
  },
  {
    "start": 4589390,
    "end": 4590218,
    "text": "実は、申し訳ない。"
  },
  {
    "start": 4590304,
    "end": 4591578,
    "text": "これは間違っているはずだ。"
  },
  {
    "start": 4591664,
    "end": 4606858,
    "text": "bnの差分からHPBNに逆伝播しているので、間違っているはずなのだが、まだ終わっていない。"
  },
  {
    "start": 4606954,
    "end": 4609354,
    "text": "まだ終わっていませんし、間違っていると思います。"
  },
  {
    "start": 4609402,
    "end": 4610480,
    "text": "これでいい。"
  },
  {
    "start": 4610850,
    "end": 4615010,
    "text": "では、BN mean IからHPBNに逆伝播してみよう。"
  },
  {
    "start": 4617190,
    "end": 4623630,
    "text": "なぜなら、ゼロ次元に沿ったブロードキャスト、あるいはゼロ次元に沿った和があるからだ。"
  },
  {
    "start": 4623710,
    "end": 4626834,
    "text": "これは今後、後方パスで放送されることになる。"
  },
  {
    "start": 4626952,
    "end": 4634646,
    "text": "この路線は、以前、実際に何度もあった路線と非常によく似ているので、もう少し速く行こうと思う。"
  },
  {
    "start": 4634828,
    "end": 4642922,
    "text": "DHのprebnは、勾配がnにわたって1ずつスケーリングされる。"
  },
  {
    "start": 4643056,
    "end": 4655418,
    "text": "そして基本的に、このDBN上の勾配は、nを1倍にして、すべての列を横切ってDhPBNに流れ込む。"
  },
  {
    "start": 4655594,
    "end": 4659422,
    "text": "私たちが欲しいのは、nを1倍したものだ。"
  },
  {
    "start": 4659556,
    "end": 4661680,
    "text": "前置きが長くなった。"
  },
  {
    "start": 4665270,
    "end": 4666974,
    "text": "グラデーションを縮小する。"
  },
  {
    "start": 4667022,
    "end": 4673554,
    "text": "この行をすべて複製する必要がある。"
  },
  {
    "start": 4673752,
    "end": 4688730,
    "text": "私は、基本的にHPBNのように一度トーチでやってみたいし、再現の作業は放送に任せたい。"
  },
  {
    "start": 4689230,
    "end": 4695900,
    "text": "そんな感じだ。"
  },
  {
    "start": 4696270,
    "end": 4703120,
    "text": "これはDHPpNであり、プラスイコールができることを願っている。"
  },
  {
    "start": 4707370,
    "end": 4711666,
    "text": "これが放送で、これがスケーリングだ。"
  },
  {
    "start": 4711778,
    "end": 4713160,
    "text": "これは正しいはずだ。"
  },
  {
    "start": 4713610,
    "end": 4718134,
    "text": "さて、これでバストローム層のバックプロパゲーションは完了だ。"
  },
  {
    "start": 4718182,
    "end": 4722458,
    "text": "リニアレイヤー1を逆伝播しよう。"
  },
  {
    "start": 4722624,
    "end": 4729520,
    "text": "さて、すべてが少し縦に狂ってきたので、ここに行をコピーペーストして、この1行を逆伝播してみよう。"
  },
  {
    "start": 4730050,
    "end": 4735310,
    "text": "もちろん、まず形状をチェックし、これが32×64であることを確認する。"
  },
  {
    "start": 4735460,
    "end": 4743698,
    "text": "McATは32×30、Wは30×64、Bは64である。"
  },
  {
    "start": 4743864,
    "end": 4749278,
    "text": "さっきも言ったように、線形レイヤーを逆伝播するのは、形を合わせるだけでかなり簡単だ。"
  },
  {
    "start": 4749374,
    "end": 4750546,
    "text": "そうしよう"
  },
  {
    "start": 4750648,
    "end": 4762198,
    "text": "DmCaTは、DH prebnの行列の掛け算に、wの1と転置を加えたものでなければならない。"
  },
  {
    "start": 4762364,
    "end": 4777050,
    "text": "mcatを32×30にするには、DhPNを32×64とし、wを1回転置して掛ける必要がある。"
  },
  {
    "start": 4779970,
    "end": 4785326,
    "text": "ドウを手に入れるには、30×64で終わらせる必要がある。"
  },
  {
    "start": 4785508,
    "end": 4795950,
    "text": "それを得るには、MCATのトランスポーズを取り、それにDHプリピアンを掛ける必要がある。"
  },
  {
    "start": 4798310,
    "end": 4800420,
    "text": "ようやくDBを手に入れることができた。"
  },
  {
    "start": 4801750,
    "end": 4809858,
    "text": "これは足し算であり、基本的にはDH prebianの要素をある次元に沿って合計すればいいということを見た。"
  },
  {
    "start": 4810034,
    "end": 4816534,
    "text": "寸法がうまくいくように、このゼロ軸に沿って合計し、この寸法をなくす必要がある。"
  },
  {
    "start": 4816662,
    "end": 4822780,
    "text": "64の1次元ベクトルだけを取得したいので、dimは保持しない。"
  },
  {
    "start": 4823150,
    "end": 4826090,
    "text": "これらは主張されている派生物である。"
  },
  {
    "start": 4827310,
    "end": 4833230,
    "text": "それをここに書いて、3行のコメントを解除して、指をくわえて見ていよう。"
  },
  {
    "start": 4833970,
    "end": 4835182,
    "text": "すべてが素晴らしい。"
  },
  {
    "start": 4835316,
    "end": 4837326,
    "text": "よし、では、もう少しそこまで続けよう。"
  },
  {
    "start": 4837428,
    "end": 4842926,
    "text": "McAtの導関数を持っているので、Mに逆伝播したい。"
  },
  {
    "start": 4843108,
    "end": 4846020,
    "text": "もう一度、この行をここにコピーした。"
  },
  {
    "start": 4846470,
    "end": 4849774,
    "text": "これがフォワードパス、そしてこれがシェイプだ。"
  },
  {
    "start": 4849902,
    "end": 4856454,
    "text": "ここでの形状は32×30であり、Mの元の形状は32×3×10であったことを思い出してほしい。"
  },
  {
    "start": 4856572,
    "end": 4864034,
    "text": "フォワードパスのこのレイヤーは、ご記憶の通り、310次元の文字ベクトルを連結している。"
  },
  {
    "start": 4864162,
    "end": 4866454,
    "text": "だから、今はそれを元に戻したい。"
  },
  {
    "start": 4866652,
    "end": 4871914,
    "text": "というのも、後方へのパスがあるからだ。"
  },
  {
    "start": 4871952,
    "end": 4872842,
    "text": "どんな眺めですか？"
  },
  {
    "start": 4872976,
    "end": 4875510,
    "text": "ビューは単なる配列の転載表現である。"
  },
  {
    "start": 4875590,
    "end": 4878394,
    "text": "配列をどう解釈するかの論理的な形に過ぎない。"
  },
  {
    "start": 4878442,
    "end": 4881630,
    "text": "以前のように解釈し直そう。"
  },
  {
    "start": 4881780,
    "end": 4889070,
    "text": "つまり、DMは32×30ではなく、基本的にはdmcatなのだ。"
  },
  {
    "start": 4889490,
    "end": 4900098,
    "text": "を元のシェイプとして見るなら、タプルをビューに渡すことができる。"
  },
  {
    "start": 4900264,
    "end": 4909446,
    "text": "つまり、このビューを再表現して、この行のコメントを解除すればいいのだ。"
  },
  {
    "start": 4909548,
    "end": 4913880,
    "text": "Mの導関数が正しいことを祈るよ。"
  },
  {
    "start": 4914970,
    "end": 4919546,
    "text": "この場合、微分の形状を元のビューに再表現するだけでよかった。"
  },
  {
    "start": 4919728,
    "end": 4921274,
    "text": "さあ、最終ラインだ。"
  },
  {
    "start": 4921312,
    "end": 4925658,
    "text": "バックプロパゲートするために残っているのは、このインデックス操作だけだ。"
  },
  {
    "start": 4925744,
    "end": 4927750,
    "text": "Mはxbでcである。"
  },
  {
    "start": 4927910,
    "end": 4930574,
    "text": "だから、前と同じように、この行をここにコピーペーストした。"
  },
  {
    "start": 4930692,
    "end": 4934560,
    "text": "関係するすべてのものの形を見て、これがどのように機能したかを思い起こそう。"
  },
  {
    "start": 4935170,
    "end": 4938960,
    "text": "つまり、m字型は32×3×10だった。"
  },
  {
    "start": 4939490,
    "end": 4941146,
    "text": "それは32の例だ。"
  },
  {
    "start": 4941258,
    "end": 4943406,
    "text": "となると、登場人物は3人。"
  },
  {
    "start": 4943518,
    "end": 4946050,
    "text": "それぞれが10次元の埋め込みを持っている。"
  },
  {
    "start": 4946630,
    "end": 4954194,
    "text": "これはルックアップテーブルCを使うことで達成された。ルックアップテーブルCには27の可能な文字があり、それぞれ10次元である。"
  },
  {
    "start": 4954322,
    "end": 4960550,
    "text": "このテンソルxbで指定された行を見上げた。"
  },
  {
    "start": 4960970,
    "end": 4962854,
    "text": "xbは32×3である。"
  },
  {
    "start": 4962972,
    "end": 4970300,
    "text": "これは基本的に、それぞれの例について、どのキャラクターがその例の一部であるかのIDまたはインデックスを与えてくれる。"
  },
  {
    "start": 4970830,
    "end": 4976886,
    "text": "そこで、ここではこのテンソルxBの最初の5行を示している。"
  },
  {
    "start": 4977078,
    "end": 4985920,
    "text": "例えば、このバッチの最初の例では、最初の文字と最初の文字と4番目の文字がニューラルネットに入ってくる。"
  },
  {
    "start": 4986370,
    "end": 4991410,
    "text": "であれば、1114の次の文字を予測したい。"
  },
  {
    "start": 4992230,
    "end": 5003778,
    "text": "基本的にここで起こっていることは、xbの中に整数があり、その整数のひとつひとつが、cのどの行を抜き出したいかを指定している、ということだ。"
  },
  {
    "start": 5003944,
    "end": 5013458,
    "text": "そして、抜き出した行を32×3×10のテンソルに並べ、このテンソルにパッケージする。"
  },
  {
    "start": 5013634,
    "end": 5016050,
    "text": "今起きているのはDMPだ。"
  },
  {
    "start": 5016210,
    "end": 5026422,
    "text": "これらの基本的に抜き出された行のひとつひとつについて、我々は今その勾配を持っているが、それらはこの32×3×10のテンソルの中に配置されている。"
  },
  {
    "start": 5026566,
    "end": 5031626,
    "text": "あとは、このグラデーションを逆向きにルーティングするだけだ。"
  },
  {
    "start": 5031738,
    "end": 5038640,
    "text": "これらの10次元の埋め込みが、すべてCのどの行から来たかを見つける必要がある。"
  },
  {
    "start": 5039010,
    "end": 5041790,
    "text": "それなら、DCに預ける必要がある。"
  },
  {
    "start": 5043010,
    "end": 5045502,
    "text": "インデックスを元に戻せばいいだけだ。"
  },
  {
    "start": 5045646,
    "end": 5057160,
    "text": "もちろん、これらのCの行のいずれかが複数回使用された場合、それはほぼ間違いなく、1行目と1行目のように複数回使用された場合、そこに到着するグラデーションは加算されなければならないことを忘れてはならない。"
  },
  {
    "start": 5057930,
    "end": 5060390,
    "text": "が発生するたびに、足し算をしなければならない。"
  },
  {
    "start": 5061130,
    "end": 5062646,
    "text": "では、これを書き出してみよう。"
  },
  {
    "start": 5062748,
    "end": 5067450,
    "text": "残念ながら、Pythonでこれを行うのに、forループよりもずっと良い方法を私は知らない。"
  },
  {
    "start": 5067790,
    "end": 5071574,
    "text": "誰かがベクトル化された効率的なオペレーションを思いつくかもしれない。"
  },
  {
    "start": 5071622,
    "end": 5073846,
    "text": "とりあえず、forループを使ってみよう。"
  },
  {
    "start": 5073958,
    "end": 5082970,
    "text": "cのようにトーチ・ゼロを作り、27×10のゼロのテンソルだけを初期化しよう。"
  },
  {
    "start": 5083130,
    "end": 5091154,
    "text": "誰かがもっといい方法を知っているかもしれない。"
  },
  {
    "start": 5091192,
    "end": 5105960,
    "text": "xb のすべての要素（これらの整数）を繰り返し処理し、この位置のインデックスを取得する。"
  },
  {
    "start": 5106730,
    "end": 5115754,
    "text": "インデックスは基本的にKJのxbであり、その例としては11や14などがある。"
  },
  {
    "start": 5115952,
    "end": 5130060,
    "text": "今、フォワード・パスでは、基本的にインデックスでcの行を取り、KでMに預けた。"
  },
  {
    "start": 5130690,
    "end": 5133146,
    "text": "それが起こったことであり、そこにパッケージされている。"
  },
  {
    "start": 5133258,
    "end": 5139310,
    "text": "今は逆に、KJのポジションにDMを配置する必要がある。"
  },
  {
    "start": 5139830,
    "end": 5148660,
    "text": "これで、各ポジションについて微分ができ、10次元になった。"
  },
  {
    "start": 5149110,
    "end": 5160198,
    "text": "IxでのDCはむしろこれだが、プラス・イコールは、同じ行が何度も何度も使われたように、複数回発生する可能性があるからだ。"
  },
  {
    "start": 5160364,
    "end": 5166940,
    "text": "そのため、デリバティブはすべてインデックスを逆行し、追加されることになる。"
  },
  {
    "start": 5167870,
    "end": 5171050,
    "text": "これが私の解決策の候補だ。"
  },
  {
    "start": 5172590,
    "end": 5174620,
    "text": "ここにコピーしよう。"
  },
  {
    "start": 5176510,
    "end": 5180110,
    "text": "コメントを解除して、指をくわえて見ていよう。"
  },
  {
    "start": 5180930,
    "end": 5181790,
    "text": "イェーイ。"
  },
  {
    "start": 5182450,
    "end": 5183406,
    "text": "それだけだ。"
  },
  {
    "start": 5183428,
    "end": 5186990,
    "text": "私たちは、この獣全体に逆宣伝してきた。"
  },
  {
    "start": 5187970,
    "end": 5189358,
    "text": "さあ、行こう。"
  },
  {
    "start": 5189444,
    "end": 5190734,
    "text": "まったく理にかなっている。"
  },
  {
    "start": 5190932,
    "end": 5192958,
    "text": "さて、次はエクササイズ2だ。"
  },
  {
    "start": 5193124,
    "end": 5202862,
    "text": "基本的に、この最初の練習では、我々はあまりにも多くの仕事をこなし、あまりにも多くの逆伝播をしていた。"
  },
  {
    "start": 5203006,
    "end": 5215010,
    "text": "その理由は、例えば、ここではこの損失計算を複数行に分け、すべてを最小のアトミックピースに分割し、そのすべてを個別にバックプロパゲートしたからだ。"
  },
  {
    "start": 5215170,
    "end": 5225830,
    "text": "その結果、損失の数式を見れば、紙とペンで微分をすれば、多くの項が相殺され、単純化できることがわかった。"
  },
  {
    "start": 5225910,
    "end": 5233806,
    "text": "最終的に得られる数式は、あなたが行ったすべての小片を逆伝播するよりもはるかに短く、実装しやすくなる。"
  },
  {
    "start": 5233988,
    "end": 5238970,
    "text": "以前は、ロジットからロスへの複雑なフォワードパスがあった。"
  },
  {
    "start": 5239130,
    "end": 5243962,
    "text": "Pytorchでは、クロスエントロピーを呼び出すだけで、すべてが統合される。"
  },
  {
    "start": 5244026,
    "end": 5248418,
    "text": "ロジットとラベルを渡すだけで、私がここで検証したのとまったく同じ損失が得られる。"
  },
  {
    "start": 5248504,
    "end": 5258438,
    "text": "今までのロスと、演算の塊をひとつの数式にすることによる高速ロスは同じだが、フォワードパスではずっとずっと高速だ。"
  },
  {
    "start": 5258604,
    "end": 5260934,
    "text": "後方へのパスもはるかに速い。"
  },
  {
    "start": 5261052,
    "end": 5267762,
    "text": "その理由は、これを数学的な形だけを見て微分し直すと、非常に小さく短い式になってしまうからだ。"
  },
  {
    "start": 5267906,
    "end": 5269338,
    "text": "それがここでやりたいことだ。"
  },
  {
    "start": 5269424,
    "end": 5276246,
    "text": "一回の操作で、あるいは一回で、あるいは非常に素早く直接デロイトに入りたい。"
  },
  {
    "start": 5276438,
    "end": 5281950,
    "text": "delojitsをlogitsとybsの関数として実装する必要がある。"
  },
  {
    "start": 5282370,
    "end": 5286078,
    "text": "ここでやったことよりもかなり短くなるだろう。"
  },
  {
    "start": 5286164,
    "end": 5289520,
    "text": "デロジットに行くには、わざわざここまで来なければならなかった。"
  },
  {
    "start": 5289890,
    "end": 5296146,
    "text": "この作業はすべて、もっともっと簡単な数式で省略できる。"
  },
  {
    "start": 5296328,
    "end": 5298962,
    "text": "自分でやってみればいい。"
  },
  {
    "start": 5299096,
    "end": 5305490,
    "text": "基本的には、損失の数学的表現が何であるかを調べ、ロジットに関して微分する。"
  },
  {
    "start": 5306090,
    "end": 5308550,
    "text": "ヒントをあげよう。"
  },
  {
    "start": 5309050,
    "end": 5311974,
    "text": "もちろん、自分で十分に試すこともできるが、そうでない場合は。"
  },
  {
    "start": 5312012,
    "end": 5314790,
    "text": "数学的に始めるヒントをあげよう。"
  },
  {
    "start": 5316570,
    "end": 5319606,
    "text": "基本的に、ここで起きているのはロジットだ。"
  },
  {
    "start": 5319718,
    "end": 5322918,
    "text": "そして、ロジットを取って確率を出すソフトマックスがある。"
  },
  {
    "start": 5323094,
    "end": 5338750,
    "text": "次に、正しい次の文字の正体を使って確率の列を抜き出し、その負の対数をとって負の対数確率を求め、すべての対数確率または負の対数確率を平均して損失を求める。"
  },
  {
    "start": 5339810,
    "end": 5351998,
    "text": "ここでいうpとは、すべての確率のベクトルのようなものだ。"
  },
  {
    "start": 5352174,
    "end": 5360354,
    "text": "yがラベルのy番目の位置で、pはもちろんソフトマックスである。"
  },
  {
    "start": 5360482,
    "end": 5366474,
    "text": "この確率ベクトルのpのi番目の成分は、単なるソフトマックス関数である。"
  },
  {
    "start": 5366592,
    "end": 5373334,
    "text": "すべてのロジットを基本的にeのべき乗にし、正規化する。"
  },
  {
    "start": 5373382,
    "end": 5374860,
    "text": "すべてが1つになる。"
  },
  {
    "start": 5375390,
    "end": 5379698,
    "text": "ここでyのpを書き出せば、ソフトマックスを書き出すことができる。"
  },
  {
    "start": 5379814,
    "end": 5386910,
    "text": "ということは、基本的に我々が興味があるのは、i番目のロジットに関する損失の導関数である。"
  },
  {
    "start": 5387890,
    "end": 5400242,
    "text": "つまり、基本的にはこの式をDLIで表したもので、lには特定のラベルyでインデックスを付け、下にはeのj乗和をLjとし、すべての負の対数を取る。"
  },
  {
    "start": 5400376,
    "end": 5406654,
    "text": "紙とペンを使って、DLIによる損失量を表す式が実際に導き出せるかどうか、試してみてほしい。"
  },
  {
    "start": 5406782,
    "end": 5408822,
    "text": "では、ここでそれを実装しよう。"
  },
  {
    "start": 5408956,
    "end": 5411320,
    "text": "さて、ではここで結果を発表しよう。"
  },
  {
    "start": 5411770,
    "end": 5416722,
    "text": "これは、勾配を解析的に導き出すために私が行った数学の一部である。"
  },
  {
    "start": 5416866,
    "end": 5422810,
    "text": "つまり、学士号取得の1年目か2年目に習った微積分のルールを応用しているだけなのだ。"
  },
  {
    "start": 5422960,
    "end": 5425930,
    "text": "式がかなり単純化されることがわかる。"
  },
  {
    "start": 5426000,
    "end": 5438302,
    "text": "logitsの内部で関心のあるi番目のインデックスがラベルと等しいか、ラベルと等しくないかのどちらかである場合、分析を分ける必要がある。"
  },
  {
    "start": 5438436,
    "end": 5440960,
    "text": "私たちが行き着くところは、とてもとてもシンプルなものだ。"
  },
  {
    "start": 5441330,
    "end": 5452002,
    "text": "基本的には、ソフトマックスの後の確率ベクトルをpとするIでのpか、単純に1を引くIでのpのどちらかになる。"
  },
  {
    "start": 5452136,
    "end": 5461910,
    "text": "いずれにせよ、ソフトマックスpを計算し、正しい次元で1を引くだけでいい。"
  },
  {
    "start": 5462410,
    "end": 5466870,
    "text": "基本的にこれを実装してみよう。ただし、これはあくまで一つの例に対して行われるものであることを念頭に置かなければならない。"
  },
  {
    "start": 5467020,
    "end": 5471898,
    "text": "ここで、私たちはたくさんの例を扱っているので、その点には注意しなければならない。"
  },
  {
    "start": 5471984,
    "end": 5476438,
    "text": "とすると、バッチでの損失はすべての例の平均損失となる。"
  },
  {
    "start": 5476534,
    "end": 5483806,
    "text": "言い換えれば、すべての個々の例について、個々の例の損失を合計してnで割ったものなのか？"
  },
  {
    "start": 5483908,
    "end": 5485774,
    "text": "バックプロパゲートも必要だ。"
  },
  {
    "start": 5485812,
    "end": 5487726,
    "text": "気をつけて"
  },
  {
    "start": 5487908,
    "end": 5491230,
    "text": "dlojitsはFドット・ソフトマックスになる。"
  },
  {
    "start": 5492870,
    "end": 5502162,
    "text": "Pytorchにはソフトマックス関数があり、それを呼び出すことができる。ロジットにソフトマックスを適用し、1次元の次元に入りたい。"
  },
  {
    "start": 5502296,
    "end": 5506710,
    "text": "基本的には、これらのロジットの行に沿ってソフトマックスを行いたい。"
  },
  {
    "start": 5507450,
    "end": 5510390,
    "text": "そして、正しい位置で1を引く必要がある。"
  },
  {
    "start": 5510540,
    "end": 5522300,
    "text": "delojitsは、すべての行を反復処理し、yb内の正しいラベルによって提供される列にインデックスを作成する際に、1つ減算する必要がある。"
  },
  {
    "start": 5522990,
    "end": 5525334,
    "text": "そして最後に平均損失だ。"
  },
  {
    "start": 5525382,
    "end": 5526230,
    "text": "それが損失だ。"
  },
  {
    "start": 5526310,
    "end": 5530334,
    "text": "平均すると、すべての負けを合計したnが1オーバーになる。"
  },
  {
    "start": 5530452,
    "end": 5533710,
    "text": "だから、その分割もバックプロパゲートする必要がある。"
  },
  {
    "start": 5534130,
    "end": 5542482,
    "text": "勾配は平均の関係でn倍に縮小されなければならないが、そうでなければこのような結果になるはずである。"
  },
  {
    "start": 5542616,
    "end": 5557782,
    "text": "しかし同時に、PytorchのロジットとRdのロジットの最大差は5eマイナス9のオーダーであることがわかる。"
  },
  {
    "start": 5557836,
    "end": 5559350,
    "text": "それは小さな、小さな数字だ。"
  },
  {
    "start": 5559500,
    "end": 5568630,
    "text": "ローディング・ポイントが不安定なため、正確なビットごとの結果は得られないが、基本的にはおおよそ正しい答えが得られる。"
  },
  {
    "start": 5569050,
    "end": 5580090,
    "text": "というのも、デロジッツとは何かということを直感的に理解してもらいたいからだ。"
  },
  {
    "start": 5580770,
    "end": 5588266,
    "text": "ここでデロジットを視覚化してみると、27文字で32例のバッチがあることがわかる。"
  },
  {
    "start": 5588458,
    "end": 5590554,
    "text": "直感的にデロジットとは何か？"
  },
  {
    "start": 5590602,
    "end": 5590910,
    "text": "そうだね。"
  },
  {
    "start": 5590980,
    "end": 5595794,
    "text": "デロジットとは、フォワードパスにおける確率行列の確率である。"
  },
  {
    "start": 5595912,
    "end": 5600980,
    "text": "そして、この黒い四角は1を引いた正しいインデックスの位置である。"
  },
  {
    "start": 5601750,
    "end": 5603726,
    "text": "これは何をしているのか？"
  },
  {
    "start": 5603768,
    "end": 5604022,
    "text": "そうだろう？"
  },
  {
    "start": 5604076,
    "end": 5606818,
    "text": "これらはデロジットに関する派生商品である。"
  },
  {
    "start": 5606994,
    "end": 5611240,
    "text": "では、最初の行だけを見てみよう。"
  },
  {
    "start": 5611850,
    "end": 5613014,
    "text": "それが私がここでやっていることだ。"
  },
  {
    "start": 5613052,
    "end": 5631214,
    "text": "このロジットの確率を計算し、最初の行だけを取り出して、これが確率の行で、最初の行のデロジットにnを掛けて、nによるスケーリングがないようにしています。"
  },
  {
    "start": 5631332,
    "end": 5637054,
    "text": "の場合、正しいインデックスの位置はマイナスが1に等しいので、その位置でマイナス1。"
  },
  {
    "start": 5637252,
    "end": 5645266,
    "text": "つまり、デロジッツをゼロとして、それを合計すると、実際にはゼロになる。"
  },
  {
    "start": 5645448,
    "end": 5651970,
    "text": "だから、各セルのこの勾配は力のようなものだと考えるべきだ。"
  },
  {
    "start": 5652870,
    "end": 5663682,
    "text": "私たちは基本的に、誤ったキャリッシャーの確率を引き下げ、正しいインデックスでの確率を引き上げるつもりだ。"
  },
  {
    "start": 5663826,
    "end": 5667698,
    "text": "というのが各列で基本的に起こっていることだ。"
  },
  {
    "start": 5667874,
    "end": 5673802,
    "text": "和がゼロになるため、押しと引きの量は正確に等しくなる。"
  },
  {
    "start": 5673936,
    "end": 5681050,
    "text": "確率を引き下げる量と、正しい文字の確率を押し上げる量は等しい。"
  },
  {
    "start": 5681210,
    "end": 5684570,
    "text": "斥力と引力は等しい。"
  },
  {
    "start": 5684730,
    "end": 5690382,
    "text": "今のニューラルネットは、巨大な滑車システムのようなものだ。"
  },
  {
    "start": 5690436,
    "end": 5696898,
    "text": "私たちはこのロジットの上にいて、不正解の確率を引き下げ、正解の確率を引き上げている。"
  },
  {
    "start": 5697064,
    "end": 5706686,
    "text": "この複雑なプーリー・システムでは、すべてが数学的に決定されているので、この張力がこの複雑なプーリー・メカニズムに変換されるようなものだと考えればいい。"
  },
  {
    "start": 5706798,
    "end": 5710290,
    "text": "そして最終的には、重みとバイアスに引っ張られる。"
  },
  {
    "start": 5710450,
    "end": 5715506,
    "text": "基本的には、更新のたびに、それぞれの要素について私たちが望む方向に引っ張っていくような感じだ。"
  },
  {
    "start": 5715618,
    "end": 5718494,
    "text": "パラメータはゆっくりとタグに与えられる。"
  },
  {
    "start": 5718562,
    "end": 5721914,
    "text": "これが、ニューラルネットをトレーニングするときの高度なレベルだ。"
  },
  {
    "start": 5722112,
    "end": 5728022,
    "text": "だから、これらのグラデーションにおける押しと引きの力は、実はとても直感的なものだと思う。"
  },
  {
    "start": 5728086,
    "end": 5731898,
    "text": "ここでは正解と不正解を押したり引いたりしている。"
  },
  {
    "start": 5731994,
    "end": 5739278,
    "text": "力の大きさは、フォワードパスで出た確率に比例する。"
  },
  {
    "start": 5739444,
    "end": 5753362,
    "text": "例えば、確率が正確に正しかったとしたら、正しい位置の1つ以外はすべてゼロになる。"
  },
  {
    "start": 5753496,
    "end": 5761618,
    "text": "あなたの予測がどの程度間違っているかは、まさにその次元でプルやプッシュを得ることになる量なのだ。"
  },
  {
    "start": 5761794,
    "end": 5778780,
    "text": "例えば、ここに非常に自信のある誤予測の要素があった場合、何が起こるかというと、その要素は非常に大きく引き下げられ、正解は同じ程度まで引き上げられ、他のキャラクターはあまり影響を受けない。"
  },
  {
    "start": 5779150,
    "end": 5784094,
    "text": "その場合、予測を誤る度合いは、引きの強さに比例する。"
  },
  {
    "start": 5784292,
    "end": 5788666,
    "text": "それは、このテンソルのすべての次元で独立して起こっている。"
  },
  {
    "start": 5788778,
    "end": 5791278,
    "text": "とても直感的で、簡単に考えることができる。"
  },
  {
    "start": 5791364,
    "end": 5797522,
    "text": "これが基本的にクロスエントロピー損失のマジックであり、ニューラルネットの後方パスでダイナミックに行われていることなのだ。"
  },
  {
    "start": 5797656,
    "end": 5804066,
    "text": "このエクササイズは、あなたの「楽しい」の定義にもよるが、とても楽しいエクササイズだ。"
  },
  {
    "start": 5804168,
    "end": 5809622,
    "text": "練習その2でクロスエントロピー損失に対して行ったのとまったく同じことを、バッチ正規化に対して行うつもりだ。"
  },
  {
    "start": 5809756,
    "end": 5820650,
    "text": "つまり、これをひとつの数式とみなし、非常に効率的な方法で逆伝播するのである。なぜなら、bashの正規化のバックワードパスについて、よりシンプルな式を導き出すからである。"
  },
  {
    "start": 5820990,
    "end": 5823226,
    "text": "私たちはペンと紙を使ってそれを行うつもりです。"
  },
  {
    "start": 5823408,
    "end": 5832880,
    "text": "以前、私たちはbashの正規化を小さな中間的な部分とその中のアトミックな操作に分解し、それをひとつひとつバックプロパゲートしていった。"
  },
  {
    "start": 5833490,
    "end": 5842834,
    "text": "これで、バッシュ用語のフォワード・パスがひとつにまとまり、以前とまったく同じ結果が得られることがわかった。"
  },
  {
    "start": 5843032,
    "end": 5850334,
    "text": "さて、バックワードパスについては、基本的にこの操作全体をバックプロパゲートするための1つの式を実装したい。"
  },
  {
    "start": 5850382,
    "end": 5851730,
    "text": "これがbashの正規化だ。"
  },
  {
    "start": 5852150,
    "end": 5863746,
    "text": "フォワード・パスでは、プリ・バッシュ正規化の隠れた状態であるHPBNを取り出し、非活性化直前の隠れた状態であるhpractを作成した。"
  },
  {
    "start": 5863938,
    "end": 5868940,
    "text": "バッチ正規化論文では、HpRBNをx、h preactをyとする。"
  },
  {
    "start": 5869470,
    "end": 5878838,
    "text": "バックワードパスでは、DHプレアクトがあるので、DHプレビアンを作りたい。"
  },
  {
    "start": 5878934,
    "end": 5883834,
    "text": "DHプレビアンを計算し、DHプレアクトを与える。"
  },
  {
    "start": 5883962,
    "end": 5893890,
    "text": "この練習では、ガンマとベータとその導関数は無視することにする。ガンマとベータとその導関数は、上でやったのと同じように、非常に単純な形をしているからだ。"
  },
  {
    "start": 5894230,
    "end": 5898674,
    "text": "では、ここでそれを踏まえて計算してみよう。"
  },
  {
    "start": 5898872,
    "end": 5910310,
    "text": "そこで、少しでも参考になればと思い、前回と同じように、まずは紙とペンを使って、バックワードパスの数式を導き出すために2枚の紙を用意した。"
  },
  {
    "start": 5910460,
    "end": 5921450,
    "text": "基本的に、問題を設定するには、ベッセル補正を除いて、論文とまったく同じように、ミューシグマ平方分散、xiハット、yiを書き出せばよい。"
  },
  {
    "start": 5921790,
    "end": 5927690,
    "text": "とすると、後方パスでは、Yのすべての要素に関する損失の導関数が得られる。"
  },
  {
    "start": 5927840,
    "end": 5929782,
    "text": "yはベクトルであることを忘れないでほしい。"
  },
  {
    "start": 5929926,
    "end": 5931600,
    "text": "ここには複数の数字がある。"
  },
  {
    "start": 5932050,
    "end": 5936190,
    "text": "すべてのyに関してすべての導関数を持っている。"
  },
  {
    "start": 5936850,
    "end": 5938986,
    "text": "そしてガンマとベータがある。"
  },
  {
    "start": 5939018,
    "end": 5940810,
    "text": "これはコンピュート・グラフのようなものだ。"
  },
  {
    "start": 5940970,
    "end": 5942222,
    "text": "ガンマとベータだ。"
  },
  {
    "start": 5942286,
    "end": 5947794,
    "text": "xハット、mu、シグマの2乗、そしてxがある。"
  },
  {
    "start": 5947912,
    "end": 5954390,
    "text": "dyによるDLがあり、これらのベクトルのすべてのIについてdxiによるDLが欲しい。"
  },
  {
    "start": 5955210,
    "end": 5957266,
    "text": "これがコンピュート・グラフだ。"
  },
  {
    "start": 5957298,
    "end": 5962274,
    "text": "ここで注意しなければならないのは、これらはベクトルであるということだ。"
  },
  {
    "start": 5962322,
    "end": 5966422,
    "text": "ここにはx、x hat、yの中にたくさんのノードがある。"
  },
  {
    "start": 5966556,
    "end": 5971770,
    "text": "muとsigma、申し訳ないがsigma squareは、単なるスカラー、単一の数値である。"
  },
  {
    "start": 5971920,
    "end": 5973626,
    "text": "それには気をつけなければならない。"
  },
  {
    "start": 5973648,
    "end": 5976940,
    "text": "ここに複数のノードがあることを想像しないと、計算を間違えてしまう。"
  },
  {
    "start": 5978430,
    "end": 5985290,
    "text": "そこで、一例として、バックプロパゲーションという観点から、次の1234の順番で行くことを提案したい。"
  },
  {
    "start": 5985370,
    "end": 5993786,
    "text": "つまり、xハットに逆伝播し、次にシグマスクエアに逆伝播し、次にミューに逆伝播し、そしてxハットに逆伝播する。"
  },
  {
    "start": 5993828,
    "end": 5996034,
    "text": "マイクログラッドでは、右から左へと進んでいく。"
  },
  {
    "start": 5996152,
    "end": 6000660,
    "text": "まったく同じことをやっているわけだが、記号を使っていることと、紙の上でやっていることを除けばね。"
  },
  {
    "start": 6001510,
    "end": 6005926,
    "text": "第一に、私は多くを語らない。"
  },
  {
    "start": 6006028,
    "end": 6020422,
    "text": "もしDxi hatのDLが欲しければ、DLをDyiで割ってガンマをかけるだけだ。"
  },
  {
    "start": 6020566,
    "end": 6023210,
    "text": "だから、あまり役に立たなかったね。"
  },
  {
    "start": 6023360,
    "end": 6026870,
    "text": "これは、基本的にすべてのxハットの導関数を与える。"
  },
  {
    "start": 6027030,
    "end": 6040730,
    "text": "そこで、この計算グラフを見ながら、DL×dシグマの2乗が何であるか、次にDL×dミューが何であるか、そして最終的にDL×dxが何であるかを導き出してみよう。"
  },
  {
    "start": 6040890,
    "end": 6041726,
    "text": "だから、やってみるんだ。"
  },
  {
    "start": 6041748,
    "end": 6044514,
    "text": "これからひとつずつ答えを明らかにしていくつもりだ。"
  },
  {
    "start": 6044632,
    "end": 6052066,
    "text": "さて、DLをdシグマの2乗で求めるには、先にも述べたように、ここには多くのXのxハットがあることを忘れてはならない。"
  },
  {
    "start": 6052248,
    "end": 6055750,
    "text": "シグマ・スクエアは、ここでは単なる個別の数字であることを忘れないでほしい。"
  },
  {
    "start": 6055900,
    "end": 6062406,
    "text": "DLをdシグマの2乗で表すとこうなる。"
  },
  {
    "start": 6062428,
    "end": 6074330,
    "text": "シグマ・スクエアに依存しているのだ。"
  },
  {
    "start": 6074480,
    "end": 6076554,
    "text": "シグマ・スクエアには大きなファンがいる。"
  },
  {
    "start": 6076592,
    "end": 6080250,
    "text": "シグマ・スクエアから矢印がたくさん出ていて、すべてのXハットに向かっている。"
  },
  {
    "start": 6080590,
    "end": 6085102,
    "text": "そして、各xハットからシグマ・スクエアに逆伝播する信号がある。"
  },
  {
    "start": 6085236,
    "end": 6104306,
    "text": "そのため、Iが1に等しいときからDLがmに等しいときまでのすべてのIをdxiハットで合計する必要がある。"
  },
  {
    "start": 6104488,
    "end": 6111590,
    "text": "数学的には、ここでは単純化して考えていますが、DLはdシグマスクエアで表されます。"
  },
  {
    "start": 6111660,
    "end": 6116342,
    "text": "この式は、muに逆伝播し、最終的にxに逆伝播するときに使うことになる。"
  },
  {
    "start": 6116476,
    "end": 6118730,
    "text": "では、ミューへの逆伝播を続けよう。"
  },
  {
    "start": 6118800,
    "end": 6120826,
    "text": "DLとは何ですか？"
  },
  {
    "start": 6121008,
    "end": 6126598,
    "text": "さて、繰り返しになるが、muはx hatに影響を与え、x hatは実際には多くの値を持つことに注意してほしい。"
  },
  {
    "start": 6126694,
    "end": 6135598,
    "text": "例えば、ミニバッチのサイズが32だとすると、この例では32の数字と32の矢印がミューに戻ることになる。"
  },
  {
    "start": 6135764,
    "end": 6139818,
    "text": "シグマ・スクエアはスカラーなので、シグマ・スクエアに向かうミューは単なる1本の矢印に過ぎない。"
  },
  {
    "start": 6139914,
    "end": 6148900,
    "text": "全部で33本の矢印がミューから発せられ、そのすべてがミューに入ってくる勾配を持ち、それらを合計する必要がある。"
  },
  {
    "start": 6149350,
    "end": 6159880,
    "text": "だから、DL by d muの式を見るとき、私はDL by dxi hat x dxi hat by d muのすべての勾配を合計しているのだ。"
  },
  {
    "start": 6160570,
    "end": 6164294,
    "text": "これがこの矢印で、これがここにある32本の矢印だ。"
  },
  {
    "start": 6164412,
    "end": 6170298,
    "text": "そして、ここから1本の矢印を足すと、dシグマの2乗×dシグマの2乗×dミューがDLされる。"
  },
  {
    "start": 6170464,
    "end": 6172822,
    "text": "さて、この式を計算しなければならない。"
  },
  {
    "start": 6172886,
    "end": 6174860,
    "text": "残りを明かそう。"
  },
  {
    "start": 6175870,
    "end": 6178230,
    "text": "ここでの単純化は複雑ではない。"
  },
  {
    "start": 6178310,
    "end": 6180990,
    "text": "最初の項は、ここで式を得るだけだ。"
  },
  {
    "start": 6181140,
    "end": 6189886,
    "text": "しかし、第2項については、dシグマの2乗をdミューで見て、ある点で単純化すると、実に興味深いことが起こる。"
  },
  {
    "start": 6189988,
    "end": 6206070,
    "text": "この場合のように、muがxisの平均である特殊なケースを想定すると、それを差し込むと、実は勾配は消えてちょうどゼロになり、第2項全体がキャンセルされる。"
  },
  {
    "start": 6206410,
    "end": 6217478,
    "text": "つまり、このような数式があり、dシグマの2乗をdミューで表すと、ミューがシグマの2乗にどのような影響を与えるかを表す数式が得られる。"
  },
  {
    "start": 6217644,
    "end": 6225946,
    "text": "バッチ正規化の場合のように、muが実際には平均に等しいという特殊な場合、その勾配は実際には消えてゼロになる。"
  },
  {
    "start": 6226128,
    "end": 6227606,
    "text": "の場合、項全体がキャンセルされる。"
  },
  {
    "start": 6227638,
    "end": 6232110,
    "text": "ここで、DLをdミューで表すと、かなりわかりやすい式が得られる。"
  },
  {
    "start": 6232260,
    "end": 6239006,
    "text": "つまり、DxiによってDLを導き出すことである。"
  },
  {
    "start": 6239188,
    "end": 6243902,
    "text": "では、まずxの中にいくつの数字があるか数えてみよう。"
  },
  {
    "start": 6243956,
    "end": 6250830,
    "text": "先ほど言ったように、32個の数字があり、32個の小さなキシがあり、それぞれのキシから発せられる矢印の数を数えてみよう。"
  },
  {
    "start": 6250990,
    "end": 6256898,
    "text": "ミューに向かう矢印があり、シグマスクエアに向かう矢印があり、そしてxハットに向かう矢印がある。"
  },
  {
    "start": 6256994,
    "end": 6260150,
    "text": "この矢印を少し調べてみよう。"
  },
  {
    "start": 6260300,
    "end": 6265394,
    "text": "それぞれのxiハットは、xiと他のすべてのスカラーの関数にすぎない。"
  },
  {
    "start": 6265522,
    "end": 6270118,
    "text": "xi hatはxiにのみ依存し、他のxには依存しない。"
  },
  {
    "start": 6270294,
    "end": 6277798,
    "text": "したがって、この1本の矢印には32本の矢印があるが、その32本の矢印はまったく平行に進んでいる。"
  },
  {
    "start": 6277894,
    "end": 6278806,
    "text": "彼らは干渉しない。"
  },
  {
    "start": 6278838,
    "end": 6281466,
    "text": "XとXハットの間を平行移動しているだけだ。"
  },
  {
    "start": 6281498,
    "end": 6282750,
    "text": "そういう見方もできる。"
  },
  {
    "start": 6282900,
    "end": 6285322,
    "text": "では、各XIからは何本の矢が出ているのか？"
  },
  {
    "start": 6285386,
    "end": 6290746,
    "text": "3本の矢印、ミューシグマの2乗、そして関連するXハットがある。"
  },
  {
    "start": 6290938,
    "end": 6297710,
    "text": "だから、逆伝播では連鎖法則を適用し、これら3つの寄与を合計する必要がある。"
  },
  {
    "start": 6297870,
    "end": 6299234,
    "text": "こんな感じだ。"
  },
  {
    "start": 6299272,
    "end": 6307602,
    "text": "このまま書き出すと、ミューシグマスクエアとXハットをチェーンでつないでいることになる。"
  },
  {
    "start": 6307666,
    "end": 6309960,
    "text": "この3つの用語はちょうどここにある。"
  },
  {
    "start": 6310410,
    "end": 6312966,
    "text": "今、私たちはすでにこのうちの3つを手にしている。"
  },
  {
    "start": 6313068,
    "end": 6315330,
    "text": "DXIハットのDLがある。"
  },
  {
    "start": 6315490,
    "end": 6321002,
    "text": "DLはDミューで、DLはdシグマの2乗である。"
  },
  {
    "start": 6321136,
    "end": 6326298,
    "text": "これとこれとこれだ。"
  },
  {
    "start": 6326384,
    "end": 6328206,
    "text": "ぜひ、それを導き出してみてほしい。"
  },
  {
    "start": 6328228,
    "end": 6329242,
    "text": "そんなに複雑なことじゃない。"
  },
  {
    "start": 6329306,
    "end": 6333390,
    "text": "これらの式を見て、xiに関して微分しているだけだ。"
  },
  {
    "start": 6334930,
    "end": 6335946,
    "text": "挑戦してみよう"
  },
  {
    "start": 6335978,
    "end": 6340880,
    "text": "これがその結果だ。"
  },
  {
    "start": 6343250,
    "end": 6346062,
    "text": "これらの表現すべてについて、Xiに関して微分しているだけだ。"
  },
  {
    "start": 6346126,
    "end": 6348226,
    "text": "正直なところ、それほど厄介なことはないと思う。"
  },
  {
    "start": 6348248,
    "end": 6349570,
    "text": "基本的な微積分だ。"
  },
  {
    "start": 6350470,
    "end": 6354450,
    "text": "さて、もう少しやっかいなのは、これからすべてをつなぎ合わせることだ。"
  },
  {
    "start": 6354600,
    "end": 6360706,
    "text": "これらの項をすべて掛け合わせ、この公式に従って足し算する。"
  },
  {
    "start": 6360738,
    "end": 6367110,
    "text": "結局のところ、大きな表現になってしまう。"
  },
  {
    "start": 6367690,
    "end": 6374378,
    "text": "もちろん、ここで注意しなければならないのは、Dxiが特定のIのためにDLしていることだ。"
  },
  {
    "start": 6374544,
    "end": 6388510,
    "text": "例えばこの項、DLをdシグマの2乗で割ると、DLをdシグマの2乗で割った式ができあがる。"
  },
  {
    "start": 6388660,
    "end": 6394978,
    "text": "なぜなら、このIはこのIとは別のIだからだ。"
  },
  {
    "start": 6395144,
    "end": 6398498,
    "text": "このIは単なるプレースホルダーで、aのローカル変数のようなものだ。"
  },
  {
    "start": 6398504,
    "end": 6399938,
    "text": "ここでループする。"
  },
  {
    "start": 6400104,
    "end": 6407990,
    "text": "というのも、このjがこのIではないことを確認する必要があるからだ。"
  },
  {
    "start": 6408060,
    "end": 6411926,
    "text": "このjは、32項にわたる小さなローカル・イテレータのようなものだ。"
  },
  {
    "start": 6412108,
    "end": 6413766,
    "text": "だから、その点には注意しなければならない。"
  },
  {
    "start": 6413788,
    "end": 6423210,
    "text": "ここからここまでの式を差し込むとき、IをJにリネームしなければならないかもしれないし、DxiによるDLに関して何が実際にIなのかに注意しなければならない。"
  },
  {
    "start": 6424110,
    "end": 6428170,
    "text": "JもあればIもある。"
  },
  {
    "start": 6428670,
    "end": 6430890,
    "text": "となれば、この式は単純化される。"
  },
  {
    "start": 6431550,
    "end": 6437646,
    "text": "ここで注目すべきは、多くの用語が前面に出てきて、それらをリファクタリングできるということだろう。"
  },
  {
    "start": 6437748,
    "end": 6441070,
    "text": "シグマの2乗とイプシロンのマイナス3乗が2乗になる。"
  },
  {
    "start": 6441220,
    "end": 6445362,
    "text": "このシグマの2乗＋イプシロンは、実際には3つの項に分けることができる。"
  },
  {
    "start": 6445496,
    "end": 6449586,
    "text": "それぞれシグマの2乗にイプシロンを足し、2乗をマイナス1乗したものである。"
  },
  {
    "start": 6449688,
    "end": 6453266,
    "text": "この3つを掛け合わせるとこうなる。"
  },
  {
    "start": 6453368,
    "end": 6457378,
    "text": "ということは、掛け算のため、この3つの項は異なる場所に行くことができる。"
  },
  {
    "start": 6457474,
    "end": 6461894,
    "text": "そのうちのひとつが実際に表に出てきて、この外に行き着くことになる。"
  },
  {
    "start": 6462092,
    "end": 6467270,
    "text": "そのうちのひとつはこの用語と結合し、もうひとつはこの別の用語と結合する。"
  },
  {
    "start": 6467610,
    "end": 6473450,
    "text": "式を単純化すると、出てくる用語のいくつかはxiハットだけであることに気づくだろう。"
  },
  {
    "start": 6473950,
    "end": 6476826,
    "text": "と書き換えるだけで単純化できる。"
  },
  {
    "start": 6477008,
    "end": 6482650,
    "text": "最終的に行き着くのは、これ以上単純化できない、かなり単純な数式である。"
  },
  {
    "start": 6482810,
    "end": 6488270,
    "text": "基本的に、我々が持っているものだけを使い、必要なものを導き出すことに気づくだろう。"
  },
  {
    "start": 6488420,
    "end": 6494850,
    "text": "氷はすべてDLバイ・ダイがある。"
  },
  {
    "start": 6495000,
    "end": 6500340,
    "text": "さらに、私たちが使っているのはXIハットとXJハットで、これらはフォワードパスから生まれたものだ。"
  },
  {
    "start": 6500950,
    "end": 6509110,
    "text": "そうでなければ、これは単純な表現であり、すべての目についてDxiによるDLを与えてくれる。"
  },
  {
    "start": 6509260,
    "end": 6513078,
    "text": "これでバッチノーマル、バックワードパスは終わりだ。"
  },
  {
    "start": 6513164,
    "end": 6516454,
    "text": "分析的に、この最終結果を実装してみよう。"
  },
  {
    "start": 6516652,
    "end": 6523286,
    "text": "さて、この式を1行のコードに実装してみた。"
  },
  {
    "start": 6523318,
    "end": 6525878,
    "text": "これがこの式の正しい実装である。"
  },
  {
    "start": 6526054,
    "end": 6534074,
    "text": "さて、この数式からこの公式を導き出すのは簡単なことではなかった。"
  },
  {
    "start": 6534122,
    "end": 6536858,
    "text": "この数式ひとつに、いろいろなことが詰まっている。"
  },
  {
    "start": 6536954,
    "end": 6545934,
    "text": "というのも、この公式はニューロン1個と32個の例に対するものだからだ。"
  },
  {
    "start": 6546062,
    "end": 6557138,
    "text": "ここでやっているのは、実際には64個のニューロンがあるので、この式は、64個のニューロンすべてについて、バッチルームのバックワードパスを並列に、独立に評価しなければならない。"
  },
  {
    "start": 6557314,
    "end": 6564134,
    "text": "これは基本的に、ここの入力のすべての列で起こらなければならない。"
  },
  {
    "start": 6564332,
    "end": 6572940,
    "text": "それに加えて、ここにたくさんの合計があるのがわかると思う。"
  },
  {
    "start": 6573310,
    "end": 6576086,
    "text": "だから、この式を得るのは、極めて非自明なことなんだ。"
  },
  {
    "start": 6576118,
    "end": 6582318,
    "text": "基本的には、それを見て、ステップを踏んで、これがチェックアウトであることを確認するための全体的な練習なんだ。"
  },
  {
    "start": 6582484,
    "end": 6590142,
    "text": "すべての形が一致し、それが正しいと自分で納得したら、Pythonがまったく同じ答えを出すことも検証できる。"
  },
  {
    "start": 6590196,
    "end": 6602702,
    "text": "だから、この数式がここで正しく実装され、正しくブロードキャストされ、このバッシュルーム・レイヤー内の64個のニューロンすべてに並列に複製されているという安心感が得られる。"
  },
  {
    "start": 6602846,
    "end": 6603106,
    "text": "いいかい？"
  },
  {
    "start": 6603128,
    "end": 6606630,
    "text": "最後に、4番目の練習は、すべてをまとめることを求めるものだ。"
  },
  {
    "start": 6606780,
    "end": 6609958,
    "text": "ここで、問題全体を再定義する。"
  },
  {
    "start": 6610044,
    "end": 6620662,
    "text": "ニューラル・ネットのスライドをゼロから読み込んでいるのがわかるだろう。"
  },
  {
    "start": 6620806,
    "end": 6635066,
    "text": "そして、このニューラルネットを最適化する。基本的には、バッシュ・ノルムのキャリブレーションと損失の評価に至るまで、すべて独自の勾配を使用する。"
  },
  {
    "start": 6635178,
    "end": 6639470,
    "text": "基本的には、以前と同じような減量を達成することができた。"
  },
  {
    "start": 6639620,
    "end": 6648050,
    "text": "というのも、私たちがやったことは、後方で本当に損をするようになり、すべてのコードを抜き出してここに挿入しただけだからだ。"
  },
  {
    "start": 6648120,
    "end": 6652446,
    "text": "これらのグラデーションは同一であり、すべてが同一であり、結果は同一である。"
  },
  {
    "start": 6652558,
    "end": 6659158,
    "text": "ただ、この具体的なケースでは、後方ロットのボンネットの下で何が行われているのか、私たちは完全に把握している。"
  },
  {
    "start": 6659324,
    "end": 6659702,
    "text": "いいかい？"
  },
  {
    "start": 6659756,
    "end": 6661670,
    "text": "これが私たちのコードのすべてだ。"
  },
  {
    "start": 6661740,
    "end": 6669110,
    "text": "これは、基本的にクロスエントロピー損失とバッシュの正規化のための簡略化された後方パスを使用した完全な後方パスである。"
  },
  {
    "start": 6669270,
    "end": 6679894,
    "text": "クロスエントロピー、セカンドレイヤー、10hノリニアリティ、バッシュ正規化、ファーストレイヤー、エンベッディングを通して逆伝播する。"
  },
  {
    "start": 6680022,
    "end": 6684206,
    "text": "ということは、たった20行程度のコードしかないことになる。"
  },
  {
    "start": 6684308,
    "end": 6686202,
    "text": "それがグラデーションを生み出す。"
  },
  {
    "start": 6686346,
    "end": 6689402,
    "text": "今、私たちは多くの後進を消せる可能性がある。"
  },
  {
    "start": 6689546,
    "end": 6694674,
    "text": "私が設定したコードでは、これを入力すれば、このセル全体を実行できるはずです。"
  },
  {
    "start": 6694792,
    "end": 6697810,
    "text": "これは100回だけ実行され、その後ブレークする。"
  },
  {
    "start": 6697960,
    "end": 6702370,
    "text": "というのも、Pytorchと比較してグラデーションをチェックする機会を与えてくれるからだ。"
  },
  {
    "start": 6703110,
    "end": 6707858,
    "text": "ここで私たちが目にするグラデーションは、まったく同じではない。"
  },
  {
    "start": 6707954,
    "end": 6710962,
    "text": "両者はほぼ同等で、その差はごくわずかだ。"
  },
  {
    "start": 6711026,
    "end": 6712310,
    "text": "マイナス9分の1くらいだ。"
  },
  {
    "start": 6712380,
    "end": 6715320,
    "text": "正直なところ、彼らがどこから来たのかよくわからない。"
  },
  {
    "start": 6715950,
    "end": 6730134,
    "text": "グラデーションが基本的に正しいという確信が持てたら、グラデーションのチェックを外し、このブレーク・ステートメントを無効にすることができる。"
  },
  {
    "start": 6730262,
    "end": 6731710,
    "text": "もう必要ない。"
  },
  {
    "start": 6732290,
    "end": 6734000,
    "text": "それを見て驚く。"
  },
  {
    "start": 6734530,
    "end": 6738570,
    "text": "そして、ここでアップデートを行う際には、Pグラッドを使用しない。"
  },
  {
    "start": 6738650,
    "end": 6741258,
    "text": "これがピトーチの古いやり方だ。"
  },
  {
    "start": 6741354,
    "end": 6743822,
    "text": "後方支援はしていないから、もうそれはない。"
  },
  {
    "start": 6743966,
    "end": 6748660,
    "text": "私たちはこのアップデートを使うつもりです。"
  },
  {
    "start": 6749030,
    "end": 6756418,
    "text": "パラメーターと同じ順番になるようにグラデーションを配置し、グラデーションとパラメーターをpとgradにzipで圧縮している。"
  },
  {
    "start": 6756514,
    "end": 6760150,
    "text": "では、ここでは手動で導き出したグラッドだけでステップを踏んでいこうと思う。"
  },
  {
    "start": 6760890,
    "end": 6768358,
    "text": "最後のピースは、Pytorchからのグラデーションが不要になったことだ。"
  },
  {
    "start": 6768454,
    "end": 6777846,
    "text": "トーチ・ノグラードを使って、このコードブロック全体をオフセットすることができる。"
  },
  {
    "start": 6778038,
    "end": 6782238,
    "text": "あなたが言っていることは、ピートーチに、私はこの件に関して後ろ向きなことを言うつもりはない、と言っているようなものだ。"
  },
  {
    "start": 6782324,
    "end": 6785326,
    "text": "これにより、Pytorchはそのすべてをもう少し効率的に使うことができる。"
  },
  {
    "start": 6785508,
    "end": 6799570,
    "text": "後方へのロスがコメントアウトされ、最適化されているのがわかるだろう。"
  },
  {
    "start": 6800470,
    "end": 6804920,
    "text": "このまま逃げ切り、いい結果を残したい。"
  },
  {
    "start": 6805290,
    "end": 6808230,
    "text": "それで、ニューラルネットに最適化を完了させた。"
  },
  {
    "start": 6808810,
    "end": 6817058,
    "text": "トレーニング・ループの中で、走りの平均と分散を記録していなかったからだ。"
  },
  {
    "start": 6817234,
    "end": 6823420,
    "text": "その結果、かなり良い損失が出た。"
  },
  {
    "start": 6823950,
    "end": 6829274,
    "text": "そしてここで、モデルからサンプリングしているのだが、私たちが慣れ親しんでいるような、名前に似せたちんぷんかんぷんな言葉がいくつか見られる。"
  },
  {
    "start": 6829392,
    "end": 6835518,
    "text": "基本的に、このモデルは機能し、私たちがこれまで使ってきたものと比べてかなりまともな結果を出している。"
  },
  {
    "start": 6835604,
    "end": 6836798,
    "text": "すべてが同じだ。"
  },
  {
    "start": 6836884,
    "end": 6844850,
    "text": "もちろん、大きな問題は、私たちがたくさんの後進を使わなかったこと、Pytrich autogradを使わなかったこと、そして私たち自身が手作業で勾配を推定したことだ。"
  },
  {
    "start": 6845000,
    "end": 6852050,
    "text": "このニューラルネットの後方パスを見て、さほど複雑ではないな、と思ってもらえれば幸いだ。"
  },
  {
    "start": 6853110,
    "end": 6862838,
    "text": "これらのレイヤーはそれぞれ3行程度のコードで、バッチ正規化のバックワードパスを例外として、そのほとんどはかなり単純なものだ。"
  },
  {
    "start": 6862924,
    "end": 6864470,
    "text": "それ以外はかなりいい。"
  },
  {
    "start": 6864620,
    "end": 6864982,
    "text": "オーケー。"
  },
  {
    "start": 6865036,
    "end": 6867406,
    "text": "というのが、今回の講義で取り上げたかったことのすべてだ。"
  },
  {
    "start": 6867538,
    "end": 6869562,
    "text": "この記事を読んで興味を持っていただけたなら幸いだ。"
  },
  {
    "start": 6869696,
    "end": 6875370,
    "text": "正直なところ、私が気に入ったのは、バックプロパゲーションするレイヤーに非常に多様性を持たせてくれたことだ。"
  },
  {
    "start": 6875520,
    "end": 6884190,
    "text": "これらのバックワードパスがどのように実装され、どのように機能するのか、かなり素晴らしく包括的な感覚を与えてくれると思う。"
  },
  {
    "start": 6884260,
    "end": 6897870,
    "text": "もちろん、実際にはそんなことはしたくないだろうし、Pytorchのオートグラッドを使いたいだろう。しかし、勾配がニューラルネットの中をどのように逆流していくのか、損失から始まって、すべての変数とすべての中間結果をどのように流れていくのか、直感的に理解できるようになっていればいいのだが。"
  },
  {
    "start": 6898290,
    "end": 6907766,
    "text": "もし、あなたがその大部分を理解し、そのような感覚を持っているのであれば、あなたはこの右の道場ではなく、左のバフ道場の一人として数えられるだろう。"
  },
  {
    "start": 6907948,
    "end": 6920498,
    "text": "さて、次回の講義では、リカレント・ニューラル・ネット、lstms、その他すべてのrnsの変種を実際に使って、アーキテクチャを複雑化し、より優れたログ尤度を達成し始めます。"
  },
  {
    "start": 6920594,
    "end": 6923060,
    "text": "楽しみにしているよ。"
  }
]