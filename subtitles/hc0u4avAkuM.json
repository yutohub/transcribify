[
  {
    "start": 680,
    "end": 1758,
    "text": "どうしたんだ、みんな？"
  },
  {
    "start": 1886,
    "end": 4870,
    "text": "このビデオのアイデアは非常に野心的なものになるだろう。"
  },
  {
    "start": 4942,
    "end": 16462,
    "text": "何千億、何兆というパラメーターのスケールまでモデルをスケールアップする方法について、最も重要なアイデアを提供しようと思う。"
  },
  {
    "start": 16598,
    "end": 20246,
    "text": "ここにあるように、複数の論文を取り上げるつもりだ。"
  },
  {
    "start": 20270,
    "end": 27384,
    "text": "ここでは、NvidiaのメガトロンLMがテンソル並列またはモデル並列を導入している。"
  },
  {
    "start": 27534,
    "end": 31796,
    "text": "GPIPの論文にあるパイプライン並列のアイデアを手短に説明しよう。"
  },
  {
    "start": 31940,
    "end": 37180,
    "text": "おそらくほとんどの人がすでに知っていることだと思うが、データ並列のアイデアについて説明しよう。"
  },
  {
    "start": 37292,
    "end": 40464,
    "text": "一応、これもカバーするつもりだ。"
  },
  {
    "start": 40764,
    "end": 44812,
    "text": "ミックスド・プレシジョン・トレーニングのペーパーも手短に見ていこうと思う。"
  },
  {
    "start": 44908,
    "end": 48260,
    "text": "最後に、ゼロオプティマイザーを見ていこうと思う。"
  },
  {
    "start": 48292,
    "end": 56628,
    "text": "つまり、マイクロソフトの冗長性ゼロのオプティマイザーは、最大1兆個のパラメータを持つモデルのトレーニングを可能にしたのだ。"
  },
  {
    "start": 56756,
    "end": 60076,
    "text": "なぜ私たちが、なぜあなたがこのビデオに関心を持たなければならないのか？"
  },
  {
    "start": 60140,
    "end": 62156,
    "text": "さて、問題は次のようなことだ。"
  },
  {
    "start": 62220,
    "end": 80732,
    "text": "例えば、GPTスタイルのモデル変換器を扱う場合、15億以上のパラメーターを必要とすると、文字通り32GB以上のVRAMが必要になります。"
  },
  {
    "start": 80828,
    "end": 90308,
    "text": "基本的に15億までは、32GBのVRMを搭載したシングルGPUでそのトレーニングに対応できる。"
  },
  {
    "start": 90436,
    "end": 95844,
    "text": "それ以外の最適化がなければ、より大きなモデルをトレーニングすることは不可能だ。"
  },
  {
    "start": 95964,
    "end": 100732,
    "text": "これらのアイデアを組み合わせることで、文字通り超ビッグなモデルを育成することができる。"
  },
  {
    "start": 100788,
    "end": 114356,
    "text": "そのうちのいくつかは、最近発表されたモデル、例えば大きな科学団体のブルームや、メタの175bモデルなどを見たことがあるはずだ。"
  },
  {
    "start": 114460,
    "end": 119234,
    "text": "これらのモデルはすべて、数千億、数千億のパラメーターを持つようなものだ。"
  },
  {
    "start": 119274,
    "end": 123490,
    "text": "他の例としては、ディープマインドのチンチラやゴーファー・パームなどがある。"
  },
  {
    "start": 123602,
    "end": 129922,
    "text": "そうだ、みんな、その前に、このビデオのスポンサーになってくれたAssemblyAIに感謝の意を表したい。"
  },
  {
    "start": 130098,
    "end": 135378,
    "text": "基本的に、彼らは非常に強力な音声理解と書き起こしのAPIを提供しています。"
  },
  {
    "start": 135546,
    "end": 138234,
    "text": "Pythonを始めるのがいかに簡単かがわかるだろう。"
  },
  {
    "start": 138274,
    "end": 142106,
    "text": "文字どおり2、3行のコードを書くだけで、ほら、テープ起こしができる。"
  },
  {
    "start": 142210,
    "end": 144488,
    "text": "今回のケースと同様に、センチメント分析だ。"
  },
  {
    "start": 144586,
    "end": 150068,
    "text": "他にも、エンティティの検出など、さまざまな理解機能を提供している。"
  },
  {
    "start": 150236,
    "end": 155060,
    "text": "コードなしの解決策をチェックすることもできるが、これはほとんどの人にとってそれほど興味深いものではないだろう。"
  },
  {
    "start": 155172,
    "end": 160156,
    "text": "サポートする機能を手っ取り早く理解したい場合は、こちらのページも参照してほしい。"
  },
  {
    "start": 160220,
    "end": 168204,
    "text": "もしあなたが始めるのに苦労しているのなら、それは超シンプルなので疑問だが、チュートリアルもある。"
  },
  {
    "start": 168324,
    "end": 180960,
    "text": "プロジェクトのアイデアがお好きなら、YouTubeチャンネルに、APIを使って様々なポッドキャストを要約する方法を説明する、文字通り30分ほどのクールなビデオがあります。"
  },
  {
    "start": 181072,
    "end": 182336,
    "text": "とてもクールだ。"
  },
  {
    "start": 182480,
    "end": 191104,
    "text": "最後に、彼らは一般的に非常にクールなブログのセットを持っており、Daliのような他の様々なモデルで始める方法についてのチュートリアルを持っています。"
  },
  {
    "start": 191224,
    "end": 193160,
    "text": "だから、かなりクールだと思うよ。"
  },
  {
    "start": 193232,
    "end": 193984,
    "text": "挑戦してみよう。"
  },
  {
    "start": 194024,
    "end": 194832,
    "text": "チャンネルをサポートする。"
  },
  {
    "start": 194888,
    "end": 200664,
    "text": "無料のAPIトークンをビデオの説明の下にリンクしているので、それを使って数秒で始めることができる。"
  },
  {
    "start": 200704,
    "end": 205022,
    "text": "文字通り、おもちゃのプロジェクトのために手に入れるのだから、無料アカウントで何の問題もない。"
  },
  {
    "start": 205078,
    "end": 206982,
    "text": "300ドルのテープ起こしができる。"
  },
  {
    "start": 207078,
    "end": 208966,
    "text": "アップグレードしたければ、いつでもできる。"
  },
  {
    "start": 209070,
    "end": 211550,
    "text": "とはいえ、ビデオに戻ろう。"
  },
  {
    "start": 211662,
    "end": 217070,
    "text": "まず、データ並列性から説明しよう。おそらくこれが一番シンプルなアイデアだからだ。"
  },
  {
    "start": 217222,
    "end": 218206,
    "text": "そのアイデアは次のようなものだ。"
  },
  {
    "start": 218310,
    "end": 226606,
    "text": "ニューラルネットワークがあるとして、何をするかというと、文字通りニューラルネットワークの重みを取って、それを複製するだけだ。"
  },
  {
    "start": 226670,
    "end": 231682,
    "text": "そのウェイトを複数のデバイスにコピー・ペーストする。"
  },
  {
    "start": 231818,
    "end": 239058,
    "text": "例えばNGPUがあったとして、同じネットワークをすべてのデバイスにコピーペーストするんだ。"
  },
  {
    "start": 239186,
    "end": 241346,
    "text": "そして、データのバッチを取る。"
  },
  {
    "start": 241450,
    "end": 243454,
    "text": "基本的にはデータのバッチを取る。"
  },
  {
    "start": 244354,
    "end": 246106,
    "text": "こんな感じになるだろう。"
  },
  {
    "start": 246210,
    "end": 249002,
    "text": "文字どおり、ここにあるのは一括データだ。"
  },
  {
    "start": 249178,
    "end": 253106,
    "text": "それを複数のパートに分けるんだ。"
  },
  {
    "start": 253130,
    "end": 255274,
    "text": "ここでは3つのデバイスがあると仮定しよう。"
  },
  {
    "start": 255434,
    "end": 257358,
    "text": "ということは、バッチを分割するということだ。"
  },
  {
    "start": 257466,
    "end": 259078,
    "text": "ちなみに、これはバッチ次元である。"
  },
  {
    "start": 259166,
    "end": 261910,
    "text": "これは簡略化しよう。"
  },
  {
    "start": 261942,
    "end": 269542,
    "text": "入力テンソルを2次元のオブジェクトとして表現するようなものだ。データによっては3次元、4次元など、さまざまな入力テンソルがある。"
  },
  {
    "start": 269718,
    "end": 276366,
    "text": "それで、最初の塊、最初の部分を掴んで、それを最初のデバイスに送り込む。"
  },
  {
    "start": 276510,
    "end": 279354,
    "text": "そして、ここで2つ目の塊をつかむ。"
  },
  {
    "start": 279934,
    "end": 284454,
    "text": "2つ目のチャンクをつかみ、その2つ目のデータチャンクを2つ目のGPUに渡す。"
  },
  {
    "start": 284494,
    "end": 285358,
    "text": "GPU2だ。"
  },
  {
    "start": 285486,
    "end": 288486,
    "text": "最後のピースをここでつかむ。"
  },
  {
    "start": 288630,
    "end": 290794,
    "text": "それをここでパスするんだ。"
  },
  {
    "start": 291254,
    "end": 293870,
    "text": "そして、ネットボックスにフォワードパスを通す。"
  },
  {
    "start": 293902,
    "end": 300470,
    "text": "ここでフォワードパス、ここでフォワードパス、ここでフォワードパスを行い、グラデーションを計算する。"
  },
  {
    "start": 300582,
    "end": 308686,
    "text": "今何が起こっているかというと、インプットバッチの異なる部分を投入した結果、これらのデバイスはすべて異なる成分を持っているということだ。"
  },
  {
    "start": 308830,
    "end": 314082,
    "text": "あとは基本的に、これらのグラデーションをすべて減らすだけだ。"
  },
  {
    "start": 314178,
    "end": 322130,
    "text": "私が言う \"減らす \"というのは、文字どおり、それらを合計し、平均勾配を得るためにデバイスの数で割るという意味だ。"
  },
  {
    "start": 322242,
    "end": 325282,
    "text": "これを実装する方法は複数ある。"
  },
  {
    "start": 325458,
    "end": 328570,
    "text": "この画像では、パラメーター・サーバーと呼ばれるものがある。"
  },
  {
    "start": 328682,
    "end": 332762,
    "text": "基本的にリデュースとスキャッターを行う。"
  },
  {
    "start": 332818,
    "end": 337772,
    "text": "すべてのグラデーションを取得したら、グラデーションをここに送る。"
  },
  {
    "start": 337858,
    "end": 345208,
    "text": "ところで、申し訳ないんだけど、この蛍光ペンでちょっと不具合があるんだ。"
  },
  {
    "start": 345296,
    "end": 349432,
    "text": "ここにグラデーションを送り、ここにグラデーションを送り、ここにグラデーションを送る。"
  },
  {
    "start": 349528,
    "end": 351848,
    "text": "そのグラデーションを平均化するのだ。"
  },
  {
    "start": 351976,
    "end": 353480,
    "text": "それなら、あなたは文字通り"
  },
  {
    "start": 353552,
    "end": 358512,
    "text": "この特定の実装では、重みはパラメータサーバー上で直接更新される。"
  },
  {
    "start": 358608,
    "end": 360088,
    "text": "その後、スキャッター操作を行う。"
  },
  {
    "start": 360136,
    "end": 366656,
    "text": "文字通り、新しいウェイトをデバイスに送り返すのだ。"
  },
  {
    "start": 366720,
    "end": 369432,
    "text": "ウェイトを送り返すんだ、いいね？"
  },
  {
    "start": 369608,
    "end": 385336,
    "text": "というのも、多少のオーバーヘッドがあるのは明らかですが、GPU1台でトレーニングする場合と比べて、文字通り3倍のスループットが得られるからです。"
  },
  {
    "start": 385400,
    "end": 386124,
    "text": "いいかい？"
  },
  {
    "start": 386464,
    "end": 391574,
    "text": "GPUと言っても、TPUでもいいし、基本的にはどんなデバイスでもいい。"
  },
  {
    "start": 391744,
    "end": 395242,
    "text": "このアイデアの何が問題なのか？"
  },
  {
    "start": 395338,
    "end": 410570,
    "text": "問題なのは、これらのネットワークはすべて1つのデバイスに収まるという前提があることだ。"
  },
  {
    "start": 410722,
    "end": 412074,
    "text": "ではどうするか？"
  },
  {
    "start": 412234,
    "end": 414994,
    "text": "それなら、私たちはモデルの並列性などが好きなんだ。"
  },
  {
    "start": 415034,
    "end": 417434,
    "text": "最初にお見せしよう。"
  },
  {
    "start": 417514,
    "end": 418642,
    "text": "これがデータ並列性だ。"
  },
  {
    "start": 418698,
    "end": 421554,
    "text": "モデル・パラレリズムのアイデアをお見せしよう。"
  },
  {
    "start": 421594,
    "end": 426626,
    "text": "これは、メガトロンLMトレーニングと呼ばれるNvidiaの代表的な論文である。"
  },
  {
    "start": 426690,
    "end": 430210,
    "text": "モデル並列性を利用した10億パラメータ言語モデル。"
  },
  {
    "start": 430362,
    "end": 436978,
    "text": "それは文字通り、ブルームもオプト175Bもメタから生まれたアイデアだ。"
  },
  {
    "start": 437146,
    "end": 445922,
    "text": "少なくとも暗黙の了解でメガトロンがバックアップしていたと思う。"
  },
  {
    "start": 445978,
    "end": 451266,
    "text": "ネオックスのコードベースとディープスピードは、基本的にバックグラウンドでメガトロンを活用している。"
  },
  {
    "start": 451370,
    "end": 452370,
    "text": "私が間違っているかもしれない。"
  },
  {
    "start": 452402,
    "end": 454146,
    "text": "これは間違いないと思う。"
  },
  {
    "start": 454290,
    "end": 456294,
    "text": "とにかく、論文を掘り下げてみよう。"
  },
  {
    "start": 457154,
    "end": 462134,
    "text": "これはイントラ・レイヤー・モデルのパラレル・アプローチと呼ばれている。"
  },
  {
    "start": 462434,
    "end": 471282,
    "text": "レイヤー間の分割であるパイプライン・アプローチについては、後でもう少し詳しく説明するつもりだ。"
  },
  {
    "start": 471378,
    "end": 472706,
    "text": "その違いは以下の通りである。"
  },
  {
    "start": 472770,
    "end": 478586,
    "text": "トランスフォーマーがあるとする。"
  },
  {
    "start": 478730,
    "end": 480774,
    "text": "ここに変圧器があると想像してほしい。"
  },
  {
    "start": 481434,
    "end": 484962,
    "text": "これら2つのアプローチの主な違いは以下の通り。"
  },
  {
    "start": 485018,
    "end": 486602,
    "text": "あなたはここで何層にも分かれている。"
  },
  {
    "start": 486698,
    "end": 489874,
    "text": "トランスのMブロックがある。"
  },
  {
    "start": 489994,
    "end": 492954,
    "text": "パイプライン・アプローチは次のようなことをする。"
  },
  {
    "start": 493034,
    "end": 495374,
    "text": "文字通り、4つのデバイスがあるとしよう。"
  },
  {
    "start": 495834,
    "end": 498490,
    "text": "デバイスが4台ある場合、次のようにする。"
  },
  {
    "start": 498642,
    "end": 507242,
    "text": "レイヤー1から4まで、そして5から8までを別々のデバイスに送る。"
  },
  {
    "start": 507298,
    "end": 508608,
    "text": "それがパイプラインのアプローチだ。"
  },
  {
    "start": 508706,
    "end": 515224,
    "text": "文字通り、これを取って、別のデバイスに入れるんだ。"
  },
  {
    "start": 515524,
    "end": 517892,
    "text": "そして、これを取って置くんだ。"
  },
  {
    "start": 517948,
    "end": 519956,
    "text": "ここに描かせてください。"
  },
  {
    "start": 520140,
    "end": 524124,
    "text": "文字通り、パイプラインのアイデアを説明していないので、全部説明した方がいいかもしれない。"
  },
  {
    "start": 524164,
    "end": 530344,
    "text": "文字通り、レイヤー5からレイヤー8までを、ここにある別の装置に送り込む。"
  },
  {
    "start": 530964,
    "end": 537056,
    "text": "そして、次の4つのレイヤーを取るんだ。"
  },
  {
    "start": 537080,
    "end": 538124,
    "text": "使うだけだよ。"
  },
  {
    "start": 538584,
    "end": 539648,
    "text": "ああ、何でもいい。"
  },
  {
    "start": 539776,
    "end": 549896,
    "text": "文字通り、それを3つ目のブロックに送り込み、最後の1つ、最後の4つのレイヤーを最後のブロックに送り込む。"
  },
  {
    "start": 550040,
    "end": 554600,
    "text": "なるほど、これがパイプライン並列のアプローチだ。"
  },
  {
    "start": 554672,
    "end": 557448,
    "text": "文字通り、モデルを分割するのだ。"
  },
  {
    "start": 557576,
    "end": 560384,
    "text": "まあ、これはそうだな、これが水平に分かれるんだ。"
  },
  {
    "start": 560504,
    "end": 569668,
    "text": "これらのデバイスがそれぞれ必要とするメモリは、文字どおり4倍少なくなることが想像できるだろう。"
  },
  {
    "start": 569716,
    "end": 571900,
    "text": "少なくともウェイトに関してはね。"
  },
  {
    "start": 572012,
    "end": 574864,
    "text": "オプティマイザーの状態などもある。"
  },
  {
    "start": 575284,
    "end": 586292,
    "text": "なるほど、メガトロンLMの論文にあるモデルの平行移動とは逆の発想で、いわゆる垂直分割をするわけだ。"
  },
  {
    "start": 586348,
    "end": 596122,
    "text": "その代わりに、緑などいくつかの色を使い、2つのデバイスを想像してみよう。"
  },
  {
    "start": 596218,
    "end": 598854,
    "text": "文字通り、トランスをこのように分割する。"
  },
  {
    "start": 599194,
    "end": 601306,
    "text": "文字通り縦に割る。"
  },
  {
    "start": 601370,
    "end": 610826,
    "text": "そして、この部分を一方のデバイスに送り、もう一方の部分、つまりトランスのもう半分をもう一方のデバイスに送る。"
  },
  {
    "start": 610930,
    "end": 617130,
    "text": "それがモデル並列性であり、テンソル並列性である。"
  },
  {
    "start": 617242,
    "end": 620010,
    "text": "さて、パイプラインの説明はすでに半分終わっているからね。"
  },
  {
    "start": 620082,
    "end": 620986,
    "text": "パイプライン並列。"
  },
  {
    "start": 621050,
    "end": 623922,
    "text": "では、さっそく見ていこう。"
  },
  {
    "start": 623978,
    "end": 625654,
    "text": "それが私の考えだ。"
  },
  {
    "start": 626354,
    "end": 630410,
    "text": "そのアイデアに言及した論文のひとつが、グーグルのgパイプだ。"
  },
  {
    "start": 630522,
    "end": 633818,
    "text": "その他は、夢物語か何かだったと思う。"
  },
  {
    "start": 633866,
    "end": 638818,
    "text": "似たようなアイデアを実施した論文は複数あるが、アイデアは前述の通り、この論文だ。"
  },
  {
    "start": 638906,
    "end": 640490,
    "text": "何が問題なんだ？"
  },
  {
    "start": 640562,
    "end": 650926,
    "text": "問題は、パイプラインの並列性を使って分割されたモデルを単純にトレーニングしようとすると、バブルと呼ばれる問題が発生することです。"
  },
  {
    "start": 651050,
    "end": 653774,
    "text": "というのはどういう意味か。"
  },
  {
    "start": 653814,
    "end": 658126,
    "text": "このパイプラインにデータのバッチを流すとする。"
  },
  {
    "start": 658190,
    "end": 658614,
    "text": "いいかい？"
  },
  {
    "start": 658694,
    "end": 660434,
    "text": "ここにバッチデータがある。"
  },
  {
    "start": 660934,
    "end": 668678,
    "text": "レイヤーとデータの違いを明確にするために、このように表記しようと思う。"
  },
  {
    "start": 668846,
    "end": 679892,
    "text": "つまり、フィードフォワードを最初のデバイスを通して行っている間、つまり最初の、仮に4つのレイヤーを通して行っている間、他の3つのデバイスはアイドル状態なのだ。"
  },
  {
    "start": 679988,
    "end": 682348,
    "text": "この図を見てほしい。"
  },
  {
    "start": 682396,
    "end": 687932,
    "text": "文字通り、これらのデバイスがアイドル状態であることがわかるだろう。"
  },
  {
    "start": 688108,
    "end": 691332,
    "text": "この3人はまったく何もしていない。"
  },
  {
    "start": 691428,
    "end": 691828,
    "text": "オーケー。"
  },
  {
    "start": 691876,
    "end": 694620,
    "text": "計算などしていない。"
  },
  {
    "start": 694692,
    "end": 696100,
    "text": "それはちょっともったいないよね？"
  },
  {
    "start": 696212,
    "end": 707352,
    "text": "そして、最初の4つのレイヤーをフィードフォワードした後、基本的に2番目のデバイスにアクティベーションを送り、ここでフィードフォワードを開始する。"
  },
  {
    "start": 707448,
    "end": 713408,
    "text": "この時点で、第1、第2、第3、第4の3つのデバイスはアイドル状態である。"
  },
  {
    "start": 713456,
    "end": 717248,
    "text": "文字通り、これらの装置は何もしていない。"
  },
  {
    "start": 717296,
    "end": 720488,
    "text": "ご覧の通り、これはアイドルになる。"
  },
  {
    "start": 720616,
    "end": 723200,
    "text": "この2台はアイドル状態だ。"
  },
  {
    "start": 723272,
    "end": 730080,
    "text": "そして、4つのデバイスのすべてに伝搬させ、バックドロップを開始する。"
  },
  {
    "start": 730112,
    "end": 731576,
    "text": "グラデーションを計算したい。"
  },
  {
    "start": 731720,
    "end": 738542,
    "text": "後方パスでそれをやり始めると、文字通り待っていることになる。"
  },
  {
    "start": 738638,
    "end": 743446,
    "text": "ここではバックプロップを行っているが、これら3つのデバイスはアイドル状態である。"
  },
  {
    "start": 743550,
    "end": 744774,
    "text": "これは非常にもったいない。"
  },
  {
    "start": 744814,
    "end": 749742,
    "text": "これを避ける簡単な方法がある。"
  },
  {
    "start": 749838,
    "end": 758214,
    "text": "ミニバッチを複数のマイクロバッチに分割し、パイプラインに投入してスループットを向上させる。"
  },
  {
    "start": 758294,
    "end": 759914,
    "text": "どういうことか、お見せしよう。"
  },
  {
    "start": 760994,
    "end": 766386,
    "text": "図解はこちらをご覧いただきたいが、概念的にその意味を説明しよう。"
  },
  {
    "start": 766530,
    "end": 772614,
    "text": "ここで行うのは、入力データを複数のチャンクに分割し、いわゆるマイクロバッチにすることだ。"
  },
  {
    "start": 773114,
    "end": 774890,
    "text": "この最初の部分をここで食べさせてくれ。"
  },
  {
    "start": 775002,
    "end": 776290,
    "text": "ここで餌をやるんだ。"
  },
  {
    "start": 776402,
    "end": 778522,
    "text": "ここで走っている間"
  },
  {
    "start": 778618,
    "end": 788512,
    "text": "そして、2つ目の装置を通過し始めた瞬間に、すぐに2つ目の部品、2つ目のマイクロバッチをこの装置に供給する。"
  },
  {
    "start": 788608,
    "end": 791456,
    "text": "これで2つのデバイスがアイドル状態でなくなった。"
  },
  {
    "start": 791560,
    "end": 801520,
    "text": "そして、このデバイスが3台目のデバイスにアクティベーションを渡すと同時に、3台目のマイクロバッチをこのデバイスに送り込むことができる。"
  },
  {
    "start": 801552,
    "end": 804768,
    "text": "ポイントを獲得し、図がこのようになっているのがわかるだろう。"
  },
  {
    "start": 804856,
    "end": 810120,
    "text": "最初は、最初のマイクロバッチの間、文字通り、あなたは持っている。"
  },
  {
    "start": 810232,
    "end": 812360,
    "text": "文字通り、ここで色を変えてみよう。"
  },
  {
    "start": 812472,
    "end": 815040,
    "text": "文字通り、4つのデバイスがアイドル状態なのだ。"
  },
  {
    "start": 815152,
    "end": 819576,
    "text": "それでも、4つのデバイスがアイドル状態であることがわかる。"
  },
  {
    "start": 819720,
    "end": 823592,
    "text": "その場合、アイドルになるのは2台だけで、その後は1台だけである。"
  },
  {
    "start": 823648,
    "end": 834864,
    "text": "ここでようやく、すべてのデバイスがビジー状態になっていることがわかり、パイプライン並列の素朴な実装に比べてスループットが倍増していることがわかる。"
  },
  {
    "start": 835024,
    "end": 843844,
    "text": "4つのデバイスがすべてアクティブになるようなカラムをたくさん作るには、マイクロバッチをたくさん用意したい。"
  },
  {
    "start": 843944,
    "end": 857556,
    "text": "GPIの論文が基本的に経験的に示したのは、mが4k以上であることが望ましいということです。kはパーティションの数、つまりデバイスの数で、NCNAではデバイスの数と言います。"
  },
  {
    "start": 857700,
    "end": 862620,
    "text": "つまり、4台のデバイスがあれば、32＋マイクロバッチが必要ということだ。"
  },
  {
    "start": 862732,
    "end": 869512,
    "text": "文字通り、スループットがほぼリニアにスケーリングされることを示している。"
  },
  {
    "start": 869668,
    "end": 877324,
    "text": "なるほど、これが巨大なモデルを複数のデバイスに分割する一つの方法だ。"
  },
  {
    "start": 877824,
    "end": 883832,
    "text": "各デバイスは、ネットワーク・ウェイトの一部、つまりスライスだけを持つことになる。"
  },
  {
    "start": 883928,
    "end": 889568,
    "text": "したがって、スループットが向上するため、このシステム全体をより速くトレーニングすることができる。"
  },
  {
    "start": 889616,
    "end": 894564,
    "text": "というのも、1つのデバイスにそれを詰め込むことはできないからだ。"
  },
  {
    "start": 895004,
    "end": 896420,
    "text": "よし、これが2つ目のアイデアだ。"
  },
  {
    "start": 896452,
    "end": 898024,
    "text": "では、実際の論文を見てみよう。"
  },
  {
    "start": 899044,
    "end": 900504,
    "text": "これはとても楽しい。"
  },
  {
    "start": 900844,
    "end": 902684,
    "text": "最初の文章に戻ろう。"
  },
  {
    "start": 902724,
    "end": 905308,
    "text": "イントラレイヤー・モデルのパラレル・アプローチだ。"
  },
  {
    "start": 905356,
    "end": 906372,
    "text": "それが何を意味するのか、今はわかっている。"
  },
  {
    "start": 906428,
    "end": 907004,
    "text": "イントラだよ。"
  },
  {
    "start": 907044,
    "end": 908124,
    "text": "実際のレイヤーを分割している。"
  },
  {
    "start": 908164,
    "end": 909892,
    "text": "レイヤーをまたいで分裂しているわけではない。"
  },
  {
    "start": 909988,
    "end": 914904,
    "text": "ひとつのレイヤーを2つのパート、あるいは4つのパート、8つのパートに分ける。"
  },
  {
    "start": 915724,
    "end": 919068,
    "text": "我々のアプローチは、新しいコンパイラーやライブラリーの変更を必要としない。"
  },
  {
    "start": 919116,
    "end": 928274,
    "text": "これは、パイプラインモデルの並列性と直交し、補完し合うもので、ネイティブのPytorchにいくつかの通信オペレーションを挿入するだけで完全に実装することができる。"
  },
  {
    "start": 928434,
    "end": 931530,
    "text": "クールなのは、補完する部分がとても重要だということだ。"
  },
  {
    "start": 931642,
    "end": 939654,
    "text": "この部分は超重要で、この2つのアプローチを組み合わせることで、さらに大きなモデルサイズに拡大することができるからだ。"
  },
  {
    "start": 940394,
    "end": 942186,
    "text": "じゃあ、こう言うんだ。"
  },
  {
    "start": 942250,
    "end": 952420,
    "text": "強力なシングルGPUと比較して76%のスケーリング効率で、アプリケーション全体で15.1ペタフロップスを維持しています。"
  },
  {
    "start": 952452,
    "end": 958420,
    "text": "ピーク時の30％にあたる39テラフロップスを維持するベースライン。"
  },
  {
    "start": 958492,
    "end": 959812,
    "text": "ちょっと整理してみよう。"
  },
  {
    "start": 959908,
    "end": 967700,
    "text": "まず最初に、ここで言い忘れたが、彼らは83億のパラメーターを持つモデルを512GPUでトレーニングしている。"
  },
  {
    "start": 967732,
    "end": 968292,
    "text": "いいかい？"
  },
  {
    "start": 968428,
    "end": 972500,
    "text": "ここで私が言いたいのは、15.1ペラのスループットを達成しているということだ。"
  },
  {
    "start": 972572,
    "end": 977244,
    "text": "パラは10の15乗くらいかな。"
  },
  {
    "start": 977324,
    "end": 981464,
    "text": "1000テラか1024テラか、それは人による。"
  },
  {
    "start": 981884,
    "end": 985228,
    "text": "Flopsは1秒あたりの浮動小数点演算回数。"
  },
  {
    "start": 985276,
    "end": 988004,
    "text": "つまり、1秒間にこれだけのオペレーションがあるということだ。"
  },
  {
    "start": 988044,
    "end": 988828,
    "text": "膨大な数だ。"
  },
  {
    "start": 988876,
    "end": 989544,
    "text": "オーケー。"
  },
  {
    "start": 989964,
    "end": 995972,
    "text": "彼らが言うところによれば、スケーリング効率は76％だという。"
  },
  {
    "start": 996068,
    "end": 997588,
    "text": "実際のところはどうなのか？"
  },
  {
    "start": 997636,
    "end": 998268,
    "text": "つまり、次のようなことだ。"
  },
  {
    "start": 998316,
    "end": 999984,
    "text": "ここで電卓を開いてみよう。"
  },
  {
    "start": 1000334,
    "end": 1005326,
    "text": "シングル・デバイス、シングルGPUで39テラフロップス。"
  },
  {
    "start": 1005430,
    "end": 1011030,
    "text": "GPUの数を39倍にすれば、理想的なスケーリングになる。"
  },
  {
    "start": 1011142,
    "end": 1013774,
    "text": "最終的には19ペタフロップスになる。"
  },
  {
    "start": 1013894,
    "end": 1017182,
    "text": "15.1点しか取れないことがわかるだろう。"
  },
  {
    "start": 1017278,
    "end": 1022390,
    "text": "そこで、この76％のスケーリング効率が威力を発揮する。"
  },
  {
    "start": 1022422,
    "end": 1029597,
    "text": "これに0.76をかけると、ちょうど15.1ペタフロップスになる。"
  },
  {
    "start": 1029725,
    "end": 1042565,
    "text": "基本的に、GPUのベースラインは理論ピークの30％で、GPUが理論ピークに達することはありません。"
  },
  {
    "start": 1042669,
    "end": 1050269,
    "text": "複数のデバイスにまたがってスケーリングする場合は、理想的なリニアスケーリングにはなりませんが、それに近いものにはなります。"
  },
  {
    "start": 1050381,
    "end": 1051313,
    "text": "クールだね。"
  },
  {
    "start": 1051693,
    "end": 1054492,
    "text": "さて、ではここで続けよう。"
  },
  {
    "start": 1054628,
    "end": 1056060,
    "text": "何が面白いか見てみよう。"
  },
  {
    "start": 1056212,
    "end": 1063196,
    "text": "これから2つのブロックをどのように分割するかを見ていく。"
  },
  {
    "start": 1063260,
    "end": 1066492,
    "text": "まずはMLPブロックをどのように分割するか見てみよう。"
  },
  {
    "start": 1066628,
    "end": 1068076,
    "text": "では、お見せしましょう。"
  },
  {
    "start": 1068180,
    "end": 1069588,
    "text": "この方が簡単だろう。"
  },
  {
    "start": 1069716,
    "end": 1072676,
    "text": "アテンションブロックをどう分けるか？"
  },
  {
    "start": 1072860,
    "end": 1077692,
    "text": "また、入力の埋め込みだけでなく、出力の埋め込みも分割する。"
  },
  {
    "start": 1077788,
    "end": 1085686,
    "text": "最後に、特筆すべき詳細として、この残留接続、追加レイヤーの規範は、実際にはデバイス間で複製される。"
  },
  {
    "start": 1085750,
    "end": 1087714,
    "text": "重複している部分がある。"
  },
  {
    "start": 1088214,
    "end": 1093114,
    "text": "さまざまな理由から、それが最も最適なことだと判断したのだ。"
  },
  {
    "start": 1093494,
    "end": 1094406,
    "text": "それが計画だ。"
  },
  {
    "start": 1094470,
    "end": 1098462,
    "text": "さて、MLPを縦割りにするにはどうすればいいか？"
  },
  {
    "start": 1098558,
    "end": 1101742,
    "text": "アテンションブロックを縦に分割するには？"
  },
  {
    "start": 1101798,
    "end": 1104390,
    "text": "これが本稿の主旨だ。"
  },
  {
    "start": 1104462,
    "end": 1106582,
    "text": "よし、ここから始めよう。"
  },
  {
    "start": 1106758,
    "end": 1111018,
    "text": "ここで、分割がどのように行われるかの図をご覧いただきたい。"
  },
  {
    "start": 1111126,
    "end": 1119482,
    "text": "上の図はMLPブロックを示している。"
  },
  {
    "start": 1119538,
    "end": 1127386,
    "text": "これが最初のリニアレイヤー、2番目のレイヤーで、こうして分割されていくのがわかるだろう。"
  },
  {
    "start": 1127530,
    "end": 1129754,
    "text": "計算式を見てみよう。"
  },
  {
    "start": 1129794,
    "end": 1132674,
    "text": "この仕組みを少しずつ理解していくつもりだ。"
  },
  {
    "start": 1132754,
    "end": 1150444,
    "text": "まずハイレベルな話として、このリニアレイヤーのウェイトを列ごとに分割し、1つのデバイスには2を、2つ目のデバイスには1を維持する。"
  },
  {
    "start": 1150484,
    "end": 1156412,
    "text": "フィードフォワード層に使う行列を2つに分割する。"
  },
  {
    "start": 1156508,
    "end": 1161812,
    "text": "ここでも同じことをするが、違うのは、ここでは列を分けていることだ。"
  },
  {
    "start": 1161868,
    "end": 1166124,
    "text": "列単位ではなく行単位で分割しているのがわかるだろう？"
  },
  {
    "start": 1166204,
    "end": 1168924,
    "text": "そうすれば、1台で1つのデバイスになる。"
  },
  {
    "start": 1169004,
    "end": 1170628,
    "text": "2つ目のデバイスにB2を置く。"
  },
  {
    "start": 1170716,
    "end": 1177744,
    "text": "基本的に、これらの操作はすべて1つのデバイスで行われていることがわかるだろう？"
  },
  {
    "start": 1178324,
    "end": 1185064,
    "text": "そして、2つのデバイスを同期させるために、このg操作が行われる。"
  },
  {
    "start": 1185724,
    "end": 1192388,
    "text": "番目のデバイスは、明らかにMLPの2番目の部分を処理している。"
  },
  {
    "start": 1192476,
    "end": 1192916,
    "text": "いいかい？"
  },
  {
    "start": 1192980,
    "end": 1194836,
    "text": "aが1つ、bが1つある。"
  },
  {
    "start": 1194860,
    "end": 1197804,
    "text": "そう、そうやって縦割りを実現したんだ。"
  },
  {
    "start": 1197884,
    "end": 1199244,
    "text": "これはあくまでもハイレベルの図だ。"
  },
  {
    "start": 1199284,
    "end": 1205756,
    "text": "これがなぜ機能するのか、同じデバイス上にすべてを置くのとどう違うのかを理解しよう。"
  },
  {
    "start": 1205860,
    "end": 1212564,
    "text": "初見で理解するのは難しいかもしれないが、少し考えれば簡単なことだ。"
  },
  {
    "start": 1212644,
    "end": 1214692,
    "text": "さて、それでは実装してみよう。"
  },
  {
    "start": 1214748,
    "end": 1216324,
    "text": "このレイヤーの役割は以下の通りだ。"
  },
  {
    "start": 1216404,
    "end": 1220036,
    "text": "ここでは、フィードフォワード層が何をするのかを説明する。"
  },
  {
    "start": 1220140,
    "end": 1229144,
    "text": "これが入力データxで、これが重み行列a、そしてこれが活性化単位の値です。"
  },
  {
    "start": 1230004,
    "end": 1232452,
    "text": "分割する方法は何通りもある。"
  },
  {
    "start": 1232508,
    "end": 1234348,
    "text": "列単位と行単位で見た。"
  },
  {
    "start": 1234396,
    "end": 1237304,
    "text": "両者の長所と短所を見てみよう。"
  },
  {
    "start": 1237604,
    "end": 1246444,
    "text": "ここにあるように、ウェイト行列を基本的に行ごとに分割すると、問題が発生する。"
  },
  {
    "start": 1246604,
    "end": 1250624,
    "text": "問題は、このパスの後にデバイスを同期させる必要があることだ。"
  },
  {
    "start": 1250704,
    "end": 1251904,
    "text": "その理由を見てみよう。"
  },
  {
    "start": 1251984,
    "end": 1262640,
    "text": "これを掛け合わせれば、x1×1＋x2×2となる。"
  },
  {
    "start": 1262752,
    "end": 1264444,
    "text": "問題はプラスだ。"
  },
  {
    "start": 1265224,
    "end": 1268256,
    "text": "つまり、2つのデバイスが通信する必要があるということだ。"
  },
  {
    "start": 1268400,
    "end": 1274344,
    "text": "それが唯一の方法であり、2つの別々のアクティベーションを追加することができるよね？"
  },
  {
    "start": 1274424,
    "end": 1275724,
    "text": "その後、その値を適用する。"
  },
  {
    "start": 1276244,
    "end": 1280284,
    "text": "問題は、ゼリーが非線形関数であることだ。"
  },
  {
    "start": 1280324,
    "end": 1289756,
    "text": "この2つを足したゼリーは、第1項のゼリーに第2項のゼリーを足したものとは違う。"
  },
  {
    "start": 1289900,
    "end": 1295468,
    "text": "そのため、この方法ではゼリー機能の前に同期ポイントが必要になるという。"
  },
  {
    "start": 1295556,
    "end": 1305900,
    "text": "さて、この行列の掛け算を、おそらく皆さんがよく知っている図にマッピングしてみよう。"
  },
  {
    "start": 1305972,
    "end": 1308468,
    "text": "よし、ではこう始めよう。"
  },
  {
    "start": 1308636,
    "end": 1310420,
    "text": "入力データxがある。"
  },
  {
    "start": 1310492,
    "end": 1314228,
    "text": "バッチサイズは1つだけと仮定する。"
  },
  {
    "start": 1314356,
    "end": 1316024,
    "text": "こんな感じだ。"
  },
  {
    "start": 1316644,
    "end": 1320492,
    "text": "ここでxを2つに分割する。"
  },
  {
    "start": 1320548,
    "end": 1324892,
    "text": "ここにx1とx2がある。"
  },
  {
    "start": 1324988,
    "end": 1330786,
    "text": "さて、次はフィードフォワード・レイヤーを通す必要がある。"
  },
  {
    "start": 1330810,
    "end": 1332786,
    "text": "ウェイトマトリックスがある。"
  },
  {
    "start": 1332930,
    "end": 1334586,
    "text": "私たちはそれを使って増殖するつもりだ。"
  },
  {
    "start": 1334690,
    "end": 1337874,
    "text": "これはただの箱になる。"
  },
  {
    "start": 1337994,
    "end": 1343094,
    "text": "詳細はもう少し後で詰めるつもりで、最終的な表現に行き着く。"
  },
  {
    "start": 1344314,
    "end": 1349122,
    "text": "ここでは赤い四角で囲むことにする。"
  },
  {
    "start": 1349258,
    "end": 1349978,
    "text": "それだけだ。"
  },
  {
    "start": 1350026,
    "end": 1355484,
    "text": "さて、ここでマトリックスのように描いてみよう。"
  },
  {
    "start": 1355984,
    "end": 1361384,
    "text": "行列を基本的に行単位で分割するとした。"
  },
  {
    "start": 1361424,
    "end": 1361912,
    "text": "そうだろう？"
  },
  {
    "start": 1362048,
    "end": 1364752,
    "text": "行列を行単位で分割することになる。"
  },
  {
    "start": 1364888,
    "end": 1366484,
    "text": "さて、どうなることやら。"
  },
  {
    "start": 1367104,
    "end": 1374884,
    "text": "この部分を掛け合わせ、少しズームインしてみる。"
  },
  {
    "start": 1376104,
    "end": 1382988,
    "text": "この部分とこの部分を掛け合わせると、どういうことになる？"
  },
  {
    "start": 1383076,
    "end": 1387284,
    "text": "ということは、次のようなことをする、ということだ。"
  },
  {
    "start": 1387404,
    "end": 1389188,
    "text": "おっと、これは文字通りだ。"
  },
  {
    "start": 1389316,
    "end": 1398476,
    "text": "もし、あなたがニューラル・ネットワークのようなものを書くとしたら、また、あなたがニューラル・ネットワークを描くとしたら、このようになります。"
  },
  {
    "start": 1398540,
    "end": 1406168,
    "text": "この部分とこの部分を掛け合わせ、さらにこの部分と2番目の部分を掛け合わせる。"
  },
  {
    "start": 1406216,
    "end": 1415560,
    "text": "さて、ここで2つ目のピースを掛け合わせると、2つ目のピースから2つ目の出力が得られる。"
  },
  {
    "start": 1415712,
    "end": 1420424,
    "text": "そして、こことここをこうすると、最終的に4つの出力ができる。"
  },
  {
    "start": 1420504,
    "end": 1425764,
    "text": "図面を簡単にするために4つしか使っていないんだ。"
  },
  {
    "start": 1426584,
    "end": 1436218,
    "text": "問題なのは、これらの出力はすべて、x2の部分からの寄与が欠けているため、まだ不完全だということだ。"
  },
  {
    "start": 1436346,
    "end": 1439602,
    "text": "だから、実際の表現を加えなければならない。"
  },
  {
    "start": 1439778,
    "end": 1444734,
    "text": "では、色を赤に変えてみましょう。"
  },
  {
    "start": 1445194,
    "end": 1453850,
    "text": "ここで、最初の出力要素に寄与するために、この要素とこの要素の掛け算をしなければならない。"
  },
  {
    "start": 1453962,
    "end": 1456778,
    "text": "よし、これでこうなった。"
  },
  {
    "start": 1456866,
    "end": 1462130,
    "text": "そして、ただ繰り返し、繰り返し、繰り返し、これにも、これにも、これにも貢献する。"
  },
  {
    "start": 1462162,
    "end": 1470174,
    "text": "さて、これで皆さんが慣れ親しんでいるニューラルネットワークの図に、この図がどのようにマッピングされているかを理解していただけたと思います。"
  },
  {
    "start": 1470334,
    "end": 1477838,
    "text": "おわかりのように、xを1回ずつやるだけでは、出力には部分的な貢献しか得られない。"
  },
  {
    "start": 1477926,
    "end": 1484110,
    "text": "そのため、さらにDXを足して2にしなければならず、そうして初めてゼリーを塗ることができる。"
  },
  {
    "start": 1484182,
    "end": 1490932,
    "text": "さて、次にウェイトマトリックスを分解する2つ目の方法を説明しよう。"
  },
  {
    "start": 1491028,
    "end": 1492388,
    "text": "これが列の分割だ。"
  },
  {
    "start": 1492436,
    "end": 1496196,
    "text": "では、別の方法として、このように列に沿って分割することもできる。"
  },
  {
    "start": 1496300,
    "end": 1504556,
    "text": "この分割によって、分割された各宝石の出力に、ゲリアン一次性を独立して適用することができる。"
  },
  {
    "start": 1504660,
    "end": 1511500,
    "text": "この利点は、文字通りxを送ることができることだ。"
  },
  {
    "start": 1511532,
    "end": 1514596,
    "text": "これは非常に重要なことだ。"
  },
  {
    "start": 1514700,
    "end": 1517354,
    "text": "ここに×1、ここに×1がある。"
  },
  {
    "start": 1517434,
    "end": 1519494,
    "text": "つまり、入力全体を渡すということだ。"
  },
  {
    "start": 1519794,
    "end": 1522374,
    "text": "ここでも2本あった。"
  },
  {
    "start": 1522674,
    "end": 1529850,
    "text": "でも、ここで得られる利点は、文字通り、そのデバイスですべてを行い、ゲルを適用して終わりということだ。"
  },
  {
    "start": 1529882,
    "end": 1531842,
    "text": "同期はしていない。"
  },
  {
    "start": 1531898,
    "end": 1534458,
    "text": "同期のスピードは遅くなる。"
  },
  {
    "start": 1534506,
    "end": 1538810,
    "text": "重さを伝え、合計して、それを返さなければならない。"
  },
  {
    "start": 1538882,
    "end": 1542512,
    "text": "なるほど、これは同期ポイントがなくなるので有利だ。"
  },
  {
    "start": 1542618,
    "end": 1550116,
    "text": "したがって、1つ目の宝石をこの列並列方式で分割し、2つ目の宝石をその行に沿って分割する。"
  },
  {
    "start": 1550220,
    "end": 1557564,
    "text": "これは、図3のaに示すように、通信を必要とせずに直接ゼリー層の出力を取る。"
  },
  {
    "start": 1557684,
    "end": 1559860,
    "text": "それが、これからやろうとしているハッキングだ。"
  },
  {
    "start": 1559932,
    "end": 1565876,
    "text": "まず、列の分割がどのようになるかをお見せしよう。"
  },
  {
    "start": 1565980,
    "end": 1568928,
    "text": "もう一度、同じ図を描くよ。"
  },
  {
    "start": 1569116,
    "end": 1570804,
    "text": "色を変えよう"
  },
  {
    "start": 1571344,
    "end": 1573696,
    "text": "もう一度、同じような図を書いてみよう。"
  },
  {
    "start": 1573840,
    "end": 1576164,
    "text": "私たちのXはここにある。"
  },
  {
    "start": 1577384,
    "end": 1582088,
    "text": "これは私たちのXだ。"
  },
  {
    "start": 1582136,
    "end": 1591064,
    "text": "このように枠を描いて、プレースホルダーを作り、赤を選ぶ。"
  },
  {
    "start": 1591104,
    "end": 1594804,
    "text": "出力表現を赤で示す。"
  },
  {
    "start": 1595244,
    "end": 1598428,
    "text": "では、入力されたxを掛け算してみよう。"
  },
  {
    "start": 1598476,
    "end": 1599452,
    "text": "これもまた×。"
  },
  {
    "start": 1599548,
    "end": 1606444,
    "text": "列ごとに分割した行列にxを掛けてみよう。"
  },
  {
    "start": 1606524,
    "end": 1608228,
    "text": "それが大きな違いだ。"
  },
  {
    "start": 1608276,
    "end": 1609636,
    "text": "オーケー、では分割しよう。"
  },
  {
    "start": 1609700,
    "end": 1612228,
    "text": "ここで横長のものを見ただろう。"
  },
  {
    "start": 1612356,
    "end": 1613804,
    "text": "ここでは縦割りになっている。"
  },
  {
    "start": 1613844,
    "end": 1615756,
    "text": "さて、それでどうなる？"
  },
  {
    "start": 1615900,
    "end": 1616916,
    "text": "では、これを見ていこう。"
  },
  {
    "start": 1617020,
    "end": 1623992,
    "text": "これとこれを掛け合わせると、文字通り完全な表現になる。"
  },
  {
    "start": 1624048,
    "end": 1627644,
    "text": "この出力は必要なものをすべて備えている。"
  },
  {
    "start": 1628024,
    "end": 1634192,
    "text": "それは完全に、入力から必要なすべての情報を持っている。"
  },
  {
    "start": 1634328,
    "end": 1635664,
    "text": "それから同じことをする。"
  },
  {
    "start": 1635744,
    "end": 1638736,
    "text": "これで、基本的に何が起こるかわかるだろう。"
  },
  {
    "start": 1638800,
    "end": 1640884,
    "text": "色をグレーに変えようかな。"
  },
  {
    "start": 1641464,
    "end": 1652126,
    "text": "この部分とこの行列を掛け続けると、出力表現ベクトルの半分が出来上がる。"
  },
  {
    "start": 1652230,
    "end": 1660262,
    "text": "この半分は、実際に必要な情報がすべて含まれているので、合計する必要はない。"
  },
  {
    "start": 1660398,
    "end": 1661518,
    "text": "それがここでのアドバンテージだ。"
  },
  {
    "start": 1661566,
    "end": 1664662,
    "text": "じゃあ、2つのデバイスでやってみよう。"
  },
  {
    "start": 1664798,
    "end": 1666390,
    "text": "結局、このような表現に行き着く。"
  },
  {
    "start": 1666502,
    "end": 1669886,
    "text": "私たちは価値観を適用し、そして餌を与える。"
  },
  {
    "start": 1669950,
    "end": 1671894,
    "text": "だから今、これがいいところなんだ。"
  },
  {
    "start": 1671934,
    "end": 1675384,
    "text": "文字どおり、ここに表示されているものを取り上げるだけだ。"
  },
  {
    "start": 1675534,
    "end": 1677060,
    "text": "またジェルを塗る。"
  },
  {
    "start": 1677132,
    "end": 1688900,
    "text": "Gelluを適用し、それをx1として、重み行列を水平に分割するこのレイヤーに送る。"
  },
  {
    "start": 1689012,
    "end": 1690428,
    "text": "それがいいところだ。"
  },
  {
    "start": 1690516,
    "end": 1699140,
    "text": "この2つを連結するとMLPになり、文字通り1つのデバイスに重みの半分、もう1つのデバイスに重みの半分があることになる。"
  },
  {
    "start": 1699252,
    "end": 1699820,
    "text": "それだけだ。"
  },
  {
    "start": 1699892,
    "end": 1700930,
    "text": "簡単なことだ。"
  },
  {
    "start": 1701052,
    "end": 1702794,
    "text": "私に言わせれば、美しいアイデアだ。"
  },
  {
    "start": 1703214,
    "end": 1705134,
    "text": "とてもシンプルだが、とても美しい。"
  },
  {
    "start": 1705294,
    "end": 1708394,
    "text": "それはまたここに描かれている。"
  },
  {
    "start": 1708854,
    "end": 1711630,
    "text": "xから始め、xを複製する。"
  },
  {
    "start": 1711782,
    "end": 1716742,
    "text": "そうすれば、これは列分割なので、xを2にすればいい。"
  },
  {
    "start": 1716878,
    "end": 1720030,
    "text": "そして値を適用し、それをここに送り込む。"
  },
  {
    "start": 1720142,
    "end": 1722278,
    "text": "で、bを2倍する。"
  },
  {
    "start": 1722366,
    "end": 1725982,
    "text": "ここでは、横一列になっている。"
  },
  {
    "start": 1726078,
    "end": 1729726,
    "text": "gがあり、これが同期操作である。"
  },
  {
    "start": 1729790,
    "end": 1731334,
    "text": "ということは、それらを総括するということだ。"
  },
  {
    "start": 1731454,
    "end": 1734766,
    "text": "最終的にzという表現になる。"
  },
  {
    "start": 1734870,
    "end": 1735526,
    "text": "それだけだ。"
  },
  {
    "start": 1735630,
    "end": 1738030,
    "text": "これがMLP層の分割方法だ。"
  },
  {
    "start": 1738102,
    "end": 1741394,
    "text": "さて、ここで何か面白いことがないか見てみよう。"
  },
  {
    "start": 1741774,
    "end": 1748886,
    "text": "このアプローチでは、MLPブロックの両ジェムをGPU間で分割し、フォワードパスでは1回の全リデュース演算しか必要としません。"
  },
  {
    "start": 1748990,
    "end": 1753286,
    "text": "後方パスでは、g演算子とf演算子ですべての演算を行う。"
  },
  {
    "start": 1753390,
    "end": 1756586,
    "text": "その様子をお見せしよう。"
  },
  {
    "start": 1756610,
    "end": 1758090,
    "text": "もう一度言う。"
  },
  {
    "start": 1758202,
    "end": 1770130,
    "text": "フォワードパスでは、オーバーデュースするために同期させる必要があるのはここ、Gだけで、バックパスでは、ここで勾配を得たら、どうにかそれらを組み合わせて、ここで表現する必要がある。"
  },
  {
    "start": 1770162,
    "end": 1775322,
    "text": "文字通り、足して2で割るしかない。"
  },
  {
    "start": 1775418,
    "end": 1777786,
    "text": "同期プリミティブが必要なのだ。"
  },
  {
    "start": 1777850,
    "end": 1781122,
    "text": "さて、次は注目の部分だ。"
  },
  {
    "start": 1781218,
    "end": 1789008,
    "text": "このような大規模な言語モデルに投入されるエンジニアリングやインフラストラクチャー全体について、ご理解いただけたと思います。"
  },
  {
    "start": 1789056,
    "end": 1800744,
    "text": "コード内のハイパーパラメーターを5層から120層のトランスフォーマーに設定するだけで、1台のデバイスですべてが魔法のように機能すると期待するようなものではない。"
  },
  {
    "start": 1800824,
    "end": 1802712,
    "text": "多くのエンジニアリングが行われている。"
  },
  {
    "start": 1802888,
    "end": 1805204,
    "text": "私はここで、その方法のいくつかを説明しようとしている。"
  },
  {
    "start": 1806744,
    "end": 1809604,
    "text": "注意はもう少し簡単だと私は思う。"
  },
  {
    "start": 1810344,
    "end": 1813402,
    "text": "つまり、クエリ・マトリクスを文字どおり受け取って、私はそれを実行する。"
  },
  {
    "start": 1813458,
    "end": 1814986,
    "text": "トランスフォーマーについて説明するつもりはない。"
  },
  {
    "start": 1815050,
    "end": 1816674,
    "text": "私のトランスフォーマーのビデオもぜひご覧ください。"
  },
  {
    "start": 1816714,
    "end": 1818214,
    "text": "ここのどこかにリンクするつもりだ。"
  },
  {
    "start": 1818594,
    "end": 1821962,
    "text": "トランスフォーマーモデルの詳細をご存じない方のために。"
  },
  {
    "start": 1822138,
    "end": 1830714,
    "text": "クエリ行列を取り出し、キー行列を取り出し、値行列を取り出し、基本的には列ごとに分割する。"
  },
  {
    "start": 1830874,
    "end": 1837458,
    "text": "これらの各カラムは、文字通り1つのヘッドに対するクエリーを計算することになる。"
  },
  {
    "start": 1837506,
    "end": 1839034,
    "text": "我々はマルチハットに注目している。"
  },
  {
    "start": 1839154,
    "end": 1842854,
    "text": "ここでは議論のために、頭が2つしかないと想像してみよう。"
  },
  {
    "start": 1842994,
    "end": 1845518,
    "text": "ところで、それで思い出したのだが、ちょっとだけ言わせてほしい。"
  },
  {
    "start": 1845606,
    "end": 1851086,
    "text": "ここでは2つしかないのに、いわゆる2ウェイモデルの並列性を分割している。"
  },
  {
    "start": 1851230,
    "end": 1856526,
    "text": "ウェイト行列をもっと、まあ、パーツに分割することは想像できるだろう。"
  },
  {
    "start": 1856590,
    "end": 1860190,
    "text": "4ウェイ・モデルのパラレリズムや8ウェイ・モデルのパラレリズムが可能だ。"
  },
  {
    "start": 1860342,
    "end": 1864430,
    "text": "その等価なものを維持するつもりだと、自分自身を納得させることができる。"
  },
  {
    "start": 1864462,
    "end": 1879218,
    "text": "を8行に分割し、入力データも同様に8個に分割すれば、x1、1＋x2、2＋x3、3＋、、、となる。"
  },
  {
    "start": 1879266,
    "end": 1882642,
    "text": "などなど、8×8、8×8になるまで。"
  },
  {
    "start": 1882738,
    "end": 1885714,
    "text": "それから同期させて、ゼリーを塗る。"
  },
  {
    "start": 1885794,
    "end": 1890294,
    "text": "これを複数の部分に分けることを妨げるものは何もない。"
  },
  {
    "start": 1890674,
    "end": 1893394,
    "text": "さて、それでは注意に戻ろう。"
  },
  {
    "start": 1893554,
    "end": 1898868,
    "text": "ここで、説明の便宜上、頭が2つしかないと仮定しよう。"
  },
  {
    "start": 1898956,
    "end": 1902464,
    "text": "基本的に何が起こるかというと、ここにある装置だ。"
  },
  {
    "start": 1902924,
    "end": 1909348,
    "text": "この装置が最初のヘッドを計算する。"
  },
  {
    "start": 1909436,
    "end": 1918924,
    "text": "この図の下部は、第1ヘッドと最下層の表現で、第2ヘッドを計算しようとしている。"
  },
  {
    "start": 1919044,
    "end": 1923508,
    "text": "これがヘッド1の表現で、これがヘッド2の表現だ。"
  },
  {
    "start": 1923636,
    "end": 1925260,
    "text": "それなら、ここで食べさせるだけだ。"
  },
  {
    "start": 1925372,
    "end": 1933636,
    "text": "これはすでにお馴染みで、うまくいけばフィードフォワード層を分割して行を作ることができる。"
  },
  {
    "start": 1933700,
    "end": 1940028,
    "text": "というのも、両者を同期させ、出力表現を得る必要があるからだ。"
  },
  {
    "start": 1940156,
    "end": 1944444,
    "text": "では、小さな図を使って、もう一度簡単にデモンストレーションしてみよう。"
  },
  {
    "start": 1944604,
    "end": 1947140,
    "text": "まずはインプットから。"
  },
  {
    "start": 1947292,
    "end": 1950700,
    "text": "バッチ1、シーケンスサイズ1とする。"
  },
  {
    "start": 1950732,
    "end": 1952252,
    "text": "文字通り、トークンは1つしかない。"
  },
  {
    "start": 1952348,
    "end": 1957306,
    "text": "それが一番簡単なケースになるだろうが、うまくいけば、その点を強調することができるだろう。"
  },
  {
    "start": 1957450,
    "end": 1960734,
    "text": "さて、これが入力データだ。"
  },
  {
    "start": 1961514,
    "end": 1961874,
    "text": "X."
  },
  {
    "start": 1961914,
    "end": 1963418,
    "text": "繰り返すが、トークンは1つだ。"
  },
  {
    "start": 1963586,
    "end": 1970202,
    "text": "bの場合、バッチサイズは1sであり、これは通常この次元に沿って1である。"
  },
  {
    "start": 1970258,
    "end": 1973450,
    "text": "私たちは、ある程度の次元を持つ単一のトークンを持っているだけだ。"
  },
  {
    "start": 1973482,
    "end": 1977866,
    "text": "じゃあ、たぶんH、隠された次元だね。"
  },
  {
    "start": 1977930,
    "end": 1986632,
    "text": "さて、ではどうするかというと、基本的にはキークエリーと値を使ってマッピングする。"
  },
  {
    "start": 1986768,
    "end": 2000724,
    "text": "最初のデバイスは、クエリ、キー、値を持っている。"
  },
  {
    "start": 2001904,
    "end": 2009680,
    "text": "入力と比較して、次元が2倍小さくなっているのがわかるだろう。"
  },
  {
    "start": 2009832,
    "end": 2020326,
    "text": "これで、文字通り変圧器のマジックを使うことになり、最終的に2×2の小さなサイズになる。"
  },
  {
    "start": 2020350,
    "end": 2021462,
    "text": "これがH2だ。"
  },
  {
    "start": 2021518,
    "end": 2023614,
    "text": "これがhなら、これはh2だ。"
  },
  {
    "start": 2023654,
    "end": 2024354,
    "text": "オーケー。"
  },
  {
    "start": 2024734,
    "end": 2027846,
    "text": "別のデバイスで同じことをするだけだ。"
  },
  {
    "start": 2027950,
    "end": 2029566,
    "text": "君も同じ理屈を言うだろう。"
  },
  {
    "start": 2029670,
    "end": 2031782,
    "text": "こんな感じでいいかな。"
  },
  {
    "start": 2031838,
    "end": 2037678,
    "text": "結局は同じ、いや、違う表現になるだろうが、ここでは同じ構造になる。"
  },
  {
    "start": 2037766,
    "end": 2039534,
    "text": "結局、このHは2つある。"
  },
  {
    "start": 2039574,
    "end": 2046958,
    "text": "トークンをフィードフォワード層に渡す。"
  },
  {
    "start": 2047086,
    "end": 2048390,
    "text": "私たちは掛け算をする。"
  },
  {
    "start": 2048502,
    "end": 2053470,
    "text": "今、私たちは文字通り、x1とx2で同じ例を持っている。"
  },
  {
    "start": 2053502,
    "end": 2055958,
    "text": "データを2つに分けた。"
  },
  {
    "start": 2056046,
    "end": 2057342,
    "text": "それが私たちがここでやったことだ。"
  },
  {
    "start": 2057478,
    "end": 2063894,
    "text": "文字通り、掛け算をするとこうなる。"
  },
  {
    "start": 2064054,
    "end": 2066622,
    "text": "そうだ、色を青に変えてみよう。"
  },
  {
    "start": 2066758,
    "end": 2068534,
    "text": "結局はこうなる。"
  },
  {
    "start": 2068614,
    "end": 2071870,
    "text": "こんな感じだ。"
  },
  {
    "start": 2071982,
    "end": 2075166,
    "text": "という完全な表現になる。"
  },
  {
    "start": 2075350,
    "end": 2079062,
    "text": "思い起こせば、我々は文字通り部分的な表現を持っている。"
  },
  {
    "start": 2079158,
    "end": 2088094,
    "text": "このマッピングの上に、この表現から得られるマッピングを追加しなければならない。"
  },
  {
    "start": 2088174,
    "end": 2095158,
    "text": "今、私たちはここにあるものを合計しなければならない。"
  },
  {
    "start": 2095286,
    "end": 2098234,
    "text": "これがg演算子だ。"
  },
  {
    "start": 2098624,
    "end": 2100720,
    "text": "アイデアが明確であることを願っている。"
  },
  {
    "start": 2100792,
    "end": 2102576,
    "text": "これまでは、それが主な考えだった。"
  },
  {
    "start": 2102600,
    "end": 2104424,
    "text": "ここで、ちょっと文章を説明しよう。"
  },
  {
    "start": 2104504,
    "end": 2115764,
    "text": "そこで、各注意ヘッドに対応する行列の乗算が1つのGPU上で局所的に行われるように、列並列方式でキー、クエリー、値に関連する宝石を分割する。"
  },
  {
    "start": 2116904,
    "end": 2127292,
    "text": "これにより、アテンション・ヘッドごとのパラメーターとワークロードをGPU間で分割することができ、自己アテンションを完了させるための即時通信を必要としない。"
  },
  {
    "start": 2127348,
    "end": 2127932,
    "text": "それはとても重要なことだ。"
  },
  {
    "start": 2127988,
    "end": 2129876,
    "text": "即座のコミュニケーションは必要ない。"
  },
  {
    "start": 2129940,
    "end": 2136660,
    "text": "なるほど、MLPと自己注意層の両方に対するこのアプローチは、2つの宝石のグループを融合させたものだ。"
  },
  {
    "start": 2136732,
    "end": 2144052,
    "text": "一般的な行列の乗算では、その間の同期ポイントがなくなり、スケーリングが向上する。"
  },
  {
    "start": 2144148,
    "end": 2154460,
    "text": "つまり、この2つの図を見ていただければわかるように、一般的な行列の乗算があり、その後に何かが起こり、そして一般的な行列の乗算がある。"
  },
  {
    "start": 2154572,
    "end": 2162340,
    "text": "コンパイラーは十分に賢いので、これらの演算を最適化し、文字どおり1つの行列乗算器になるように融合させることができる。"
  },
  {
    "start": 2162452,
    "end": 2165036,
    "text": "そのような低レベルの詳細にはあまり詳しくない。"
  },
  {
    "start": 2165060,
    "end": 2168424,
    "text": "そうする必要があったことはないけど、今のところはそう理解している。"
  },
  {
    "start": 2169804,
    "end": 2170796,
    "text": "ここではそう言われている。"
  },
  {
    "start": 2170820,
    "end": 2172492,
    "text": "その結果、スケーリングが向上する。"
  },
  {
    "start": 2172588,
    "end": 2176924,
    "text": "これにより、シンプルなトランスフォーマーレイヤーで、たった2つのレイヤーですべてのジェムを実行することができる。"
  },
  {
    "start": 2177044,
    "end": 2180532,
    "text": "フォワード・パスではすべて減少し、バックワード・パスでは2つ減少する。"
  },
  {
    "start": 2180588,
    "end": 2191212,
    "text": "繰り返しになるが、トランスフォーマー・レイヤーは1つのアテンションで構成されているため、ここに1つのオーバードーズがあり、ここから出てくるデータを渡す。"
  },
  {
    "start": 2191308,
    "end": 2195524,
    "text": "ここでパスして、もうひとつはすでにここにあるGだ。"
  },
  {
    "start": 2195604,
    "end": 2199892,
    "text": "つまり、トランスレイヤーを1回通過する間に2回通過することになる。"
  },
  {
    "start": 2199948,
    "end": 2202624,
    "text": "よし、みんな、これでほとんど終わりだ。"
  },
  {
    "start": 2203644,
    "end": 2210756,
    "text": "さて、出力の埋め込み、入力の埋め込み、その他もろもろを分割しなければならないとは言った。"
  },
  {
    "start": 2210780,
    "end": 2212364,
    "text": "ちょっと急がせてもらうよ。"
  },
  {
    "start": 2212404,
    "end": 2213572,
    "text": "ロジックはよく似ている。"
  },
  {
    "start": 2213668,
    "end": 2215766,
    "text": "これは説明するまでもない。"
  },
  {
    "start": 2215900,
    "end": 2226546,
    "text": "入力の埋め込み行列をeとして並列化し、その代用として隠れ次元をh、語彙次元に沿った語彙サイズをvとする。"
  },
  {
    "start": 2226610,
    "end": 2238338,
    "text": "各パーティションは埋め込みテーブルの一部分しか含まないため、g演算子は入力埋め込み後に必要となる。"
  },
  {
    "start": 2238426,
    "end": 2246734,
    "text": "ボキャブラリーが5万個になることもあるような巨大なeマトリックスを分割することができる。"
  },
  {
    "start": 2247034,
    "end": 2251866,
    "text": "複数のピースに分割し、それぞれのピースをGPUに送ることができる。"
  },
  {
    "start": 2251970,
    "end": 2256042,
    "text": "それからマッピングを行い、また同期させるだけだ。"
  },
  {
    "start": 2256218,
    "end": 2258642,
    "text": "以前見たのと同じ考えだ。"
  },
  {
    "start": 2258738,
    "end": 2265122,
    "text": "それから、アウトプットはもう少し複雑だから、いろいろとね。"
  },
  {
    "start": 2265298,
    "end": 2268794,
    "text": "ただ単純にやるだけなら超高額だが、そう言われる。"
  },
  {
    "start": 2268834,
    "end": 2273854,
    "text": "しかしこの場合、全ゲッターはb×s×vの要素を通信する。"
  },
  {
    "start": 2273934,
    "end": 2280046,
    "text": "Bはバッチサイズ、sはシーケンス長、vはボキャブサイズで、ボキャブサイズが大きいため巨大になる。"
  },
  {
    "start": 2280150,
    "end": 2288150,
    "text": "通信サイズを小さくするために、並列ジェムの出力をクロスエントロピー損失で融合し、次元をb×sに減らす。"
  },
  {
    "start": 2288262,
    "end": 2295598,
    "text": "ロジットの代わりにスカラーロスを通信することは、通信を大幅に削減し、我々のモデル並列アプローチの効率を向上させる。"
  },
  {
    "start": 2295686,
    "end": 2300046,
    "text": "そして最後に、彼らはこう言った。"
  },
  {
    "start": 2300230,
    "end": 2308030,
    "text": "これらは、トランスを構成するほぼすべての部品だが、残留接続、レイヤー規範、その他多くの部品もある。"
  },
  {
    "start": 2308102,
    "end": 2309734,
    "text": "それについて簡単に触れておこう。"
  },
  {
    "start": 2309894,
    "end": 2320942,
    "text": "1つのGPUがドロップアウト層の正規化や残差接続の一部を計算し、その結果を他のGPUにブロードキャストするのではなく、GPU間で計算を二重化することにしました。"
  },
  {
    "start": 2321078,
    "end": 2328094,
    "text": "なぜそうなのかは、ご自分のペースで読んでいただきたいが、この論文の要点はすでにご理解いただけたと思う。"
  },
  {
    "start": 2328954,
    "end": 2338014,
    "text": "ミックスド・プレシジョン・トレーニングに入る前に、なぜその方法が必要なのかを理解し、納得していただくために、もう少し詳しく説明しよう。"
  },
  {
    "start": 2338354,
    "end": 2339962,
    "text": "ちょっとここで話をさせてくれ。"
  },
  {
    "start": 2340018,
    "end": 2343922,
    "text": "そこで、モデルを効率的に訓練するために、混合精度訓練を利用する。"
  },
  {
    "start": 2343978,
    "end": 2348354,
    "text": "申し上げたように、ダイナミック・ロス・スケーリングについては、それが何なのか、なぜ必要なのかを学ぶつもりだ。"
  },
  {
    "start": 2348474,
    "end": 2353094,
    "text": "そうすれば、モデルをどのように初期化するか、どのように拡大縮小するか、といった詳細がたくさん見えてくる。"
  },
  {
    "start": 2353414,
    "end": 2355342,
    "text": "ノルムのクリッピングをするんだ。"
  },
  {
    "start": 2355398,
    "end": 2357314,
    "text": "ここでは多くのエンジニアリングが行われている。"
  },
  {
    "start": 2357654,
    "end": 2364462,
    "text": "最後に、メモリフットプリントをよりよく管理するために、各変換レイヤーの後に活性化チェックポイントを利用する。"
  },
  {
    "start": 2364558,
    "end": 2366086,
    "text": "これは超重要なアイデアだ。"
  },
  {
    "start": 2366110,
    "end": 2370974,
    "text": "いつもいつも使われているので、ここで簡単に説明しておこう。"
  },
  {
    "start": 2371014,
    "end": 2377694,
    "text": "チェックポイントの活性化......このコンセプトをよく耳にするだろう。"
  },
  {
    "start": 2377734,
    "end": 2378734,
    "text": "というものである。"
  },
  {
    "start": 2378854,
    "end": 2382154,
    "text": "ここにも変圧器がある。"
  },
  {
    "start": 2382774,
    "end": 2385558,
    "text": "大きなモデルで、たくさんのレイヤーがある。"
  },
  {
    "start": 2385726,
    "end": 2394262,
    "text": "モデルを通してフィードフォワードを行い、アクティベーションを収集し続ける。"
  },
  {
    "start": 2394318,
    "end": 2397134,
    "text": "各レイヤーはアクティベーションを保存する。"
  },
  {
    "start": 2397214,
    "end": 2397718,
    "text": "なぜですか？"
  },
  {
    "start": 2397846,
    "end": 2407524,
    "text": "なぜなら、バックプロップするとき、グラデーションを計算するためには、対応する各レイヤーのアクティブ度が必要だからだ。"
  },
  {
    "start": 2407944,
    "end": 2411216,
    "text": "このアプローチに問題があることは、すでにお気づきだろう。"
  },
  {
    "start": 2411320,
    "end": 2414824,
    "text": "あなたは文字通り、ここ、ここ、ここに大量のデータを保存している。"
  },
  {
    "start": 2414944,
    "end": 2418808,
    "text": "ネットワークが進むにつれて、メモリはピークに達する。"
  },
  {
    "start": 2418896,
    "end": 2421752,
    "text": "メモリの消費量はどんどん増えている。"
  },
  {
    "start": 2421888,
    "end": 2424672,
    "text": "アクティベーション・チェックポイントの考え方は次のようなものだ。"
  },
  {
    "start": 2424728,
    "end": 2426624,
    "text": "とてもシンプルで、美しいアイデアだ。"
  },
  {
    "start": 2426704,
    "end": 2428984,
    "text": "他の新聞でも取り上げられている。"
  },
  {
    "start": 2429104,
    "end": 2439838,
    "text": "しかし、もし要望が多ければ、このビデオで説明している論文の後に出てきたより高度なテクニックと合わせて、将来的に取り上げるかもしれない。"
  },
  {
    "start": 2439886,
    "end": 2442438,
    "text": "アイデアはいたってシンプルだ。"
  },
  {
    "start": 2442566,
    "end": 2446550,
    "text": "すべてのレイヤーのアクティベーションを保存するのではなく、チェックポイントするだけでいい。"
  },
  {
    "start": 2446622,
    "end": 2450054,
    "text": "基本的には、4人だとしよう。"
  },
  {
    "start": 2450134,
    "end": 2453234,
    "text": "4つのレイヤーがあるとしよう。"
  },
  {
    "start": 2454494,
    "end": 2466728,
    "text": "すべてのフィードフォワード層のアクティブ度をブロックの中に保存する代わりに、アクティブ度をブロックの最後に保存します。"
  },
  {
    "start": 2466816,
    "end": 2469512,
    "text": "文字通り、究極のアクティベーションを保存するだけだ。"
  },
  {
    "start": 2469568,
    "end": 2477344,
    "text": "じゃあ、トランスフォーマーブロックの端にあるアクティベーションを提案するように、これらのアクティベーションを保存すればいいんだね。"
  },
  {
    "start": 2477424,
    "end": 2479920,
    "text": "じゃあ、これを保管しておいて。"
  },
  {
    "start": 2480032,
    "end": 2481664,
    "text": "今、バックプロップをしているときだ。"
  },
  {
    "start": 2481744,
    "end": 2483848,
    "text": "では、バックプロップがどうなるか見てみよう。"
  },
  {
    "start": 2483896,
    "end": 2485528,
    "text": "オーケー、じゃあ、それを始めるんだ。"
  },
  {
    "start": 2485616,
    "end": 2488284,
    "text": "色をグレーに変えてみようか。"
  },
  {
    "start": 2488634,
    "end": 2490466,
    "text": "ここからバックプロップだ。"
  },
  {
    "start": 2490570,
    "end": 2491978,
    "text": "我々はいい、我々はいい、我々はいい。"
  },
  {
    "start": 2492026,
    "end": 2495434,
    "text": "今、アクティベーションがない部分にぶつかった。"
  },
  {
    "start": 2495594,
    "end": 2497810,
    "text": "それを再計算するのだ。"
  },
  {
    "start": 2497882,
    "end": 2501698,
    "text": "このチェックポイントから再計算を開始する。"
  },
  {
    "start": 2501786,
    "end": 2504746,
    "text": "よし、ここから再計算を開始しよう。"
  },
  {
    "start": 2504850,
    "end": 2506626,
    "text": "そうしたら、バックプロップを続けることができる。"
  },
  {
    "start": 2506730,
    "end": 2508266,
    "text": "そして、この部分にぶつかる。"
  },
  {
    "start": 2508330,
    "end": 2509194,
    "text": "アクティベーションはない。"
  },
  {
    "start": 2509314,
    "end": 2510586,
    "text": "を打った。"
  },
  {
    "start": 2510650,
    "end": 2514466,
    "text": "もう一度計算をし直すと、アクティべーションに行き着く。"
  },
  {
    "start": 2514570,
    "end": 2517148,
    "text": "明らかに、これはもう少し巧妙な方法で起こるだろう。"
  },
  {
    "start": 2517266,
    "end": 2520552,
    "text": "あなたがバックプロップをしている間、私たちは計算をしています。"
  },
  {
    "start": 2520608,
    "end": 2523512,
    "text": "再計算をトリガーにしているので、待つ必要はない。"
  },
  {
    "start": 2523608,
    "end": 2525896,
    "text": "最適化の詳細をすべて説明する。"
  },
  {
    "start": 2525920,
    "end": 2526936,
    "text": "これが要点だ。"
  },
  {
    "start": 2526960,
    "end": 2529624,
    "text": "これが活性化チェックポイントの仕組みだ。"
  },
  {
    "start": 2529704,
    "end": 2531444,
    "text": "オーケー、それを理解してもらえるといいね。"
  },
  {
    "start": 2531904,
    "end": 2535096,
    "text": "さて、もう少し詳しく説明しよう。"
  },
  {
    "start": 2535120,
    "end": 2536336,
    "text": "本稿はここまでとする。"
  },
  {
    "start": 2536440,
    "end": 2545784,
    "text": "当社のインフラは、サーバー内のGPU間で300GB/秒の帯域幅を持ち、マルチノードのディープラーニング・アプリケーションに最適化されています。"
  },
  {
    "start": 2545824,
    "end": 2553774,
    "text": "このNS nvsスイッチと、サーバー間の100ギガバイトの相互接続帯域幅が重要です。"
  },
  {
    "start": 2553854,
    "end": 2554686,
    "text": "なるほど、それは重要だ。"
  },
  {
    "start": 2554750,
    "end": 2563478,
    "text": "GPU間には300GB/秒の処理能力がある。"
  },
  {
    "start": 2563526,
    "end": 2565822,
    "text": "それがサーバー間のポイントなんだ。"
  },
  {
    "start": 2565918,
    "end": 2567806,
    "text": "なぜこんなことを言うのか？"
  },
  {
    "start": 2567870,
    "end": 2575558,
    "text": "なぜかというと、メタルやモデルの平行性を求めるからだ。"
  },
  {
    "start": 2575606,
    "end": 2583318,
    "text": "同期ポイントは、帯域幅が非常に広いサーバー内で発生させたい。"
  },
  {
    "start": 2583406,
    "end": 2583750,
    "text": "いいかい？"
  },
  {
    "start": 2583782,
    "end": 2591558,
    "text": "だから、ノードに8つのGPUしかないようなクラスタでは、8ウェイ以上のモデル並列は避けたい。"
  },
  {
    "start": 2591606,
    "end": 2599366,
    "text": "16台にすると、同期時に2台のサーバーが通信することになり、最悪だからだ。"
  },
  {
    "start": 2599550,
    "end": 2600046,
    "text": "いいかい？"
  },
  {
    "start": 2600110,
    "end": 2601994,
    "text": "そうであればいいのだが...。"
  },
  {
    "start": 2602874,
    "end": 2605818,
    "text": "では、その成果をいくつかお見せしよう。"
  },
  {
    "start": 2605906,
    "end": 2610434,
    "text": "1、2、4、8GPUとスケーリングしているのがわかるだろう。"
  },
  {
    "start": 2610514,
    "end": 2614490,
    "text": "効率は多少落ちているのがわかるが、大きくは落ちていない。"
  },
  {
    "start": 2614522,
    "end": 2618970,
    "text": "こちらは8ウェイモデル並列の77％である。"
  },
  {
    "start": 2619082,
    "end": 2628842,
    "text": "もしそうなら、データ並列アプローチと組み合わせれば、512GPUでまだ74％ある。"
  },
  {
    "start": 2628938,
    "end": 2629772,
    "text": "それは大きいね。"
  },
  {
    "start": 2629898,
    "end": 2630360,
    "text": "それは大きいね。"
  },
  {
    "start": 2630392,
    "end": 2635632,
    "text": "モデル並列性とデータ並列性をどのように組み合わせるかを手短に説明しよう。"
  },
  {
    "start": 2635688,
    "end": 2637808,
    "text": "とても素晴らしいビジュアライゼーションだ。"
  },
  {
    "start": 2637976,
    "end": 2640544,
    "text": "早く、こんな感じになる。"
  },
  {
    "start": 2640704,
    "end": 2646976,
    "text": "今言ったように、サーバーには8つのGPUが搭載されているので、基本的には次のようなことをすることになる。"
  },
  {
    "start": 2647000,
    "end": 2657520,
    "text": "このようなものがあり、このサーバーを8つにスライスすることになる。なぜなら、すべてのピースが1つのGPUであり、非常に高密度に接続されているからだ。"
  },
  {
    "start": 2657632,
    "end": 2665032,
    "text": "つまり、文字通り、モデルの重みの8分の1がここにあり、モデルの重みの8分の1がここにある。"
  },
  {
    "start": 2665128,
    "end": 2672368,
    "text": "データの並列性を覚えておいてほしいのだが、ただ複製し、コピー・ペーストで何度も正確に貼り付けるだけだ。"
  },
  {
    "start": 2672496,
    "end": 2676912,
    "text": "これらは64ウェイデータ並列を使用する。"
  },
  {
    "start": 2676968,
    "end": 2686794,
    "text": "文字どおり、これを複製して、最終的にこうなる。"
  },
  {
    "start": 2686874,
    "end": 2688294,
    "text": "ここには8人いる。"
  },
  {
    "start": 2689074,
    "end": 2689786,
    "text": "おっと。"
  },
  {
    "start": 2689890,
    "end": 2691162,
    "text": "ここには8人いる。"
  },
  {
    "start": 2691218,
    "end": 2701386,
    "text": "とすると、ここに8があるので、64×8で512となる。"
  },
  {
    "start": 2701530,
    "end": 2702898,
    "text": "これがあなたのセットアップになる。"
  },
  {
    "start": 2702946,
    "end": 2705010,
    "text": "あなたは文字通り64台のサーバーを持っている。"
  },
  {
    "start": 2705082,
    "end": 2712868,
    "text": "各サーバーには、内部的に高い帯域幅を持ち、外部的に少し低い帯域幅を持つ8つのGPUが搭載されている。"
  },
  {
    "start": 2712996,
    "end": 2716476,
    "text": "ノード間とノード内。"
  },
  {
    "start": 2716660,
    "end": 2719708,
    "text": "ああ、それなら基本的には、今説明した論理を実行することになる。"
  },
  {
    "start": 2719756,
    "end": 2728196,
    "text": "この例では、巨大なバッチがあり、それを64のチャンクに分割し、それぞれのチャンクをサーバーのひとつに渡そうとしている。"
  },
  {
    "start": 2728300,
    "end": 2736240,
    "text": "そして、メガトロンLMの論文で見たようなロジックを、すべてのシンクロポイント、その他諸々で行い、グラディエーションを計算する。"
  },
  {
    "start": 2736372,
    "end": 2740072,
    "text": "その後、Oリデュースを行い、クラスター全体を更新することになる。"
  },
  {
    "start": 2740168,
    "end": 2740792,
    "text": "それだけだ。"
  },
  {
    "start": 2740888,
    "end": 2741704,
    "text": "極めてシンプルだ。"
  },
  {
    "start": 2741784,
    "end": 2742484,
    "text": "オーケー。"
  },
  {
    "start": 2742944,
    "end": 2744328,
    "text": "少なくとも概念的には。"
  },
  {
    "start": 2744496,
    "end": 2754924,
    "text": "GPT-3は、おそらく最も有名な言語モデルであり、一般的なMLモデルでもある。"
  },
  {
    "start": 2755464,
    "end": 2757288,
    "text": "彼らはすでにその傾向に気づいていた。"
  },
  {
    "start": 2757336,
    "end": 2763084,
    "text": "スケーリングがパフォーマンスの向上につながることは、すでに誰もが知っていた。"
  },
  {
    "start": 2763714,
    "end": 2773562,
    "text": "例えば、83億のモデルは25億のモデルよりも当惑度が低いことがわかります。"
  },
  {
    "start": 2773738,
    "end": 2780322,
    "text": "モデルサイズが大きくなるにつれて、検証の当惑度は減少し、検証の当惑度はブラブラになると何度も述べている。"
  },
  {
    "start": 2780418,
    "end": 2783834,
    "text": "モデルサイズを小さくすればするほど、当惑度も低くなるという傾向が見られる。"
  },
  {
    "start": 2783874,
    "end": 2784698,
    "text": "ブラブラ、ブラブラ、ブラブラ。"
  },
  {
    "start": 2784826,
    "end": 2797176,
    "text": "最近、マイクロソフトの研究者たちは、Nvidiaと共同で、メガトロンを使ってチューリングNLGと呼ばれる170億パラメータのGPT-2を訓練した。"
  },
  {
    "start": 2797280,
    "end": 2800224,
    "text": "誰かがやるのは超明々白々だった。"
  },
  {
    "start": 2800304,
    "end": 2803804,
    "text": "たまたまOpenAIがそれを最初にやった。"
  },
  {
    "start": 2804824,
    "end": 2805112,
    "text": "そして"
  },
  {
    "start": 2805128,
    "end": 2808884,
    "text": "ああ、歴史的なメモとして言及する価値はあると思うよ。"
  },
  {
    "start": 2809304,
    "end": 2818254,
    "text": "レイヤー規範をどこに置くかを再設定することで、より大きな鳥を訓練できることを示したのだ。"
  },
  {
    "start": 2818344,
    "end": 2819946,
    "text": "そうでなければ、このような不安定さが生じる。"
  },
  {
    "start": 2820010,
    "end": 2825834,
    "text": "このデフォルトのバート・アーキテクチャーを使うだけで、モデルの損失が爆発的に増えるのがわかるだろう。"
  },
  {
    "start": 2825914,
    "end": 2828578,
    "text": "それは僕らにとって重要なことではない。"
  },
  {
    "start": 2828706,
    "end": 2829858,
    "text": "そうだね。"
  },
  {
    "start": 2830026,
    "end": 2833562,
    "text": "何事も重要だということを意識しなければならない。"
  },
  {
    "start": 2833738,
    "end": 2836698,
    "text": "モデル・アーキテクチャでさえ非常に敏感だ。"
  },
  {
    "start": 2836746,
    "end": 2842746,
    "text": "何かを変更したり、配置を変えたりすると、突然、大きなモデルのトレーニングができなくなったりする。"
  },
  {
    "start": 2842810,
    "end": 2845462,
    "text": "じゃあ、次はミックスド・プレシジョン・トレーニングだ。"
  },
  {
    "start": 2845518,
    "end": 2849686,
    "text": "早速、これを説明し、ゼロの論文について掘り下げていこうと思う。"
  },
  {
    "start": 2849790,
    "end": 2862110,
    "text": "パイプライン並列、データ並列、モデル並列、テンソル並列の3つのアプローチを紹介したが、これらはすべて組み合わせることができる。"
  },
  {
    "start": 2862182,
    "end": 2867902,
    "text": "両者は補完関係にあり、3Dパラレリズムの烙印を押されたのだと思う。"
  },
  {
    "start": 2868038,
    "end": 2871478,
    "text": "この3つが組み合わさると、巨大なスケールのようなものができる。"
  },
  {
    "start": 2871566,
    "end": 2880496,
    "text": "そして、これをミックスド・プレシジョンと組み合わせ、さらにゼロ・オプティマイザを使えば、本当に驚異的なスケールを達成することができる。"
  },
  {
    "start": 2880680,
    "end": 2882368,
    "text": "よし、これで終わりだ。"
  },
  {
    "start": 2882456,
    "end": 2883608,
    "text": "さて、この論文を掘り下げてみよう。"
  },
  {
    "start": 2883656,
    "end": 2886936,
    "text": "そこで、この論文から2、3の貢献があった。"
  },
  {
    "start": 2887040,
    "end": 2889152,
    "text": "ちょっと読んでみよう。"
  },
  {
    "start": 2889248,
    "end": 2895224,
    "text": "まず、各オプティマイザー・ステップ後に勾配を蓄積する重みの単精度コピーを維持することを推奨する。"
  },
  {
    "start": 2895264,
    "end": 2898438,
    "text": "このコピーは、前方と後方の支柱の精度を出すために丸みを帯びている。"
  },
  {
    "start": 2898486,
    "end": 2899542,
    "text": "これが最初の部分だ。"
  },
  {
    "start": 2899638,
    "end": 2903942,
    "text": "文字どおり、3つの構成要素について説明する。"
  },
  {
    "start": 2904038,
    "end": 2906606,
    "text": "もうひとつは、ロス・スケーリングを提案することだ。"
  },
  {
    "start": 2906670,
    "end": 2911678,
    "text": "このコンセプトが、小さな小さなマグニチュードを持つグラデーション値を維持するために何を意味するのか、これから見ていくことにしよう。"
  },
  {
    "start": 2911806,
    "end": 2917438,
    "text": "第三に、単精度出力に累積される半精度演算を使用する。"
  },
  {
    "start": 2917486,
    "end": 2923566,
    "text": "これはFP32とFP16の比較であり、メモリに格納する前に精度を持つように変換される。"
  },
  {
    "start": 2923630,
    "end": 2926086,
    "text": "なるほど、アイデアはいたってシンプルだ。"
  },
  {
    "start": 2926190,
    "end": 2928846,
    "text": "通常、ニューラルネットワークを訓練するときは"
  },
  {
    "start": 2928950,
    "end": 2931974,
    "text": "歴史的に、人々はFP32のフォーマットを使ってきた。"
  },
  {
    "start": 2932014,
    "end": 2935766,
    "text": "つまり、ひとつの数字には文字通り32ビットが必要なのだ。"
  },
  {
    "start": 2935910,
    "end": 2940390,
    "text": "その代わりに、32ビットは必要ないことを人々は示してきた。"
  },
  {
    "start": 2940542,
    "end": 2943822,
    "text": "ニューラルネットワークのトレーニングの精度を低くすることができる。"
  },
  {
    "start": 2943918,
    "end": 2946910,
    "text": "だから、16作で終わり。"
  },
  {
    "start": 2946982,
    "end": 2956678,
    "text": "データ量と、ひとつの数字が必要とするメモリ量を持つだけで、文字通り大量のメモリを節約することができる。"
  },
  {
    "start": 2956726,
    "end": 2964950,
    "text": "しかし、この論文では、FP 32を使用するベースラインと同じ精度、同じ性能を維持している。"
  },
  {
    "start": 2965102,
    "end": 2966166,
    "text": "とてもクールだね。"
  },
  {
    "start": 2966350,
    "end": 2968230,
    "text": "では、なぜそれが重要なのか？"
  },
  {
    "start": 2968302,
    "end": 2972974,
    "text": "メモリーを保存するだけでなく、最新のハードウェアではより高速になる。"
  },
  {
    "start": 2973054,
    "end": 2980884,
    "text": "最近のGPUの毛髪精度数学のスループットは、単精度より2倍から8倍高い。"
  },
  {
    "start": 2981004,
    "end": 2985372,
    "text": "スピードの向上だけでなく、精度の低いフォーマットはトレーニングに必要なメモリ量も減らすことができる。"
  },
  {
    "start": 2985428,
    "end": 2985908,
    "text": "それは明らかだ。"
  },
  {
    "start": 2985956,
    "end": 2987484,
    "text": "それはもう言ったよ。"
  },
  {
    "start": 2987524,
    "end": 2988184,
    "text": "オーケー。"
  },
  {
    "start": 2988684,
    "end": 2990364,
    "text": "よし、何が起こっているのか見てみよう。"
  },
  {
    "start": 2990444,
    "end": 2995804,
    "text": "そこで具体的には、IEEEの半精度フォーマットを使ってさまざまなニューラルネットワークを訓練する。"
  },
  {
    "start": 2995924,
    "end": 2997464,
    "text": "さっそくお見せしよう。"
  },
  {
    "start": 2998124,
    "end": 3002240,
    "text": "ビデオの下のどこかにリンクしておく。"
  },
  {
    "start": 3002372,
    "end": 3006384,
    "text": "これが彼らの言うフォーマットだ。"
  },
  {
    "start": 3006464,
    "end": 3011144,
    "text": "指数には5ビット、分数には10ビット、そして符号ビットがある。"
  },
  {
    "start": 3011264,
    "end": 3013364,
    "text": "これが数字を表す方法だ。"
  },
  {
    "start": 3014864,
    "end": 3021044,
    "text": "浮動小数点数32は基本的に、明らかに指数も分数も大きい。"
  },
  {
    "start": 3021344,
    "end": 3033514,
    "text": "ここでフォーマットの説明をしている間に、Bフロート16（ブレイン・フロート）について簡単に触れておこう。"
  },
  {
    "start": 3033634,
    "end": 3035154,
    "text": "何が違うかわかるだろう。"
  },
  {
    "start": 3035234,
    "end": 3037290,
    "text": "Bフロートの方が指数が大きい。"
  },
  {
    "start": 3037402,
    "end": 3041330,
    "text": "ここでの主な洞察は、ニューラルネットワークのトレーニングである。"
  },
  {
    "start": 3041442,
    "end": 3045242,
    "text": "あなたは飛距離を気にしているが、実際の精度は気にしていない。"
  },
  {
    "start": 3045338,
    "end": 3051538,
    "text": "この有効数字（仮数）が、数値の微調整を決定する。"
  },
  {
    "start": 3051626,
    "end": 3055178,
    "text": "一方、指数はどれだけ大きくできるかを決定する。"
  },
  {
    "start": 3055306,
    "end": 3064106,
    "text": "明らかに、B floatを使えば、オーバーフローや無限大、ナンドなどを発生させることなく、もっと大きな数値やもっと小さな数値を持つことができる。"
  },
  {
    "start": 3064210,
    "end": 3070050,
    "text": "基本的に、TpusはこのB floatフォーマットをネイティブでサポートしている。"
  },
  {
    "start": 3070162,
    "end": 3087860,
    "text": "例えば、ボリス・ダイマがダリ・ミニをトレーニングする際に、GPUでトレーニングする場合と比べてどのような問題があったかを見てみるとわかるように、TPUはBフロート形式を採用しているため、基本的にロスの乖離に対してより堅牢なのだ。"
  },
  {
    "start": 3087932,
    "end": 3091020,
    "text": "それが僕の理解だ。"
  },
  {
    "start": 3091132,
    "end": 3092748,
    "text": "私が間違っているかもしれないが、それはそうだ。"
  },
  {
    "start": 3092876,
    "end": 3095428,
    "text": "これらすべてのフォーマットについて簡単に触れておきたい。"
  },
  {
    "start": 3095516,
    "end": 3096820,
    "text": "さて、論文に戻ろう。"
  },
  {
    "start": 3096892,
    "end": 3101556,
    "text": "さて、それでは何が起こっているのか見てみよう。"
  },
  {
    "start": 3101700,
    "end": 3104860,
    "text": "我々は、彼らが示したマスターウェイトを保管しなければならない。"
  },
  {
    "start": 3105012,
    "end": 3107456,
    "text": "ほとんどのモデルにとって、これは必要なことだ。"
  },
  {
    "start": 3107620,
    "end": 3112296,
    "text": "FP32マスターウェイトの必要性は普遍的なものではないという。"
  },
  {
    "start": 3112360,
    "end": 3115568,
    "text": "彼らがトレーニングしたほとんどのモデルには、その必要があった。"
  },
  {
    "start": 3115696,
    "end": 3117284,
    "text": "これがアイデアだ。"
  },
  {
    "start": 3117584,
    "end": 3125776,
    "text": "ウェイトをFP32として保存し、フォワード・プロップ、バック・プロップ、すべてを半分の精度で行う。"
  },
  {
    "start": 3125880,
    "end": 3128112,
    "text": "文字通り、フロートを半分にする操作だ。"
  },
  {
    "start": 3128168,
    "end": 3132376,
    "text": "文字通り、FB32をFP16に変換するようなものだ。"
  },
  {
    "start": 3132560,
    "end": 3133728,
    "text": "それからフィードフォワードを行う。"
  },
  {
    "start": 3133776,
    "end": 3136884,
    "text": "アクティベーションはFP16から始まる。"
  },
  {
    "start": 3137574,
    "end": 3141238,
    "text": "データを管理しているのだから、常にそうであることを確認することができる。"
  },
  {
    "start": 3141326,
    "end": 3144302,
    "text": "入力があなたの画像だとしよう。"
  },
  {
    "start": 3144398,
    "end": 3150158,
    "text": "文字通り、画像をFP16の画像として送り、それをFP16のウェイトと組み合わせることができる。"
  },
  {
    "start": 3150246,
    "end": 3154870,
    "text": "前方のパスで活性化し、後方でも同じことをする。"
  },
  {
    "start": 3154902,
    "end": 3156398,
    "text": "ウェイトはFP16。"
  },
  {
    "start": 3156526,
    "end": 3158342,
    "text": "アクティベーション・グレードを計算するんだ。"
  },
  {
    "start": 3158438,
    "end": 3163014,
    "text": "アクティベーション・グレードからウェイト・グレードが得られ、それらはすべてFP16に入っている。"
  },
  {
    "start": 3163094,
    "end": 3172570,
    "text": "そうすることで、より小さなメモリ、設計図、そしてより高いスループットの恩恵を受けることができる。"
  },
  {
    "start": 3172602,
    "end": 3179106,
    "text": "最新のGPUの中には、基本的にFP 32よりもFP 16の方がスループットが高いものがあることを見たとおりだ。"
  },
  {
    "start": 3179130,
    "end": 3180258,
    "text": "それが結論だ。"
  },
  {
    "start": 3180306,
    "end": 3184194,
    "text": "オーケー、これは、すべてがどのように機能するかの概略図だ。"
  },
  {
    "start": 3184354,
    "end": 3189386,
    "text": "FP32のマスターウエイトがなぜ必要なのか、その理由のひとつを述べている。"
  },
  {
    "start": 3189490,
    "end": 3197674,
    "text": "1つの説明として、更新ウエイトの勾配に学習率を掛けた値が小さすぎて、FP16で表現できなくなることが挙げられる。"
  },
  {
    "start": 3197834,
    "end": 3205682,
    "text": "2より小さい値を-24乗した値は、FP16ではゼロになる。"
  },
  {
    "start": 3205818,
    "end": 3209054,
    "text": "ところで、なぜ14ではなく24なのか、混乱するかもしれない。"
  },
  {
    "start": 3209594,
    "end": 3214162,
    "text": "それを掘り下げるつもりはないが、サブノーマルでググってみてほしい。"
  },
  {
    "start": 3214298,
    "end": 3218234,
    "text": "サブノーマルとかそんな感じ。"
  },
  {
    "start": 3218274,
    "end": 3227832,
    "text": "サブノーマル値は、float 16とfloat 32のウィキページを開くだけだ。"
  },
  {
    "start": 3227888,
    "end": 3230644,
    "text": "下にリンクを貼っておくから、それが何なのか見てほしい。"
  },
  {
    "start": 3232064,
    "end": 3241288,
    "text": "図2のbを見ると、ウェイト勾配値の約5％が-24より小さい指数を持っていることがわかる。"
  },
  {
    "start": 3241416,
    "end": 3243824,
    "text": "図2のBに行こう。"
  },
  {
    "start": 3243904,
    "end": 3249982,
    "text": "これはFP 32でモデルをトレーニングしたときのものだ。"
  },
  {
    "start": 3250078,
    "end": 3262182,
    "text": "ほとんどのグラデーションが、この魔法の赤い線、つまりFP16の表現範囲が終わる-24を下回っているのがわかるだろう。"
  },
  {
    "start": 3262278,
    "end": 3268518,
    "text": "つまり、これらはすべてゼロに丸められ、トレーニング中に多くの情報を失うことになる。"
  },
  {
    "start": 3268606,
    "end": 3273474,
    "text": "そのため、モデルの最終的な精度は下がるかもしれないし、下がらないかもしれない。"
  },
  {
    "start": 3273914,
    "end": 3281290,
    "text": "なるほど、FP32が必要な理由はそういう考え方もあるのか。"
  },
  {
    "start": 3281442,
    "end": 3287294,
    "text": "ここで説明するには少し複雑だが、他にもいくつかの説明がある。"
  },
  {
    "start": 3287994,
    "end": 3289682,
    "text": "今はちょっと省略する。"
  },
  {
    "start": 3289858,
    "end": 3295394,
    "text": "この追加コピーを保存しなければならなくなったことで、メモリが膨れ上がるのでは？"
  },
  {
    "start": 3295434,
    "end": 3299160,
    "text": "アクティベーションこそが重要なのだから。"
  },
  {
    "start": 3299242,
    "end": 3310372,
    "text": "重みの追加コピーを維持することで、単精度トレーニングに比べて重みに必要なメモリが50％増加しても、トレーニング全体のメモリ使用量に与える影響ははるかに小さい。"
  },
  {
    "start": 3310428,
    "end": 3319604,
    "text": "メモリ消費は、バッチサイズが大きいことと、バックプロップパスで再利用するために各レイヤーのアクティベーションが保存されることから、アクティベーションが支配的である。"
  },
  {
    "start": 3319764,
    "end": 3327962,
    "text": "アクティベーションも半精度フォーマットで保存されるため、ディープ・ニューラル・ネットワークをトレーニングする際の全体的なメモリ消費量は約半分になる。"
  },
  {
    "start": 3328108,
    "end": 3328422,
    "text": "オーケー。"
  },
  {
    "start": 3328438,
    "end": 3331838,
    "text": "彼らは明らかに活性化チェックポイントを考慮していない。"
  },
  {
    "start": 3331886,
    "end": 3334790,
    "text": "彼らは、あなたがすべてのアクティベーションを保存しなければならないと思い込んでいるだけなのです。"
  },
  {
    "start": 3334862,
    "end": 3338634,
    "text": "その場合、彼らが今ここで言ったことがそのまま当てはまる。"
  },
  {
    "start": 3339094,
    "end": 3339806,
    "text": "そうだね。"
  },
  {
    "start": 3339910,
    "end": 3343438,
    "text": "さて、次はロスのスケーリングに入ろう。"
  },
  {
    "start": 3343486,
    "end": 3345166,
    "text": "これが2つ目の重要なコンセプトだ。"
  },
  {
    "start": 3345190,
    "end": 3347758,
    "text": "ミックスド・プレシジョン・トレーニングを機能させる必要がある。"
  },
  {
    "start": 3347846,
    "end": 3356868,
    "text": "FP16の表現可能な範囲の多くが未使用のままであり、多くの値が最小表現可能範囲を下回り、ゼロとなっていることに注意されたい。"
  },
  {
    "start": 3356966,
    "end": 3363704,
    "text": "勾配を拡大することで、表現可能な範囲の多くを占めるようになり、そうでなければゼロに失われてしまう値が保存される。"
  },
  {
    "start": 3363784,
    "end": 3368352,
    "text": "この特殊なネットワークは、勾配をスケーリングせず、8倍にスケーリングすると発散する。"
  },
  {
    "start": 3368448,
    "end": 3374848,
    "text": "指数を3つ増やせば、FP32のトレーニングで達成される精度を十分に高めることができる。"
  },
  {
    "start": 3375016,
    "end": 3383984,
    "text": "このことは、-27乗の大きさに引き上げられた2以下の活性化勾配は、このモデルの訓練には無関係であることを示唆している。"
  },
  {
    "start": 3384024,
    "end": 3387170,
    "text": "この範囲の値を維持することが重要だった。"
  },
  {
    "start": 3387202,
    "end": 3388738,
    "text": "よし、これを分解して説明しよう。"
  },
  {
    "start": 3388786,
    "end": 3394346,
    "text": "それでは、基本的な活性化勾配値のヒストグラムをご覧ください。"
  },
  {
    "start": 3394450,
    "end": 3395794,
    "text": "私が何を言ったかわかるだろう。"
  },
  {
    "start": 3395914,
    "end": 3400906,
    "text": "FP16が基本的にサポートする範囲から外れてしまった。"
  },
  {
    "start": 3400930,
    "end": 3403058,
    "text": "これがFP16の好きな範囲だ。"
  },
  {
    "start": 3403146,
    "end": 3407226,
    "text": "さて、これは正常値以下、あるいは非正規化された範囲である。"
  },
  {
    "start": 3407370,
    "end": 3413672,
    "text": "から-14まで、これらの値のほとんどが範囲外であることがわかる。"
  },
  {
    "start": 3413778,
    "end": 3421092,
    "text": "グラデーションを8倍すると、文字通り、これらすべてが右方向にシフトする。"
  },
  {
    "start": 3421148,
    "end": 3424580,
    "text": "あるいは、赤線をここに移動させる。"
  },
  {
    "start": 3424732,
    "end": 3429180,
    "text": "これで、これらすべてがFP16で表現できるようになった。"
  },
  {
    "start": 3429252,
    "end": 3431524,
    "text": "したがって、ゼロに丸めることはしない。"
  },
  {
    "start": 3431604,
    "end": 3433504,
    "text": "我々はこの情報を失うことはない。"
  },
  {
    "start": 3434124,
    "end": 3444034,
    "text": "その結果、ここにある特定の範囲（ここにはたくさんのデータがあるのがわかると思うが）は、保存することが非常に重要であることがわかった。"
  },
  {
    "start": 3444114,
    "end": 3451042,
    "text": "だから、この特別なモデルで8倍にスケーリングすることは、モデルが何であるかさえ問題ではなく、ただコンセプトが重要なのだ。"
  },
  {
    "start": 3451218,
    "end": 3452450,
    "text": "そのおかげでトレーニングが救われたようなものだ。"
  },
  {
    "start": 3452522,
    "end": 3464450,
    "text": "では、勾配値をFP16で表現可能な範囲にシフトさせる効率的な方法の1つは、バックプロパゲーションを開始する前に、フォワードパスで計算された損失値をチェーンルールでスケーリングすることだ。"
  },
  {
    "start": 3464482,
    "end": 3468530,
    "text": "バックプロパゲーションは、すべての勾配値が同じ量だけスケールされることを保証する。"
  },
  {
    "start": 3468642,
    "end": 3471498,
    "text": "これは、これらのグラデーションをすべて拡大する簡単な方法だ。"
  },
  {
    "start": 3471586,
    "end": 3475402,
    "text": "最終的な負けを、例えば8倍にするんだ。"
  },
  {
    "start": 3475498,
    "end": 3481850,
    "text": "そうすることで、バック・プロップを始めると、チェーン・ルールの仕組みから、文字通りすべてのグラデーションを8倍することになる。"
  },
  {
    "start": 3481922,
    "end": 3485934,
    "text": "したがって、このグラデーションを表現可能な範囲にシフトすることになる。"
  },
  {
    "start": 3486514,
    "end": 3491294,
    "text": "これが、そう、これがこの論文から汲み取ってほしい主な直感だ。"
  },
  {
    "start": 3491994,
    "end": 3497184,
    "text": "これがモデルの精度を維持するための3つ目のテクニックだ。"
  },
  {
    "start": 3497224,
    "end": 3507464,
    "text": "いくつかのネットワークでは、FP 16ベクトル積が部分積をFP 32値に累積し、それをFP 16に変換してからメモリに書き込む必要があることがわかった。"
  },
  {
    "start": 3507584,
    "end": 3510104,
    "text": "この積み重ねがなければ、FP32になる。"
  },
  {
    "start": 3510144,
    "end": 3513088,
    "text": "FPV 60モデルの中には、ベースラインモデルの精度に及ばないものもあった。"
  },
  {
    "start": 3513136,
    "end": 3513844,
    "text": "オーケー。"
  },
  {
    "start": 3514824,
    "end": 3521288,
    "text": "また、例えばベクトルの要素間の和のような大きな削減は、すべてFP 32で実行されるべきである。"
  },
  {
    "start": 3521336,
    "end": 3528138,
    "text": "このような削減は、統計量を蓄積する際のバッチ正規化層やソフトマックス層で主に見られる。"
  },
  {
    "start": 3528226,
    "end": 3535218,
    "text": "我々の実装では、両レイヤーともFP 16テンソルをメモリから読み書きし、FP 32で演算を行う。"
  },
  {
    "start": 3535306,
    "end": 3541450,
    "text": "なぜなら、これらの層はメモリ帯域幅に制限があり、演算速度に影響されないからだ。"
  },
  {
    "start": 3541642,
    "end": 3548054,
    "text": "オーケー、繰り返しになるけど、細かいことに対処する必要があるんだ。"
  },
  {
    "start": 3548614,
    "end": 3549998,
    "text": "基本的には3つのカテゴリーに分かれる。"
  },
  {
    "start": 3550046,
    "end": 3552634,
    "text": "彼らはここでこう言っている。"
  },
  {
    "start": 3554254,
    "end": 3557198,
    "text": "概して、ニューラルネットワークの演算は3つのカテゴリーに分類される。"
  },
  {
    "start": 3557246,
    "end": 3563278,
    "text": "ベクトルのドット積、漸化式、活性化関数のような点演算。"
  },
  {
    "start": 3563406,
    "end": 3576844,
    "text": "つまり、ベクトルのドット積や漸化式では、精度を保つためにFP 32に変換して演算する必要がある場合があるということだ。"
  },
  {
    "start": 3577624,
    "end": 3578472,
    "text": "以上だ。"
  },
  {
    "start": 3578568,
    "end": 3581240,
    "text": "これがミックスド・プレシジョン・トレーニングの考え方だ。"
  },
  {
    "start": 3581392,
    "end": 3583048,
    "text": "では、結果をお見せしよう。"
  },
  {
    "start": 3583216,
    "end": 3589008,
    "text": "彼らは文字通りベースラインを示し、比較し、ほとんどの場合、ベースラインよりもさらに優れている。"
  },
  {
    "start": 3589056,
    "end": 3594520,
    "text": "自分の本拠地でこの数字をチェックすれば、数字が常に少し良くなっていることがわかるだろう。"
  },
  {
    "start": 3594632,
    "end": 3601804,
    "text": "これは、FP16でトレーニングを行うための、ほとんど正則化のようなものだ。"
  },
  {
    "start": 3602914,
    "end": 3609770,
    "text": "いくつかのモデルについては、前述したように、これらのネットワークの混合精度学習を成功させるためには、ロス・スケーリング技術は必要なかった。"
  },
  {
    "start": 3609882,
    "end": 3612418,
    "text": "ある人たちにとっては、とても重要なことだった。"
  },
  {
    "start": 3612546,
    "end": 3613814,
    "text": "ひとつお見せしよう。"
  },
  {
    "start": 3614354,
    "end": 3620058,
    "text": "ここでは、最後の目盛りが1の場合、混合精度トレーニングが発散することがわかる。"
  },
  {
    "start": 3620186,
    "end": 3623594,
    "text": "損失スケールが128のときは発散しない。"
  },
  {
    "start": 3623714,
    "end": 3627010,
    "text": "彼らは文字通り、このように4つの異なるクラスのモデルを示している。"
  },
  {
    "start": 3627042,
    "end": 3634298,
    "text": "ここでもまた、言語モデルや機械翻訳は、精度に関しては常にベースラインと一致する。"
  },
  {
    "start": 3634346,
    "end": 3635282,
    "text": "すごいね。"
  },
  {
    "start": 3635378,
    "end": 3642374,
    "text": "最後のアイデアは、これはとてもエキサイティングな論文なので、最後ではあるが、絶対に最後ではない。"
  },
  {
    "start": 3643354,
    "end": 3648634,
    "text": "本稿では、基本的にディープスピード・ライブラリを紹介する。"
  },
  {
    "start": 3648714,
    "end": 3650194,
    "text": "聞いたことがあるかもしれない。"
  },
  {
    "start": 3650274,
    "end": 3656110,
    "text": "もし、あなたが人気のあるLLMのどれかを見てきたなら、そのほとんどはディープスピードのエレウターAIを使っている。"
  },
  {
    "start": 3656142,
    "end": 3657714,
    "text": "ディープスピードを使っているのは知っている。"
  },
  {
    "start": 3658134,
    "end": 3662270,
    "text": "ブルームはディープスピードオプト175 Bを使用。"
  },
  {
    "start": 3662302,
    "end": 3667198,
    "text": "メタフォークスがそれを使ったかどうかはわからないが、文字通りマイクロソフトの論文だ。"
  },
  {
    "start": 3667286,
    "end": 3672754,
    "text": "兆パラメータモデルのトレーニングに向けたゼロメモリー最適化と呼ばれるものだ。"
  },
  {
    "start": 3673094,
    "end": 3674278,
    "text": "さて、私はこの紙が大好きだ。"
  },
  {
    "start": 3674366,
    "end": 3676514,
    "text": "順を追って説明しよう。"
  },
  {
    "start": 3676974,
    "end": 3678474,
    "text": "ステップ・バイ・ステップで考えよう。"
  },
  {
    "start": 3679494,
    "end": 3681422,
    "text": "冗長性ゼロのオプティマイザー。"
  },
  {
    "start": 3681518,
    "end": 3683198,
    "text": "その頭文字をとったものだ。"
  },
  {
    "start": 3683326,
    "end": 3684014,
    "text": "その理由は今にわかる。"
  },
  {
    "start": 3684054,
    "end": 3685934,
    "text": "冗長性はゼロだ。"
  },
  {
    "start": 3686014,
    "end": 3690614,
    "text": "まあ、モデル状態と残留状態に関して言えば、冗長さをすべて減らしてくれる。"
  },
  {
    "start": 3690654,
    "end": 3693434,
    "text": "それが何であるかはこれからわかるだろうが、そういうことだ。"
  },
  {
    "start": 3693734,
    "end": 3701070,
    "text": "ゼロは、データとモデルの並列トレーニングにおけるメモリの冗長性を排除する。ゼロは、1兆パラメータを超えるスケールの可能性を秘めている。"
  },
  {
    "start": 3701102,
    "end": 3706610,
    "text": "今日のハードウェアを使えば、ゼロでも最大130億のパラメーターを持つ大規模なモデルを訓練することができる。"
  },
  {
    "start": 3706742,
    "end": 3709186,
    "text": "例えば、メガトロンGPTよりも大きい。"
  },
  {
    "start": 3709290,
    "end": 3710242,
    "text": "エイトスリーB"
  },
  {
    "start": 3710298,
    "end": 3714410,
    "text": "これは、私が最初に取り上げたメガトロンLMの論文で学習させたモデルだ。"
  },
  {
    "start": 3714522,
    "end": 3722066,
    "text": "グーグル社のモデルは、モデルの並列性を必要とすることなく、110億パラメータという大きさを実現した。"
  },
  {
    "start": 3722210,
    "end": 3737304,
    "text": "というのも、この一連の最適化によって、実務家としては、たった1つの、しかし非常に優れたGPUがあれば、文字通り13bもの大きなモデルを訓練することができるからだ。"
  },
  {
    "start": 3737464,
    "end": 3738644,
    "text": "それは驚きだ。"
  },
  {
    "start": 3739064,
    "end": 3747352,
    "text": "もちろん、実際の最適化を使えば、もっと大きなサイズに拡張できる。"
  },
  {
    "start": 3747528,
    "end": 3757256,
    "text": "1兆個のパラメーターまでスケールアップできることを示したが、それにはちょっとした注意点がある。"
  },
  {
    "start": 3757360,
    "end": 3766286,
    "text": "彼らはそれを訓練するのに1年必要であることを示したが、現実的にはそうではない。"
  },
  {
    "start": 3766350,
    "end": 3767430,
    "text": "それはちょっとクールだね。"
  },
  {
    "start": 3767502,
    "end": 3770502,
    "text": "じゃあ、掘り下げてみようか。"
  },
  {
    "start": 3770678,
    "end": 3771118,
    "text": "Mp."
  },
  {
    "start": 3771166,
    "end": 3780118,
    "text": "そのため、モデルの並列性はモデルを垂直方向に分割し、各レイヤーの計算とパラメーターを複数のデバイスに分割し、各レイヤー間で大きな通信を必要とする。"
  },
  {
    "start": 3780166,
    "end": 3780710,
    "text": "オーケー。"
  },
  {
    "start": 3780822,
    "end": 3783926,
    "text": "その結果、1つのノード内でうまく機能する。"
  },
  {
    "start": 3783990,
    "end": 3792962,
    "text": "GPU間通信の帯域幅は広いが、シングルノードを超えると効率が急速に低下する。"
  },
  {
    "start": 3793058,
    "end": 3805898,
    "text": "メガトロンLmを使用した4デシベルのパラメータモデルを2つのDgX 2ノードでテストしたところ、ハードウェアピークの5％未満である、v 100 gpuあたり約5テラフロップスを観測した。"
  },
  {
    "start": 3805986,
    "end": 3812354,
    "text": "複数ノードにまたがるモデル並列処理を始めると、劇的に低下するのがわかるだろう。"
  },
  {
    "start": 3813574,
    "end": 3820030,
    "text": "では、大規模なモデルの場合、メモリの大部分はモデルの状態によって占められるという。"
  },
  {
    "start": 3820222,
    "end": 3822102,
    "text": "これは重要な用語である。"
  },
  {
    "start": 3822238,
    "end": 3824350,
    "text": "紙面全体で再利用するつもりだ。"
  },
  {
    "start": 3824462,
    "end": 3826542,
    "text": "それを強調しよう。"
  },
  {
    "start": 3826638,
    "end": 3839404,
    "text": "モデル状態には、運動量や原子勾配やパラメータの分散などのオプティマイザ状態が含まれるため、それらをモデル状態とみなす。"
  },
  {
    "start": 3840304,
    "end": 3847880,
    "text": "残りのメモリは、アクティベーションや一時的なバッファに消費され、使い物にならない。"
  },
  {
    "start": 3847952,
    "end": 3854184,
    "text": "使用不可能な断片化されたメモリで、私たちはこれらを総称して残留状態と呼んでいる。"
  },
  {
    "start": 3854304,
    "end": 3857832,
    "text": "ここでもまた、2つの用語、新しい用語が登場した。"
  },
  {
    "start": 3857928,
    "end": 3865606,
    "text": "残留州とモデル州があり、それぞれを別々に扱うことになる。"
  },
  {
    "start": 3865720,
    "end": 3875914,
    "text": "さて、ゼロDPは、モデルの状態を複製する代わりに分割することで、データ並列プロセス間のメモリー状態の冗長性を取り除く。"
  },
  {
    "start": 3875954,
    "end": 3877090,
    "text": "というのが主旨だ。"
  },
  {
    "start": 3877162,
    "end": 3878986,
    "text": "これが本稿の文字通り主旨である。"
  },
  {
    "start": 3879170,
    "end": 3882214,
    "text": "複製するのではなく、分割しているのだ。"
  },
  {
    "start": 3882514,
    "end": 3889494,
    "text": "つまり、概念的にはシンプルだが、これを効率的に機能させるためには多くの作業が必要で、それが重要なんだ。"
  },
  {
    "start": 3889874,
    "end": 3893822,
    "text": "図をお見せしましょう。"
  },
  {
    "start": 3893878,
    "end": 3895582,
    "text": "これが何を意味するのか、まだ説明するつもりはない。"
  },
  {
    "start": 3895638,
    "end": 3897126,
    "text": "あと数秒で見られる。"
  },
  {
    "start": 3897150,
    "end": 3901950,
    "text": "オプティマイザーのステート・パーティショニングという、いくつかの最適化がある。"
  },
  {
    "start": 3901982,
    "end": 3909474,
    "text": "オプティマイザーの状態を複製する代わりに分割すると、勾配分割ができるようになり、さらにパラメータ分割もできるようになる。"
  },
  {
    "start": 3909814,
    "end": 3913150,
    "text": "彼らは、メモリ削減がdp次数に対して線形であることを示している。"
  },
  {
    "start": 3913222,
    "end": 3927718,
    "text": "つまり、データ並列化を行う際にモデルを複製するために使用するデバイスの数を意味します。例えば、64個のGPUに分割すると、64×メモリ削減となり、これは非常に大きなことです。"
  },
  {
    "start": 3927846,
    "end": 3931014,
    "text": "しかし、通信量は50％ほど増える。"
  },
  {
    "start": 3931094,
    "end": 3931694,
    "text": "オーケー。"
  },
  {
    "start": 3931814,
    "end": 3941294,
    "text": "3つのステージをすべて有効にすると、xeroはわずか1024個のNvidia GPUでトリリウム・パラメータ・モデルを訓練することができる。"
  },
  {
    "start": 3941454,
    "end": 3943234,
    "text": "さて、これがメインダイアグラムだ。"
  },
  {
    "start": 3943994,
    "end": 3954234,
    "text": "まず、この文章を読んでいただいてから、フォワードパスからバックワードパスを行うために必要なアクティベーションの図を説明します。"
  },
  {
    "start": 3954274,
    "end": 3956114,
    "text": "チェックポイントが役に立つことに気づいた。"
  },
  {
    "start": 3956194,
    "end": 3962034,
    "text": "アクティベーション・チェックポイントについては30分ほど前に説明した。"
  },
  {
    "start": 3962114,
    "end": 3971370,
    "text": "このように、zero rは、活性化パーティショニングを通じて、既存の空のアプローチにおける活性化の複製を特定し、除去することにより、活性化メモリを最適化する。"
  },
  {
    "start": 3971402,
    "end": 3973218,
    "text": "またしても、仕切り、仕切り。"
  },
  {
    "start": 3973306,
    "end": 3976338,
    "text": "また、適切な場合にはアクティベーションをCPUにオフロードする。"
  },
  {
    "start": 3976426,
    "end": 3979294,
    "text": "よし、これもできるディテールだ。"
  },
  {
    "start": 3980034,
    "end": 3988694,
    "text": "さて、ゼロDPとゼロrを組み合わせることで、DLトレーニングのための強力なメモリ最適化システムを形成する。"
  },
  {
    "start": 3988994,
    "end": 3990690,
    "text": "繰り返すが、これも専門用語のひとつだ。"
  },
  {
    "start": 3990762,
    "end": 3994994,
    "text": "もしあなたがディープスピードでプレーするようになったら、知っておくと役に立つかもしれない。"
  },
  {
    "start": 3995114,
    "end": 3997954,
    "text": "では、何が起こっているのか見てみよう。"
  },
  {
    "start": 3998574,
    "end": 4006234,
    "text": "上段のベースラインは、クラシックで色を変える方法だ。"
  },
  {
    "start": 4006894,
    "end": 4011434,
    "text": "これがデータ並列の仕組みだ。"
  },
  {
    "start": 4011734,
    "end": 4018914,
    "text": "基本的には、パラメーター、勾配、オプティマイザーの状態の3種類がある。"
  },
  {
    "start": 4019734,
    "end": 4025520,
    "text": "オプティマイザーの状態がメモリの最も大きな部分を占めていることがわかるだろう。"
  },
  {
    "start": 4025712,
    "end": 4027800,
    "text": "データ並列化を行う場合。"
  },
  {
    "start": 4027952,
    "end": 4030960,
    "text": "これらすべてを文字通り再現していることは申し上げた。"
  },
  {
    "start": 4031032,
    "end": 4033752,
    "text": "コピー＆ペーストで、超非効率的だ。"
  },
  {
    "start": 4033808,
    "end": 4034176,
    "text": "オーケー。"
  },
  {
    "start": 4034240,
    "end": 4039112,
    "text": "消費されるメモリは、2＋2＋kのPsi倍であることがわかるだろう。"
  },
  {
    "start": 4039208,
    "end": 4041352,
    "text": "これらが何なのか、すぐに説明するつもりだ。"
  },
  {
    "start": 4041488,
    "end": 4045720,
    "text": "にしては、GPTモデルを使っているような気がする。"
  },
  {
    "start": 4045872,
    "end": 4050772,
    "text": "1台につき120GBのメモリが必要だという。"
  },
  {
    "start": 4050868,
    "end": 4051596,
    "text": "それは大きいね。"
  },
  {
    "start": 4051700,
    "end": 4055664,
    "text": "PSiはパラメータの数で、15億だと思う。"
  },
  {
    "start": 4056244,
    "end": 4059984,
    "text": "この例では、GPTモデルを使用している。"
  },
  {
    "start": 4060404,
    "end": 4064732,
    "text": "GPT-2の2というのは、2バイトを使うからだ。"
  },
  {
    "start": 4064788,
    "end": 4070980,
    "text": "混合精度トレーニングを使用する場合、重みに2バイト、勾配に2バイトを使用する。"
  },
  {
    "start": 4071132,
    "end": 4072668,
    "text": "だから2プラス2があるんだ。"
  },
  {
    "start": 4072756,
    "end": 4073524,
    "text": "それからK。"
  },
  {
    "start": 4073604,
    "end": 4080504,
    "text": "Kが12に等しいのは、これがオプティマイザーの状態だからである。"
  },
  {
    "start": 4080624,
    "end": 4082696,
    "text": "アダムの場合、Kは12に相当する。"
  },
  {
    "start": 4082800,
    "end": 4088424,
    "text": "ということは、1.5億ドルを16倍すると、最終的にこの数字になると思うが、正しいか？"
  },
  {
    "start": 4088584,
    "end": 4094604,
    "text": "16の1.5倍で何かしくじったかどうか、ちょっと確認させてください。"
  },
  {
    "start": 4095144,
    "end": 4095944,
    "text": "よく分からない。"
  },
  {
    "start": 4096024,
    "end": 4098768,
    "text": "ああ、その理由は今にわかるよ。"
  },
  {
    "start": 4098936,
    "end": 4100840,
    "text": "ああ、ごめん、7.5だ。"
  },
  {
    "start": 4100912,
    "end": 4101844,
    "text": "こう書いてある。"
  },
  {
    "start": 4102553,
    "end": 4103693,
    "text": "だから、私たちは得るのだ。"
  },
  {
    "start": 4104473,
    "end": 4111665,
    "text": "最初の最適化は、オプティマイザーの状態をどこにでもコピーしておくのではなく、分割しておくことだ。"
  },
  {
    "start": 4111729,
    "end": 4115441,
    "text": "オプティマイザーの状態の一部を1つのGPUに保存する。"
  },
  {
    "start": 4115537,
    "end": 4124457,
    "text": "2番目の部分はここに保存され、n番目の部分はここに保存される。"
  },
  {
    "start": 4124545,
    "end": 4134743,
    "text": "だから、最終的には、これらすべてを組み合わせても、ここと同じ情報が得られることになるんだ。"
  },
  {
    "start": 4135203,
    "end": 4137835,
    "text": "そうすれば、他のすべてについても同じことができる。"
  },
  {
    "start": 4137939,
    "end": 4139635,
    "text": "グラデーションの場合、分割することができる。"
  },
  {
    "start": 4139699,
    "end": 4143987,
    "text": "パラメータについては、パーティションで区切って、メモリが徐々に減っていく様子を見ることができる。"
  },
  {
    "start": 4144035,
    "end": 4154219,
    "text": "ここではチューブPsiとチューブPsiを足している。パラメータと勾配の最適化はしていないが、オプティマイザーの状態は節約している。"
  },
  {
    "start": 4154331,
    "end": 4161140,
    "text": "そのため、k倍のPsiをNDで割っている。"
  },
  {
    "start": 4161212,
    "end": 4166324,
    "text": "この場合、メモリが劇的に減るのがわかるだろう。"
  },
  {
    "start": 4166444,
    "end": 4173540,
    "text": "120GBで始めたのに、最終的に1.9GBになるなんてクレイジーだ。"
  },
  {
    "start": 4173692,
    "end": 4175148,
    "text": "つまり、これは驚くべき最適化なんだ。"
  },
  {
    "start": 4175236,
    "end": 4177824,
    "text": "よし、ここで続けよう。"
  },
  {
    "start": 4178844,
    "end": 4180424,
    "text": "これは前にも述べたことだ。"
  },
  {
    "start": 4181494,
    "end": 4191726,
    "text": "Xeroの最適化一式を使えば、例えば1000対100GPUのような、今日のハイエンド・ハードウェア・クラスタ上で数兆のパラメーターを持つモデルを実行することができる。"
  },
  {
    "start": 4191830,
    "end": 4199126,
    "text": "しかし、ハードウェアの計算能力はまだ限られており、トレーニング期間は1年以上と非現実的だ。"
  },
  {
    "start": 4199230,
    "end": 4200950,
    "text": "常に塩の粒にこだわる。"
  },
  {
    "start": 4200982,
    "end": 4207234,
    "text": "誰かが1兆ドルと言ったら、細かい字を読んでその方法の詳細を理解しなければならない。"
  },
  {
    "start": 4208884,
    "end": 4215316,
    "text": "ゼロパワーは、17個のdパラメータを持つ最大の言語モデルであり、記録的な精度を誇る。"
  },
  {
    "start": 4215380,
    "end": 4225304,
    "text": "チューリング NLGで重要なことは、これは文字通り、GPT-3が発表される1カ月前だったと思う。"
  },
  {
    "start": 4225684,
    "end": 4232188,
    "text": "私たちは、ディープスピードと呼ばれるオープンソースのDLトレーニング最適化ライブラリの一部としてゼロを共有しています。"
  },
  {
    "start": 4232316,
    "end": 4235140,
    "text": "私はこの図書館について何度も言及した。"
  },
  {
    "start": 4235172,
    "end": 4238112,
    "text": "特に大きなモデルでプレーしたい人はチェックしてみるといい。"
  },
  {
    "start": 4238308,
    "end": 4246960,
    "text": "ところで、私がこれらの論文に目を通しているのは、次のビデオでMLモデルの中でも最大級のものを取り上げるからだ。"
  },
  {
    "start": 4247152,
    "end": 4254264,
    "text": "何か提案してほしいことがあれば言ってほしい。"
  },
  {
    "start": 4254424,
    "end": 4256284,
    "text": "コメント欄にお気軽にどうぞ。"
  },
  {
    "start": 4256824,
    "end": 4262444,
    "text": "また、このビデオに最後までお付き合いくださった方、おめでとうございます。"
  },
  {
    "start": 4263934,
    "end": 4268394,
    "text": "Kが12歳である理由などを理解するために、簡単な記憶分析をしてみよう。"
  },
  {
    "start": 4269054,
    "end": 4274990,
    "text": "15億のパラメーターを持つGPT-2モデルは、重みのために3GBのメモリーを必要とする。"
  },
  {
    "start": 4275102,
    "end": 4285914,
    "text": "FP16または16ビット精度と仮定すると、tensorflowやPytorchを使用して32GBのメモリを搭載したシングルGPUで学習することはできない。"
  },
  {
    "start": 4286214,
    "end": 4292194,
    "text": "PytorchとTensorflowは、少なくとも最適化されていない。"
  },
  {
    "start": 4292524,
    "end": 4295452,
    "text": "メモリはどこへ行ってしまったのだろうと思うかもしれない。"
  },
  {
    "start": 4295548,
    "end": 4297252,
    "text": "さて、どうなることやら。"
  },
  {
    "start": 4297388,
    "end": 4298980,
    "text": "具体的な例としてアトムを挙げてみよう。"
  },
  {
    "start": 4299012,
    "end": 4311764,
    "text": "atomを使用したPSIパラメータを持つモデルの混合精度学習では、パラメータと勾配のFP16コピーを保持するのに十分なメモリが必要で、それぞれ2PSiとチューブPSIバイトのメモリが必要となる。"
  },
  {
    "start": 4311804,
    "end": 4315384,
    "text": "基本的に、この表は以前にも見たことがある。"
  },
  {
    "start": 4315804,
    "end": 4322144,
    "text": "さらに、オプティマイザーの状態とパラメーターのFP 32コピーを保持する必要がある。"
  },
  {
    "start": 4322224,
    "end": 4323808,
    "text": "その理由はわかっている。"
  },
  {
    "start": 4323856,
    "end": 4329616,
    "text": "混合精度のトレーニングのため、マスターコピーは常にFP32に保存する必要があるんだ。"
  },
  {
    "start": 4329720,
    "end": 4335616,
    "text": "でも、勢いと分散が必要なんだ。"
  },
  {
    "start": 4335720,
    "end": 4343512,
    "text": "これらはアトムの特質であり、そしてPsiとPsiバイトのメモリ要件である。"
  },
  {
    "start": 4343608,
    "end": 4346496,
    "text": "ここにはFB32がある。"
  },
  {
    "start": 4346600,
    "end": 4351608,
    "text": "そのため、それらを合計すると12になり、kが12に等しくなる。"
  },
  {
    "start": 4351736,
    "end": 4355896,
    "text": "合計で16Psiバイトのメモリクエリとなる。"
  },
  {
    "start": 4356040,
    "end": 4363112,
    "text": "そう、だからGPUでは、これらの最適化がない限り、GPT one 5dのトレーニングはできないんだ。"
  },
  {
    "start": 4363208,
    "end": 4366744,
    "text": "よし、これで残留メモリーの消費量を減らせるぞ。"
  },
  {
    "start": 4366784,
    "end": 4378506,
    "text": "例えば、GPT-2でシーケンス長1000、バッチサイズ32の場合、アクティベーション・チェック・ポインティングをしない限り、60GBのメモリが必要になる。"
  },
  {
    "start": 4378610,
    "end": 4382058,
    "text": "そしてここで、アクティベーション・チェック・ポインター、あるいはアクティベーション計算と言う。"
  },
  {
    "start": 4382106,
    "end": 4392066,
    "text": "再計算は、33％の再計算オーバヘッドを犠牲にして、総活性化量の平方根ほど活性化メモリを削減する一般的なアプローチである。"
  },
  {
    "start": 4392170,
    "end": 4397026,
    "text": "これにより、このモデルの起動メモリ消費量は約8GBに減る。"
  },
  {
    "start": 4397130,
    "end": 4399298,
    "text": "これは大きな節約だ。"
  },
  {
    "start": 4399426,
    "end": 4404834,
    "text": "さて、モデルのサイズが大きい場合、これらの一時的なバッファーのサイズは些細なものではない。"
  },
  {
    "start": 4404954,
    "end": 4408970,
    "text": "さらに、残存メモリ消費には3つの要素があるという。"
  },
  {
    "start": 4409082,
    "end": 4413334,
    "text": "アクティブ化、一時的なバッファ、メモリの断片化。"
  },
  {
    "start": 4415154,
    "end": 4417178,
    "text": "ああ、これはスキップするつもりだ。"
  },
  {
    "start": 4417226,
    "end": 4423356,
    "text": "そうだね、減量などをしたいときには一時的なバッファが必要だ。"
  },
  {
    "start": 4423530,
    "end": 4425924,
    "text": "ああ、このビデオには詳しすぎるよ。"
  },
  {
    "start": 4427384,
    "end": 4429992,
    "text": "さて、なぜこれが有効なのか、ヒントを得よう。"
  },
  {
    "start": 4430168,
    "end": 4445004,
    "text": "ZerodPはモデル状態を複製する代わりに分割し、通信量を最小化しながらモデル状態の本質的な時間的性質を利用する動的な通信スケジュールを使用する。"
  },
  {
    "start": 4445984,
    "end": 4450054,
    "text": "そう、本質的に時間的なものなのだ。"
  },
  {
    "start": 4450224,
    "end": 4452962,
    "text": "早速、この図に戻ってみよう。"
  },
  {
    "start": 4453018,
    "end": 4455374,
    "text": "それが一番簡単だと思う。"
  },
  {
    "start": 4456674,
    "end": 4460090,
    "text": "つまり、パラメーターを例にとって考えてみよう。"
  },
  {
    "start": 4460122,
    "end": 4479630,
    "text": "この青い線は、文字通りフォワードパスをするとき、明らかにフォワードパスは常にモデルのあるレイヤーのあるポイントにある。"
  },
  {
    "start": 4479702,
    "end": 4484566,
    "text": "そうすれば、今までのことはすべて捨てられるし、これからのことは気にならなくなる。"
  },
  {
    "start": 4484710,
    "end": 4511580,
    "text": "そのため、基本的にすべてがすでにそこに存在しているかのような錯覚に陥り、モデルトレーニング中に特定の固有レイテンシーが発生するため、オーバーヘッドを隠蔽してしまうのだ。"
  },
  {
    "start": 4511732,
    "end": 4514664,
    "text": "これ以上詳しく説明するつもりはない。"
  },
  {
    "start": 4515964,
    "end": 4517212,
    "text": "ここに戻ろう。"
  },
  {
    "start": 4517268,
    "end": 4519708,
    "text": "ここに戻ろう、私たちはここにいると思う。"
  },
  {
    "start": 4519796,
    "end": 4522188,
    "text": "よし、あと2、3したら、ここで終わりにしよう。"
  },
  {
    "start": 4522276,
    "end": 4534416,
    "text": "1反復あたりの計算量と1反復あたりの活性化チェックポイント量の算術密強度比は非常に大きく、隠れ次元とともに線形に増加するため、隠蔽が可能になる。"
  },
  {
    "start": 4534520,
    "end": 4563784,
    "text": "アクティベーション・チェックポイントのデータ移動コストは、非常に大きなモデルで帯域幅が低い場合でも、アクティベーション・パーティションをCPUのメモリに移動させることができます。"
  },
  {
    "start": 4564644,
    "end": 4566824,
    "text": "残念ながら、この論文は非常に文字が多い。"
  },
  {
    "start": 4567644,
    "end": 4572148,
    "text": "図やこれまでの説明から、何らかのヒントが得られることを願っている。"
  },
  {
    "start": 4572276,
    "end": 4576864,
    "text": "私が強調したことのうち、洞察に富んでいると思われるものをもう少し読んでみよう。"
  },
  {
    "start": 4577244,
    "end": 4581740,
    "text": "DPはNDのデータ並列性を意味する。"
  },
  {
    "start": 4581852,
    "end": 4586460,
    "text": "オプティマイザーの状態をnd等分するんだ。"
  },
  {
    "start": 4586652,
    "end": 4594224,
    "text": "そのため、i番目のデータ並列プロセスは、i番目のパーティションに対応するオプティマイザの状態のみを更新する。"
  },
  {
    "start": 4594564,
    "end": 4606744,
    "text": "したがって、各データ並列プロセスは、オプティマイザーの全状態のうちnd以上の1つを保存・更新し、nd以上のパラメータのうち1つを更新するだけでよい。"
  },
  {
    "start": 4607254,
    "end": 4618314,
    "text": "各ステップの終了時にデータ並列プロセス全体のオールギャザーを実行し、すべてのデータ並列プロセスで完全に更新されたパラメータを取得する。"
  },
  {
    "start": 4618814,
    "end": 4621454,
    "text": "すべてを説明するのは難しいんだ。"
  },
  {
    "start": 4621534,
    "end": 4623382,
    "text": "ここでひとつお見せしたいことがある。"
  },
  {
    "start": 4623438,
    "end": 4634538,
    "text": "リデュース、オール・リデュース、ブラブラ、オール・ギャザー、オール・スキャッター、オール・トゥ・オール、オール・スキャッターなどなど。"
  },
  {
    "start": 4634626,
    "end": 4639354,
    "text": "これらはすべて、NvidiaのNCCLなどのライブラリに実装されている。"
  },
  {
    "start": 4639394,
    "end": 4642866,
    "text": "これはNvidia集団通信ライブラリの略である。"
  },
  {
    "start": 4643010,
    "end": 4644338,
    "text": "それをチェックすることができる。"
  },
  {
    "start": 4644386,
    "end": 4645578,
    "text": "ここの図は役に立つ。"
  },
  {
    "start": 4645626,
    "end": 4658266,
    "text": "でも、最終的には誰かが、たぶん僕でもいいんだけど、これをうまく視覚化して、何が起こっているのかを理解できるようなものを作る必要があるんだ。"
  },
  {
    "start": 4658290,
    "end": 4661648,
    "text": "そうだね、これで直感をつかんでもらえればと思うし、僕らが目指しているのはそれなんだ。"
  },
  {
    "start": 4661696,
    "end": 4667776,
    "text": "ただ、少なくとも基本的な用語と、これらすべての最適化手法の基本的な理解を持っているように。"
  },
  {
    "start": 4667880,
    "end": 4673976,
    "text": "もっと詳しく知りたければ、使っているライブラリのドキュメントを読めばいい。"
  },
  {
    "start": 4674080,
    "end": 4677644,
    "text": "よし、ここでは全部省略しよう。"
  },
  {
    "start": 4678984,
    "end": 4681560,
    "text": "興味深い理論だが、それほど実用的なものではない。"
  },
  {
    "start": 4681672,
    "end": 4696904,
    "text": "というのも、これらの公式はすでに表で見たが、最終的にはメモリ量についてNdを超える16psiの公式に行き着く。"
  },
  {
    "start": 4697024,
    "end": 4698784,
    "text": "ええ、現実的ではありません。"
  },
  {
    "start": 4698824,
    "end": 4701512,
    "text": "このことは、このことが重大な意味を持つことを示している。"
  },
  {
    "start": 4701568,
    "end": 4707968,
    "text": "ゼロパワーDPは、モデルの状態を共有するのに十分な数のデバイスがある限り、任意のサイズのモデルに適合する。"
  },
  {
    "start": 4708056,
    "end": 4714104,
    "text": "そう、あるポイントを過ぎると飽和点が聞こえてくる。"
  },
  {
    "start": 4714604,
    "end": 4716308,
    "text": "さて、これが最後のパートだ。"
  },
  {
    "start": 4716356,
    "end": 4718828,
    "text": "ちょっと読みながら説明しよう。"
  },
  {
    "start": 4718956,
    "end": 4720092,
    "text": "見識が深まるかもしれない。"
  },
  {
    "start": 4720188,
    "end": 4734348,
    "text": "つまり、より具体的には、モデルのある層の順伝搬が計算されると、入力活性度は、バックプロパゲーションの間に再び必要になるまで、すべてのモデル並列処理に分割される。"
  },
  {
    "start": 4734516,
    "end": 4739892,
    "text": "さて、ここで彼らが言っているのは、試しにこれを引き出してみようということだ。"
  },
  {
    "start": 4740028,
    "end": 4746228,
    "text": "例えば、このようなデバイスがたくさんあるとしよう。"
  },
  {
    "start": 4746276,
    "end": 4757220,
    "text": "例えば、3台のデバイスがあるとして、あなたは今、ネットワークのこの部分にいて、いくつかのアクティベーションを計算したとします。"
  },
  {
    "start": 4757292,
    "end": 4758452,
    "text": "そうしたら、前に進むんだ。"
  },
  {
    "start": 4758548,
    "end": 4763596,
    "text": "その後、前方に進み、ここで前方のプロップを続ける。"
  },
  {
    "start": 4763740,
    "end": 4764260,
    "text": "いいかい？"
  },
  {
    "start": 4764332,
    "end": 4770744,
    "text": "チェックポイントを持つ代わりに、チェックポイントはここに保存される。"
  },
  {
    "start": 4772164,
    "end": 4774508,
    "text": "そうする代わりに、なぜパーティションにしないのか？"
  },
  {
    "start": 4774596,
    "end": 4778908,
    "text": "基本的に、なぜ保管しないのか、文字通り色を変えないのか。"
  },
  {
    "start": 4778996,
    "end": 4782060,
    "text": "代わりに、ここにチャンクだけを保存する。"
  },
  {
    "start": 4782212,
    "end": 4788068,
    "text": "チャンクをここに保存し、2つ目のチャンクをここに保存し、3つ目のチャンクをここに保存する。"
  },
  {
    "start": 4788236,
    "end": 4789004,
    "text": "そういうことだ。"
  },
  {
    "start": 4789044,
    "end": 4799478,
    "text": "そして、再びアクティベーションが必要になったら、そのアクティベーションをこのデバイスに伝え、グラディエントなどを計算できるようにする。"
  },
  {
    "start": 4799606,
    "end": 4800646,
    "text": "これが基本的な考え方だ。"
  },
  {
    "start": 4800670,
    "end": 4808118,
    "text": "アルゴリズム、データ構造、ハードウェア、エレクトロニクスなどなど。"
  },
  {
    "start": 4808246,
    "end": 4811678,
    "text": "そうだね、ある抽象的なレベルで止めなければならない。"
  },
  {
    "start": 4811806,
    "end": 4820726,
    "text": "なるほど、アクティブ化チェックポイントと連動し、複製されたコピーの代わりにパーティション化されたアクティブ化チェックポイントのみを保存する。"
  },
  {
    "start": 4820750,
    "end": 4822230,
    "text": "それは私がここで話したことだ。"
  },
  {
    "start": 4822302,
    "end": 4837958,
    "text": "さらに、非常に大きなモデルでデバイスのメモリが非常に限られている場合、これらのパーティション化されたアクティベーション・チェックポイントをCPUにオフロードすることで、追加の通信コストでアクティベーション・メモリのオーバーヘッドをほぼゼロにすることもできる。"
  },
  {
    "start": 4838006,
    "end": 4839366,
    "text": "このことは前にも述べた。"
  },
  {
    "start": 4839470,
    "end": 4848656,
    "text": "各トランスフォーマーレイヤーに対して1つのアクティベーションをチェックポイントするとすると、アクティベーションのチェックポイントを保存するためだけに、1GPUあたり約33GBのメモリが必要になる。"
  },
  {
    "start": 4848790,
    "end": 4855236,
    "text": "この最適化により、PAがゼロになり、1GPUあたり約2GBまで削減できる。"
  },
  {
    "start": 4855420,
    "end": 4862204,
    "text": "そうだね、モデルの並列度が16の場合、16で割ればだいたい2GBになる。"
  },
  {
    "start": 4862324,
    "end": 4868540,
    "text": "さらに、この2GBをCPUにアップロードすることで、アクティベーションに必要なメモリ・フットプリントをほぼゼロにすることができる。"
  },
  {
    "start": 4868652,
    "end": 4871628,
    "text": "よし、みんな、これでほとんど終わりだ。"
  },
  {
    "start": 4871716,
    "end": 4872904,
    "text": "紙は巨大だ。"
  },
  {
    "start": 4874344,
    "end": 4879584,
    "text": "その背景には明らかに多くのヒューリスティックな要素がある。"
  },
  {
    "start": 4879624,
    "end": 4886184,
    "text": "モデルとハードウェアの特性が与えられたら、上記の分析を活用して、PAとPAプラスCPUを適用するかどうか、またいつ適用するかを決定する。"
  },
  {
    "start": 4886224,
    "end": 4893464,
    "text": "アクティブ化チェックポイントの最適化、アクティブ化チェックポイントのパーティショニング、およびCPUオフロードの最適化。"
  },
  {
    "start": 4893624,
    "end": 4897032,
    "text": "上記の分析はぜひ読んでいただきたい。"
  },
  {
    "start": 4897128,
    "end": 4901904,
    "text": "様々なレイテンシーに応じて、これが良いアイデアかどうかを判断するというものだ。"
  },
  {
    "start": 4901944,
    "end": 4911154,
    "text": "そこには多くの詳細があるが、概念的に根本的なことは何もない。"
  },
  {
    "start": 4911274,
    "end": 4911978,
    "text": "そうだね。"
  },
  {
    "start": 4912146,
    "end": 4916442,
    "text": "みんな、このビデオが気に入ってくれるといいな。"
  },
  {
    "start": 4916498,
    "end": 4919466,
    "text": "では、最後にこの素敵なチャートをご覧いただこう。"
  },
  {
    "start": 4919530,
    "end": 4921842,
    "text": "さて、このビデオが気に入ってもらえるといいんだけど。"
  },
  {
    "start": 4921978,
    "end": 4930534,
    "text": "もしそうなら、このスケーリング・テクニックを理解することが有益だと思われる人に、ぜひこの記事を教えてあげてほしい。"
  },
  {
    "start": 4930634,
    "end": 4932454,
    "text": "私たちはここで多くのことを学んだ。"
  },
  {
    "start": 4932494,
    "end": 4955314,
    "text": "データ並列のアプローチ、テンソル並列のアプローチ、パイプライン並列のアプローチ、混合精度トレーニング、そして最後にゼロオプティマイザーについて説明した。"
  },
  {
    "start": 4955894,
    "end": 4959430,
    "text": "このビデオが面白かったかどうか、ぜひ教えてください。"
  },
  {
    "start": 4959582,
    "end": 4963860,
    "text": "ご意見、ご感想、チャンネル登録、そして次回まで。"
  },
  {
    "start": 4963972,
    "end": 4964260,
    "text": "さようなら。"
  }
]