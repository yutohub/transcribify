[
  {
    "start": 4960,
    "end": 16854,
    "text": "10年以上にわたってAIの最前線をハックし、教育してきた伝説的な人物を紹介できることに、私は今、超感激している。"
  },
  {
    "start": 17022,
    "end": 28406,
    "text": "ニューラルネットワークからコンピュータ・ビジョンまで、自然言語処理から強化学習まで、彼は限界を押し広げ、世界中の何百万もの人々にインスピレーションを与えてきた。"
  },
  {
    "start": 28438,
    "end": 45010,
    "text": "オープンAIの創設メンバーであり、イマジネットのリファレンス・ヒューマンであり、元グーグルの頭脳であり、元ディープマインドであり、元テスラであり、ミスター・オートパイロットである。"
  },
  {
    "start": 45350,
    "end": 47010,
    "text": "彼は本当にすべてを見てきた。"
  },
  {
    "start": 48110,
    "end": 63910,
    "text": "数ヶ月前、記念すべき日に、この特別な人はCudaモードのディスコードに参加し、LLM Cで他の人とハッキングを始めました。"
  },
  {
    "start": 64770,
    "end": 68226,
    "text": "彼自身が語るのが一番だと思う。"
  },
  {
    "start": 68378,
    "end": 74590,
    "text": "アンドレ・カパティという素晴らしい人物を歓迎しよう。"
  },
  {
    "start": 82700,
    "end": 83276,
    "text": "ワオ。"
  },
  {
    "start": 83388,
    "end": 84160,
    "text": "オーケー。"
  },
  {
    "start": 86620,
    "end": 87760,
    "text": "とても印象的だ。"
  },
  {
    "start": 89300,
    "end": 89668,
    "text": "オーケー。"
  },
  {
    "start": 89684,
    "end": 90732,
    "text": "ああ、ここに来られてとても興奮している。"
  },
  {
    "start": 90756,
    "end": 92740,
    "text": "これは私が一番好きな発表の場だ。"
  },
  {
    "start": 92780,
    "end": 96612,
    "text": "そう、招待してくれてありがとう、そしてクダ・モードを走らせてくれて、これをつけてくれてありがとう。"
  },
  {
    "start": 96676,
    "end": 98160,
    "text": "これは素晴らしいイベントのようだ。"
  },
  {
    "start": 98540,
    "end": 101092,
    "text": "では、LLM Cについて少しお話ししましょう。"
  },
  {
    "start": 101196,
    "end": 102044,
    "text": "我々は何をしているのか？"
  },
  {
    "start": 102092,
    "end": 105284,
    "text": "トランスフォーマーはCとピンチでトレーニングしているんだ。"
  },
  {
    "start": 105452,
    "end": 110696,
    "text": "では、このプロジェクトがどのようにして生まれたのか、そして私の視点から見たこのプロジェクトがどのようなものなのか、少しお話したいと思います。"
  },
  {
    "start": 110788,
    "end": 117816,
    "text": "それで、だいたい1年前、私は自分のYouTubeシリーズにビデオを追加しようとしていて、LLMトレーニングやGPTトレーニングなどを人々に教えようとしていた。"
  },
  {
    "start": 117888,
    "end": 120536,
    "text": "私は基本的にnano GPTをハックして動作させようとしていた。"
  },
  {
    "start": 120688,
    "end": 122264,
    "text": "それは私だった。"
  },
  {
    "start": 122432,
    "end": 125432,
    "text": "では、皆さんはもちろんパイトーチと仕事をしたことがありますよね？"
  },
  {
    "start": 125456,
    "end": 128912,
    "text": "しかし、このような場合、あなたが書いたモデルを使うことになる。"
  },
  {
    "start": 128976,
    "end": 129712,
    "text": "それは理にかなっている。"
  },
  {
    "start": 129816,
    "end": 133696,
    "text": "今、あなたはここでいくつもの抽象的なものを同時に把握しなければならない。"
  },
  {
    "start": 133768,
    "end": 137688,
    "text": "そのため、デバイスをコンパイルし、DDPでラッピングする必要がある。"
  },
  {
    "start": 137824,
    "end": 143200,
    "text": "というのも、どういう順番でやればいいのかさえわからないからだ。"
  },
  {
    "start": 143240,
    "end": 144192,
    "text": "具体的に何が起こるのか？"
  },
  {
    "start": 144216,
    "end": 145120,
    "text": "抽象的な表現とは何か？"
  },
  {
    "start": 145160,
    "end": 146352,
    "text": "彼らはあなたのモデルに何をするのか？"
  },
  {
    "start": 146456,
    "end": 148632,
    "text": "どのような仕組みになっているのか、完全には理解していない。"
  },
  {
    "start": 148736,
    "end": 155952,
    "text": "そうなると、モデルを評価、トレーニング、モデル推論など、さまざまな方法で使いたいと思うだろう。"
  },
  {
    "start": 156136,
    "end": 163144,
    "text": "私の場合、モデルのトレーニングはできたのですが、なぜか評価と推論がうまくいきませんでした。"
  },
  {
    "start": 163232,
    "end": 168924,
    "text": "evalと推論を実行しようとすると、トーチ・コンパイラのようなものが表示されたんだ。"
  },
  {
    "start": 169012,
    "end": 171236,
    "text": "これはトーチのコンパイル・エラーの一例です。"
  },
  {
    "start": 171268,
    "end": 178836,
    "text": "でも、2つとも推論エラーとevalエラーと別のエラーが出て、何が起こっているのかさっぱりわからなかった。"
  },
  {
    "start": 178988,
    "end": 180868,
    "text": "私は自分の立場なら誰でもすることをした。"
  },
  {
    "start": 180924,
    "end": 192120,
    "text": "ショートに嫌気がさしたので、問題を解決するためにPTR Blckを探している。"
  },
  {
    "start": 192740,
    "end": 198536,
    "text": "残念ながら、PTR Blckにはそのエラーに関するガイダンスがなかったので、正直、行き詰まってしまった。"
  },
  {
    "start": 198568,
    "end": 204080,
    "text": "2時間後、トーチコンパイルと格闘し、一体何が起こっているのか理解しようとして、私はちょっと悲しいパンダになった。"
  },
  {
    "start": 204120,
    "end": 205860,
    "text": "これをどう解決すればいいのか、正確にはわからない。"
  },
  {
    "start": 206280,
    "end": 210992,
    "text": "だから、最初の頃は悲しみの段階を踏んでいるように感じた。"
  },
  {
    "start": 211016,
    "end": 211600,
    "text": "私は否定していた。"
  },
  {
    "start": 211640,
    "end": 212976,
    "text": "こんなことが私に起こるはずがないと思った。"
  },
  {
    "start": 213008,
    "end": 215752,
    "text": "クレイジーなことは何もしていない。GPTを少しトレーニングしているだけだ。"
  },
  {
    "start": 215896,
    "end": 217184,
    "text": "なぜこれが機能しないのか？"
  },
  {
    "start": 217272,
    "end": 218416,
    "text": "これは本当に簡単なことのように思える。"
  },
  {
    "start": 218448,
    "end": 219768,
    "text": "おかしなことはしていない。"
  },
  {
    "start": 219904,
    "end": 226584,
    "text": "そしてやがて怒りの段階に入り、私はこう思った。"
  },
  {
    "start": 226752,
    "end": 229376,
    "text": "自分のやろうとしていることは頭では理解している。"
  },
  {
    "start": 229408,
    "end": 236056,
    "text": "計算そのものもそうだが、アルゴリズムそのものは私の頭の中では完全にクリアなのだが、なぜかトーチ・コンパイルはそれを使わせてくれないし、実行もさせてくれない。"
  },
  {
    "start": 236088,
    "end": 241912,
    "text": "私は少し無力感を感じていて、よし、自分の手で人生を切り開き、自分の運命をコントロールしようと思ったんだ。"
  },
  {
    "start": 241936,
    "end": 244860,
    "text": "これを書いて、どれだけ悪いことができるか見てみるよ。"
  },
  {
    "start": 245720,
    "end": 249368,
    "text": "ピトーチがあなたに何を提供しているのか、考えてみよう。"
  },
  {
    "start": 249464,
    "end": 252144,
    "text": "いろいろなことがあるけれど、多分、ここに関係することのいくつかだろう。"
  },
  {
    "start": 252312,
    "end": 258288,
    "text": "なぜ箇条書きが1対1なのか、私のスライドに何が書いてあるのかわからない。"
  },
  {
    "start": 258304,
    "end": 266312,
    "text": "ここでどんな変換が行われたのかわからないが、第一に、我々は配列を得ている、つまり非常に便利なn次元配列で、操作を操作することができる。"
  },
  {
    "start": 266456,
    "end": 272864,
    "text": "もしこれを放棄するのであれば、多くのポインタ演算をしなければならなくなる。"
  },
  {
    "start": 273032,
    "end": 274584,
    "text": "つ目は、オートグラッドが無料で手に入ることだ。"
  },
  {
    "start": 274632,
    "end": 280090,
    "text": "オートグラッドがない場合は、デバイスがないすべてのレイヤーのフォワードパスとバックワードパスを行う必要がある。"
  },
  {
    "start": 280130,
    "end": 287138,
    "text": "メモリがホスト上にあるのかデバイス上にあるのか、CPUとGPUの間でメモリをシャトル移動させるのかなど、さまざまなデバイスを心配しなければならない。"
  },
  {
    "start": 287274,
    "end": 294290,
    "text": "私たちには単純なDTAP変換がないので、どのテンソルがどのような精度で保存されているかに細心の注意を払い、それらの間で明示的に変換しなければならない。"
  },
  {
    "start": 294410,
    "end": 295698,
    "text": "トーチコンパイルがないんだ。"
  },
  {
    "start": 295794,
    "end": 298634,
    "text": "カーネル・フュージョンはすべて手作業でやらなければならない。"
  },
  {
    "start": 298762,
    "end": 301762,
    "text": "スペースと時間のパフォーマンスを手動で最適化しなければならない。"
  },
  {
    "start": 301946,
    "end": 308390,
    "text": "そのため、すべてのプロセスを手動で立ち上げ、互いを見つけ、ニッケルと通信できるようにしなければならない。"
  },
  {
    "start": 308530,
    "end": 310118,
    "text": "ピトーチは本当に、本当に素晴らしい。"
  },
  {
    "start": 310174,
    "end": 312086,
    "text": "これはPytorchが提供するもののほんの一部である。"
  },
  {
    "start": 312158,
    "end": 314358,
    "text": "ピートーチがいなければ、僕らは世界で裸同然だろう？"
  },
  {
    "start": 314414,
    "end": 316078,
    "text": "多分、大丈夫だと思う。"
  },
  {
    "start": 316254,
    "end": 318982,
    "text": "ああ、どれだけ悪いんだ？"
  },
  {
    "start": 319006,
    "end": 323742,
    "text": "ステップ1では、Pytorchのコードがある。"
  },
  {
    "start": 323766,
    "end": 327350,
    "text": "それは、私たちが正しさをチェックするための参照でしかない。"
  },
  {
    "start": 327470,
    "end": 328630,
    "text": "ここはピトーチの地だ。"
  },
  {
    "start": 328670,
    "end": 329614,
    "text": "すべてが素晴らしく、清潔だ。"
  },
  {
    "start": 329662,
    "end": 332278,
    "text": "小さな変圧器といくつかのモジュールがあって、それを呼んでいるだけだ。"
  },
  {
    "start": 332294,
    "end": 333214,
    "text": "すべてが素晴らしい。"
  },
  {
    "start": 333302,
    "end": 335610,
    "text": "これがピトーチでのリファレンスとなる。"
  },
  {
    "start": 336270,
    "end": 338462,
    "text": "レイヤーの一例をお見せしよう。"
  },
  {
    "start": 338486,
    "end": 341422,
    "text": "例えば、ここでのレイヤー・ノルムはPytorchのレイヤーのようなものだ。"
  },
  {
    "start": 341526,
    "end": 344502,
    "text": "基本的にはこれをC言語に移植したい。"
  },
  {
    "start": 344606,
    "end": 346174,
    "text": "どのようなプロセスを経るのか？"
  },
  {
    "start": 346262,
    "end": 347750,
    "text": "では、すべてのレイヤーを反復することにしよう。"
  },
  {
    "start": 347830,
    "end": 349958,
    "text": "第一に、前方へのパスが必要だ。"
  },
  {
    "start": 350094,
    "end": 360870,
    "text": "というのも、Pytorchはレイヤーノルムの実装をPytorchだけで実装しているわけではなく、ブロックのようなもので、最終的にはいくつかのcudaカーネルを呼び出すからです。"
  },
  {
    "start": 361030,
    "end": 365676,
    "text": "レイヤーノルムのフォワードパスを書いて、それがPytorchのレイヤーノルムと同等であることを確認しなければならなかった。"
  },
  {
    "start": 365838,
    "end": 368752,
    "text": "そしてもちろん、レイヤーノルムのバックワードパスを書かなければならなかった。"
  },
  {
    "start": 368856,
    "end": 371992,
    "text": "ここでペンと紙を取り出し、バックドロップを行う。"
  },
  {
    "start": 372136,
    "end": 375016,
    "text": "これはバッチノルムの場合だが、レイヤーノルムも同様だろう。"
  },
  {
    "start": 375208,
    "end": 377144,
    "text": "そうだ、バックワードパスを書かなければならない。"
  },
  {
    "start": 377272,
    "end": 380240,
    "text": "繰り返しになるが、これはすべてPytorchのままだ。"
  },
  {
    "start": 380280,
    "end": 390688,
    "text": "Pytorchのレイヤーノルムが、この基本的に手動のテンソルベースの実装と一致することを確認するだけだ。"
  },
  {
    "start": 390824,
    "end": 393342,
    "text": "これでPytorchのコードは前方後方になった。"
  },
  {
    "start": 393536,
    "end": 395818,
    "text": "次にすることは、これをC言語に移植することだ。"
  },
  {
    "start": 395914,
    "end": 398506,
    "text": "これは実は、あなたが思っているよりずっと単純なことなのだ。"
  },
  {
    "start": 398578,
    "end": 403070,
    "text": "左側がピトーチのコードで、右側が基本的にC言語の等価レイヤー・ノルム・フォワードだ。"
  },
  {
    "start": 403450,
    "end": 405186,
    "text": "そんなにクレイジーじゃないだろ？"
  },
  {
    "start": 405218,
    "end": 410194,
    "text": "Pytorchと違って、我々はただたくさんの浮動小数点配列を持っているだけだ。"
  },
  {
    "start": 410362,
    "end": 416970,
    "text": "フロート・スター出力、フロート・スター入力、出力、平均、標準偏差、重み、バイアス、ハイパーパラメーターがある。"
  },
  {
    "start": 417090,
    "end": 421034,
    "text": "エレンCで本当にやりたかったことのひとつは、物事をシンプルに保つことだ。"
  },
  {
    "start": 421122,
    "end": 422954,
    "text": "テンソルの抽象化はしたくない。"
  },
  {
    "start": 423002,
    "end": 428094,
    "text": "浮動小数点数配列と浮動小数点数配列に対する演算だけを抽象化することはしたくない。"
  },
  {
    "start": 428142,
    "end": 430182,
    "text": "なぜ、もっと複雑でなければならないのか？"
  },
  {
    "start": 430286,
    "end": 433342,
    "text": "すべてが単なる浮動小数点配列で、すべてが完全に自己完結している。"
  },
  {
    "start": 433406,
    "end": 437534,
    "text": "根底にある表現、インポートと呼ぶべき抽象的なものなどがない。"
  },
  {
    "start": 437622,
    "end": 439606,
    "text": "これはフロート・アレイの前進に関する学習である。"
  },
  {
    "start": 439678,
    "end": 440614,
    "text": "それだけだ。"
  },
  {
    "start": 440702,
    "end": 441810,
    "text": "それがフォワードだ。"
  },
  {
    "start": 442390,
    "end": 445118,
    "text": "次に、すべてのレイヤーに対して後戻りをする。"
  },
  {
    "start": 445294,
    "end": 452770,
    "text": "すべてのレイヤーでこの作業を行い、すべてをcに変換して、リファレンスの実装と一致していることを確認したら、それをひも付けしていく。"
  },
  {
    "start": 453470,
    "end": 461262,
    "text": "LLMで使用するすべてのメモリを確保しなければならない。"
  },
  {
    "start": 461366,
    "end": 464238,
    "text": "すべての割り当ては最初に一度だけ行われる。"
  },
  {
    "start": 464334,
    "end": 467142,
    "text": "私たちは、使用するすべてのメモリを事前に計画している。"
  },
  {
    "start": 467286,
    "end": 472622,
    "text": "そうすれば固定され、それ以降はただデータを送り込んでモデルをトレーニングするだけのダイナミクスになる。"
  },
  {
    "start": 472726,
    "end": 477414,
    "text": "すべてのテンソル、そのサイズ、そしてパラメータを事前に計画しなければならない。"
  },
  {
    "start": 477502,
    "end": 483302,
    "text": "atomwのバッファーのデータグラッドとMNV、そしてアクティベーションのデータグラッドとMNVがある。"
  },
  {
    "start": 483326,
    "end": 485230,
    "text": "データもグラッドもスペースが必要だ。"
  },
  {
    "start": 485390,
    "end": 490366,
    "text": "だから、すべてのメモリを事前に計画し、それをすべて割り当てて、それをつなぎ合わせる必要がある。"
  },
  {
    "start": 490478,
    "end": 505806,
    "text": "バックプロパゲーションにはフォワードパスとバックワードパスがあり、フォワードパスでは、これらのテンソルをすべて割り当てて、慎重にインデックスを作成し、すべてが正しく流れるようにします。"
  },
  {
    "start": 505878,
    "end": 509262,
    "text": "そうすれば、グラデーションが残り、アップデートができる。"
  },
  {
    "start": 509366,
    "end": 512264,
    "text": "それをつなぎ合わせるのが2つ目の仕事だ。"
  },
  {
    "start": 512422,
    "end": 516468,
    "text": "そして、それをつなぎ合わせれば、コンパイルして実行できるものができる。"
  },
  {
    "start": 516564,
    "end": 519980,
    "text": "左上にあるのが必要なものすべてだ。"
  },
  {
    "start": 520100,
    "end": 525220,
    "text": "私たちはスターターパックをダウンロードします。これはGPT-2のウェイトを1つのバイナリファイルにしただけのもので、とてもシンプルです。"
  },
  {
    "start": 525380,
    "end": 530172,
    "text": "また、データセット（この場合は小さなシェイクスピアとトークナイザーなど）も必要だ。"
  },
  {
    "start": 530276,
    "end": 533484,
    "text": "そして、この小さなCコード・ファイルをコンパイルして実行するだけだ。"
  },
  {
    "start": 533532,
    "end": 539708,
    "text": "この時点ではCの単一ファイルで、記憶が正しければ2000行とかそんな感じだと思う。"
  },
  {
    "start": 539844,
    "end": 549404,
    "text": "このプログラムを実行すると、ちょっとしたトレーニングが行われ、最後にシェークスピアが出力される。"
  },
  {
    "start": 549452,
    "end": 550692,
    "text": "私たちはC言語で動いているだけだ。"
  },
  {
    "start": 550836,
    "end": 555548,
    "text": "この時点で、私はとても素晴らしい気分になっている。"
  },
  {
    "start": 555724,
    "end": 559164,
    "text": "Cファイルは1つだけで、依存関係はまったくない。"
  },
  {
    "start": 559332,
    "end": 561564,
    "text": "即座にコンパイルし、即座に実行する。"
  },
  {
    "start": 561652,
    "end": 564892,
    "text": "すべてのメモリは単一のブロブに割り当てられる。"
  },
  {
    "start": 564996,
    "end": 567620,
    "text": "ステップを踏み始めたら、後でウームなんてことはありえない。"
  },
  {
    "start": 567740,
    "end": 570292,
    "text": "すべて事前に計画されており、完全に決定論的だ。"
  },
  {
    "start": 570436,
    "end": 575476,
    "text": "原理的にはGPT-2をトレーニングすることができる。"
  },
  {
    "start": 575668,
    "end": 578132,
    "text": "ジャガイモの上でも、どんなものの上でも動く。"
  },
  {
    "start": 578156,
    "end": 580276,
    "text": "これは、依存関係のない単一のCファイルだ。"
  },
  {
    "start": 580388,
    "end": 594120,
    "text": "原理的には、これはフォン・ノイマン探査機で動作させることができます。宇宙では、もう少し固めれば、フォン・ノイマン探査機にピトルチのコードを搭載することはないでしょうが、LMCはそのための素晴らしい候補になると思います。"
  },
  {
    "start": 595940,
    "end": 597748,
    "text": "この時点では最高の気分だった。"
  },
  {
    "start": 597924,
    "end": 604988,
    "text": "余談だが、モルディブで時差ぼけになっていたとき、ここまでの仕事はすべて休暇中に行われた。"
  },
  {
    "start": 605164,
    "end": 608812,
    "text": "基本的に午前1時に目覚めるので完璧だ。"
  },
  {
    "start": 608916,
    "end": 610200,
    "text": "何もすることがない。"
  },
  {
    "start": 610500,
    "end": 614852,
    "text": "LLMのCのようなものを書き、日の出にはすべての気象活動を行う。"
  },
  {
    "start": 614956,
    "end": 618400,
    "text": "この別荘は、LLM Cの大半を訓練した場所である。"
  },
  {
    "start": 618700,
    "end": 619700,
    "text": "完璧だった。"
  },
  {
    "start": 619780,
    "end": 626164,
    "text": "これはその写真で、月が沈んで朝日が昇ろうとしているところだと思う。"
  },
  {
    "start": 626252,
    "end": 628840,
    "text": "これは、ソフトウェア開発を行う上で推奨される方法である。"
  },
  {
    "start": 631820,
    "end": 635140,
    "text": "さて、これでCのコードができたが、効率が悪いのでもっと速く実行したい。"
  },
  {
    "start": 635220,
    "end": 636708,
    "text": "そのためにGPUを使う。"
  },
  {
    "start": 636764,
    "end": 638812,
    "text": "すべてのCコードをGPUに変換する必要がある。"
  },
  {
    "start": 638956,
    "end": 643372,
    "text": "ここでレポのdev Cudaパートに移動し、すべてのカーネルを開発し始める。"
  },
  {
    "start": 643476,
    "end": 645580,
    "text": "これが、前述したフォワードパスだ。"
  },
  {
    "start": 645660,
    "end": 651132,
    "text": "今、私たちは、同じ機能を持ちながらGPU上で動作し、より高速なカーネルをいくつか開発しようとしている。"
  },
  {
    "start": 651276,
    "end": 654680,
    "text": "そのため、通常は123456などのバージョンがある。"
  },
  {
    "start": 654760,
    "end": 656144,
    "text": "これらはすべて異なるカーネル実装である。"
  },
  {
    "start": 656192,
    "end": 662024,
    "text": "通常、時間が経つにつれて少し速くなるが、仕様にぴったり合っており、まったく同じ数値が出る。"
  },
  {
    "start": 662192,
    "end": 664780,
    "text": "私たちはそれらのレイヤーをすべて開発し、CuDAに移植する。"
  },
  {
    "start": 665240,
    "end": 667360,
    "text": "これが何なのか、私にはわからない。"
  },
  {
    "start": 667400,
    "end": 668504,
    "text": "それは省略する。"
  },
  {
    "start": 668672,
    "end": 670776,
    "text": "基本的にはカーネルの1つのようなものだ。"
  },
  {
    "start": 670808,
    "end": 686460,
    "text": "ここで重要なのは、最初のカーネルは、バッチと時間を麻痺させるので、通常は些細なことであり、その後、基本的にCコードをcudaカーネルにコピーペーストする。"
  },
  {
    "start": 686500,
    "end": 691372,
    "text": "最初のカーネルは通常些細なことだが、その後、最適化はかなり精巧になる。"
  },
  {
    "start": 691476,
    "end": 695940,
    "text": "最終的には、例えばレイヤー・ノームではカーネル6まで到達する。"
  },
  {
    "start": 695980,
    "end": 700120,
    "text": "私たちはいくつかの仕事をプロデュースしている。"
  },
  {
    "start": 700860,
    "end": 703196,
    "text": "また、共有メモリーやグローバルメモリーを介してコミュニケーションをとる。"
  },
  {
    "start": 703228,
    "end": 710880,
    "text": "我々はそれを正しくオーケストレーションし、キャッシュストリーミングのヒントや、すべてに対処するための小さなヒントやトリックをたくさん用意している。"
  },
  {
    "start": 711600,
    "end": 715600,
    "text": "後でもう少し詳しく説明するつもりだが、ここでは任意に複雑にすることができる。"
  },
  {
    "start": 715640,
    "end": 717180,
    "text": "Cudaのコードを書く。"
  },
  {
    "start": 717560,
    "end": 725100,
    "text": "このプロジェクトでわかったことのひとつは、残念ながらCuDAを学ぶのは簡単ではないということだ。"
  },
  {
    "start": 725760,
    "end": 729224,
    "text": "クーダについてはある程度知っていたが、もっとうまくなるのは簡単なことではないと思う。"
  },
  {
    "start": 729312,
    "end": 732696,
    "text": "これらの本の中には、残念ながら少し古いものもあると思う。"
  },
  {
    "start": 732808,
    "end": 745396,
    "text": "PMPはとても良い本ですが、LMCプロジェクトで開発したCUDAコードの多くは、この本には載っていません。"
  },
  {
    "start": 745508,
    "end": 750452,
    "text": "結局、追加したカーネルの多くはカバーしきれなかった。"
  },
  {
    "start": 750556,
    "end": 758668,
    "text": "その上、このCUDA Cプログラミング・ガイドがあるのだが、正直なところ、CUDAの初心者には読みにくい。"
  },
  {
    "start": 758844,
    "end": 765708,
    "text": "このブログは、インターネット上で私たちが適当に書いたものよりもずっと素晴らしい。"
  },
  {
    "start": 765804,
    "end": 766788,
    "text": "信じられないよ。"
  },
  {
    "start": 766844,
    "end": 768840,
    "text": "それがもっとあれば、とても素晴らしいことだ。"
  },
  {
    "start": 768900,
    "end": 772300,
    "text": "でも、そうだね、だからちょっと難しいと思ったんだ。"
  },
  {
    "start": 773000,
    "end": 781360,
    "text": "でも、Cudaモードのようなものが、cudaの書き込みをスピードアップしてくれることを期待しているんだ。"
  },
  {
    "start": 781520,
    "end": 787688,
    "text": "さて、次に何が起こったかというと、僕は基本的にCudaのコードと少し格闘していた。"
  },
  {
    "start": 787744,
    "end": 794144,
    "text": "この本を読みながらCudaカーネルを実装していたんだけど、Cudaカーネルはいいんだけど、あまり良くないんだ。"
  },
  {
    "start": 794272,
    "end": 799490,
    "text": "というわけで、そのシーンを見たインターネットから集まったアベンジャーズのチームが投稿を始めた。"
  },
  {
    "start": 799530,
    "end": 806690,
    "text": "特に、エリック、アルン、アレクサは、LLM Cの中心的な開発者のようなもので、LLM Cに多大な貢献をしてきた。"
  },
  {
    "start": 806810,
    "end": 810122,
    "text": "彼らは、本当に最適化してカーネルを書き始めたんだ。"
  },
  {
    "start": 810146,
    "end": 812610,
    "text": "見ていて、多くを学ぶことができた。"
  },
  {
    "start": 812730,
    "end": 813738,
    "text": "他にもたくさんある。"
  },
  {
    "start": 813834,
    "end": 816618,
    "text": "ロス、ウィーラー、チンティスル、その他数名。"
  },
  {
    "start": 816754,
    "end": 817330,
    "text": "あるんだ。"
  },
  {
    "start": 817450,
    "end": 820234,
    "text": "その結果、LM Cプロジェクトには60人の協力者が集まった。"
  },
  {
    "start": 820362,
    "end": 822794,
    "text": "ラムダがLM Cのスポンサーであることに敬意を表したい。"
  },
  {
    "start": 822922,
    "end": 826506,
    "text": "これらのカーネルをすべて走らせ、最適化するために、彼らはコンピュート（計算能力）に貢献してくれている。"
  },
  {
    "start": 826618,
    "end": 829878,
    "text": "インターネットから人々が集まってきて、プロジェクトに協力してくれたことは、私にとって驚きだった。"
  },
  {
    "start": 829934,
    "end": 832462,
    "text": "これは、起こりうることの中で最も好きなことのひとつだ。"
  },
  {
    "start": 832646,
    "end": 838686,
    "text": "オープンソースのMITライセンス・レポで起こることで、私が一番好きなことは、インターネットから人々がやってきて、貢献するのを手伝ってくれることだ。"
  },
  {
    "start": 838718,
    "end": 839730,
    "text": "素晴らしいよ。"
  },
  {
    "start": 840310,
    "end": 843182,
    "text": "さて、すべてのレイヤーをCuDAに変換した。"
  },
  {
    "start": 843246,
    "end": 847982,
    "text": "これですべてのカーネルが揃い、これまでのところFP32のシングルGPUでトレーニングができるようになった。"
  },
  {
    "start": 848086,
    "end": 849050,
    "text": "それは素晴らしいことだ。"
  },
  {
    "start": 849470,
    "end": 852110,
    "text": "それ以降、私たちはどんどん最適化を進めていく。"
  },
  {
    "start": 852150,
    "end": 856680,
    "text": "つまり、第一に、自分でコードをロールするときにFP 32にマトマルを入れたくないということだ。"
  },
  {
    "start": 856980,
    "end": 862444,
    "text": "私たちは実際にクブラのステップ2に切り替えた。"
  },
  {
    "start": 862532,
    "end": 863804,
    "text": "それはかなり複雑だと思う。"
  },
  {
    "start": 863892,
    "end": 868400,
    "text": "Cudnnが非常に優れたフラッシュ・アテンションを実装していることがわかったので、それに切り替えた。"
  },
  {
    "start": 870300,
    "end": 875780,
    "text": "次に、コードを高速化するために、間違いなく混合精度に手を伸ばしたい。"
  },
  {
    "start": 875860,
    "end": 880564,
    "text": "パラメータやアクティベーションなど、すべてのテンソルを調べたい。"
  },
  {
    "start": 880612,
    "end": 888316,
    "text": "どれがfloat32で、どれがbfloat16で、どれがどのような精度なのかを考え始めなければならない。"
  },
  {
    "start": 888428,
    "end": 890932,
    "text": "私たちはそれに手を伸ばし、実行に移した。"
  },
  {
    "start": 891076,
    "end": 894044,
    "text": "他にも多くの最適化があり、時間をかけて実装していった。"
  },
  {
    "start": 894132,
    "end": 900800,
    "text": "例として、すべてのカーネル・フュージョンを行ったが、異なる再計算設定で、バックワード中にフォワード・パスの一部を再計算した。"
  },
  {
    "start": 902100,
    "end": 907600,
    "text": "エリックからは、特に後方パス時に必要なメモリ量の最小化について、多くの最適化がなされている。"
  },
  {
    "start": 908420,
    "end": 920296,
    "text": "これは基本的に、コンパイラに128ビットのロード命令とストア命令を使わせるものだが、どういうわけか多くの場合、コンパイラは使いたがらない。"
  },
  {
    "start": 920488,
    "end": 938896,
    "text": "アルンは、SASを見て、SASSをアセンブルして、ループに使われている命令を見て、これは128ビットのロード＆ストアのはずだが、MVCCコンパイラの何かがうまくいっていないために、32ビットや他の命令になっていることを突き止めたんだ。"
  },
  {
    "start": 938928,
    "end": 942940,
    "text": "このデータ構造は、コンパイラの手を少し強引に動かすようなものだ。"
  },
  {
    "start": 943440,
    "end": 949900,
    "text": "私たちは、計算の一部をオーバーラップさせるために、あらゆる種類のCUDAストリームを実装しましたが、これは大失敗に終わりました。"
  },
  {
    "start": 950560,
    "end": 957480,
    "text": "というのも、LLM Cのある時点で、アルンが言うように、私は基本的に軌道から入って核攻撃したんだ。"
  },
  {
    "start": 957600,
    "end": 962600,
    "text": "私はただ中に入って、ストリームのすべての言及をfコントロールし、私はただ、削除、削除、削除した。"
  },
  {
    "start": 962720,
    "end": 968704,
    "text": "基本的には、すべてのストリームを削除し、すべてをシングルスレッドにした。"
  },
  {
    "start": 968712,
    "end": 969796,
    "text": "ただ、それに関わりたくなかったんだ。"
  },
  {
    "start": 969848,
    "end": 977116,
    "text": "LMCは、実際にはそれほど重なってはいないが、現時点では十分な利得がない割に複雑すぎるという感じだ。"
  },
  {
    "start": 977148,
    "end": 981156,
    "text": "だから、でも、もしかしたら、その一部をゆっくりと再導入できるかもしれない。"
  },
  {
    "start": 981268,
    "end": 983364,
    "text": "確率的丸め込みもあれば、完全な決定論もある。"
  },
  {
    "start": 983452,
    "end": 988588,
    "text": "完全な決定論はかなり難しいことがわかった。アトミックが使えないため、カーネルのいくつかはかなり複雑化するからだ。"
  },
  {
    "start": 988684,
    "end": 995812,
    "text": "エンコーダーバックワードは特にクレイジーだった。エンコーダーバックワードはアトミックがあれば些細なことだが、アトミックがなければ些細なことではない。"
  },
  {
    "start": 995956,
    "end": 1005320,
    "text": "とにかく、多くの最適化は、効率性と決定性、そして確率的丸めなどの精度を念頭に置いて行われた。"
  },
  {
    "start": 1005700,
    "end": 1008276,
    "text": "次に、単一のGPUだけでなく、複数のGPUを使いたい。"
  },
  {
    "start": 1008348,
    "end": 1014532,
    "text": "ここでニッケルを持ち込むと、さまざまな労働者の間で過剰投与が始まる。"
  },
  {
    "start": 1014716,
    "end": 1024664,
    "text": "基本的にオプティマイザーの状態はfloatで、アトムwのための非常に大きなバッファとなる。"
  },
  {
    "start": 1024752,
    "end": 1027352,
    "text": "このような多くのことを、すべてのGPUに分散させることができる。"
  },
  {
    "start": 1027376,
    "end": 1031120,
    "text": "メモリの面でGPUあたりの要件を抑えるのにとても役立ちます。"
  },
  {
    "start": 1031200,
    "end": 1033432,
    "text": "そのために手を差し伸べるのはとても役に立つ。"
  },
  {
    "start": 1033536,
    "end": 1037240,
    "text": "現在、LMCはゼロ・ワンを使用しており、これはシャードされたオプティマイザーの状態である。"
  },
  {
    "start": 1037320,
    "end": 1044408,
    "text": "pr40が2つあるが、少しごちゃごちゃするのでまだマージしていないと思うが、いずれマージするかもしれない。"
  },
  {
    "start": 1044544,
    "end": 1052234,
    "text": "LMCの多くは、スピードの向上と実際に導入するものの複雑さとのバランスを取ることだ。"
  },
  {
    "start": 1052282,
    "end": 1059830,
    "text": "コードがクレイジーになり始め、プロジェクトに参加できる人数が減ってしまうからだ。"
  },
  {
    "start": 1061090,
    "end": 1063514,
    "text": "マルチGPの次はマルチノードだ。"
  },
  {
    "start": 1063562,
    "end": 1069186,
    "text": "複数のマシンにまたがって実行する場合、すべてのマシンを同期させ、互いを見つけられるようにしなければならない。"
  },
  {
    "start": 1069218,
    "end": 1076764,
    "text": "その結果、GPT-2を実際に変更することができるようになり、すべての作業の後にそれを再現することができるようになった。"
  },
  {
    "start": 1076882,
    "end": 1084768,
    "text": "LLM Cの議論に投稿がありますが、2019年くらいの時点で最新のLLMであった16億GPT-2をトレーニングすることができます。"
  },
  {
    "start": 1084944,
    "end": 1088640,
    "text": "h100台のノードを約24時間でトレーニングできる。"
  },
  {
    "start": 1088760,
    "end": 1091288,
    "text": "およそ600ドルである。"
  },
  {
    "start": 1091464,
    "end": 1093800,
    "text": "そうすることで、依存性が非常になくなる。"
  },
  {
    "start": 1093840,
    "end": 1099904,
    "text": "pythonもPytorchも必要ないので、最も重い依存関係であるCDNNが必要になる。"
  },
  {
    "start": 1100032,
    "end": 1101336,
    "text": "CudNnはオプション。"
  },
  {
    "start": 1101408,
    "end": 1104968,
    "text": "もし、自分でマニュアルを巻きたいのであれば、それはLMCで可能だ。"
  },
  {
    "start": 1105064,
    "end": 1106962,
    "text": "クドンは最も毛深い依存性のようなものだ。"
  },
  {
    "start": 1107056,
    "end": 1108822,
    "text": "その後はただのCコードの束だ。"
  },
  {
    "start": 1108846,
    "end": 1109854,
    "text": "それをコンパイルして実行する。"
  },
  {
    "start": 1109902,
    "end": 1111766,
    "text": "本当に何も必要ない。"
  },
  {
    "start": 1111918,
    "end": 1116222,
    "text": "condaの環境とpipのインストールは必要ない。"
  },
  {
    "start": 1116406,
    "end": 1119366,
    "text": "そしてコードをコンパイルして実行すると、ステップを踏み始める。"
  },
  {
    "start": 1119398,
    "end": 1124374,
    "text": "24時間待って、診断結果を印刷する。"
  },
  {
    "start": 1124462,
    "end": 1129570,
    "text": "あるノードでは、ほぼ50％のmfuがある。"
  },
  {
    "start": 1130590,
    "end": 1133898,
    "text": "本当にいいプロットが手に入るし、ヘラ・スワガーでGPT-2に勝てる。"
  },
  {
    "start": 1133984,
    "end": 1136846,
    "text": "基本的に、これは最適化がうまくいったことを示している。"
  },
  {
    "start": 1136958,
    "end": 1140686,
    "text": "このサイズであれば、数値的な問題やスパイクのロストなどはない。"
  },
  {
    "start": 1140838,
    "end": 1158390,
    "text": "そう、LMCで本当に良いモデルを達成しても、PyTorchと比較することができるんだ。PyTorchには、このようなことをすべて並列で行う実装があることを覚えておいてほしい。"
  },
  {
    "start": 1158550,
    "end": 1173062,
    "text": "特にその投稿を書いた時点では、PyTorchチームは時間の経過とともに最適化を続けているので、これが変わったかどうかはわかりませんが、その投稿の時点では、Elon30%少ないメモリを使っていて、スループットだけでトレーニングが20%速くなっていました。"
  },
  {
    "start": 1173206,
    "end": 1176334,
    "text": "PyTorchの実装を完全に超最適化したかどうかはわからない。"
  },
  {
    "start": 1176382,
    "end": 1184022,
    "text": "自己ベストは更新できたが、LNCのGPT-2のトレーニングではPyTorchに勝てたと思う。"
  },
  {
    "start": 1184166,
    "end": 1189374,
    "text": "それ以外のトレーニングをしようと思ったら、大変なことになるが、コードをたくさん変えなければならない。"
  },
  {
    "start": 1189422,
    "end": 1191060,
    "text": "そうしているところだ。"
  },
  {
    "start": 1191150,
    "end": 1194540,
    "text": "GPTのトレーニングのために、あれだけの仕事をしたんだ。"
  },
  {
    "start": 1195160,
    "end": 1197656,
    "text": "また、コンパイルや動作も格段に速くなった。"
  },
  {
    "start": 1197728,
    "end": 1200320,
    "text": "トーチのコンパイルには1分とかかなり時間がかかる。"
  },
  {
    "start": 1200360,
    "end": 1201192,
    "text": "ただ待っているだけだ。"
  },
  {
    "start": 1201336,
    "end": 1204728,
    "text": "というのも、個人的にはあまりやりたくないことなんだ。"
  },
  {
    "start": 1204904,
    "end": 1209152,
    "text": "さて、ループして戻ってみると、それほど単純なことではなかった。"
  },
  {
    "start": 1209336,
    "end": 1215832,
    "text": "いろいろなことがあり、何人かで数ヶ月かかったが、楽しかった。"
  },
  {
    "start": 1215976,
    "end": 1218370,
    "text": "多くのことを学んだし、その過程で友人もできた。"
  },
  {
    "start": 1218490,
    "end": 1225402,
    "text": "これはLLMCのコア開発者たちによるもので、現在進行形の素晴らしい仕事だった。"
  },
  {
    "start": 1225546,
    "end": 1227018,
    "text": "私たちはラマ3のサポートを追加します。"
  },
  {
    "start": 1227114,
    "end": 1233282,
    "text": "本当は今日までに完成させるつもりだったんだけど、もう少し作業が残っているんだ。"
  },
  {
    "start": 1233386,
    "end": 1237270,
    "text": "もうすぐLLM Cでラマ3.1のトレーニングがあります。"
  },
  {
    "start": 1237770,
    "end": 1239754,
    "text": "FP8人のサポートがある。"
  },
  {
    "start": 1239842,
    "end": 1246600,
    "text": "アルンはこの件に取り組んでおり、FP 8のサポートについて大きなPRがある。"
  },
  {
    "start": 1247380,
    "end": 1249668,
    "text": "c.には注目すべきフォークがたくさんある。"
  },
  {
    "start": 1249724,
    "end": 1251360,
    "text": "これらはすべてGitHubのレポに掲載されている。"
  },
  {
    "start": 1251700,
    "end": 1264260,
    "text": "私が知る限り、AMDのフォークは非常に活発で、とてもいい。"
  },
  {
    "start": 1264300,
    "end": 1266052,
    "text": "LLM Cはかなり読みやすいと思う。"
  },
  {
    "start": 1266076,
    "end": 1267940,
    "text": "私はそれを清潔に保ち、十分に文書化するよう努めた。"
  },
  {
    "start": 1267980,
    "end": 1269972,
    "text": "中身はよく理解されていると思う。"
  },
  {
    "start": 1270076,
    "end": 1274230,
    "text": "たぶん、3000行くらいのコードで、基本的にはほとんどがC言語だ。"
  },
  {
    "start": 1275410,
    "end": 1281626,
    "text": "もうひとつ、私が伝えたかったことは、このプロジェクトを始めるにあたって、すべてが行き当たりばったりだったわけではないということだ。"
  },
  {
    "start": 1281738,
    "end": 1286790,
    "text": "このプロジェクトを始めたもうひとつの動機があった。"
  },
  {
    "start": 1287210,
    "end": 1288522,
    "text": "つまり、LM Cとはどんなものなのか？"
  },
  {
    "start": 1288546,
    "end": 1292642,
    "text": "Pytorchが特にそうだとすれば、torchはソフトウェア2.0用のGCCのように少しコンパイルする。"
  },
  {
    "start": 1292706,
    "end": 1295802,
    "text": "LMCはコンパイラであり、アセンブラを書くようなものだ。"
  },
  {
    "start": 1295866,
    "end": 1297830,
    "text": "すべて手作業でやっているよね？"
  },
  {
    "start": 1298300,
    "end": 1309640,
    "text": "GPT-2のトレーニングという特殊な環境において、LLMCを3カ月かけて複数人で書き、Pytorchよりも速いものを得たのだと思う。"
  },
  {
    "start": 1309980,
    "end": 1313196,
    "text": "だから、この練習は基本的にそれが可能であることを証明している。"
  },
  {
    "start": 1313348,
    "end": 1324934,
    "text": "しかし、もしLLMが時間の経過とともにコーディングがもっと上手になるのであれば、LLMは時間の経過とともに、どんなカスタム・アプリケーションにも対応できるようになるだろう。"
  },
  {
    "start": 1325092,
    "end": 1329946,
    "text": "だからLLMは、あなたが興味を持つカスタム・アプリケーションのコンパイラのような役割を果たすことができる。"
  },
  {
    "start": 1329978,
    "end": 1335842,
    "text": "彼らはすべてのLLMC作業を行い、特定のアプリケーション用にコンパイルして実行できるバイナリを出力してくれる。"
  },
  {
    "start": 1335986,
    "end": 1342346,
    "text": "パイソンやパイトーチを使うのが好きなのかどうかはわからないし、人間は有限だから、他のものはすべて松葉杖に過ぎない。"
  },
  {
    "start": 1342418,
    "end": 1344586,
    "text": "私たちの知識、知性、注意力には限りがある。"
  },
  {
    "start": 1344778,
    "end": 1349066,
    "text": "実際、カスタムCuDAカーネルなどですべてのコードを書きたいのでは？"
  },
  {
    "start": 1349098,
    "end": 1349994,
    "text": "たぶんね。"
  },
  {
    "start": 1350162,
    "end": 1361324,
    "text": "というのも、LLMの初期段階や彼らの知能では、ただ促しただけではゼロからこのコードを書くことができないかもしれないからだ。"
  },
  {
    "start": 1361372,
    "end": 1369108,
    "text": "GPT-2とcを書けば、おそらくLM Cは取れないだろうが、LM CをそのようなLLMの文脈に置けば、取れる可能性はかなり高くなる。"
  },
  {
    "start": 1369204,
    "end": 1373628,
    "text": "LLMにとって、基本的にサンプルコードを与えるための数ショット学習は非常に役立つと期待できる。"
  },
  {
    "start": 1373724,
    "end": 1379570,
    "text": "だからLMCは、これからカスタム・アプリケーションを書こうとしているlmsにこのサンプルコードを渡すのにとても役に立つと思う。"
  },
  {
    "start": 1379740,
    "end": 1382170,
    "text": "だから、この可能性は決して低くないと思う。"
  },
  {
    "start": 1382950,
    "end": 1384406,
    "text": "ああ、これは起こりそうなことだ。"
  },
  {
    "start": 1384438,
    "end": 1386982,
    "text": "おそらく、ソフトウェア開発全般が大きく変わっていくと思う。"
  },
  {
    "start": 1387006,
    "end": 1392950,
    "text": "エレン、私には、これが可能かどうかの探求が見える。"
  },
  {
    "start": 1392990,
    "end": 1394854,
    "text": "そう、それだけだ。"
  },
  {
    "start": 1394862,
    "end": 1395070,
    "text": "ありがとう。"
  }
]