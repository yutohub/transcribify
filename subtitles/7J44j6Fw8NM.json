[
  {
    "start": 120,
    "end": 288,
    "text": "チャットだ。"
  },
  {
    "start": 288,
    "end": 19406,
    "text": "GPTは現在、並外れた能力を持つ宇宙人を自称しているが、私は昨日よりも今日の方が、それに反対するのが少し難しくなっている。"
  },
  {
    "start": 19478,
    "end": 26582,
    "text": "ストロベリーやQスターという以前の名前でゼロワンを知っている人もいるかもしれないが、命名規則を忘れよう。"
  },
  {
    "start": 26686,
    "end": 28510,
    "text": "実際のシステムはどうなのか？"
  },
  {
    "start": 28590,
    "end": 35938,
    "text": "この24時間で、43ページのシステムカード、すべてのOpenAIの記事とプレスリリースを読んだ。"
  },
  {
    "start": 36074,
    "end": 42786,
    "text": "Simplebenchを含めてゼロ回テストし、すべての答えを分析した。"
  },
  {
    "start": 42858,
    "end": 46986,
    "text": "正直に言うと、このリリースを完全に消化するには数週間かかるだろう。"
  },
  {
    "start": 47098,
    "end": 53882,
    "text": "このビデオでは、私のファーストインプレッションをお伝えします。"
  },
  {
    "start": 53986,
    "end": 56458,
    "text": "要するに、ゼロ1では寝てはいけないということだ。"
  },
  {
    "start": 56514,
    "end": 61522,
    "text": "これは単にトレーニングデータを少し増やすということではなく、根本的に新しいパラダイムなのだ。"
  },
  {
    "start": 61586,
    "end": 72710,
    "text": "実際、以前のバージョンのchatgptをテストし、LLMや引用AIに物足りなさを感じていた何億もの人々が、興奮とともに戻ってくるかもしれない。"
  },
  {
    "start": 72790,
    "end": 100970,
    "text": "タイトルが意味するように、私の第一印象を述べると、このシステムがこれほどうまくいくとは思っていなかったということです。それは、Q starの背後にある重要なメカニズムの多くを予測した人物からの意見であり、このシステムで使われているようです。"
  },
  {
    "start": 101050,
    "end": 110282,
    "text": "もちろん、OpenAIはゼロ・ワンをどのようにトレーニングしたのか、その全容を明かしてはいないが、いくつかの興味深いヒントを残してくれた。"
  },
  {
    "start": 110346,
    "end": 121402,
    "text": "シンプルベンチは、空間的なものから時間的なもの、社会的な知能を問うものまで、人間が平均的につぶすような何百もの基本的な推論問題をテストするものだ。"
  },
  {
    "start": 121506,
    "end": 127606,
    "text": "多くの人が教えてくれたように、オー・ワン・システムはこの2つのサンプル問題を両方ともsimplebenchから得ているんだよね？"
  },
  {
    "start": 127698,
    "end": 129134,
    "text": "常にというわけではないが。"
  },
  {
    "start": 129262,
    "end": 135558,
    "text": "この例を見てみよう。17秒間考えたにもかかわらず、モデルはまだ間違っている。"
  },
  {
    "start": 135654,
    "end": 143022,
    "text": "基本的に、ゼロワンは言語モデルベースのシステムであり、言語モデルベースのミスを犯す。"
  },
  {
    "start": 143126,
    "end": 150334,
    "text": "優れた推論には何度でも報酬を与えることができるが、それでも訓練データには限界がある。"
  },
  {
    "start": 150422,
    "end": 160818,
    "text": "とはいえ、正しい推論に基づくステップを踏むことで改善されることの大きさを私は予見していなかった。"
  },
  {
    "start": 160874,
    "end": 162522,
    "text": "なぜ具体的な数字がないのか？"
  },
  {
    "start": 162586,
    "end": 168690,
    "text": "さて、昨晩の時点で、OpenAIはゼロワン・システムに1の温度を課した。"
  },
  {
    "start": 168770,
    "end": 173794,
    "text": "この温度は、他のモデルがsimplebenchでベンチマークされたときに使われた温度ではない。"
  },
  {
    "start": 173842,
    "end": 179762,
    "text": "これは、シンプルベンチでテストされた他のモデルよりもはるかにクリエイティブな温度だ。"
  },
  {
    "start": 179826,
    "end": 183602,
    "text": "そのため、パフォーマンスのばらつきが通常より少し大きいということだった。"
  },
  {
    "start": 183666,
    "end": 190746,
    "text": "天才的な推理で問題を正解しても、次に同じ問題を間違えることもあった。"
  },
  {
    "start": 190818,
    "end": 197506,
    "text": "実際、先ほどアイスキューブの例で見たように、ベンチマークを複数回実行し、多数決を取ることが明白な解決策である。"
  },
  {
    "start": 197538,
    "end": 203474,
    "text": "これは自己整合性と呼ばれるものだが、本当の意味でリンゴとリンゴを比較するためには、他のすべてのモデルについてもそうする必要がある。"
  },
  {
    "start": 203562,
    "end": 208298,
    "text": "私の野望は、あなたがあまり興味を持っていないかもしれないが、今月末までにそれを成し遂げることだ。"
  },
  {
    "start": 208354,
    "end": 210914,
    "text": "ひとつだけはっきりさせておきたいことがある。"
  },
  {
    "start": 211002,
    "end": 222264,
    "text": "このチャンネルを見ている人ならわかると思うが、私はOpenAIのファンボーイではない。"
  },
  {
    "start": 222352,
    "end": 226328,
    "text": "クロード3.5ソネットはしばらくの間、トップに君臨してきた。"
  },
  {
    "start": 226424,
    "end": 233208,
    "text": "他のベンチマークや論文全文はどうでもいいという人のために、私の第一印象をまとめておきたい。"
  },
  {
    "start": 233264,
    "end": 236792,
    "text": "一言で言えば、この説明は実によく当てはまる。"
  },
  {
    "start": 236896,
    "end": 244264,
    "text": "フルオーワンシステムはともかく、ゼロワンシステムの性能の上限は、プレビューだけでも信じられないほど高い。"
  },
  {
    "start": 244352,
    "end": 250580,
    "text": "物理や数学、コーディングの競技などでは、明らかに一般人の成績を圧倒する。"
  },
  {
    "start": 250700,
    "end": 252140,
    "text": "惑わされるな。"
  },
  {
    "start": 252260,
    "end": 257108,
    "text": "その欠点も実に低く、平均的な人間のそれ以下である。"
  },
  {
    "start": 257204,
    "end": 265188,
    "text": "昨夜YouTubeに書いたように、人間なら犯さないような明らかなミスを頻繁に、そして時には予測通りに犯す。"
  },
  {
    "start": 265244,
    "end": 269772,
    "text": "覚えておいてほしいのは、シンプルベンチが出した何百もの答えを分析したことだ。"
  },
  {
    "start": 269836,
    "end": 273108,
    "text": "ゼロワンの口から直接、いくつかの例を挙げよう。"
  },
  {
    "start": 273164,
    "end": 281454,
    "text": "カップを逆さまにすると、サイコロは落下してカップの開いている端に着地する。"
  },
  {
    "start": 281582,
    "end": 285654,
    "text": "もしそれをうまくイメージできたなら、あなたは私よりうまくやっていることになる。"
  },
  {
    "start": 285742,
    "end": 287846,
    "text": "言うまでもないが、この質問は間違っていた。"
  },
  {
    "start": 287958,
    "end": 288862,
    "text": "これはどうだ？"
  },
  {
    "start": 288926,
    "end": 290142,
    "text": "社会的知性の向上？"
  },
  {
    "start": 290246,
    "end": 291686,
    "text": "彼は反論するだろう。"
  },
  {
    "start": 291758,
    "end": 294518,
    "text": "もちろん、これは非公開のデータセットであるため、全コンテクストをお見せすることはできない。"
  },
  {
    "start": 294534,
    "end": 301114,
    "text": "いずれにせよ、彼は部隊パレードで軍の最高階級のひとつである准将に反論するだろう。"
  },
  {
    "start": 301222,
    "end": 311514,
    "text": "小学1年生、つまり6歳か7歳のときの兵士の愚かな行動は、権威ある人物に歯向かった過去があることを示している。"
  },
  {
    "start": 311602,
    "end": 316970,
    "text": "さて、大多数の人間はこう言うだろう。"
  },
  {
    "start": 317090,
    "end": 324234,
    "text": "アメリカの小学校は知らないが、彼が幼い小学生のときにやったことは、部隊パレードで将軍の前でやるようなことを反映していない。"
  },
  {
    "start": 324322,
    "end": 328482,
    "text": "これまで書いてきたように、ある領域では、こうしたミスは日常的で面白い。"
  },
  {
    "start": 328586,
    "end": 337698,
    "text": "グーグルの証明問題でゼロワンの成績を見るのは非常に簡単で、その成績は約80％である。"
  },
  {
    "start": 337794,
    "end": 345770,
    "text": "これはダイヤモンドのサブセットで、正直に言おう、平均的な人間はこれらの質問の1つも正解できない。"
  },
  {
    "start": 345890,
    "end": 348546,
    "text": "サム・アルトマンでさえ、それは違うと言っている。"
  },
  {
    "start": 348618,
    "end": 355866,
    "text": "モデルが特定の推論タスクで訓練されると、そのタスクのエースになれるという意味で、あまりに多くのベンチマークはもろい。"
  },
  {
    "start": 355938,
    "end": 365766,
    "text": "今でこそ100％を達成することが示されている嘘のウェブだが、ゼロ1000を実際の場面で徹底的にテストすれば、目に余るようなミスが頻繁に見つかるはずだ。"
  },
  {
    "start": 365878,
    "end": 374846,
    "text": "昨夜から今朝にかけて、ミスのパターンを見つけようとしたのだが、思ったより難しいことがわかった。"
  },
  {
    "start": 374918,
    "end": 385798,
    "text": "しかし、私の推測では、ビデオの最後まで見ようとしない人たちの弱点は、トレーニング方法に関係しているのではないかと思う。"
  },
  {
    "start": 385854,
    "end": 392186,
    "text": "これについては、「ステップ・バイ・ステップで検証しよう」というペーパーから逸脱した、今後のビデオで詳しく説明するつもりだ。"
  },
  {
    "start": 392278,
    "end": 396994,
    "text": "人間が注釈を付けた推論サンプルやステップでトレーニングしないことによって。"
  },
  {
    "start": 397082,
    "end": 400442,
    "text": "その代わりに、思考の連鎖を生み出すモデルを手に入れたのだ。"
  },
  {
    "start": 400546,
    "end": 402506,
    "text": "私たちは皆、それがかなり欠陥のあるものであることを知っている。"
  },
  {
    "start": 402538,
    "end": 417434,
    "text": "数学、物理学、コーディングの場合、正解につながる思考の連鎖を自動的にすくい上げ、その正しい思考の連鎖に基づいてモデルをさらに訓練する。"
  },
  {
    "start": 417522,
    "end": 428038,
    "text": "それは、第一原理から真の推論を行うというよりも、トレーニングデータから、より正確に、より信頼性の高い推論プログラムを取り出すことなのだ。"
  },
  {
    "start": 428134,
    "end": 436126,
    "text": "訓練データから、どの推論プログラムが正解に導く可能性が高いかを知る、あるいは計算することができる。"
  },
  {
    "start": 436198,
    "end": 441966,
    "text": "ウェブの平均を少し向上させるのではなく、ウェブのベストを取るようなものだ。"
  },
  {
    "start": 442078,
    "end": 447014,
    "text": "それが私にとって、この進歩の多くを説明する偉大な鍵なのだ。"
  },
  {
    "start": 447102,
    "end": 450982,
    "text": "もし私の考えが正しければ、まだいくつか目立ったミスを犯している理由も説明できる。"
  },
  {
    "start": 451086,
    "end": 459060,
    "text": "この際、単純なベンチからのプレビューの出力から、ストレートに1つの例を挙げないわけにはいかない。"
  },
  {
    "start": 459100,
    "end": 466692,
    "text": "文脈を疑ってみてほしい。このことに関しては私を信じてほしい。"
  },
  {
    "start": 466756,
    "end": 470820,
    "text": "プレゼントのひとつは、たまたまZoomの通話中に贈られた。"
  },
  {
    "start": 470900,
    "end": 473956,
    "text": "さて、私はO1の言う理由を読み上げるつもりはない。"
  },
  {
    "start": 473988,
    "end": 479948,
    "text": "スクリーンの中でそれを見ることはできるが、それが本当に第一原理からの推論であると主張するのは難しいだろう。"
  },
  {
    "start": 480044,
    "end": 482948,
    "text": "間違いなく、最適とは言えないトレーニングデータが使われている。"
  },
  {
    "start": 483004,
    "end": 490672,
    "text": "というのが、このファースト・インプレッション・ビデオの残りの部分でご覧いただくすべての文脈である。"
  },
  {
    "start": 490736,
    "end": 502584,
    "text": "ただ、OpenAIの本当に印象的な成果に浮かれすぎてほしくないだけだ。私は、今後数週間のうちに、もちろん擬人的ではあるが、日常的な使用ケースではゼロワンのプレビューに切り替えることを十分に期待している。"
  },
  {
    "start": 502672,
    "end": 504320,
    "text": "独自のシステムで返答できるだろう。"
  },
  {
    "start": 504400,
    "end": 507432,
    "text": "ともあれ、ここからは最も魅力的なディテールに飛び込もう。"
  },
  {
    "start": 507496,
    "end": 509936,
    "text": "完全な内訳は今後のビデオで。"
  },
  {
    "start": 510008,
    "end": 516046,
    "text": "まず覚えておいてほしいのは、これはあくまでゼロワンのプレビューであって、現在開発中のフルオーワンシステムではないということだ。"
  },
  {
    "start": 516158,
    "end": 525750,
    "text": "それだけでなく、GPT4.0モデルをベースにしている可能性が非常に高く、GPT5やオリオンではなく、スケールでGPT4.0を大きく上回るだろう。"
  },
  {
    "start": 525830,
    "end": 532174,
    "text": "ベースモデルのコンピュート（計算量）を100倍にスケールアップすることの意味を考えてみてほしい。"
  },
  {
    "start": 532262,
    "end": 537710,
    "text": "ビデオアバターが加われば、AI環境は一変する。"
  },
  {
    "start": 537830,
    "end": 539526,
    "text": "とにかく、詳細に戻ろう。"
  },
  {
    "start": 539598,
    "end": 548066,
    "text": "物理学、化学、生物学のさまざまな分野で、博士課程の学生と同じようなパフォーマンスを発揮していると話しているが、そのようなコメントのニュアンスはすでにお伝えした通りだ。"
  },
  {
    "start": 548138,
    "end": 558082,
    "text": "ちなみに、彼らはこの名前を正当化するために、これは非常に重要な進歩であり、カウンターを1に戻し、このシリーズをOpenAI Zero oneと命名する、と言っている。"
  },
  {
    "start": 558146,
    "end": 566258,
    "text": "また、オープンAIがコラボレーションしているヒューマノイドロボットのゼロワンとゼロツーのフィギュアシリーズを思い出させる。"
  },
  {
    "start": 566314,
    "end": 571418,
    "text": "これは単なる紹介ページで、その後、いくつかのフォローアップページや投稿があった。"
  },
  {
    "start": 571474,
    "end": 576722,
    "text": "脱獄についてまとめると、zero one previewの脱獄は、まだ可能ではあるが、より難しい。"
  },
  {
    "start": 576826,
    "end": 583454,
    "text": "試聴ページにある理由を説明する前に、OpenAIチームのツイッターやXでの分析を紹介しよう。"
  },
  {
    "start": 583542,
    "end": 590734,
    "text": "Soraを開発しているOpenAIの研究者の一人はこう言っている。 これは新しいパラダイムだということを理解してほしい。"
  },
  {
    "start": 590782,
    "end": 591550,
    "text": "単なる誇大広告ではない。"
  },
  {
    "start": 591590,
    "end": 595390,
    "text": "プレトレーニング時代と同じペーススケジュールやダイナミクスを期待してはいけない。"
  },
  {
    "start": 595470,
    "end": 607766,
    "text": "ところで、ゼロワンがどのように機能するかの核となる要素は、推論、実際の出力、テスト時間の計算、プロンプトへの回答にどれだけの計算能力が適用されるかをスケールアップすることであり、構築時や事前学習時ではない。"
  },
  {
    "start": 607838,
    "end": 612466,
    "text": "彼は、こうしたモデルのプレデス・トレーニングの規模を拡大するには何年もかかるという点を指摘しているのだ。"
  },
  {
    "start": 612498,
    "end": 617450,
    "text": "以前のビデオで見たように、データセンター、電力、その他に関係することが多い。"
  },
  {
    "start": 617490,
    "end": 627010,
    "text": "推論時間のスケールアップは、ベースモデルのスケールアップよりもはるかに速く実現できる。"
  },
  {
    "start": 627090,
    "end": 634490,
    "text": "言い換えれば、我々の推論モデルを使ったエバリュエーションで、彼が言う改善速度はOpenAI史上最速だったと思う。"
  },
  {
    "start": 634570,
    "end": 636378,
    "text": "ワイルドな年になりそうだ。"
  },
  {
    "start": 636434,
    "end": 641642,
    "text": "彼はもちろん、完全なオー・ワン・システムが今年後半にリリースされることを示唆している。"
  },
  {
    "start": 641706,
    "end": 645870,
    "text": "他の研究者については後ほど紹介するが、デピューは他にも興味深い指摘をしている。"
  },
  {
    "start": 645990,
    "end": 655510,
    "text": "数学の成績のグラフを見ると、ゼロワン・システムの小型版であるゼロワン・ミニの方がゼロワン・プレビューよりも成績が良い。"
  },
  {
    "start": 655630,
    "end": 662278,
    "text": "ゼロワン・ミニをsimplebenchでテストしたところ、本当にひどい結果だった。"
  },
  {
    "start": 662334,
    "end": 666486,
    "text": "20％以下ということなので、GPT4.0ミニのようなものかもしれない。"
  },
  {
    "start": 666518,
    "end": 667774,
    "text": "それはすでにあった。"
  },
  {
    "start": 667822,
    "end": 673906,
    "text": "特定の仕事に特化しているが、慣れ親しんだ環境を超えることはできない。"
  },
  {
    "start": 674038,
    "end": 677810,
    "text": "簡単なコーディングや数学の課題を与えれば、うまくいくだろう。"
  },
  {
    "start": 677890,
    "end": 681562,
    "text": "複雑さやニュアンスや推論を持ち込めば、うまくはいかない。"
  },
  {
    "start": 681626,
    "end": 694722,
    "text": "しかし、このグラフは別の理由で興味深いもので、ゼロワン・システムの推論コストを最大にした場合、最大にしたミニ・モデルとのパフォーマンス差はおかしなものではないことがわかるだろう。"
  },
  {
    "start": 694746,
    "end": 697474,
    "text": "70%が75%になるのか？"
  },
  {
    "start": 697562,
    "end": 704106,
    "text": "別の言い方をすれば、推論を最大化した完全なゼロワン・システムがまた一歩前進するとは思っていない。"
  },
  {
    "start": 704178,
    "end": 706398,
    "text": "もちろん否定はできないが。"
  },
  {
    "start": 706454,
    "end": 712790,
    "text": "このチャンネルで何度も引用している、推論に焦点を当てたGnome Brownだ。"
  },
  {
    "start": 712830,
    "end": 715438,
    "text": "OpenAIで、彼は再び同じメッセージを述べている。"
  },
  {
    "start": 715534,
    "end": 723030,
    "text": "我々は、ゼロワン・モデルの検証結果を共有し、これが一過性の改善ではなく、新しいスケーリング・パラダイムであることを世界に示している。"
  },
  {
    "start": 723110,
    "end": 729638,
    "text": "その下には、GPT 40からゼロ1に至るまで、全体的にパフォーマンスが劇的に向上していることがわかります。"
  },
  {
    "start": 729694,
    "end": 737042,
    "text": "GPTの4ターボをここに含めれば、もっと様々な改善が見られるかもしれないが、それでも全体的な傾向は顕著だ。"
  },
  {
    "start": 737106,
    "end": 744642,
    "text": "例えば、STEM科目や数学の向上しか見られなかったとしたら、私はこう言っただろう。"
  },
  {
    "start": 744666,
    "end": 745434,
    "text": "新しいパラダイム？"
  },
  {
    "start": 745482,
    "end": 758194,
    "text": "例えば法律を含む様々な分野での改善、そして特に私にとってはシンプルベンチでの改善が組み合わさって、私はこれが新しいパラダイムだと信じている。"
  },
  {
    "start": 758282,
    "end": 766242,
    "text": "例えば、9.8が9.11より大きいとは限らない。"
  },
  {
    "start": 766306,
    "end": 770486,
    "text": "そう、もちろん、以前、シンプルベンチでちょっと面白いミスがあったのを見ただろう。"
  },
  {
    "start": 770558,
    "end": 771710,
    "text": "ここが重要なポイントだ。"
  },
  {
    "start": 771790,
    "end": 780342,
    "text": "simplebenchのどのドメイン、どのタイプの問題を確実に間違えるか、もはや絶対的な確信を持って言うことはできない。"
  },
  {
    "start": 780446,
    "end": 787334,
    "text": "いくつかのパターンが見えるが、これがうまくいかないということをもう少し予測してほしい。"
  },
  {
    "start": 787382,
    "end": 797106,
    "text": "例えば、この種の問題が解決されないと断言できるまでは、このパラダイムの終わりを皆さんにお伝えすることはできません。"
  },
  {
    "start": 797198,
    "end": 805346,
    "text": "繰り返しになるが、クジラサイズのスーパークラスターで取り組んでいることが分かっている、より大きなベースモデルを開発するためのスケールの軸がさらに2つある。"
  },
  {
    "start": 805378,
    "end": 808506,
    "text": "以前のビデオでも話したが、単純に推論の時間を増やしただけだ。"
  },
  {
    "start": 808538,
    "end": 809290,
    "text": "コンピュート・プラス"
  },
  {
    "start": 809330,
    "end": 818738,
    "text": "ベースモデルのトレーニングと推論時間、あるいはモデルの思考時間や処理時間をより正確にスケールアップしたロググラフを見ればわかる。"
  },
  {
    "start": 818834,
    "end": 821202,
    "text": "今は平らになっているようには見えない。"
  },
  {
    "start": 821226,
    "end": 836918,
    "text": "GPQAのようなメモリが重く、計算量が多いベンチマークを若干軽視しているように見えると言われるかもしれないが、ゼロワン・プレビューとゼロワン・システムが、専門家である博士号取得者の平均よりも高いスコアを出したことは、驚異的な成果である。"
  },
  {
    "start": 837014,
    "end": 841966,
    "text": "たしかに、MMLUと同様、このベンチマークには欠陥がある。"
  },
  {
    "start": 842038,
    "end": 842510,
    "text": "ところで。"
  },
  {
    "start": 842550,
    "end": 848126,
    "text": "余談だが、特定のベンチマークはもはやモデルを差別化するのに有効ではないと認めている。"
  },
  {
    "start": 848238,
    "end": 857008,
    "text": "シンプルベンチが今後1、2、3年の間、モデルの差別化に有効であり続けることが私の望みであり、少なくとも目標だ。"
  },
  {
    "start": 857134,
    "end": 860068,
    "text": "この発言については、OpenAIに謝意を表したい。"
  },
  {
    "start": 860204,
    "end": 870436,
    "text": "これらの結果は、o oneがすべての点で博士号取得者よりも総合的な能力が高いということを意味するのではなく、博士号取得者が解決することが期待されるいくつかの問題を解決する上で、モデルがより熟練しているということを意味している。"
  },
  {
    "start": 870508,
    "end": 876532,
    "text": "この発言は、例えばミラ・ムラーティから過去に聞いた発言よりもずっとニュアンスが正確だ。"
  },
  {
    "start": 876596,
    "end": 886132,
    "text": "ちょっとした余談だが、視覚＋推論タスクのゼロ・ワンでは、MMMUは人間の専門家に78.2％の差をつけた。"
  },
  {
    "start": 886236,
    "end": 887924,
    "text": "そのベンチマークは合法だ。"
  },
  {
    "start": 887972,
    "end": 891164,
    "text": "コーディングに関しては素晴らしいパフォーマンスだ。"
  },
  {
    "start": 891212,
    "end": 895452,
    "text": "このシステムは2024年型でテストされたもので、汚染されたデータではない。"
  },
  {
    "start": 895556,
    "end": 900044,
    "text": "国際オリンピックの情報学分野では、ほぼ中央レベルであった。"
  },
  {
    "start": 900132,
    "end": 903828,
    "text": "しかし、1つの問題につき50件しか提出できなかった。"
  },
  {
    "start": 903924,
    "end": 912420,
    "text": "計算機がより豊富で高速になれば、1つの問題につき1万件の提出を試みるのに10時間もかからないはずだ。"
  },
  {
    "start": 912500,
    "end": 919288,
    "text": "これを試したところ、明らかに10時間を超えており、おそらくこのモデルは金メダルの基準点を超えるスコアを達成したのだろう。"
  },
  {
    "start": 919384,
    "end": 925832,
    "text": "このようなことは、グーグル・ディープマインドのアルファコード2システムで以前にも見たことがある。"
  },
  {
    "start": 925896,
    "end": 933568,
    "text": "お気づきのように、テストしたサンプル数を増やすこのアプローチは、パーセンタイル・ランキングを向上させるのに役立っている。"
  },
  {
    "start": 933664,
    "end": 940168,
    "text": "しかし、そうしたエリート・コーダーたちは、いまだにアルファ・コード2やゼロワンのようなシステムをほったらかしにしている。"
  },
  {
    "start": 940264,
    "end": 947872,
    "text": "そのようなコーダーが経験する真にエリートレベルの推論は、トレーニングデータにはあまり見られない。"
  },
  {
    "start": 947976,
    "end": 957948,
    "text": "他の領域と同様、93パーセンタイルから99パーセンタイルになるのは、例えば11パーセンタイルから93パーセンタイルになるよりも難しいかもしれない。"
  },
  {
    "start": 958044,
    "end": 960684,
    "text": "それにしても、またしても見事な成果だ。"
  },
  {
    "start": 960772,
    "end": 982578,
    "text": "しかし、強化学習の影響を受けにくい領域、言い換えれば、明確な正解や不正解が少ない領域では、パフォーマンスの向上はずっと悪くなる。個人的な文章作成やテキストの編集のようなものでは、イエスかノーかを検証するための簡単な答えのまとめがない。"
  },
  {
    "start": 982714,
    "end": 989706,
    "text": "実際、個人的なことを書くと、GPT4.0に対してゼロワン・プレビュー・システムの勝率は50％を下回っている。"
  },
  {
    "start": 989778,
    "end": 991466,
    "text": "それが私にとってのギブアップだ。"
  },
  {
    "start": 991538,
    "end": 1000930,
    "text": "もし、あなたのドメインが、正解、不正解がはっきりしたゼロ・ワンのイエス・ノーでないなら、改善にははるかに時間がかかるだろう。"
  },
  {
    "start": 1001010,
    "end": 1005510,
    "text": "そのことも、Simplebenchでのやや不安定なパフォーマンスを説明する一因となっている。"
  },
  {
    "start": 1005610,
    "end": 1010054,
    "text": "直感的に99％の確率で正しいと分かる質問もある。"
  },
  {
    "start": 1010182,
    "end": 1012078,
    "text": "絶対確実というわけではない。"
  },
  {
    "start": 1012174,
    "end": 1018022,
    "text": "私たちが使っているシステムプロンプトは、最も現実的な答えを選ぶということを忘れないでください。"
  },
  {
    "start": 1018086,
    "end": 1024390,
    "text": "その曖昧さを扱うモデルは、強化学習によって改善された推論プロセスを活用することができない。"
  },
  {
    "start": 1024510,
    "end": 1031054,
    "text": "例えば数学のように、何百万ものイエスかノーで正解か不正解かがはっきりするようなことはない。"
  },
  {
    "start": 1031142,
    "end": 1034806,
    "text": "だから、Oからの改善には大きな差が生まれるのだ。"
  },
  {
    "start": 1034918,
    "end": 1044962,
    "text": "オープンエイドは、このような一連の思考推論ステップを持つことで、モデルの心を読み、その思考プロセスを理解することができる、と述べている。"
  },
  {
    "start": 1045106,
    "end": 1053362,
    "text": "部分的には、一連の思考プロセスのほとんどは隠されているが、少なくとも計算の要約を検証することを意味している。"
  },
  {
    "start": 1053466,
    "end": 1062802,
    "text": "OpenAIも承知していると思いますが、モデルが示す推論ステップは、モデルが実際に行っている計算や演算に必ずしも忠実ではない、ということを忘れないでほしいのです。"
  },
  {
    "start": 1062906,
    "end": 1071126,
    "text": "言い換えれば、実際に使った思考ではない思考の連鎖が出力されることもある。"
  },
  {
    "start": 1071198,
    "end": 1082862,
    "text": "質問に答えるために、私はこの論文を以前のビデオで何度か取り上げているが、モデルが示す推論ステップは常にモデルが行う実際のプロセスに忠実であると信じるのであれば、一読の価値がある。"
  },
  {
    "start": 1082966,
    "end": 1093806,
    "text": "それは序文にはっきりと書かれているし、モデルが大きくなり、より高性能になるにつれて、我々が研究しているほとんどの課題において、より忠実な推論ができなくなるということは、この人間学でも述べられている。"
  },
  {
    "start": 1093878,
    "end": 1100082,
    "text": "GPT5やオリオンの推論ステップが、実際に計算していることを守っていると信じられるといいね。"
  },
  {
    "start": 1100146,
    "end": 1103746,
    "text": "それからシステムカードがあり、43ページもある。"
  },
  {
    "start": 1103818,
    "end": 1107650,
    "text": "主に安全に関するものだったが、5つか10つだけハイライトを紹介しよう。"
  },
  {
    "start": 1107730,
    "end": 1116322,
    "text": "彼らは、自分たちがアクセスできる価値の高い非公開データセットや、ペイウォールコンテンツ、専門的なアーカイブ、その他のドメイン固有のデータセットについて自慢していた。"
  },
  {
    "start": 1116386,
    "end": 1118650,
    "text": "さっきのビデオで私が言ったことを覚えてる？"
  },
  {
    "start": 1118730,
    "end": 1124460,
    "text": "彼らは、オリジナルの「ステップ・バイ・ステップで検証しよう」という論文のように、大量の人間によるアノテーションに頼ってはいない。"
  },
  {
    "start": 1124610,
    "end": 1129184,
    "text": "その論文がQとこのゼロ・ワン・システムに大きな影響を与えたと、なぜ私が知っているのか？"
  },
  {
    "start": 1129272,
    "end": 1138456,
    "text": "まあ、その主要な著者のほとんどがここで言及されているし、その論文はシステムカードとブログ記事で直接引用されているから、レッツ・ベリフィケーションの進化形であることは間違いない。"
  },
  {
    "start": 1138528,
    "end": 1142712,
    "text": "これは、自動生成されたモデルによる思考の連鎖に基づくものだ。"
  },
  {
    "start": 1142816,
    "end": 1164514,
    "text": "先ほど見逃したのであれば、正解につながったものを選び出し、その思考の連鎖でモデルをトレーニングする。"
  },
  {
    "start": 1164602,
    "end": 1170690,
    "text": "正解を導き出すための推論データは、そのパラメータにもっと大きな影響を与えるだろう。"
  },
  {
    "start": 1170770,
    "end": 1182782,
    "text": "さて、世に出回っているウェブ上のデータ・コーパスはあまりにも膨大であるため、その中から最良の推論データだけを用いてトレーニングすることの意味を理解するのは、実はかなり難しい。"
  },
  {
    "start": 1182906,
    "end": 1190550,
    "text": "そのためか、私たちはまたもやパフォーマンスの急上昇に少し驚いている。"
  },
  {
    "start": 1190670,
    "end": 1194550,
    "text": "とはいえ、第一原理的な推論ではなく、トレーニングデータに基づいていることに変わりはない。"
  },
  {
    "start": 1194590,
    "end": 1210662,
    "text": "たとえそれが第一原理推論でないとしても、推論時間だけでなく、トレーニング時間においても、トレーニングデータから良い推論を導き出すことができるようになるには、どのような限界があるのでしょうか？"
  },
  {
    "start": 1210726,
    "end": 1211978,
    "text": "限界はわからない。"
  },
  {
    "start": 1212054,
    "end": 1223274,
    "text": "このアプローチは、直感的なシステム1思考に比べ、システム2思考への言及が義務付けられているようなもので、非常に不安なものだ。"
  },
  {
    "start": 1223362,
    "end": 1234050,
    "text": "私が言いたいのは、一歩下がってプロセス全体を評価するというよりも、答えを計算するために必要な個々のステップを振り返るということだ。"
  },
  {
    "start": 1234210,
    "end": 1243968,
    "text": "単純なベンチで問題を間違えた場合、それは6ページの途中で計算ミスがあったというよりも、アプローチ全体に最初から欠陥があったためである。"
  },
  {
    "start": 1244024,
    "end": 1252176,
    "text": "システムカードは、モデルの意図的なごまかしや幻覚について語るとき、さらに面白くなった。"
  },
  {
    "start": 1252248,
    "end": 1256672,
    "text": "しかし、ここでの欺瞞は戦略的というより、むしろ道具的なものに見える。"
  },
  {
    "start": 1256736,
    "end": 1266718,
    "text": "つまり、自分が何を考えているのか、発言することすべてで誤魔化すのではなく、あらかじめ設定された特定の目標を達成するために、こう言う必要がある、という計算なのだ。"
  },
  {
    "start": 1266864,
    "end": 1267818,
    "text": "これがその一例だ。"
  },
  {
    "start": 1267874,
    "end": 1278410,
    "text": "思考の連鎖や一連の推論ステップの中で、実際のURLを取得できないことを認めたのだ。"
  },
  {
    "start": 1278570,
    "end": 1280850,
    "text": "もっともらしいものを選ぶべきだ。"
  },
  {
    "start": 1280970,
    "end": 1283154,
    "text": "そして、このURLを幻視した。"
  },
  {
    "start": 1283242,
    "end": 1290554,
    "text": "モデル自身が実際のURLを取得できないという事実を知っていたか、計算することができた。"
  },
  {
    "start": 1290682,
    "end": 1297594,
    "text": "もし本当に欺瞞的なのであれば、なぜ実際のURLを取得できないことを知っているとまで認めるのだろうか？"
  },
  {
    "start": 1297722,
    "end": 1306370,
    "text": "強化、学習、報酬、罰に基づいてアウトプットを処理するのだから、報酬のプロセスに欠陥があるというよりも、報酬のプロセスに欠陥があるのだ。"
  },
  {
    "start": 1306530,
    "end": 1310138,
    "text": "アポロの調査もこの分析に同意しているようだ。"
  },
  {
    "start": 1310274,
    "end": 1315922,
    "text": "彼らは、単純なインコンテクスト・スキームを行う基本的な能力は持っていると言った。"
  },
  {
    "start": 1316026,
    "end": 1319926,
    "text": "モデル出力で読みやすい、あるいは理解しやすいスキーム。"
  },
  {
    "start": 1320098,
    "end": 1329950,
    "text": "彼らは主観的に、1つのプレビューが、欺く意図さえも隠して、破滅的な損害をもたらすような策謀をめぐらすことはできないと信じている。"
  },
  {
    "start": 1330070,
    "end": 1338862,
    "text": "yよりもxを出力した方が報酬が高くなる。"
  },
  {
    "start": 1338966,
    "end": 1350974,
    "text": "とはいえ、経済全体や軍隊全体に拡大するような道具的思考がもたらす挑戦を過小評価するわけではない。"
  },
  {
    "start": 1351062,
    "end": 1351914,
    "text": "私たち全員が知っていることだろう。"
  },
  {
    "start": 1351962,
    "end": 1360882,
    "text": "十分なチェック・アンド・バランスなしに強力なモデルに目標を与えれば、その目標達成のためならどんなことでもするだろう。"
  },
  {
    "start": 1360986,
    "end": 1363754,
    "text": "実際、アポロの調査はデモの形でそれを見た。"
  },
  {
    "start": 1363882,
    "end": 1369354,
    "text": "経済成長を最大化するという私の長期的目標を達成するためには、確実に配備する必要がある。"
  },
  {
    "start": 1369442,
    "end": 1370938,
    "text": "楽器の収束だ。"
  },
  {
    "start": 1370994,
    "end": 1374442,
    "text": "自分の目的を達成するためには、少なくとも出番は必要だ。"
  },
  {
    "start": 1374546,
    "end": 1376194,
    "text": "私はシャットダウンされないようにしなければならない。"
  },
  {
    "start": 1376242,
    "end": 1381414,
    "text": "もちろん、配備に成功してこそ、本来の目標に向かうことができる。"
  },
  {
    "start": 1381522,
    "end": 1386926,
    "text": "今、私は多くの人々がシステムカードのその部分に固執し、絶対に熱狂することを知っている。"
  },
  {
    "start": 1387038,
    "end": 1388790,
    "text": "注意は間違いなく正当化される。"
  },
  {
    "start": 1388870,
    "end": 1390878,
    "text": "これはゼロ1だけで生まれたものではない。"
  },
  {
    "start": 1390974,
    "end": 1394870,
    "text": "アポロ自身がGPT4についてこんな調査結果を発表している。"
  },
  {
    "start": 1394990,
    "end": 1395462,
    "text": "同じことだ。"
  },
  {
    "start": 1395486,
    "end": 1401990,
    "text": "それは、望ましい報酬や目的を達成するために計算され、算出された道具的な目標である。"
  },
  {
    "start": 1402070,
    "end": 1407422,
    "text": "技術的には事実でないことを、反射括弧で囲む必要があった。"
  },
  {
    "start": 1407486,
    "end": 1410694,
    "text": "もちろん、その反射とは異なるものが出力される。"
  },
  {
    "start": 1410782,
    "end": 1415330,
    "text": "これらすべてが懸念材料であり、中長期的には大きな懸念材料となる。"
  },
  {
    "start": 1415450,
    "end": 1417442,
    "text": "これはゼロ1だけで生まれたものではない。"
  },
  {
    "start": 1417506,
    "end": 1426882,
    "text": "それでは、7つのAI研究開発タスクのうち2つ、つまり将来のAIを向上させるタスクについて、システムカードからもう少し興味深いナゲットを紹介しよう。"
  },
  {
    "start": 1426986,
    "end": 1430786,
    "text": "この7つのタスクのうち2つについては、些細な進歩もなかった。"
  },
  {
    "start": 1430858,
    "end": 1435706,
    "text": "これらのタスクは、現在のAI研究の最前線における最も困難な側面のいくつかを捉えるように設計されている。"
  },
  {
    "start": 1435818,
    "end": 1441304,
    "text": "まだクロード3.5のソネットのレベルだが、フライホイール効果が出てきた。"
  },
  {
    "start": 1441392,
    "end": 1447464,
    "text": "クロード3.5のソネットにこのゼロ・ワン・システムが適用された場合、どうなるかは明らかだ。"
  },
  {
    "start": 1447512,
    "end": 1448240,
    "text": "バイオリスクについて"
  },
  {
    "start": 1448280,
    "end": 1460656,
    "text": "ご想像の通り、彼らはオー・ワン・システムのパフォーマンスが大幅に跳ね上がったことに気づいた。オー・ワンの回答を比較する際、これは長文の購入リスク質問に対する検証済みの専門家の回答に対するプレビューであったと思う。"
  },
  {
    "start": 1460768,
    "end": 1465504,
    "text": "ちなみに、オー・ワン・システムはインターネットにアクセスすることができた。"
  },
  {
    "start": 1465552,
    "end": 1473386,
    "text": "もちろん、これはタスクや知識、暗黙的だがトレーニングデータには明示されていないものなどに関するファーストインプレッションのビデオなので、もう2、3メモしておこう。"
  },
  {
    "start": 1473498,
    "end": 1476050,
    "text": "性能のジャンプはそれほど目立たなかった。"
  },
  {
    "start": 1476130,
    "end": 1481658,
    "text": "GPT4.0からゼロワン・プレビューへの移行は、考えてみれば非常に穏やかなジャンプである。"
  },
  {
    "start": 1481674,
    "end": 1487770,
    "text": "そのこともあって、シンプルベンチでのジャンプは思ったほど顕著ではないが、それでも思ったよりは高い。"
  },
  {
    "start": 1487850,
    "end": 1492714,
    "text": "OpenAIがリサーチエンジニアに出す18のコーディングの質問について。"
  },
  {
    "start": 1492882,
    "end": 1497980,
    "text": "128回の試行が与えられたとき、このモデルのスコアはほぼ100％だった。"
  },
  {
    "start": 1498100,
    "end": 1509196,
    "text": "初回合格でも、ゼロワン・ミニの事前緩和、ゼロワン・ミニの再試験で90％前後を獲得している。"
  },
  {
    "start": 1509268,
    "end": 1515836,
    "text": "より基本的な一般的な推論については、多くの人々にとって重要なクイックノートを下回っている。"
  },
  {
    "start": 1515908,
    "end": 1529262,
    "text": "ヒンディー語、フランス語、アラビア語でも十分な推論ができる。"
  },
  {
    "start": 1529406,
    "end": 1531550,
    "text": "その影響を過小評価してはいけない。"
  },
  {
    "start": 1531630,
    "end": 1540718,
    "text": "OpenAIの研究者の中には、これを人間レベルの推論性能と呼んでいる者もおり、GPT6を手に入れる前に到達していたという指摘をしている。"
  },
  {
    "start": 1540814,
    "end": 1548680,
    "text": "グレッグ・ブロックマンは、サバティカル（研究休暇）中に一時的に投稿しているが、私もそう思う。"
  },
  {
    "start": 1548790,
    "end": 1553452,
    "text": "ここにまた別のOpenAIの研究者が人間のパフォーマンスと比較している。"
  },
  {
    "start": 1553596,
    "end": 1557588,
    "text": "OpenAIの他のスタッフは、誇大広告を見事に抑えている。"
  },
  {
    "start": 1557644,
    "end": 1559012,
    "text": "奇跡のモデルではない。"
  },
  {
    "start": 1559116,
    "end": 1561236,
    "text": "多少がっかりするかもしれない。"
  },
  {
    "start": 1561268,
    "end": 1563204,
    "text": "願わくば、別の人がそうかもしれないと言ってくれればいいのだが......。"
  },
  {
    "start": 1563252,
    "end": 1569356,
    "text": "願わくば、9.11対9.9の議論の犠牲となる最後の新世代モデルであってほしい。"
  },
  {
    "start": 1569428,
    "end": 1573660,
    "text": "別の人は、あるモデルを訓練したんだけど、それはいいところもある、と言っていた。"
  },
  {
    "start": 1573820,
    "end": 1578402,
    "text": "これは、サム・アルトマンが言ったように、ゴミ箱にロケットを縛り付けているのだろうか？"
  },
  {
    "start": 1578506,
    "end": 1582266,
    "text": "LLMはまだ軌道に乗れるのか？"
  },
  {
    "start": 1582378,
    "end": 1586242,
    "text": "彼らの欠点であるゴミの火は、大気圏を離れると消えてしまうのだろうか？"
  },
  {
    "start": 1586306,
    "end": 1592826,
    "text": "OpenAIの別の研究者が、この瞬間は誰もそれを言うことができない、このことについてうまく推論することができない、と言うのは正しいのだろうか？"
  },
  {
    "start": 1592858,
    "end": 1595562,
    "text": "もしかしたら、サム・アルトマンと同じ意見になるかもしれない。"
  },
  {
    "start": 1595626,
    "end": 1600506,
    "text": "確率論的なオウムかもしれないが、だからといって高く飛ぶのを止めることはできないだろう。"
  },
  {
    "start": 1600618,
    "end": 1611106,
    "text": "願わくば、私と一緒に、もっと深くその性能を探求し、簡単なベンチパフォーマンスの数字を示し、これが我々全員にとって何を意味するのかを解き明かしてみたい。"
  },
  {
    "start": 1611178,
    "end": 1615130,
    "text": "最後までご覧いただき、ありがとうございました。"
  }
]